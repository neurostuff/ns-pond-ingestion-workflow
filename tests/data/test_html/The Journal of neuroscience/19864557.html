<html lang="en" dir="ltr" xmlns="http://www.w3.org/1999/xhtml" xmlns:mml="http://www.w3.org/1998/Math/MathML" class="modernizr-svg modernizr-mutationobserver modernizr-localstorage modernizr-inlinesvg modernizr-svgclippaths modernizr-matchmedia modernizr-flexbox js"><head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# book: http://ogp.me/ns/book#"><script async="" src="https://sn.ecommerce.highwire.org/cart?cart=get&amp;callback=jQuery18208262146943546453_1717583159153&amp;output=json&amp;_=1717583160519"></script><script type="text/javascript" async="" src="https://www.googletagmanager.com/gtag/js?id=G-G5TCNFJCYP&amp;l=dataLayer&amp;cx=c"></script><script src="https://apis.google.com/_/scs/abc-static/_/js/k=gapi.lb.en.6jI6mC1Equ4.O/m=auth/exm=plusone/rt=j/sv=1/d=1/ed=1/am=AAAQ/rs=AHpOoo-79kMK-M6Si-J0E_6fI_9RBHBrwQ/cb=gapi.loaded_1?le=scs" async=""></script><script src="https://apis.google.com/_/scs/abc-static/_/js/k=gapi.lb.en.6jI6mC1Equ4.O/m=plusone/rt=j/sv=1/d=1/ed=1/am=AAAQ/rs=AHpOoo-79kMK-M6Si-J0E_6fI_9RBHBrwQ/cb=gapi.loaded_0?le=scs" async=""></script><script type="text/javascript" async="" src="https://www.googletagmanager.com/gtag/js?id=G-FL7DMQSCNT&amp;l=dataLayer&amp;cx=c"></script><script src="https://pagead2.googlesyndication.com/tag/js/gpt.js" async=""></script><meta http-equiv="origin-trial" content="Az520Inasey3TAyqLyojQa8MnmCALSEU29yQFW8dePZ7xQTvSt73pHazLFTK5f7SyLUJSo2uKLesEtEa9aUYcgMAAACPeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZS5jb206NDQzIiwiZmVhdHVyZSI6IkRpc2FibGVUaGlyZFBhcnR5U3RvcmFnZVBhcnRpdGlvbmluZyIsImV4cGlyeSI6MTcyNTQwNzk5OSwiaXNTdWJkb21haW4iOnRydWUsImlzVGhpcmRQYXJ0eSI6dHJ1ZX0=">
    <!--[if IE]><![endif]-->
<link rel="dns-prefetch" href="//www.googleadservices.com">
<link rel="dns-prefetch" href="//cdn.pbgrd.com">
<link rel="dns-prefetch" href="//cdn.jsdelivr.net">
<link rel="dns-prefetch" href="//www.google.com">
<link rel="dns-prefetch" href="//cdn.foxycart.com">
<link rel="dns-prefetch" href="//scholar.google.com">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="shortlink" href="/node/370480">
<meta name="Generator" content="Drupal 7 (http://drupal.org)">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="issue_cover_image" content="https://www.jneurosci.org/sites/default/files/highwire/jneuro/29/43.cover.gif">
<meta name="type" content="article">
<meta name="category" content="research-article">
<meta name="HW.identifier" content="/jneuro/29/43/13445.atom">
<meta name="HW.pisa" content="jneuro;29/43/13445">
<meta name="DC.Format" content="text/html">
<meta name="DC.Language" content="en">
<meta name="DC.Title" content="Dual Neural Routing of Visual Facilitation in Speech Processing">
<meta name="DC.Identifier" content="10.1523/JNEUROSCI.3194-09.2009">
<meta name="DC.Date" content="2009-10-28">
<meta name="DC.Publisher" content="Society for Neuroscience">
<meta name="DC.Rights" content="Copyright © 2009 Society for Neuroscience 0270-6474/09/2913445-09$15.00/0">
<meta name="DC.AccessRights" content="restricted">
<meta name="DC.Description" content="Viewing our interlocutor facilitates speech perception, unlike for instance when we telephone. Several neural routes and mechanisms could account for this phenomenon. Using magnetoencephalography, we show that when seeing the interlocutor, latencies of auditory responses (M100) are the shorter the more predictable speech is from visual input, whether the auditory signal was congruent or not. Incongruence of auditory and visual input affected auditory responses ∼20 ms after latency shortening was detected, indicating that initial content-dependent auditory facilitation by vision is followed by a feedback signal that reflects the error between expected and received auditory input (prediction error). We then used functional magnetic resonance imaging and confirmed that distinct routes of visual information to auditory processing underlie these two functional mechanisms. Functional connectivity between visual motion and auditory areas depended on the degree of visual predictability, whereas connectivity between the superior temporal sulcus and both auditory and visual motion areas was driven by audiovisual (AV) incongruence. These results establish two distinct mechanisms by which the brain uses potentially predictive visual information to improve auditory perception. A fast direct corticocortical pathway conveys visual motion parameters to auditory cortex, and a slower and indirect feedback pathway signals the error between visual prediction and auditory input.">
<meta name="DC.Contributor" content="Luc H. Arnal">
<meta name="DC.Contributor" content="Benjamin Morillon">
<meta name="DC.Contributor" content="Christian A. Kell">
<meta name="DC.Contributor" content="Anne-Lise Giraud">
<meta name="article:published_time" content="2009-10-28">
<meta name="article:section" content="Articles">
<meta name="citation_title" content="Dual Neural Routing of Visual Facilitation in Speech Processing">
<meta name="citation_abstract" lang="en" content="<p>Viewing our interlocutor facilitates speech perception, unlike for instance when we telephone. Several neural routes and mechanisms could account for this phenomenon. Using magnetoencephalography, we show that when seeing the interlocutor, latencies of auditory responses (M100) are the shorter the more predictable speech is from visual input, whether the auditory signal was congruent or not. Incongruence of auditory and visual input affected auditory responses ∼20 ms after latency shortening was detected, indicating that initial content-dependent auditory facilitation by vision is followed by a feedback signal that reflects the error between expected and received auditory input (prediction error). We then used functional magnetic resonance imaging and confirmed that distinct routes of visual information to auditory processing underlie these two functional mechanisms. Functional connectivity between visual motion and auditory areas depended on the degree of visual predictability, whereas connectivity between the superior temporal sulcus and both auditory and visual motion areas was driven by audiovisual (AV) incongruence. These results establish two distinct mechanisms by which the brain uses potentially predictive visual information to improve auditory perception. A fast direct corticocortical pathway conveys visual motion parameters to auditory cortex, and a slower and indirect feedback pathway signals the error between visual prediction and auditory input.</p>">
<meta name="citation_journal_title" content="Journal of Neuroscience">
<meta name="citation_publisher" content="Society for Neuroscience">
<meta name="citation_publication_date" content="2009/10/28">
<meta name="citation_mjid" content="jneuro;29/43/13445">
<meta name="citation_id" content="29/43/13445">
<meta name="citation_public_url" content="https://www.jneurosci.org/content/29/43/13445">
<meta name="citation_abstract_html_url" content="https://www.jneurosci.org/content/29/43/13445.abstract">
<meta name="citation_full_html_url" content="https://www.jneurosci.org/content/29/43/13445.full">
<meta name="citation_pdf_url" content="https://www.jneurosci.org/content/jneuro/29/43/13445.full.pdf">
<meta name="citation_issn" content="0270-6474">
<meta name="citation_issn" content="1529-2401">
<meta name="citation_journal_abbrev" content="J. Neurosci.">
<meta name="citation_doi" content="10.1523/JNEUROSCI.3194-09.2009">
<meta name="citation_pmid" content="19864557">
<meta name="citation_volume" content="29">
<meta name="citation_issue" content="43">
<meta name="citation_article_type" content="Research Article">
<meta name="citation_section" content="Articles">
<meta name="citation_firstpage" content="13445">
<meta name="citation_lastpage" content="13453">
<meta name="citation_author" content="Luc H. Arnal">
<meta name="citation_author" content="Benjamin Morillon">
<meta name="citation_author" content="Christian A. Kell">
<meta name="citation_author" content="Anne-Lise Giraud">
<meta name="citation_reference" content="citation_journal_title=Journal of Cognitive Neuroscience;citation_journal_abbrev=J. Cogn. Neurosci.;citation_author=NE. Barraclough;citation_author=D. Xiao;citation_author=CI. Baker;citation_author=MW. Oram;citation_author=DI. Perrett;citation_title=Integration of Visual and Auditory Information by Superior Temporal Sulcus Neurons Responsive to the Sight of Actions;citation_pages=377-391;citation_volume=17;citation_year=2005;citation_issue=3;citation_issn=0898-929X;citation_pmid=15813999;citation_doi=10.1162/0898929053279586">
<meta name="citation_reference" content="citation_journal_title=Neuron;citation_author=MS. Beauchamp;citation_author=KE. Lee;citation_author=BD. Argall;citation_author=A. Martin;citation_title=Integration of auditory and visual information about objects in superior temporal sulcus;citation_pages=809-823;citation_volume=41;citation_year=2004a;citation_pmid=15003179;citation_doi=10.1016/S0896-6273(04)00070-4">
<meta name="citation_reference" content="citation_journal_title=Nature neuroscience;citation_journal_abbrev=Nat Neurosci;citation_author=MS. Beauchamp;citation_author=BD. Argall;citation_author=J. Bodurka;citation_author=JH. Duyn;citation_author=A. Martin;citation_title=Unraveling multisensory integration: patchy organization within human STS multisensory cortex.;citation_pages=1190-1192;citation_volume=7;citation_year=2004b;citation_issue=11;citation_pmid=15475952;citation_doi=10.1038/nn1333">
<meta name="citation_reference" content="citation_journal_title=Brain research;citation_journal_abbrev=Brain Res;citation_author=LE. Bernstein;citation_author=ZL. Lu;citation_author=J. Jiang;citation_title=Quantified acoustic-optical speech signal incongruity identifies cortical sites of audiovisual speech processing.;citation_pages=172-184;citation_volume=1242;citation_year=2008a;citation_pmid=18495091;citation_doi=10.1016/j.brainres.2008.04.018">
<meta name="citation_reference" content="citation_journal_title=Neuroimage;citation_author=LE. Bernstein;citation_author=ET. Auer;citation_author=M. Wagner;citation_author=CW. Ponton;citation_title=Spatiotemporal dynamics of audiovisual speech processing;citation_pages=423-435;citation_volume=39;citation_year=2008b;citation_pmid=17920933;citation_doi=10.1016/j.neuroimage.2007.08.035">
<meta name="citation_reference" content="citation_journal_title=The European journal of neuroscience;citation_journal_abbrev=Eur J Neurosci;citation_author=J. Besle;citation_author=A. Fort;citation_author=C. Delpuech;citation_author=MH. Giard;citation_title=Bimodal speech: early suppressive visual effects in human auditory cortex.;citation_pages=2225-2234;citation_volume=20;citation_year=2004;citation_issue=8;citation_pmid=15450102;citation_doi=10.1111/j.1460-9568.2004.03670.x">
<meta name="citation_reference" content="citation_journal_title=Journal of Neuroscience;citation_journal_abbrev=J. Neurosci.;citation_author=J. Besle;citation_author=C. Fischer;citation_author=A. Bidet-Caulet;citation_author=F. Lecaignard;citation_author=O. Bertrand;citation_author=MH. Giard;citation_title=Visual Activation and Audiovisual Interactions in the Auditory Cortex during Speech Perception: Intracranial Recordings in Humans;citation_pages=14301-14310;citation_volume=28;citation_year=2008;citation_issue=52;citation_issn=0270-6474;citation_pmid=19109511;citation_doi=10.1523/JNEUROSCI.2875-08.2008">
<meta name="citation_reference" content="citation_journal_title=Journal of Cognitive Neuroscience;citation_journal_abbrev=J. Cogn. Neurosci.;citation_author=GA. Calvert;citation_author=R. Campbell;citation_title=Reading Speech from Still and Moving Faces: The Neural Substrates of Visible Speech;citation_pages=57-70;citation_volume=15;citation_year=2003;citation_issue=1;citation_issn=0898-929X;citation_pmid=12590843;citation_doi=10.1162/089892903321107828">
<meta name="citation_reference" content="citation_journal_title=Science;citation_journal_abbrev=Science;citation_author=GA. Calvert;citation_author=ET. Bullmore;citation_author=MJ. Brammer;citation_author=R. Campbell;citation_author=SC. Williams;citation_author=PK. McGuire;citation_author=PW. Woodruff;citation_author=SD. Iversen;citation_author=AS. David;citation_title=Activation of Auditory Cortex During Silent Lipreading;citation_pages=593-596;citation_volume=276;citation_year=1997;citation_issue=5312;citation_issn=0036-8075;citation_pmid=9110978;citation_doi=10.1126/science.276.5312.593">
<meta name="citation_reference" content="citation_journal_title=The European journal of neuroscience;citation_journal_abbrev=Eur J Neurosci;citation_author=C. Cappe;citation_author=P. Barone;citation_title=Heteromodal connections supporting multisensory integration at low levels of cortical processing in the monkey.;citation_pages=2886-2902;citation_volume=22;citation_year=2005;citation_issue=11;citation_pmid=16324124;citation_doi=10.1111/j.1460-9568.2005.04462.x">
<meta name="citation_reference" content="citation_journal_abbrev=PLoS Comput Biol;citation_author=C. Chandrasekaran;citation_author=A. Trubanova;citation_author=S. Stillittano;citation_author=A. Caplier;citation_author=AA. Ghazanfar;citation_title=The natural statistics of audiovisual speech.;citation_pages=e1000436-e1000436;citation_volume=5;citation_year=2009;citation_issue=7;citation_pmid=19609344;citation_doi=10.1371/journal.pcbi.1000436">
<meta name="citation_reference" content="citation_journal_title=Neuron;citation_author=J. Driver;citation_author=T. Noesselt;citation_title=Multisensory interplay reveals crossmodal influences on ‘sensory-specific’ brain regions, neural responses, and judgments;citation_pages=11-23;citation_volume=57;citation_year=2008;citation_pmid=18184561;citation_doi=10.1016/j.neuron.2007.12.013">
<meta name="citation_reference" content="citation_journal_title=Journal of Neuroscience;citation_journal_abbrev=J. Neurosci.;citation_author=A. Falchier;citation_author=S. Clavagnier;citation_author=P. Barone;citation_author=H. Kennedy;citation_title=Anatomical Evidence of Multimodal Integration in Primate Striate Cortex;citation_pages=5749-5759;citation_volume=22;citation_year=2002;citation_issue=13;citation_issn=0270-6474;citation_pmid=12097528;citation_doi=20026562">
<meta name="citation_reference" content="citation_journal_title=Philosophical Transactions of the Royal Society B: Biological Sciences;citation_journal_abbrev=Phil Trans R Soc B;citation_author=K. Friston;citation_title=A theory of cortical responses;citation_pages=815-836;citation_volume=360;citation_year=2005;citation_issue=1456;citation_issn=0080-4622;citation_pmid=15937014;citation_doi=10.1098/rstb.2005.1622">
<meta name="citation_reference" content="citation_journal_title=Neuroimage;citation_author=KJ. Friston;citation_author=C. Buechel;citation_author=GR. Fink;citation_author=J. Morris;citation_author=E. Rolls;citation_author=RJ. Dolan;citation_title=Psychophysiological and modulatory interactions in neuroimaging;citation_pages=218-229;citation_volume=6;citation_year=1997;citation_pmid=9344826;citation_doi=10.1006/nimg.1997.0291">
<meta name="citation_reference" content="citation_journal_title=Journal of Neuroscience;citation_journal_abbrev=J. Neurosci.;citation_author=AA. Ghazanfar;citation_author=JX. Maier;citation_author=KL. Hoffman;citation_author=NK. Logothetis;citation_title=Multisensory Integration of Dynamic Faces and Voices in Rhesus Monkey Auditory Cortex;citation_pages=5004-5012;citation_volume=25;citation_year=2005;citation_issue=20;citation_issn=0270-6474;citation_pmid=15901781;citation_doi=10.1523/JNEUROSCI.0799-05.2005">
<meta name="citation_reference" content="citation_journal_title=Journal of Neuroscience;citation_journal_abbrev=J. Neurosci.;citation_author=AA. Ghazanfar;citation_author=C. Chandrasekaran;citation_author=NK. Logothetis;citation_title=Interactions between the Superior Temporal Sulcus and Auditory Cortex Mediate Dynamic Face/Voice Integration in Rhesus Monkeys;citation_pages=4457-4469;citation_volume=28;citation_year=2008;citation_issue=17;citation_issn=0270-6474;citation_pmid=18434524;citation_doi=10.1523/JNEUROSCI.0541-08.2008">
<meta name="citation_reference" content="citation_journal_title=Trends in cognitive sciences;citation_journal_abbrev=Trends Cogn Sci;citation_author=K. Grill-Spector;citation_author=R. Henson;citation_author=A. Martin;citation_title=Repetition and the brain: neural models of stimulus-specific effects.;citation_pages=14-23;citation_volume=10;citation_year=2006;citation_issue=1;citation_pmid=16321563;citation_doi=10.1016/j.tics.2005.11.006">
<meta name="citation_reference" content="citation_journal_title=Neuropsychologia;citation_author=I. Hertrich;citation_author=K. Mathiak;citation_author=W. Lutzenberger;citation_author=H. Menning;citation_author=H. Ackermann;citation_title=Sequential audiovisual interactions during speech perception: a whole-head MEG study;citation_pages=1342-1354;citation_volume=45;citation_year=2007;citation_pmid=17067640;citation_doi=10.1016/j.neuropsychologia.2006.09.019">
<meta name="citation_reference" content="citation_journal_title=Nature reviews. Neuroscience;citation_journal_abbrev=Nat Rev Neurosci;citation_author=G. Hickok;citation_author=D. Poeppel;citation_title=The cortical organization of speech processing.;citation_pages=393-402;citation_volume=8;citation_year=2007;citation_issue=5;citation_pmid=17431404;citation_doi=10.1038/nrn2113">
<meta name="citation_reference" content="citation_journal_abbrev=Front Integr Neurosci;citation_author=C. Kayser;citation_author=NK. Logothetis;citation_title=Directed Interactions Between Auditory and Superior Temporal Cortices and their Role in Sensory Integration.;citation_pages=7-7;citation_volume=3;citation_year=2009;citation_pmid=19503750">
<meta name="citation_reference" content="citation_journal_title=Journal of Neuroscience;citation_journal_abbrev=J. Neurosci.;citation_author=C. Kayser;citation_author=CI. Petkov;citation_author=M. Augath;citation_author=NK. Logothetis;citation_title=Functional Imaging Reveals Visual Modulation of Specific Fields in Auditory Cortex;citation_pages=1824-1835;citation_volume=27;citation_year=2007;citation_issue=8;citation_issn=0270-6474;citation_pmid=17314280;citation_doi=10.1523/JNEUROSCI.4737-06.2007">
<meta name="citation_reference" content="citation_journal_title=Cereb Cortex;citation_author=C. Kayser;citation_author=CI. Petkov;citation_author=NK. Logothetis;citation_title=Visual modulation of neurons in auditory cortex;citation_volume=18;citation_year=2008;citation_pmid=18180245;citation_doi=10.1093/cercor/bhm187">
<meta name="citation_reference" content="citation_journal_title=Neuron;citation_author=P. Lakatos;citation_author=CM. Chen;citation_author=MN. O'Connell;citation_author=A. Mills;citation_author=CE. Schroeder;citation_title=Neuronal oscillations and multisensory interaction in primary auditory cortex;citation_pages=279-292;citation_volume=53;citation_year=2007;citation_pmid=17224408;citation_doi=10.1016/j.neuron.2006.12.011">
<meta name="citation_reference" content="citation_journal_title=Science;citation_journal_abbrev=Science;citation_author=P. Lakatos;citation_author=G. Karmos;citation_author=AD. Mehta;citation_author=I. Ulbert;citation_author=CE. Schroeder;citation_title=Entrainment of Neuronal Oscillations as a Mechanism of Attentional Selection;citation_pages=110-113;citation_volume=320;citation_year=2008;citation_issue=5872;citation_issn=0036-8075;citation_pmid=18388295;citation_doi=10.1126/science.1154735">
<meta name="citation_reference" content="citation_journal_title=Cereb Cortex;citation_author=A. Malikovic;citation_author=K. Amunts;citation_author=A. Schleicher;citation_author=H. Mohlberg;citation_author=SB. Eickhoff;citation_author=M. Wilms;citation_author=N. Palomero-Gallagher;citation_author=E. Armstrong;citation_author=K. Zilles;citation_title=Cytoarchitectonic analysis of the human extrastriate cortex in the region of V5/MT+: a probabilistic, stereotaxic map of area hOc5;citation_volume=17;citation_year=2007;citation_pmid=16603710;citation_doi=10.1093/cercor/bhj181">
<meta name="citation_reference" content="citation_journal_title=Nature;citation_journal_abbrev=Nature;citation_author=H. McGurk;citation_author=J. MacDonald;citation_title=Hearing lips and seeing voices.;citation_pages=746-748;citation_volume=264;citation_year=1976;citation_issue=5588;citation_issn=0028-0836;citation_pmid=1012311;citation_doi=10.1038/264746a0">
<meta name="citation_reference" content="citation_journal_title=Trends in cognitive sciences;citation_journal_abbrev=Trends Cogn Sci;citation_author=L. Melloni;citation_author=CM. Schwiedrzik;citation_author=E. Rodriguez;citation_author=W. Singer;citation_title=(Micro)Saccades, corollary activity and cortical oscillations.;citation_pages=239-245;citation_volume=13;citation_year=2009;citation_issue=6;citation_pmid=19428286;citation_doi=10.1016/j.tics.2009.03.007">
<meta name="citation_reference" content="citation_journal_title=Journal of Neuroscience;citation_journal_abbrev=J. Neurosci.;citation_author=LM. Miller;citation_author=M. D'Esposito;citation_title=Perceptual Fusion and Stimulus Coincidence in the Cross-Modal Integration of Speech;citation_pages=5884-5893;citation_volume=25;citation_year=2005;citation_issue=25;citation_issn=0270-6474;citation_pmid=15976077;citation_doi=10.1523/JNEUROSCI.0896-05.2005">
<meta name="citation_reference" content="citation_journal_title=Neuroimage;citation_author=P. Morosan;citation_author=J. Rademacher;citation_author=A. Schleicher;citation_author=K. Amunts;citation_author=T. Schormann;citation_author=K. Zilles;citation_title=Human primary auditory cortex: cytoarchitectonic subdivisions and mapping into a spatial reference system;citation_pages=684-701;citation_volume=13;citation_year=2001;citation_pmid=11305897">
<meta name="citation_reference" content="citation_journal_title=International Journal of Psychophysiology;citation_journal_abbrev=International Journal of Psychophysiology;citation_author=KS. Rockland;citation_author=H. Ojima;citation_title=Multisensory convergence in calcarine visual areas in macaque monkey.;citation_pages=19-26;citation_volume=50;citation_year=2003;citation_issue=1-2;citation_pmid=14511833;citation_doi=10.1016/S0167-8760(03)00121-1">
<meta name="citation_reference" content="citation_journal_title=Trends in cognitive sciences;citation_journal_abbrev=Trends Cogn Sci;citation_author=CE. Schroeder;citation_author=P. Lakatos;citation_author=Y. Kajikawa;citation_author=S. Partan;citation_author=A. Puce;citation_title=Neuronal oscillations and visual amplification of speech.;citation_pages=106-113;citation_volume=12;citation_year=2008;citation_issue=3;citation_pmid=18280772;citation_doi=10.1016/j.tics.2008.01.002">
<meta name="citation_reference" content="citation_journal_title=Journal of Cognitive Neuroscience;citation_journal_abbrev=J. Cogn. Neurosci.;citation_author=JJ. Stekelenburg;citation_author=J. Vroomen;citation_title=Neural correlates of multisensory integration of ecologically valid audiovisual events.;citation_pages=1964-1973;citation_volume=19;citation_year=2007;citation_issue=12;citation_issn=0898-929X;citation_pmid=17892381;citation_doi=10.1162/jocn.2007.19.12.1964">
<meta name="citation_reference" content="citation_journal_title=J Acoust Soc Am;citation_author=WH. Sumby;citation_author=I. Polack;citation_title=Perceptual amplification of speech sounds by visual cues;citation_pages=212-215;citation_volume=26;citation_year=1954;citation_doi=10.1121/1.1907309">
<meta name="citation_reference" content="citation_journal_title=Proc Natl Acad Sci U S A;citation_author=V. van Wassenhove;citation_author=KW. Grant;citation_author=D. Poeppel;citation_title=Visual speech speeds up the neural processing of auditory speech;citation_volume=102;citation_year=2005;citation_pmid=15647358;citation_doi=10.1073/pnas.0408949102">
<meta name="citation_reference" content="citation_journal_title=Proc Natl Acad Sci U S A;citation_author=K. von Kriegstein;citation_author=O. Dogan;citation_author=M. Grüter;citation_author=AL. Giraud;citation_author=CA. Kell;citation_author=T. Grüter;citation_author=A. Kleinschmidt;citation_author=SJ. Kiebel;citation_title=Simulation of talking faces in the human brain improves auditory speech recognition;citation_volume=105;citation_year=2008;citation_pmid=18436648;citation_doi=10.1073/pnas.0710826105">
<meta name="twitter:title" content="Dual Neural Routing of Visual Facilitation in Speech Processing">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://www.jneurosci.org/sites/default/files/highwire/jneuro/29/43.cover.gif">
<meta name="twitter:description" content="Viewing our interlocutor facilitates speech perception, unlike for instance when we telephone. Several neural routes and mechanisms could account for this phenomenon. Using magnetoencephalography, we show that when seeing the interlocutor, latencies of auditory responses (M100) are the shorter the more predictable speech is from visual input, whether the auditory signal was congruent or not. Incongruence of auditory and visual input affected auditory responses ∼20 ms after latency shortening was detected, indicating that initial content-dependent auditory facilitation by vision is followed by a feedback signal that reflects the error between expected and received auditory input (prediction error). We then used functional magnetic resonance imaging and confirmed that distinct routes of visual information to auditory processing underlie these two functional mechanisms. Functional connectivity between visual motion and auditory areas depended on the degree of visual predictability, whereas connectivity between the superior temporal sulcus and both auditory and visual motion areas was driven by audiovisual (AV) incongruence. These results establish two distinct mechanisms by which the brain uses potentially predictive visual information to improve auditory perception. A fast direct corticocortical pathway conveys visual motion parameters to auditory cortex, and a slower and indirect feedback pathway signals the error between visual prediction and auditory input.">
<meta name="og-title" property="og:title" content="Dual Neural Routing of Visual Facilitation in Speech Processing">
<meta name="og-url" property="og:url" content="https://www.jneurosci.org/content/29/43/13445">
<meta name="og-site-name" property="og:site_name" content="Journal of Neuroscience">
<meta name="og-description" property="og:description" content="Viewing our interlocutor facilitates speech perception, unlike for instance when we telephone. Several neural routes and mechanisms could account for this phenomenon. Using magnetoencephalography, we show that when seeing the interlocutor, latencies of auditory responses (M100) are the shorter the more predictable speech is from visual input, whether the auditory signal was congruent or not. Incongruence of auditory and visual input affected auditory responses ∼20 ms after latency shortening was detected, indicating that initial content-dependent auditory facilitation by vision is followed by a feedback signal that reflects the error between expected and received auditory input (prediction error). We then used functional magnetic resonance imaging and confirmed that distinct routes of visual information to auditory processing underlie these two functional mechanisms. Functional connectivity between visual motion and auditory areas depended on the degree of visual predictability, whereas connectivity between the superior temporal sulcus and both auditory and visual motion areas was driven by audiovisual (AV) incongruence. These results establish two distinct mechanisms by which the brain uses potentially predictive visual information to improve auditory perception. A fast direct corticocortical pathway conveys visual motion parameters to auditory cortex, and a slower and indirect feedback pathway signals the error between visual prediction and auditory input.">
<meta name="og-type" property="og:type" content="article">
<meta name="og-image" property="og:image" content="https://www.jneurosci.org/sites/default/files/highwire/jneuro/29/43.cover.gif">
<link rel="alternate" type="application/vnd.ms-powerpoint" title="Powerpoint" href="/content/29/43/13445.ppt">
<link rel="alternate" type="text/plain" title="Full Text (Plain)" href="/content/29/43/13445.full.txt">
<link rel="alternate" type="application/pdf" title="Full Text (PDF)" href="/content/29/43/13445.full.pdf">
<link rel="canonical" href="https://www.jneurosci.org/content/29/43/13445">
<link rel="shortcut icon" href="https://www.jneurosci.org/sites/default/files/images/favicon.ico" type="image/vnd.microsoft.icon">
    <title>Dual Neural Routing of Visual Facilitation in Speech Processing | Journal of Neuroscience</title>  
    <link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__oGrwYwNLydIH8LEPL7Q_zNR3oYho7tyb3eBzyc_FV7c__4RxRI7dcWKzCNg5-Iklm8YtiErKROQuZmNC8pCE-jwE__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">
<link type="text/css" rel="stylesheet" href="//cdn.jsdelivr.net/qtip2/2.2.1/jquery.qtip.min.css" media="all">
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__KbfRFiywImiW_Thwe7Tk2oOMT3vLLHzvB1mpqUrnMgA__GngDeRkvYrj2z1AD23_44JIZgDylAyChKSNbfqIegBs__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">
<style type="text/css" media="all">
/* <![CDATA[ */
#sliding-popup.sliding-popup-bottom,#sliding-popup.sliding-popup-bottom .eu-cookie-withdraw-banner,.eu-cookie-withdraw-tab{background:#104b7d}#sliding-popup.sliding-popup-bottom.eu-cookie-withdraw-wrapper{background:transparent}#sliding-popup .popup-content #popup-text h1,#sliding-popup .popup-content #popup-text h2,#sliding-popup .popup-content #popup-text h3,#sliding-popup .popup-content #popup-text p,.eu-cookie-compliance-secondary-button,.eu-cookie-withdraw-tab{color:#fff !important}.eu-cookie-withdraw-tab{border-color:#fff}.eu-cookie-compliance-more-button{color:#fff !important}
/* ]]> */
</style>

<!--[if lte IE 7]>
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__ElJr3PIJEvw3qLXc1cnYiLj2G4KgDPSXFOfm6Phf8hw__JdWGm15cDWjsK6KrFlQVXQix9YgNeYysf22XZHj-Y-c__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all" />
<![endif]-->
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__BuoDuzoWcz2CL9-rYVqiOwZYB0s9mtqPm1bLrGHX4Z4__WNptNuPkTJ2rxI9jvljwIQXeYY9GgnsTxhjOkFT4fEY__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__lqAVCw-uXLlePDFpaWJQK-26mElfZo2ndTLYhJ5R8n0__wG4vlq-yzu9K_ytWzIymrrpuiVgFUlzDWI3tRo6AvmI__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">

<!--[if (lt IE 9)&(!IEMobile)]>
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__XH6bpcI0f2dImc-p674DLCZtWBGb-QwxJK1YexVGtno__vUceGprdo5nIhV6DH93X7fI3r8RcTJbChbas9TQXeW4__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all" />
<![endif]-->

<!--[if gte IE 9]><!-->
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__oWyrHF_mmv3c4PPGrsNSmh5Ub_1TfiuNA2i1_MOafWg__1kTjT7uqr7v6BlTbuE-4U2S8EzyEcBTxZhvp1VjA-qo__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">
<!--<![endif]-->

<!--[if gte IE 9]><!-->
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__-Kek3KTto4Kje1mJ9bp_-a_lv0D9QS29NgfFBV-inOY__90wksBfd5YlmG0UjedmGQFn8Ano49PMQRwGgVOM50YE__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">
<!--<![endif]-->
<link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__Carm5LBVKkTk74_lig-35rws9_NtejFg2e8OOjGBQsA___FP1FSWojPI3d_YQH-N3W0JTI1OEcAKnGzLndiVEkm8__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">
    <script async="" type="text/javascript" src="https://servedbyadbutler.com/app.js"></script><script src="//www.googletagmanager.com/gtm.js?id=GTM-T845VD6" type="text/javascript" async=""></script><script type="text/javascript" async="" src="https://www.gstatic.com/recaptcha/releases/9pvHvq7kSOTqqZusUzJ6ewaF/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-35beLYB8J+E3oW9vsZdrYlTMm/yJU76vKQNSwKHtb4Ug7VeAPwqIzHBRAOMwbzRb"></script><script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__tjUAMMrsakQiojMfZcDLs8wZnJf6IFPjp-gcFyHAuNI__x8nH83j8DMR7rOwKora9juZimNqwyqzDwDMyZs-aG90__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js"></script>
<script type="text/javascript" src="//cdn.jsdelivr.net/qtip2/2.2.1/jquery.qtip.min.js"></script>
<script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js___BHA5hgaE5B5ZIdmOeVfTHpOmUuy4HBtCFsGmtOaNaw__u0jM4sqycV1-Fx0QRlVyHTVIxBBqveZ9weVACEDWVxM__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js"></script>
<script type="text/javascript" src="https://www.google.com/recaptcha/api.js?hl=en&amp;render=explicit&amp;onload=drupalRecaptchaOnload"></script>
<script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__v0cvUDY-KraNhSsvLOBJO4f8vYleoHiV-RQLcRy1H2o__B-0pbA5LQcJwz2grux4L9BVMAykHwcOZXZgSxfPCdVo__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js"></script>
<script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__GM3GJPR36rRIz0TRkjC5OQwrioSyN9aoYRivDhCO_AM__qAl84FcCv2jyN22yFGS5Oc85cjd9zKX6p_cFNLGhe-M__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js" async="async"></script>
<script type="text/javascript" defer="defer" async="async" src="//cdn.foxycart.com/sn.ecommerce.highwire.org/loader.js"></script>
<script type="text/javascript" async="async" src="https://scholar.google.com/scholar_js/casa.js"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
/*!
 * yepnope1.5.4
 * (c) WTFPL, GPLv2
 */
(function(a,b,c){function d(a){return"[object Function]"==o.call(a)}function e(a){return"string"==typeof a}function f(){}function g(a){return!a||"loaded"==a||"complete"==a||"uninitialized"==a}function h(){var a=p.shift();q=1,a?a.t?m(function(){("c"==a.t?B.injectCss:B.injectJs)(a.s,0,a.a,a.x,a.e,1)},0):(a(),h()):q=0}function i(a,c,d,e,f,i,j){function k(b){if(!o&&g(l.readyState)&&(u.r=o=1,!q&&h(),l.onload=l.onreadystatechange=null,b)){"img"!=a&&m(function(){t.removeChild(l)},50);for(var d in y[c])y[c].hasOwnProperty(d)&&y[c][d].onload()}}var j=j||B.errorTimeout,l=b.createElement(a),o=0,r=0,u={t:d,s:c,e:f,a:i,x:j};1===y[c]&&(r=1,y[c]=[]),"object"==a?l.data=c:(l.src=c,l.type=a),l.width=l.height="0",l.onerror=l.onload=l.onreadystatechange=function(){k.call(this,r)},p.splice(e,0,u),"img"!=a&&(r||2===y[c]?(t.insertBefore(l,s?null:n),m(k,j)):y[c].push(l))}function j(a,b,c,d,f){return q=0,b=b||"j",e(a)?i("c"==b?v:u,a,b,this.i++,c,d,f):(p.splice(this.i++,0,a),1==p.length&&h()),this}function k(){var a=B;return a.loader={load:j,i:0},a}var l=b.documentElement,m=a.setTimeout,n=b.getElementsByTagName("script")[0],o={}.toString,p=[],q=0,r="MozAppearance"in l.style,s=r&&!!b.createRange().compareNode,t=s?l:n.parentNode,l=a.opera&&"[object Opera]"==o.call(a.opera),l=!!b.attachEvent&&!l,u=r?"object":l?"script":"img",v=l?"script":u,w=Array.isArray||function(a){return"[object Array]"==o.call(a)},x=[],y={},z={timeout:function(a,b){return b.length&&(a.timeout=b[0]),a}},A,B;B=function(a){function b(a){var a=a.split("!"),b=x.length,c=a.pop(),d=a.length,c={url:c,origUrl:c,prefixes:a},e,f,g;for(f=0;f<d;f++)g=a[f].split("="),(e=z[g.shift()])&&(c=e(c,g));for(f=0;f<b;f++)c=x[f](c);return c}function g(a,e,f,g,h){var i=b(a),j=i.autoCallback;i.url.split(".").pop().split("?").shift(),i.bypass||(e&&(e=d(e)?e:e[a]||e[g]||e[a.split("/").pop().split("?")[0]]),i.instead?i.instead(a,e,f,g,h):(y[i.url]?i.noexec=!0:y[i.url]=1,f.load(i.url,i.forceCSS||!i.forceJS&&"css"==i.url.split(".").pop().split("?").shift()?"c":c,i.noexec,i.attrs,i.timeout),(d(e)||d(j))&&f.load(function(){k(),e&&e(i.origUrl,h,g),j&&j(i.origUrl,h,g),y[i.url]=2})))}function h(a,b){function c(a,c){if(a){if(e(a))c||(j=function(){var a=[].slice.call(arguments);k.apply(this,a),l()}),g(a,j,b,0,h);else if(Object(a)===a)for(n in m=function(){var b=0,c;for(c in a)a.hasOwnProperty(c)&&b++;return b}(),a)a.hasOwnProperty(n)&&(!c&&!--m&&(d(j)?j=function(){var a=[].slice.call(arguments);k.apply(this,a),l()}:j[n]=function(a){return function(){var b=[].slice.call(arguments);a&&a.apply(this,b),l()}}(k[n])),g(a[n],j,b,n,h))}else!c&&l()}var h=!!a.test,i=a.load||a.both,j=a.callback||f,k=j,l=a.complete||f,m,n;c(h?a.yep:a.nope,!!i),i&&c(i)}var i,j,l=this.yepnope.loader;if(e(a))g(a,0,l,0);else if(w(a))for(i=0;i<a.length;i++)j=a[i],e(j)?g(j,0,l,0):w(j)?B(j):Object(j)===j&&h(j,l);else Object(a)===a&&h(a,l)},B.addPrefix=function(a,b){z[a]=b},B.addFilter=function(a){x.push(a)},B.errorTimeout=1e4,null==b.readyState&&b.addEventListener&&(b.readyState="loading",b.addEventListener("DOMContentLoaded",A=function(){b.removeEventListener("DOMContentLoaded",A,0),b.readyState="complete"},0)),a.yepnope=k(),a.yepnope.executeStack=h,a.yepnope.injectJs=function(a,c,d,e,i,j){var k=b.createElement("script"),l,o,e=e||B.errorTimeout;k.src=a;for(o in d)k.setAttribute(o,d[o]);c=j?h:c||f,k.onreadystatechange=k.onload=function(){!l&&g(k.readyState)&&(l=1,c(),k.onload=k.onreadystatechange=null)},m(function(){l||(l=1,c(1))},e),i?k.onload():n.parentNode.insertBefore(k,n)},a.yepnope.injectCss=function(a,c,d,e,g,i){var e=b.createElement("link"),j,c=i?h:c||f;e.href=a,e.rel="stylesheet",e.type="text/css";for(j in d)e.setAttribute(j,d[j]);g||(n.parentNode.insertBefore(e,n),m(c,0))}})(this,document);

//--><!]]>
</script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
yepnope({
  test: Modernizr.matchmedia,
  nope: '/sites/all/libraries/media-match/media.match.min.js'
});
//--><!]]>
</script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
document.createElement( "picture" );
//--><!]]>
</script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
if(typeof window.MathJax === "undefined") window.MathJax = { menuSettings: { zoom: "Click" } };
//--><!]]>
</script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
jQuery.extend(Drupal.settings,{"basePath":"\/","pathPrefix":"","ajaxPageState":{"theme":"jcore_1","theme_token":"YZrtEwn3lVvXIAsXVoQwaZ1fUAZ-A5wi7xttB29RKCY"},"colorbox":{"opacity":"0.85","current":"{current} of {total}","previous":"\u00ab Prev","next":"Next \u00bb","close":"Close","maxWidth":"98%","maxHeight":"98%","fixed":true,"mobiledetect":true,"mobiledevicewidth":"480px"},"highwire":{"nid":"370480","apath":"\/jneuro\/29\/43\/13445.atom","pisa":"jneuro;29\/43\/13445","ac":{"\/jneuro\/29\/43\/13445.atom":{"access":{"full":true},"pisa_id":"","apath":"\/jneuro\/29\/43\/13445.atom","jcode":"jneuro"}},"processed":["highwire_math"],"markup":[{"requested":"long","variant":"full-text","view":"full","pisa":"jneuro;29\/43\/13445"},{"requested":"full-text","variant":"full-text","view":"full","pisa":"jneuro;29\/43\/13445"},{"requested":"full-text","variant":"full-text","view":"full","pisa":"jneuro;29\/43\/13445"}],"modal_window_width":"560","share_modal_width":"560","share_modal_title":"Share this Article","trendmd":{"trendmd-suggestions":"{\u0022element\u0022:\u0022#trendmd-suggestions\u0022,\u0022track_id\u0022:\u0022null\u0022}"}},"user_uid":0,"customer_email":"","cartstack_siteid":"","foxycart_subdomain":"sn.ecommerce.highwire.org","foxycart_always_show_cart_link":true,"hw_fc_cookie_domain":".jneurosci.org","highwire_panel_tabs":[{"panel_name":"jnl_sfneneuro_tab_pdf","panel_ajax_tab":"jnl_sfneneuro_tab_pdf"}],"panel_ajax_tab":{"path":"sites\/all\/modules\/contrib\/panels_ajax_tab"},"instances":"{\u0022highwire_abstract_tooltip\u0022:{\u0022content\u0022:{\u0022text\u0022:\u0022\u0022},\u0022style\u0022:{\u0022tip\u0022:{\u0022width\u0022:20,\u0022height\u0022:20,\u0022border\u0022:1,\u0022offset\u0022:0,\u0022corner\u0022:true},\u0022classes\u0022:\u0022qtip-custom hw-tooltip hw-abstract-tooltip qtip-shadow qtip-rounded\u0022,\u0022classes_custom\u0022:\u0022hw-tooltip hw-abstract-tooltip\u0022},\u0022position\u0022:{\u0022at\u0022:\u0022right center\u0022,\u0022my\u0022:\u0022left center\u0022,\u0022viewport\u0022:true,\u0022adjust\u0022:{\u0022method\u0022:\u0022shift\u0022}},\u0022show\u0022:{\u0022event\u0022:\u0022mouseenter click \u0022,\u0022solo\u0022:true},\u0022hide\u0022:{\u0022event\u0022:\u0022mouseleave \u0022,\u0022fixed\u0022:1,\u0022delay\u0022:\u0022100\u0022}},\u0022highwire_author_tooltip\u0022:{\u0022content\u0022:{\u0022text\u0022:\u0022\u0022},\u0022style\u0022:{\u0022tip\u0022:{\u0022width\u0022:15,\u0022height\u0022:15,\u0022border\u0022:1,\u0022offset\u0022:0,\u0022corner\u0022:true},\u0022classes\u0022:\u0022qtip-custom hw-tooltip hw-author-tooltip qtip-shadow qtip-rounded\u0022,\u0022classes_custom\u0022:\u0022hw-tooltip hw-author-tooltip\u0022},\u0022position\u0022:{\u0022at\u0022:\u0022top center\u0022,\u0022my\u0022:\u0022bottom center\u0022,\u0022viewport\u0022:true,\u0022adjust\u0022:{\u0022method\u0022:\u0022\u0022}},\u0022show\u0022:{\u0022event\u0022:\u0022mouseenter \u0022,\u0022solo\u0022:true},\u0022hide\u0022:{\u0022event\u0022:\u0022mouseleave \u0022,\u0022fixed\u0022:1,\u0022delay\u0022:\u0022100\u0022}},\u0022highwire_reflinks_tooltip\u0022:{\u0022content\u0022:{\u0022text\u0022:\u0022\u0022},\u0022style\u0022:{\u0022tip\u0022:{\u0022width\u0022:15,\u0022height\u0022:15,\u0022border\u0022:1,\u0022mimic\u0022:\u0022top center\u0022,\u0022offset\u0022:0,\u0022corner\u0022:true},\u0022classes\u0022:\u0022qtip-custom hw-tooltip hw-ref-link-tooltip qtip-shadow qtip-rounded\u0022,\u0022classes_custom\u0022:\u0022hw-tooltip hw-ref-link-tooltip\u0022},\u0022position\u0022:{\u0022at\u0022:\u0022bottom left\u0022,\u0022my\u0022:\u0022top left\u0022,\u0022viewport\u0022:true,\u0022adjust\u0022:{\u0022method\u0022:\u0022flip\u0022}},\u0022show\u0022:{\u0022event\u0022:\u0022mouseenter \u0022,\u0022solo\u0022:true},\u0022hide\u0022:{\u0022event\u0022:\u0022mouseleave \u0022,\u0022fixed\u0022:1,\u0022delay\u0022:\u0022100\u0022}}}","qtipDebug":"{\u0022leaveElement\u0022:0}","urlIsAjaxTrusted":{"\/content\/29\/43\/13445.long":true},"panels_ajax_pane":{"new-5dcd5b91-dcfd-456a-b6b3-e0ee2f5679eb":"{\u0022encrypted\u0022:\u0022{\\\u0022encrypted\\\u0022:\\\u0022R94XYJByT0jWpyIJ+ByZKGdAoqimxQhROlg4UWWsjuZ38Yr8VWEkbXaP5NAp+50zVmI9nPGtXFw6+\\\\\\\/I4IhKBmF42fS8x6TDL6jEjF6QJROrJ33WeECDyJBa0X2smokyDJ4GFqMBry4BQoe+\\\\\\\/pxBCwb7tyWJwgIVrrCeXQjqO13pZYfMdWRfhMKD\\\\\\\/FAgPNs0KXEKBeil8rXm918xnxovxycvijztjFCi1uvrQIyDwtthG16JptQgf75SWks011A3Hxn0Lz5YDpa0aWaONx6BXvaUWXo5EQ8mcndEl1BJrGWlbvSnsI7yHBcqRi\\\\\\\/cnrgSs1\\\\\\\/UMOFZyrCvVXi32GRxZNlQdXnt79v9c3jQogb\\\\\\\/AFnVGBJwwJcIcQ5ibhLS+OdH6idkL8LTvCFZn1YRU1AeiU8p2bSrEndZou2QfpU4JbWiNLyS+pW\\\\\\\/vcqMKGXYBGJWicR7Ec30bmjmPARTX3b972DhKNwr9U4H+gnWidjhK6SuEQJiIGDttHWJfvKm5Z8pM2KQ2gDEkx6qS3O9L1X+TTIAustQcXxYweBx\\\\\\\/Fl8thsU4oWUNKNsUcycJyDF+546bvMjyE147R1Tux2NoXrZmxb1msL8PAAxMEOSbRvc5cJQ7LV4j\\\\\\\/vd+606viHW9UEnPKtmdJDiEinDxP45ooEQpgfd4h6CIEVFGoFjFLF49EYYZjrkcAiw+8RHhCti43iCBgn\\\\\\\/MT4SNn\\\\\\\/WfgA4DOHZDs1qrbO9dWD4BmynIJCwxdrV4Uxct+\\\\\\\/DCIhhyH36KtS+GiefZ7QvTsHqRZ5OcypZezuBTbl5nkcsXX3UHOcvYlEgxXJ433l7pgJpPejHH+pUyeEyCW4JAj\\\\\\\/nyecCUmJv62u3yX7KB1NT7pEevoh3snHUVqNmtv0IdWrbz5aAhJa07rFaWLObNvGpbsShsHMAwnIlOrX6rTXQijSERUWv++OeutRSBgXjiiiWxI19qziWsC8VX22y17didJVDvKlJky3pr1C27cmbwwqy4l2QDzp7fJOR28syJw2smUT3MXKO5+BZeuo7fFVrvGxk4oLfs9NvoHQcyYVm2vbcyve5vENiBGJUtWfEMr8BQ5Do1t\\\\\\\/7TWiSLcRwXcDiXYUecxujXogotINuC0LGkfzO7ZpcHilr3WsJUAgfWg8nqGSVF0YhB7lMq6TRjPKPXSxejav2r2UcU3HDRtqr\\\\\\\/D9kpZvLR+mhbbm5xqqHN6JswTjvFUx\\\\\\\/zwQJabxGsCRpVHiJeBQsdl66uqNYZ\\\\\\\/gJuNUF+llf31zqIePK9bYrIVWgsH9FhW8LXG1bz10V5Ef4Gf3r\\\\\\\/5CSgkcBeM05uWSfgpktuJLoUCP2th3UkZJGzqXmJelkQAfChzBt\\\\\\\/bsseWaA5FB6cFLGk1LVIr54j0CLzdQ9elXfkA716tbtc\\\\\\\/mo\\\\\\\/ZxlBQeQo1APyc0DeP\\\\\\\/miquj6Y+U4VTFzNDJMXSlyIkNxXos44PG3WemZf7PY3aT8fKT2PU9QO1XFTGst01L6pWmYdkQuUY+4yLd7938vnEcq\\\\\\\/tklSjRyRXeJRxJmVWa3Ak9BcKzJYtDQ7GChFFyP8X9IvfduhUcAsgM6NyQ0juOZedEJT+L92saaNK3\\\\\\\/tb5JaHu4QX+zeJu79u2LfhfNP3piL+IkspCWiTkFOsIeaFSkWGHboNGDoiJj3CMvZgddJXBdtXZ2L8aHeoooTY5vWdgburlawqFQXDAphuqsbPBvtndkrh8ngh7t2fcA9Z9P1Y0OiLBcpJg29N+AOONCOb9wTxBzMQJNaDwYIAQkDlKnIGb7ldWkRUn2UtuC\\\\\\\/TU3WZDWHhwZi7h9drjQ1VLQlyhls5HEM5Vyz6doL48sw1zrMfNwwW+ya8iF0qMpnA9mA5p+5+WSC\\\\\\\/xGpdp1uVRdTKpktO3QdA+IpLiyMdHHcrwks5ef5wJl20hcxGgrCQH1MEOZSlmtOCDF2pbxR951coUiTxl8APmWLc6G+GZkhZuIY+wns0kTGfIOeWd4kOXhhkkQLc5W\\\\\\\/XpFVQbRf0bIdCe5dvLiiHJ8u9yQ8ishyOQTrkSCxIYRLnREY9uoaS4XqNnlZZ0Si\\\\\\\/Ov\\\\\\\/Cy3Bff4rqP2cIpURZMI5TI9JUXM5\\\\\\\/vAR3\\\\\\\/iJVdzxJHFeRqgtDVTHeiqOdxAy2WLwfjdGfXRRAi7pop12RFcsuOCvB7fCBK7qFhwU9IRqD\\\\\\\/gFXFnYqrfDm\\\\\\\/4Jwb1E+5fiwiX7xyXkplMx5iArh4iYhMwqQ0xMl4JBqXfjUUItexl2zhrd+wj2BW2NvFfSzxV9gZ5Hm\\\\\\\/OmKsG+Rr6AD50hnJx4xqt9Ff9RirW0s+I\\\\\\\/UM=\\\u0022,\\\u0022iv\\\u0022:\\\u0022rtrq+EOeoPlITLYzYTc5bA==\\\u0022,\\\u0022salt\\\u0022:\\\u002216be9cf9ae1a90f43b11f5dd5fd4d8ab\\\u0022}\u0022,\u0022hmac\u0022:\u002275019f0a318f48559397574ca0d0ca270ae73a82d959cebdcd39df122c3fdd97\u0022}","new-566b3850-779e-4e3f-8ae9-0d5aff34e8f8":"{\u0022encrypted\u0022:\u0022{\\\u0022encrypted\\\u0022:\\\u0022BS8xUYUz9OW\\\\\\\/oEBmCHoDvrJMfvbQkVDj9gOB5Ob9QNDu7uLiwO057RQI5gqu6zjqzyqVO1TVUZH\\\\\\\/1ZBSoXR76CJkM64wraEGMAnlaAWOFUtE5nq5JvtYywfvn0eQDHV5zgcVwsto7fb1ahcXAQ8\\\\\\\/FA72aDQht4s2olmAfEoDRVhRCTVMmuYlA\\\\\\\/8VKQcAaXHkyJ9htDnlV0bXvdrQ4lONHEhHM\\\\\\\/kru7Rgizhnk8L0U0lK9BhBnTQUkrJedt481rtmzhDa9juBWtMuvDz2YfVwUu\\\\\\\/2KwYcONe8\\\\\\\/I0TgiG+tOQzDGgczNXpv1F8khDpyPvfvn57oWLgVa4wh4BCWlpzCo9QdWD7mVc0E4SZ3EfLVuxfWq1gQy8UlMvfB7XFDxuGRDA7KwAp6Zq5dINCExS\\\\\\\/l9k3PSfpkNXQ3TVUSlICWbNjTRcPF8he6lWP0ygliOxlUUoz8Ro6Fl02gpPGYOAr8YtPuhSN9W9TF4ZNdJfVuSpukkdi+wiKKdyGY8YxSiaJMC5Gbky4MP9CSgCt9R\\\\\\\/G7onZrWpwvjY1gODMF6a\\\\\\\/I+UqOe2SL7ch+PbMvt5lmzdjZunBCIQx58Aai4cPiQ2\\\\\\\/L8wvMxNwetw3J5TqBRxwjpFtgZSMwctRK\\\\\\\/QqwFBK7gaT+hg66PETJBXLDRwKbhLXPgnhLx2n+QuyG7P8FR630b4JxJ+6TAx78dFtInn0tY8d+g2Zp8kKxBdhCJHQnnwdA5jyjk2AT97rofv93FJzQkeutrSbUzN\\\\\\\/Jdkn91zWkrSDG1IPLwYYxCyLs9o0vMSKLaEiQ\\\\\\\/G1isJqPwQ\\\\\\\/1e3kSo4Cx1nCRm13dG540OHm7nMb1vQ7s8mzCZmcZ0dEeZY8+L73eIJVmOqRs0Q5CAldVczwl3MNyYC6isu9de7qpQPtW3Yj4ilMc0to0hTzqdwqda1ZfXGhcnxSO8P0UPSmOMrPOZKwPVOVLfOsJE8EvQ9tBAmr55wV5KnCqLJR7sQPsEnKvlYWWPzy7gt5MxG9FA2eDAtJdX\\\\\\\/W9gNV\\\\\\\/120ADoqVNB6Q8XibxgEXjZY7dgjIKYEO\\\\\\\/UZVqyH+NHWsXWv0TtnLJB4+DFmKuzij0tKEu5jOyaYDrD09FVFKLzA0s4KCp7jpyZ5tTcf8MmW3QEMbudlFlm2jElysYKyVMCT7LpZND4XffErMYo8WzL6nPTgR6q35oVEZeuNAN6f054UjBp33FS+xMtT6SjYWJHjDM5xDB6tRYtCTNVSCFCBcXGWylXHmixW5Sex+J6g+9dICIcjS+A\\\\\\\/bEuy9ztlPpxVdYvGpw3R9P9hwWxq+hdzjiw6gKT47rxsKOgg1EA2NrNxi0JXjglvcMU2FxJxlIRXXUveurLEVfiv\\\\\\\/xb2+P\\\\\\\/B68DHqMnF0BvLdhJuhJStIGkXGtPae0xwN9fWU09Y\\\\\\\/qkAXz8pEpmXZli8gdqLYX60T\\\\\\\/keQCU4VoCkasWlj6R\\\\\\\/fyHG5NZVi0\\\\\\\/ajHUMkM0GaZ8tylHH\\\\\\\/J04\\\\\\\/YRn0QZ9DBxObz\\\\\\\/hZPhXmgEht5hdpkm62V05IsLIfJRAi2UbEUV5TYQKN40Qng+HSRUrdc2ILTGiraQWiHU4k2RwEQzFoAdm0MbaVp8ORVWGFWE7\\\\\\\/HkNAvjByBI4wrlmSEZAmLGOPivzbslgTEnE\\\\\\\/FAxcARbyq6xG9M0dt\\\\\\\/8X4ZYMCJXrHXatjkWzv8PLZUIHK2ojyW6OVVKJBr5J90DwBThvWGdaymMjbyUhVqREvaccFeMi5dyV81SKuYqE6ENKWrirzIIA2Gm3RyQ1TkVZ6YHV4ANAZOjk9pQPPEa0EFPdacDTTtfsaCyKSa5YaygaM99lBEpsoz+NxX+II1WYTG\\\\\\\/sKM0o\\\\\\\/ixrNuqsiKx06b34SUgRw0UemjPPoiij+OYUvNgtc2FWSXbRqUAOTKRBKbUwNoaik46DZe0B2UdCWiHpyWTwVmXqS2HLDZcNySKONuT7yhaLVYTMDbmea6IfYA3PxE8B6ppfb189DkOsItHSdnUf3zhRgOd0uB0IERmHekOsmmmWTClNuX4PGZtZqtB9+rgUX7HZsqWqDXZHmSeuNQOGaNMuBpMrtk+8uHGT86fSpi0RPwHZ8Z4UAhVeyGW+BLTHMCxxxIxWIfaR7kVyiDtmuFjDVbQtT2RpBnRqTLHpTKNOlAjI2Jgwg6VN+PwktQAjQYKmSyTEj6S65ueqlEXtIze1uOogGJUmjOzgzaRhfuu9nA2nzOi5tDJPln4kf6eFfM17ZucBUEFEnYzxQOxXjguxwOHY7oKrQH12P75qMMMDk8Z1xJU50sRGoarW0Q7TCfxaliK0XVEUplEZIBaDkFpdXITSpHMQYAj0A8QYjMAhFLDXNKj0w==\\\u0022,\\\u0022iv\\\u0022:\\\u0022mhgu8qsCTzo0l+WmnrUp0A==\\\u0022,\\\u0022salt\\\u0022:\\\u002216be9cf9ae1a90f43b11f5dd5fd4d8ab\\\u0022}\u0022,\u0022hmac\u0022:\u0022da4d12b86151a3d6b7a1f1cbe26eced676f110481b3b36fb55f7afc52973b02e\u0022}","new-eb60520a-88cb-4bbd-bc54-af436f4995f5":"{\u0022encrypted\u0022:\u0022{\\\u0022encrypted\\\u0022:\\\u0022D6p\\\\\\\/0zUMJIyPSEqK3oyl5uXnb26j6mIalcFvS4IM0Kib\\\\\\\/VK+lvjbo1Ja\\\\\\\/BLCqIUorCS\\\\\\\/aafAMnFR3FpEo8gpUYVjU7oDnKfIr\\\\\\\/hhxurYtjypRoJD95yis68SSKWXZo2Kg6+IB2rcpyjHc09nJNxHHtwWCzcveUJSak+1UiECa5SSaP6CMtKJYLMi\\\\\\\/ZMk4Tpi7QkdmMiwFuBODrsVlNhvl8KXpJgctcaYP3ZRhhk2McRIzFnVgKNlKbZhSdgrJa9GoSod9ugDi43u9cZSsKtUtYxxaEUj6WkRSLwpm8o2T8BngQQNWja4ZdZMJVUCwTbcXH8ExCdhoBaRB444RhtoAlnNE8kjnzQX6YXCGHzDDywpNtT5HkuaWciObeD8wOpCrpezQuhXV5ONvG0oXExDOggYTX5Bz640\\\\\\\/LKSCJ0g94HVyT8dRdoruxCeIAE1bE6Ms19XXITrjsP2a1qt6vorVjd8yNXIiF48ozw4ViTOiE3zaKEK6gTba42tnE52MLTNGkzqiJBOc4xQowKr3xwVY+r4nP4hw83G3Sk7CrL4he1HV+ZXc7SvTtoJACoT\\\\\\\/GsN0y3VwIJDTBF7SRWsnGxNKNqzbJodGMgVjXX3kzzfXrY1tKWUe2IQso7A6It9LBl3QarHzSCdzwlcQ7QJbLCuPgEcv4bbeOsl0Jr3NPF0bZ0Dz564mx75vmlw9NzAgLjzxYnnLaiiidkwRwKc+kGSFBpFjNoHxVVzAHZzhoZK67hZNtaoa2MlNVOD9VmLRzPtf0WyPPfAyq\\\\\\\/9tcO\\\\\\\/NDfTemPQXpBIu9sQeZpnn8q4GOnYZyUXueuJK32SGNVbslCWv5NrMEdg7AGlJB5i67isTIlF8qTfY0eNPSbnuDxIuTyXdB+YS539YKdjae5lJhmL5Sb7KTNoGBDmJyT1jGqkWqioS9Pnf1kUb2DlmTgaTGWBDqV\\\\\\\/K5Oz7Lk3R3gRzHNh1xJWPo\\\\\\\/rQKDPzxcQrb5wMaEX3pKbzFXMRntMZue0c2oAQBNZg3ZMZygaQdKFTF3bhAkYA7d1mtJWhg0XpE3WcFVtDDozyzWSkFOYUkGV2wEYApwOj4icnyE6arpG\\\\\\\/B28sIomnP\\\\\\\/ILYxoFHjER6laxVs8qM5CPDYGOSbjr+cp\\\\\\\/Iq42QQiRbSAnTIy\\\\\\\/3binLgQcrvhkNntt86PxI9DZd3hLwbMACwOOdeflUNmD0vXCIvzdU028ZkiUuAz9TKYldi4VQgIvaQHWjxyf755D6IEbhyLfcpTUybYMIAOLtluQQqTtw0hZ1I1mF6khGAr+yYbl2f+bj2Uow3XCmZUqbzu6U6e7B7ffUgCyHN6ZgeNky5Ey2Vz+voq3dxgjxfi7HRz1IraYoR4zX0lNHnXNs5\\\\\\\/XzGwpYTf1aAxzHSeJ5i8WuJGR4dbbOBW+K8WydMMQUwVuT7x1dS8aj1xXPSjDF5NoOqU1i3CqyXzM186NTQ4r5rxm\\\\\\\/LrPX5CV5tNkPktHRBtyZ8Uyn+WeXblXYohjl9fRSKTl\\\\\\\/dQmQWeU7VVaJFRx4CnHXK8voOcb4zQP+wfTePWKOKuAbPFPIodW6IKt84+1hic9poiM+537Cn+QKE1lgNkzZHYnbnlyJXGH1Q9aem8hkq8xQdAT1K9sZSziABgr1EY\\\\\\\/fulDwVP+dMaZkF\\\\\\\/C5DT\\\\\\\/CeWzU7y+a1wzezn816jVGf+6GQtaC3B9a4J3qBFxeXmFoyG3DJDmti2QU0vp0S+L4itkxy6ZQ3coMvS25B5wSYgGKnoPDTKcL4FpGN11xaiocojUcWNeflvfKBxEaQ\\\\\\\/hibHO+tTwyk8RN5uGkjF+7NeJ53WdRqPI62DIjTMvMONuvSD5bjI4zMNAifL8ljGMfz8qWRKHgbfAvzmqt5rD6b6oK64l39R2oYWYqV0gO7UCB5SLC6p3G3zet9ILuk+ejJL6kq1GhX2GnYavQYqJo12zriRw3eomN5vqULHUWA30zBu\\\\\\\/uecVFrtQE\\\\\\\/Vr6ofV3knRCqaFDn4pXrbpmyKuTzXffHQ86aw417\\\\\\\/Rs6IXQOE0jKZPGVJ5yDmN\\\\\\\/McAmiv\\\\\\\/seaGc9BhLuO7lUTnrJvYXUz+mVnYQFpM7i0QcNgxoZ+pI3P9RX2Z1LU0V9MSMb2I7T7\\\\\\\/4sWFVmHcbvEXzkVEgvMDHD9t5fdKdYD9JXxMdf3M0alaQgtaCJs8nVnlT89sYuMTxz6KMx9ELN3\\\\\\\/YPT0NPEC9HzLXVI91afrsiNjMpkheqRQLFv4kj8qI3C61A8rVsZCnv72IqRwW0B+ss2iN6eG+brZc8L0bXXFQxAoi8kUihhtyTu4yipFHRc3r1kKmIXwloK62ZJqOa0\\\\\\\/AvNEdMCNideMjoaJNy5HryQyhK0Q8CPHg51UF5dzoB+0ZjVMruXuCXjJyD5NAQLAMAzL2zTKizi0p+pBfDLAzm9EPgARlYhqtThGItiTTGgayM1cJMzvjfAmKcVHm01MaB+tVxTj+4sdLSiqTb2jOEkZAQUM+CavR8BgGcFZ1Ys\\\\\\\/sASzjUfKwWzyQAfKWUOON3sMw0b\\\\\\\/HcazcHtQ33iRGuzO0cwWWkRxgCTksijC8TK6ay0Q\\\\\\\/\\\\\\\/pqHxsTrbTXUyJvn13pdMHUbXi2IhdOqXfEs\\\\\\\/Bm+pdlxaytAJ2GriAvbKbtH7RypxBZKYDJVFELCm0uTw6ClIErzbUNjLVkvcym6yQDPWHt7ebS40KVq4zmEFIxN+pHuhN8KQrwZ728y9ny6TjK\\\\\\\/IhRKr0xAFEuGk\\\\\\\/NWI\\\\\\\/yaTgGdgHg3gD5TO0GXtqHH2jxtML6tm\\\\\\\/Nj53UOgxRMmB0pl2URVrKR7odlVFjBu2kTY980xKfBpMQNDJrMulF9fPKu2FFZE9T6J11A7twiPieLcE2uZLzlibBDQ0XaB2UOo483+3QvGloCNWNGMrznt4GcVeXHC04G7i\\\\\\\/hO8H8tgv+vOM12haepq3u8BwGtaAmaklJ3a+ouCBvCoB+kLMH8oSxvlvHI5EWFh8ynoJ4yKpXfENTAmr4UkdE3a+ej1+z7fdOSPcoFvNpfiIWbZq51q\\\\\\\/nw5b7OdEDtOX3+s25VNVskbuD\\\\\\\/HOF2WxhqtbU6Hwmn3zv9hB5DRtcl+7t8UMd5jDUoGmg7lM09\\\\\\\/04DP28BhQpUMyveEAwsG3JQr2WxO5Ai0UbftX72JgS3nCZnvEo3o+u8cqukxZUdJUUeKlk6tdkVTRf4fSHl\\\\\\\/cFt6oBz\\\\\\\/ghlmhSs0L0LZrLv5q5wsI3XjK7giW76ci4tyson+N1Vv6Znthp+Sp0uaklEkpgC+3ep2cHgvPRJi8uSoTpvtW8D\\\\\\\/ehwHIXN7YB8XBbRAoF3d2O04IW8HvPX\\\\\\\/Bg0n0f90ZPWglmy8JCqub6T8Oem7zpwuBvQG0fvcYQNWTLriojHFrCluvStzF8\\\\\\\/LAymt21DhwxAAFLA0PLStyNajBUt1x\\\\\\\/vI0gfcH+3kaMLWHPoKLbgdep+VGTkzOHl9MvETpwzU3apLG3skbud9h8KoOaou8qAT4IBz\\\\\\\/wG4AlowiIqkUQ\\\\\\\/osbjBmoh+DH9bUBEleu8qU\\\\\\\/bMoXOVuDU0CDuOKoNhn7kRewLjRqy15WflXIzC\\\\\\\/VVGnSeypCWwywdd2C9nwsEAhwqaikHKevu2MbOoLBdN\\\\\\\/CCNRH\\\\\\\/7TK\\\\\\\/HYejFzwVY2NXAgCD6BJOL8YPmbuVZ2MOdW\\\\\\\/c3DpdqnmABHFRZQZzxSSfhlicU6Ef5NcDXGVDq5Mat6YiEWzYIyGLkhiHsgMnbB4caY8ahiEe2w4Jg9Tll8llnGEvDGotfUQbErHZpDiYWGdI5TLPynBHtPooHQ5\\\\\\\/LgzVZOdZxLsjf0IUcZFswhosZaEAr7LKYbbZHRVgSU3umLEMCxusBg7vBQRAvzP46usWEN9i4Sr+XniyJ8ji2jEvlFZpJ8roqg2j7JHTA3DTrtNuI98ZDBKOca1HoOvPbKSNyjiKiEce\\\\\\\/y0k2ics\\\\\\\/1f4xnLVznBu0b+YCFZmiSw2eklzy2uNpZgckEU2EADd03KXSdulzWIwRL01aWFHuxaNXSR26+8Tks17S8ndCeVcZ+nfdFegiIzveA1WfEOW61fybVu7ZfPADWB\\\\\\\/HQpelOBaubKiIy4fo\\\\\\\/1lJi2LVbu6yhPF2qgW1VkynqPQAWtWwcsc+lVwN+7FCDsm30R81Bs6xGKoHyWBjqy2wBN2Banz7Rw\\\\\\\/VSTlZPcm8CTPsWq\\\\\\\/8bvTs4A58yq1wnr+243B17BOjsAGwtbyWp18K2U5gGfgjddLA6e5ApsuMl9eTGOgLQMR0sfj6DtdkBNNo4YXWiqgn8f5D7F2ETYtdubgR8t+Cy5Lfg88YFoJbZobYYnmW7+7OG47gHsMXQV2\\\\\\\/4fSjNpeHAmZ1b9qdGsCEqmOh7rG6ZI7Whiy4N2Q51eWFqOdapPfc2OryFKC090pFtA2AIV\\\\\\\/9LIKYfFJNSdCOzR06Eq2De9cDB5Zx0Sxb\\\\\\\/y+xCnMouxquiCrvzUVXpJ7uuMz+3kMQrX2seZxG1lZ6L2rKV3sgfoDKDZ9cgeIlh8mQ5nnk86D9xWu\\\\\\\/wlebL5i4VqgXCme9tw945uDi0RVMy7u8kfr3d3jANwioXXDvedItm1IDay8d8M2dBVb2SoIVyZgf7j0cDUGDp4UwQ3KHnG4Q+CJsp0\\\\\\\/Dubz\\\\\\\/Mgz3N3zbiLzgx5eniHXkJWbX87BHX79tDJx46quiCMI9UikU7w7hPP7zSSM37Skfvh3rU77\\\\\\\/6dfnrthR4bcSrT+swMNRjGxgjmoCI7Vrtv1DVf\\\\\\\/y9PcwUQT1kz2P58ndEtWzkhy5voIrrR2fgeOKaXhX1Cy0XTdT5FIfaIrL8gqmFstzHwaz8mp8IY8T30K0QK4hrhqzkAo7IPwNjOhGYQSKn4kbgeDOSE0wdFTCspyf\\\\\\\/d1N2Opbx8oqsav47kV7rUsIetQkJEzqMQ4RRarO79y+DdBelzW7fJY61MXG0\\\\\\\/7bMJO2BVSuM5Aw\\\\\\\/8wyv7etYJAZQ4mIhtoF0UFVtlfHj360r6OF5+MQKoNghDzEGyc6klinjg+xsisd1Nrxl3tBXnDR1BvlhLfe8wxhC46Wzn+RQ\\\\\\\/qmu9PZbOgmaVKMPDoNxX35yDKmOBo5ZdZqhAcfjECzGTaNJBO4+OShPEmhLh7+ntEJOnoyqHKF5fn+3ezwVy\\\\\\\/RwWUcOjbLcWqfeXGbkEDFC8cNhHigYx\\\\\\\/THTuQbkKrITXGi45ac5d7ONQUMgFPex6tXBIaQx8TIu1YD90XwJVnAHxmgmtomwg16OcrKX0uuVPzWuvv9mwB3slP0r5to099BKFX84lQrAFjrjoEO9ZZ2\\\\\\\/wsr\\\\\\\/y5Bcgdlrt5h\\\\\\\/fBbHTS7v3Nh3n+gAYjfRQpfj1FEiJDx5KLaI8QYqJf4m0LKky4piLCLxAp\\\\\\\/eT++URVsqdRY8jPojAuI7Fa8bDMbp32Z2aykcOPUzVuDgj5fqhnqUOEYLdVd7L+uLnExNi\\\\\\\/tS7Bhm1EMaZ4c3P7Wbl2hoTc\\\\\\\/TlGeZokc9119eyGIj+QeMZef\\\\\\\/8164Lbv7c+QG9lCPIaUmQQNLIlzMVGUhNgimaoVi4BgP42EwrUQAxFu6YfY21ABQ4JV3khMCnlCMNtAK\\\\\\\/8pYsw6DvXlOi\\\\\\\/XytE6LujCggt+USPTPLT7TAINlKRfYKH6Tu1CU0hc8UtN9JSlxL03x6SMWdnPMvIphijEscbC2ej6Wu+mv4fta7+2+Kgr2kLepEO8QeDSfYD7vAoZFBDSAvE1SI3Tzu23ChC4VDAU1uQQ0pq5rOkolHdQeAdJZwCLIn7p5o\\\\\\\/Zqm0dGWXC1CJhrkvN7\\\\\\\/ruK3qgxNlJu+aqgWKrMJg54vvyqvxWM5QzJZqeZZaGasBC34c56iDd6ezLfkGxB1SswArLmX+v4+49yWrm+MJzo8Oe1hBqKgY\\\\\\\/RXEZqa6c4bEIkb5KzZZZLZRzffvpAAEm\\\\\\\/7lndGW9er6ujPLAXM0ulzFivUWLHqzOrsI58TIw8p9nsgjT6F6R5oBzDbmlrMnMO475l0E8B9lUbLMGWa53XJCUOCozyAXl61dr7lxV88BsA6gyIWba44+59h9VHRkQeeo\\\\\\\/6K\\\\\\\/u9PQEn1fM9P\\\\\\\/p74BvLeaf4xiZPSb1ki4DNA\\\\\\\/SDdYBIOd08o6QDUIHTeB31UjFLl4uUxjd4bozfIK+AcTZAuowXAi0YT5H9dZ9rBYIfrorC+jguKo0G48J8arq7bNn5Y+4pBhiVSKbxN3FJv+aSK82fT6VZz7WGXvqCGQ1bcT2ZNppQ0FoJNb94fJnmpaVreoNdrHPEjd5ugG3MFzm4m+sEV1\\\\\\\/uyjyenSugHKwN1EH0cLKhbDkfjwfBq3IMzHwU1hUd25ipIj2u77\\\\\\\/8wVNPj2xffVPXkjN5DIY8CJB0Trl0IZSsct9zZdOmRxwVbwtfXuG23cujZ7mSBXzSRNPbkpuDfb6\\\\\\\/558zc7ENmqswLorwi9yMTBNp4ySYMLpKOXi0UwvS0bn9ccRo9wLWw12NTt74b2RSCNfVR3ClCnbG7qK3idXKONHz45EJlxtsNiHy9j7TJtTDn5xKu47A7rzUBEzrTwetQRQ+AqtUh+neY0fkaqpoFIDWnU7xlHQlXcFCLOVsiAqAxm3iIbELR6dweWz0MeWAvbeMObI+q6nF1QgzyLor6duHiluE67JZWMZb9wmxp\\\\\\\/D4IvQxDEPzHNk8kgZWbmElfMe+coSOMGQOiLIbxBDvPR+LYXXelL5Vkjy1I4D9Ex4A4Dtz4HL9m3AqzoCUR7y7\\\\\\\/ahw40C15iu8KBxngeyv11H8BEWKcg1kAnCOzH\\\\\\\/D\\\\\\\/JSX+brTAEsKb6Ku34TTxeQCQ2mTlmVe0nKQ\\\\\\\/g6cVkK0gOU8tgTTqFTDDFWdIFj\\\\\\\/lzxIsCyNM04XuV5qf1tTOueyyuKxenWTB\\\\\\\/aDOUUEwh\\\\\\\/s+2y4jSLeDPELvQC9hZZ2g1c\\\\\\\/rcoAD12qPmUB+oo0iy9rIUUYSFiAILD0ztwrohllhD+p7JKtnsEM0aNPP7bc8AfsvyTFYKz1xG4nFhZnDvykb\\\\\\\/N7LKij2b72S88NrZb0h2QEifen5Nn98+OTlQ7o6i1GP3mo6u\\\\\\\/A6uLOapu\\\\\\\/UwzGjy+zagJ3pFmsncAn1hMdymhEON\\\\\\\/RRHONI14+9eC70khMPQjaDDUl+H1ZmLX2Dc0HT99xK9bFzvfLkTiOUSVTxPtIJuaAYGOgWAZ0A2foV1GPluK+I5cGnwwSR3zS40ui\\\\\\\/GjmxotHd59px5MTu1pPdfIZkoGiPs\\\\\\\/UXZ2PkKV9eXlAc7urAsNERrypVNmqL+cmCPNvJWm7+UQb7hOicv9dMyqBlPv194\\\\\\\/Vhl\\\\\\\/pM\\\\\\\/VdUgUUm3DMaG4NPU87qijzF8DN0pWFylDvBg0tLVrn8DXuIfKgPgkxn59l8NPLPzAXP3tNEOagmqDrBv0hb3cIX3I03VsJgiBhHS2UPKjY\\\\\\\/xJcQ5AtH8DPjQIeifRemBL9qtJ0KADlSPH2b1PPYaAoJxL0TTFLlqcsGRx\\\\\\\/P81keoDRMEobr3YX2Sybv2F7AOnOsR7EEme5nGosdh\\\\\\\/pnkkzbhv0JA5QHE4u1nhpx5JHjOYn8mwuoj7UKSaLdt1G\\\\\\\/rOcBErLE+1VAc6jJsnOBsD8pvx2p5wqKn0MkPfbK5wdSykqZreaYD96MX\\\\\\\/jTSuElFzb9ik3Q2A3Gj\\\\\\\/XLSSLar9fvS2jqaLkVy+VaHjYWeKZ\\\\\\\/2mAZKIgC7LZyFg04UpG7mwF+vLgRm4PY9qAjXWhzfvhgCuRxuf7HSlNXmvmYnwqnTFkcfrNBdvU6bfc7lYLkdmXTGT20xJWwD9q7G1TkQOJ8cAi3wyZ5IpYmeA2zDAbRR5Rw8qBBFpTmzZKky5LbgrdBcD8DwKcIRcVvgnub2\\\\\\\/1hV8rJ2VKI3vSgAFMQkN+COUpzEaeSjfniL0fudg+sNKUzPKARYca9hPumVJOIO3EoTMPPoo7JDxNHUlFr6Xb1wGIPxipbrfZ9wOTdvAYz99jatk1KCFJhPb+\\\\\\\/B9aaaZ8hazPK9B2JC\\\\\\\/1TuSI8n1KTLwaYb7L5aXwvYBnHKbd\\\\\\\/aolBvJxAOC5ve+nglWakIUT8t1tH0S6PjrcyfyozOfGUuG1ctM226yD02wjKbritAFQ16bYSVvN7RwhOmLNn74hVr\\\\\\\/ipq6fooez3Fe5qhN7iCbiXcYIkN0hvE4dDBnKjHSYfBf0ah7hw5WZkgnnE5qXdh1pxuxeoNonBjrusSeWLCUwtsiDSmz+Czq2WYA7Q6Z\\\\\\\/ySuywQFO\\\\\\\/FzPYyq09pwKd2IRT6H1ggjRc\\\\\\\/NSFICnGTHNefubE5tn8sut6LwQA7uafJwJ6oItej5xItcJ5sXJlai6d2IncEdiuDl12AmzKhMZulfpikCoKuYDWk\\\\\\\/ItbjG1AEqSpCFNg8C28976oA8DOdTwAQHJIoYXsjvT0o11Wwku1GRQFY2IFa6OSz5NtZCk2SX9Le7Nn2fTWoat9849TyjwMjjD9zC70HaKCfkBlWFEtfLjyyJ2cssHk51iElYDSCnVsUKAJ0qCirYVqNnvUqZ24YwDO8xH+0N88k6vyz\\\\\\\/+THz5I6LClSVCqfRGwuptOfCuQM9sMuRknqf0AgjEOQLIVqSFqN72LdIC0iECEAYl7QKnIA65TdEUfA5xM\\\\\\\/KqGTpajCFNM0HDbKFWA6J4fJArwZ2IzjQ5qYBH5XiD0\\\\\\\/UrMUtYxqsAPXGD616b8CIiPR053u38B5aSM\\\\\\\/aECrcFA9cm5vzCb9TzTiLtP0hKLw3SHQVCFc4ps6is4hlkS277faK9EmjZ7Wb8sTTFHNW1csScq4Lsh5933gvOo4SLB0fLR09TINo9cNH948lvMR9NlXnUHFkBH19wBxdv401mHdNbCP8AWYC93SOfXaFKqhl2FaKZX+r27HwDGmUF1HIT6qQWLtHJeczqGXlhSO3bv6MLLeZ\\\\\\\/EGjLRsbDR7nPn4cjGKU8HBltU5S\\\\\\\/NxejjKV4wJ1q\\\\\\\/Q+YzuHhfWsF2jmn3gC+6VUkCwkxDxHwqptT5CYnqDPHfQrWl\\\\\\\/deEWh7xFO5CcTMdjzNroH8VVSkxHlqh5Wi6Vo9juUa2rfnH0KUHGgANvUkSiyV936P8+dwIP\\\\\\\/fyj\\\\\\\/mIGMznfy3fnQrVbF4txgPAYcpsuHeE0dixepcF+ktL6ZBvomryr31bodzxoJrYY8O8RbZBiaISeskxU4dcJgKNlvJ4rKPs7pGkQWTMlvM5FdlsqApJAuV+DNLuQpfHVE33gAGOeciddDDSek4w7oFDA+J2MJSpJqy7x\\\\\\\/0znOynPK3z9kRlv7b0pHvyPhI71ie9BJwazNGZyd9oSe05JpsMGW13PVMjFM2\\\\\\\/jKaV1deeffynaXm6oXyWiR5mO9LOiRMeAl7VNM59DInkP2S4cZvdgMcIEqVLOFRP9UsxnmQqPxH9fsZqaDWF6kzmNRmhrF\\\\\\\/K8jIEmbu1VDLwzA8Xq7bJLMq18KhmRnY+w2JP\\\\\\\/fJGCknkCCcLBpeFEb3FjclOmS2eZ4ghB2L6WV+JKbaNW+LpLXUdMFLXAuP4ZnsCIbgEAIGTOTl6Ai2RSEjMrm4KuOOsHiixf6ePcrgzHfUmgw1CSJNU36ilhpCJjw9IOs3WVLK4\\\\\\\/wKr42RxQaIsDfPQhxfZ3ATMWdWAOKXgha7UG3pPI9\\\\\\\/NZsmDbEtSr3eKUtzJlocLTNR6bm67lBxUVVFYwbXfXdIrmvFulhsqWSQcCV+rFmFB6p1hyRJSErDEtcOjxjCXNdV\\\\\\\/OAMWekQbEBc4F2ReCTpBB+QK6uf0yCknZPUv\\\\\\\/Ya27IYfAAyjVupZKokerR64gzcV5IPdW8W+y3Umd8UDxQGPrkWjY\\\\\\\/UGMxr9ZteqLxAgIGxIt2POUJgpb2jh2gs8FsCrLSRcvd6ZvtUsjsc6RhDbXdX5dY7+UWWZr7J0mN5l03WFpM3VoasNxMa6jHbpcj9doroqwqRUejc31Wp+5X3pDKFV9tcTqGODafkvDsPpTwLsiUDnnFIToJWBXSvuerXp9ZEMxzaA3gz6jzQJANSoLnUPP1\\\\\\\/NMqT2gjC\\\\\\\/nC4XWPcuoKifDwCTC7IzqHmtDdVhbN8KJDWLrdfk0ipBnkyVSdGJXdIzpZqx1UdIvjNxO73xq0WZHYH44nsLATD16MdyBcewk1NOGzRGTS6al3TLGXjSGwQMpEQSbMS9LgfecBGCnYyB+fmFNnFPbKdx7DOmFYZ+TVj+ZW37Vrb7cScwdz4cV27BtoaieaQXtL4tHlUb74dCWFZsR5jDr6Z5seuUrcBhGIM6jcDbw9m8HTg+rSLeG0ZALtv3A7QUz3olUscbEtEHLZmydWdr2wZmqG6YCSp\\\\\\\/zQM5wjSjqww\\\\\\\/5DM07QZxYRD0nCsXFukwwqpvXlsAwYGiA9D5p1SLTnYIeJ7NHvA0jVQchnKaHBwG\\\\\\\/yjYiz93xjhrMlYDWYWLmeBC+X1hJgLSbF\\\\\\\/f6dcNPNI99TA2y3GP1HmLs1yz\\\\\\\/Sjd9yD7rMk1pO5pwh4GhdlXBBfAiTImVYisOefZBIglGJ5ib6yLpmUbxf5aib5BpN4o46CWUJ6M5H+Kxe5oMNaPxIcIGpdUEEEGblOZlu6HdnugRGH7yT3xaoDk\\\\\\\/s9jdWUjqfae8FHHRrQ\\\\\\\/Ee06hvZJSEU9wksRUi484lMrkiHwUfJgv5xel0xxFpTik4WukbPBEnoux0QMOQ1vAPMq4TqS2HWa8zAWZGvA7T9fta51TykCyIgUZ4z0LpmvRuKbNsvldr0UsXgirfjLGYixYI73dR9PtoIVYN+mHoiuuFvdDszZEWNmGCZHeqatvf9zinQk2\\\\\\\/KzbAU7D79XnkOlgJpDfiswL4ThKeJ7uyoaZiW7LoezeNUrtVXL7zSsccHT6BH4F943NXb2dWtJJJNIpFpvvBg+omUXxC7Q887nLlWe8sjbY3W8VXfM5yuDU43bARNO2tbxpZuHxpJfyWnJaZQRm+LHcuUdEp\\\\\\\/SNr94PerGTc7QyS0Z3vkDC4MH0UMHsOeOHWOCVyGtg78drpwz7qSYfyEz0ndlACsw9YConj0btcgReHCSo0dvZKkdxX5vvxVy3aGoLKAOQllBK6jF9oN8FIm68hZ1\\\\\\\/byn4FeZB+68qVB+xA+SXEUBwL0DN\\\\\\\/VrKJ\\\\\\\/u6wsyeQwbV7C\\\\\\\/hsUFKbI0rYdeeSWyK1mf8vRvOza2Z4y3CLLTGRtvY3Bh6ApUbn18TI+JXTYZ2gufdgQ1fjzdwY+lYokerO1r\\\\\\\/mU4IWGo9Lr3th4ZEkmb24uwqr8ACal\\\\\\\/OG2Krh2jltbewDNYC7VjsKtq68i46486tlB8UHH37kEFrJpBOOusL79wfm\\\\\\\/g32b0K+0Z7d4HgYH1ariRAsxzcCK47+cAf04Dwv5BbmzsLMYpSnYs8SPt\\\\\\\/7+Eet0EsEXvchAa18Hggc7XPjkqbC8OfJf6GdBb+9KT2ZcjrAn3etEb1QZWHbALKxpFG+okbW2oq04chANfH7EKHbEpxIniIp7tG+ssT+Rvqm+VKEBJgsMN1XCBlcWQe9y6iIjj3GiVf5c34uu+\\\\\\\/ojrr75W9SDPrMYY9fg4CvummwtuZUr20UAdQZGz87YYVpgk6i3LLSDbzBRY5+xEElIhTLRNwpf9ElgJYCcDXJqsH9ingX64kgpGQPLx0mvGKlU54lUiqVfnZSmjFKRNprkZJd35kR3P9AZcEkMdMKc2qaxha1GmTqXqRCRDz+bNdDWB\\\\\\\/t3Xs258ZA84xEFLbkRZFmYRuIjkWGzNSOKAw3WS1rOnIxtW6zKId20oTKonT\\\\\\\/llk0OvELsvQ1wlp1GLF2o4k21kADVC3Yam4EzGijx\\\\\\\/Eg0jxfdapT3UKsE41Px+Io8AzDq13dTa4vH0B9uX+aHXlmvfXnsIJOqN1GNZD7qnkyO2\\\\\\\/59XvZ2Q\\\\\\\/A+pvOxCBcG9t\\\\\\\/2O4C4rnrflyBERKthqPVjOeCu7uSXJ5vQh1UdN31D9fRZq6r4Y1uwkKyIJrPa5QeRz\\\\\\\/ajS0tYGIbSB4lfNZhzl4bnWcHFSLSyKAoXYqfGKEaHR8SXAF8h\\\\\\\/ykyoIPSMwn6LW3ezWWjEclgJ\\\\\\\/FlLxJdUkG8Bt56kAiX20ZJyTm+LgSMQRrcY8xnqOJOuGiq0kcubbV\\\\\\\/KFcmAu9HZYvRmJxh2MKVsoDkUKOPIzmOLp7hAMulVtbNaBqHy28xKlW5nNzZpNDY13VIgwhNUZjrrg5nbtjYM2OMHCObzMrXHaHAY+JnI\\\\\\\/qU0DhuzQH6Ip\\\\\\\/UuCrFs1mARQTlaG1cuHS3igAionyyFt1+Ed6hBSm+2dvbmw6Z8CKs0wq7HYA1+kUCh\\\\\\\/jctVD6lgT9kUZ48qvofc7lYXzxybgJB6lRRl4SXRXWnc3ViGWcdZTy3d7QHd55GSslOO14T2P8AM+YtiJNJJFWXFAgyrlIUOQxYOkMiTvafjm3ORD+3VAFeYKLSrLZyTvbUcIryqY6nB0vCYFfEfOqbOVw0ceIlrz8RFTqYbZcFsuWCGR9e3dqeCf1ubc4uZsrIGU6FaoRDbRy+JtZ1VNc6cxjhMVoSj0eaeukphWAkCciYmcSTvhthgld\\\\\\\/8NMzPs7xzX0BQCoNhe0WJvPX3b+muVSJbIFo62LG4os+vsAG93l0QHQkQTOtadz2vXJzysn9bfC+yrQPO6tvohzPZrz3xjU+3HAgcRlFXaTPejWEDIYE7C\\\\\\\/apktHxfz3dikhk878CivCG+\\\\\\\/z4mFoqGCbTz7DUn5esd75WtGOKaUtp7qucJvNpSyTlCsuHUsMlQ2WldPkrtafGAningUFjI3zdLhUbIQs\\\\\\\/GWfxaW2vkLPp90l3G6Zh\\\\\\\/ECq997DmBIU\\\\\\\/Ztb6oj0uJZd+uKNRCdxtdtW8Yw4v1vXTWjr9siSo8DfoSoZBedItvzdbS26aNEo+g7acGIDQErOXVq44g6maHgKMs0lZMbZO06yRC89VB1x0AOTKX+wIs+w+l2oVqR628NJdUR+T6VZbMs5Oyfg3rS9AOvtvED2CUQ\\\\\\\/BBajeeIa2A1Ct83AVuE4aG4tqBIlcf1WLSzHjmMVAW\\\\\\\/YQic\\\\\\\/iQeCMU5vKj9cyjZ2\\\\\\\/9hf5xAGwIfycqoDaLfwWnNnNSotfV1IKeiQ1kNqOvw2cPz\\\\\\\/fk4nquQrkrT8SQW6mr9aTxiZYS8cwlavbVhYQxI03+Yq64Wq8BVxW6bgk0sWhbjHnN\\\\\\\/rv\\\\\\\/9G6ntTvdV5pNhJJlRp7DTsQ4xHjZBjWbStXelG5Ii0HZ4Nqaz8IGxF98zwj\\\\\\\/tt2+88mAunx90w08hS\\\\\\\/nNqrL4d0k8\\\\\\\/+oMBQjzaKhf+jtiHSZ0\\\\\\\/qJARA9Cb1tv4KDbmlJ\\\\\\\/jg\\\\\\\/GL2k9ftfaRD4z5ROOCgZHB\\\\\\\/FgKNOT6kk9+HQMtn+26NtQT101YBKUfxBPF3ChH4\\\\\\\/IC0SYNrEatoyoCDKWPCfgiDXg0ewaJcLEjm2s87uFpt\\\\\\\/O2B1bSds3koenzI3Jmpb+QhVAZjXqt0zkN59+xEaIc3GavcluuQU09gJnKhshGqS+nIGTq\\\\\\\/M9QZhNfvBX4PjNyQYMtZuX74TJB6bTpysN036B\\\\\\\/F0yVzm5zERz1XOiklA\\\\\\\/YyD7dFClm7oP\\\\\\\/Ki3ocGs2Kq8ze4oHgMp66XBX+2icVauvIjPWs1d8uUnbAFVkfLVX8fwHrVJ90j+AnhKhfX+S8T+K3om0iIA9BNegHlCwhRcJgqf1yDePk4EjG5ithmofPLC0dn9BiJq6TSe\\\\\\\/A3Dqhu75A3O6ztiV2wy82CKCl6fnVS4GMVa398Fr00Qpooqp5\\\\\\\/IpiRJn\\\\\\\/uicK7Yx+OGN4nzl1GDdqOMhO2tY5+wkzpaaTzDfQPa82AdMbteOI2s3s0CrG4+lpn5Ezh0TqCKgmXUjvK1rYWqeVJUgZbZynuzDhhLY8HWgqxGLdTHp4MDAcq9JBMaChPtPAPlc+w8AzSjVPDzvK+kCQsHLln6CwWmjjEeaz7BMvdgHu+4vcdVZSMXFzVG7n\\\\\\\/TEUvbYg+96cG2j\\\\\\\/M1NU3a6zQsbiXVV+f3Oy6JBriUSjIEbb1FRWAJhrdYwZ2SYYLbj\\\\\\\/rOq\\\\\\\/bePcf\\\\\\\/\\\\\\\/JCISgGsFTl5Fkw+jk4lAEQLvGpeXnVP3BqCIs7umQ0QMl0hcI4JSDcGn+ECaL2rCNpzHRjDCdVsJ9TsdtjF8LM4jx1pRlLOcQQnnv6vcCxjazUhbn8sVaZdFqkfa2m+AzLaoP4hAq9nNYD7vK\\\\\\\/6Ez3IU+kh6vKQ4vnZI1yWHSu+hFEtw6bIq5aIzS4isXaeNEHuSj28hEq+OqQfEQ\\\\\\\/Y6dr+5OQ5f51yC+iOiprZR+krQXfRgpAN3DyhWlVHKAAUy2TOfBzHZcc1TdIaUsMm2xIFMYM40\\\\\\\/lS5v3u\\\\\\\/owBv9icElB+6myOtJSevABAOgnTMxR0V9KF5HfS27U1c7Xe8tnXS1NEKQJbBmk+bHpn5rk2fB1c2bA+UdzlATVnS3ddomNsvYFfYTPOHRo4cNCxqKIsnC2\\\\\\\/VHANOWyGDWh5MNTRITYb6w0p5FAn8jc1uyFan2VEW16\\\\\\\/0FEy8S5pnKrtfgt1wDxUKdtirUl+GqeN4VazIuLqkcamKwPWZlH65K6DCvsVkvc9IQ5BnEmaYCH\\\\\\\/GKQudE4vcAmWD\\\\\\\/mKhOVEsQ8hK1KFMW3JCeqBRO2PDjacVyhYj8CgqSafgpQa2JWDlWeK3wEfqWvbsmGXpG0q0wwcwn+a1Oo\\\\\\\/Gaqk2u6VD3D\\\\\\\/iMhrZT3R208x4v+0wT\\\\\\\/IhUCeedsok8yFdMmU7arPhuMO3tfY6XY48a9Wd2QPHgc4HJ4FQTEUiNa+4r41mRfk6I1YheLFe9Pm\\\\\\\/kzVxRLbVEjt0zjgD+eqBXBBen1QCquUqQEm5E3g6vfZWgTg1OZNhMljfKoNLPivYmZTgsglyozYTTFJ9BoIs1gmVf0GcCc+PzJ5Ap\\\\\\\/sTZ4i\\\\\\\/w5JQz0rg2eEa9LJot9JosRh8NSY9nDx4JhpE7nnLuGT3JDBa1Sm5WB6d0CdWdAIvMAwKABqSfBQ9um+EBMQRgAXgVfcdbzNKVQNbWhMb1MTCtCNBSQlOzHN0Atu6qNdreLNUR4j7qznVFZln7x2b82pUUcv3Kf+jYELHgBhJkCfMSXB4yKRS6swtsYm0+h3qmj3U4VbxDeQpQ9IeiwvyynOKGGELdB3Zca5jg\\\\\\\/eDj9i4iGO8kibClaJS1FcXJF5rGUhoVkPVG9UOSb1Xogmpy3lhU23B48briM+sfUbTQ6N+mQgTCgOACw0pC1Zdd7ca9gbGXjvVZtS5\\\\\\\/D8z6hvtDguZaJfBqZ9zXsGfBAFdoyvh5Xa850TjmmXS4lGyR4swF3TitMmt94th2Q1zIvlNFPccR1WoDDrwtlYRH+sHBgEEt52HOdBZxIsnGQwYu1OCgQ5KNH7AvB2RsGp262lP9Pk71BYCxDJ6Z1W427zG51D40Ff\\\\\\\/+trnZVH1KbCKr4ZE3luCbyj\\\\\\\/3YpONxgjaupVi7U++Btl40wJ8uguoQlvTYY+HBD2p+qy5oRiJQIMCtVOZ0GeZAkFvCI5FdWapjfnvt5kYZGoZZrQ4dMvK9QscCGiTebN3iT5Ufydw7JgsmI\\\\\\\/vE1Rz3scZLFE1drW5cSQKY37lmpyqKnXygVwuBL4CJmkaFZRUYhgZi4vTzrJMijfskkidlKD+TPJFKDYaHg09aNXw\\\\\\\/vIqTSPXA+6M+myLzYqwGT3koRzsEWPdMvg7gNYBEIbah7kTFqwDZjgvBXkSWdzq35Dv9CVKw31mBCRpuvsWJaWMUhe\\\\\\\/xUjIykvr7aHg95n3abyspyAuPpHYMecvbN33emsg+jPFkgTsE6PSZvoyAuJk8b6iBCBCgCFOZT+jTa2EQmJOdxaHk4NiX1rhVSsRVNcbByLiy4Gqvq2QhlVoDk+SyWEin1XBD0h9hMunhksLgNYYloR2oUJjWNCknAIM8HUtCz5atWhdzVci7P8ISN85W7Max7xBqQOi6kQXhDSffjewq0wOzSoNus7Tthp\\\\\\\/Ip5qdw8IwpOo0gWgAyWli8YvIG+hYtHUYyJDJcMLFFirUTDlRXC7WTYo6q+g6aC\\\\\\\/9ydEV+k5lhm7kNRBO7HiRFcMcCV1JqfswHb+sL7hO43ojbi7YMA69xpxNjuInHul5bvITJ+Idupp7K\\\\\\\/lo5yMzyzvfrniENTlmu9sNjwsKLlCGZkngCYjfOMZLFYEnyQx4V3CcfdLM9zsEc5FICFJHMi\\\\\\\/V7N5ircwLwqo9+rl1iBSBBezgTIRUayIfn8X1S7TZj1ReVNOSFVFQfHdRheCEhMl5B9WDOsVr57M12CE2zVA6bSE8K\\\\\\\/gnlK9QJFxE349X3sF9382pHzD1a6lrrOch7QU8m3bZolN03vOkGDeou7TESHllFO\\\\\\\/rhijkLZtO8MMDu5QruWvDl17lS5Ubjk\\\\\\\/uvizpc77OdyWZqShshS4QAGq85WTu855kR4ptHZu9TexKulhX9WITdgLRdJmNcwvbAAXQT137K0II07143vHjcfBjxKCvp6JDpj+OCDlqRj9STmZpSloJbbQLv2D9LFgr4hVQvLpGyR2hWvgekOnyLsG56SXo1L\\\\\\\/aSo\\\\\\\/Qy63FO60gdLmNlOWR47EMeiko5Wv+hkhJMRRi78L7ZM1lCONhb34QFYNH\\\\\\\/5Pr7tNNe5ySblMuJ\\\\\\\/ZaVWr0PKtFbFiRrqbMo5d7HjoU46HCwUk0lXvlc6LJEbZwzjPRGPwI4ZBUWAouE8n227iypxCt4QV2HhD5Xp+t7eAeurXDcKbHaM2qmgcAzIaxmZQJWvWBz+eryo+Y7Ca83bBYz3deolYgv4HnC5k8mk+TfA09SkJvTqOsc2oCbw2\\\\\\\/W\\\\\\\/TUPGeLNawqN7DCwe03O\\\\\\\/ATL0q5b5qjRMudNCE5xe34RPdvZVSlCIBwrnqCD84eqcO0fY62sugYlP1vlSt4z5jPWlQot6j2+IDXexEoCQ3mCkBhEJHo946p4zIFB8vUX0dgEOAMI3vMhiEnAvRXhiYS\\\\\\\/hRWB8AG2urZB+qmg+imcK4xlTfQ6rxQZzeU7oT6mje3LhQI+lDfl50KtluRfgs358ypM9BA25CdVuJTj9nkgP\\\\\\\/jK6P\\\\\\\/rPAL7UXlt6dxlSYjAZe+4JqljuYe+pJVd0EkjINX4trLWlbZWRIDQcgnfZxatAMEZ350y\\\\\\\/QZaroLkRL\\\\\\\/gJujA6nVkyjlLD6QCsfSXO4gkWL2N42GokWlnInCq1lk4UMLsMDB9mXItgFRIfDeTTItij2tSdkgV\\\\\\\/GADO\\\\\\\/lzvK7I0TiDXVQ1g8c1TrVw5voNNLiPxO6MmvdRTNLFzV2p3O89JR61agiR0KNweRX4TewEnxBLaHMnK5jFuo7865APOkJTl31t9hWXOoNwbzkPw+i\\\\\\\/HBkAZEAj6EXNtLNLKz5ELizPsEVl9o8cxCp4qMkVVrwgYxDNbXFdBwjTC+YQ89DQqATapFWB91pfhiKldu2OHVR+c\\\\\\\/Ppnx8WcQgQKHMLbMqcIggPz702oqgUZh1SAamSQaCE9r9E7SvUePF5trDg\\\\\\\/p\\\\\\\/uS9mVflfs3mYOUUlQkY05lJ7JnNMz3++KN0ER6njUnTdwN2KuSI+rx6i37N2zYAQwyrLthDcaB6oJ0i0EAQO7oeyku1FqIwtXw4ejwlnbFWwqX8u\\\\\\\/m1IWieWmVn1YHzSSwq8dOTmqUPnHUmlZO\\\\\\\/qS6ZOz0aC+gvZnPtsyKiuEi66OAsCghraRFpMHFPnYnCnt8x8o2PsfZiwE1hxjO\\\\\\\/G5p9T0l7mVblzzWauSieOeAyV9LKqsc9kt2rLgNkIeFDMIN3HtXmpnTChJ1R46f7mXyYxVPtVcsqDUQ+fRhnBgcNP+mB4WTaEy6naJB6XM3Qty2h7lZrv\\\\\\\/FNP9gDXvLLj2Flj\\\\\\\/6SUAdQL3i+20T8gVI6SHzcL+9dRrnoHZ9SAlMcM+3qjScvHNfGcz7Avd9Ob5b2cUG+Bmr3P7DgGD8dqON20xFn4et6k81K+tdxcd4W6waWTu6diEinl60IZE5cVq8YJwsylb2Uz5nIf+0TLj6KrVPzQtB15XN9\\\\\\\/F\\\\\\\/VP0CjkU7wIZPQRkpDdIwK9URfCltL1ssAmWZwuAM+t3e9dZ328H88rhLEo+o\\\\\\\/el3Ly49P9OLXniazoipV4fIK3ED9XPUdng2\\\\\\\/ugaM2SYYP3TuI9J3X8Z+Gni+8wuok1QIcQaot\\\\\\\/8Mj9nC136Fq09XsAY6es40m\\\\\\\/F2epk5s\\\\\\\/t2AJng2mt09MyACjDCdhr7Qj2w4FPSLHSGLIY5AblESnUMZjlMBvyngbFd0jCIhNb2M0Lsxp0PYHhVMZ7vBkh7S4m2bG1vLFBkItr6qGRNagsFSG+fr5OusGKgb2c03thR2kNUP7FZgJDJ8bD8c1nksqijrWavO7k7tUrej09BfnM1cC8yJ+yQURw04mErOF55BHki0yzeS\\\\\\\/JmEst3LdT2rdSFzGKqwYRINW8WlDDISLvvEFhg5yJwqNCP2eCQJFGCOBwDPOqkML\\\\\\\/q8SoE36uQVxS58+1Qibf4A\\\\\\\/EZ0na7e0oVuKrj2nml46o9joY583ZXXHWp\\\\\\\/5ixZ3PQHriSTx6yGjfSXsmo0AJE\\\\\\\/RjwUj6AoQfOUvbyZRuJNMQuNVqZ5i4YSmo8BemJ4gKIo6zAdm8uhIhQqGBl461uzQHt4d3x2INc61GnwXHgPcefrhJJu+C2aAqYhznMpyK9vJLB21h8RpuRa8znIbz3Ipijw5r3UySmVa3447MVDOHtqsoZ67IdX5hmKlj7tYIGvUVftS\\\\\\\/nIdczRHXxolmPxKuOm+Y6V9KUtWweMnOlEBa0Xw5hwKTEiAOG3pJtYQJmyyNjuCgDayJfexEiyuFYrYuRzOz0o0j703wPPGwMqtWBYPXBivBiPazGVT6CTfqC1qCh5cVwCMkurR9DHIkGin+RP7NJtncDNKo8C9L6elPOAcnJFDTdLXyf1FLarM5WVwaBatBFrFkXIox9EsbzWfibxnhjlm2VplghWUQ04S+M67HuLjHVMjb51tlOBoxcPpSAyV\\\\\\\/Losbk8380MJDIm9rKcUPmMIXE1yLOw2NcTGUlOd9NZY3G8k6yiwjVcrVnRY+7t1EAluJne7FiTwDsNmVNKFgs20ScZyfiqW8q\\\\\\\/oDobJdGmUKzbUQk1CdlPhR\\\\\\\/EVTP\\\\\\\/+fWaB6LsbQkFAYju3D4\\\\\\\/V1lnxQIMrmixEh2vPivcZn0ZymKy80cM7kTWV\\\\\\\/Xdp9frqUfBFDWYJLgH9+pot0FNi22GhbwIRuf3VJfaI3lE7b5QSL2nw7JnfBu15iq4MDFzPmVq6dFL3h3lbEqX4uwt6vL+UccD4kw6DoRfmUOWgrm7WfWf9IWEcKq3qd5H1R9o7W2K7lCneFeQOWU8fHE2u3y\\\\\\\/dfa9RGJUmIG0wPMiFv73Ewue\\\\\\\/gYxvtBE4omwtF8MsPueP3y4fArnYGIKBUTuuXiaNY2lD54soPHHK+X9kpcBNSm9WwK74dhCwaoid0h+CsDwP+zjGKd3VR+n5F9PULyTQMqQv7mQOjsAxhVfi7gIhUlPfHNG\\\\\\\/I47GO3wm5kTAT4LLMNiyL3O9b8P+EMCMgknL54dS7r2b+jMpLFbVpffMtHrEO0RFLwDK0rCN\\\\\\\/9grj65bfGexkjRDAMfcG7cwy7wA1zj5LMXted3CBBuRaAGcg33UpAYis6CwhwkodVUNe\\\\\\\/DEH37obmNk+01Y9QsdzDJb3WUuy1zv9PueGeezNTi7R97agzyuOg7GGRK2fk9gp8Pkpu5jHzYgthVc3ofZP0Bt5kl9izs9VM5ioegjf33RtL7slJb4eABKVY2TdrEXvFp1SEY0A6NTtugbEAA93rWGLpGq8\\\\\\\/SyxUBaBN5nTDu4Gr02RsKP+9XfnodtGHPNq7LrQTjXVtXGboSBqpz50W58MYIDQFxiSbUh3KXuRdWOgTHd\\\\\\\/VaiyJ\\\\\\\/84a9oT0A86iqiEgxyDK1D1eMvB8OtY7ORPyS4foqh6zZ19EZCyZR1ovFo81P3lB8YyRck3shQ2kdOXw2VbkpWii\\\\\\\/UPgAUlwvQ4gv07ve0L2hyiQ8IrSMpU5W7RxnSpukrMTyOFVMlpwJvMQb7NOykdwPg7FY0ZtszbEXC\\\\\\\/oiPzun2nJN36IEgO3Ph9lwU87wniRIPa2w9UjrZxWqp12E0XF6iOwom5H3lJi9sGcF8AxV4DAR1VKay5iHUjhxLOVsGlnpsDzDVRtME2dEd4bfqrnvhVkWgm2P6C+pHgmA1EnxUTR6fyuiQT2ygoXOAbJjUcegJCuhomYVaArcuHi7sQdM+vKpDxdm01wbf1hO+dBctQnp\\\\\\\/ez\\\\\\\/fWxdpqP\\\\\\\/rleStheQrHTW6Q8YX+5y7t4Q1JIRcdY3W+VWVhUd0ifaVFL6tYdiFtTtoz8P\\\\\\\/8McEDbqREFO37NPV8IUd2nE\\\\\\\/vAnuVSXSIwdjhQBZZXRD8pORGhmT7S4GKhwFKarnsrJW7IDMvpIIIuQXhepRcpHwDtVAD4JHse+FOXDmEAy6jAin2JOvdVyoeg34q14Si44yXUqsmdw5N5\\\\\\\/DDARbQt6T2kmp1S3VUzBvmdNWNl67R0fVUZb5AKibpY7WsNckwzoU4Hi9fcWOcqYF7miJDWDpN0e9pBZVt2Ra8umO7RsTbVTV+guJ19S8kJhYGzAehMcRz1V5Gjq++DelMjhlVpMIza2ahMRu0jJuPNDjnob+\\\\\\\/UNhKpLAvuNPcQCgJkiXcl9a07eX6Ri0oEEDsojJXwbTfphhLBdqUXCbc+qBBPrQp\\\\\\\/AxHMEmBu+jOcOdJuCQsma2C\\\\\\\/cqUaAK51Nz2482MUt2ZHXNh696oSwSZP1kIs4NBRmyusLtIYnFQR16kzZjEWwgeZ9qObaTbBntqCJi1iv\\\\\\\/wWYxHY+zj\\\\\\\/YpIF25qgWTjnRtlvGsxU+bIG5Wq3eCSCJJH3xfo5O9eWkps46PmMfh2xebaLwyH38I+yeN7PUN9RqYl6tSCkVHUZrTIN65LeSACn1WJXatCWj4+p8JIeADM2RwD\\\\\\\/NH\\\\\\\/oGmnS+mVq7i8KAI8iHmiwXcjKVJTuETuQoZ69Jpej3e4\\\\\\\/mz\\\\\\\/1bxlHAi4dgr8NwOGmr4J+ZVqbD5W+Cek0YXYs8IwgHz5yLyVzBfe0RwgZlISAzZbTJKjK3VDFE9b8KOAoWCHdkdGVvold9RLaq7UdHrymeCAxcejlpMzskGlecXnmhscJ+fl\\\\\\\/7rA9ADpkY99YLPQpKhLnMCVf3eRjQt\\\\\\\/hq\\\\\\\/24AQiIQJzY0qoR+0vjlacliAE9rJxmJGWQdm3ttfTha8vZLxrSRIC96qpwnzDk5lL4q\\\\\\\/jyXRL+l47K3\\\\\\\/toI9Zgcw4nfBXkUpJPkyxHPWoGwjHj3aY\\\\\\\/3WktCMB+qx0R7xkwVOE6XzkEEzmjLLveSmUsFn9OV7w955Q3jJa3pBDbpx+4WKAG6KsqvfkrTuFsKpkTFRHvm4naNvjd0k4S8Gh2MerwdMKRF\\\\\\\/Kx9iUI0fOq4y8Rzk5uBV5XANZBorYSF6c4rVUiVN4cj\\\\\\\/BCYarUK6fZS23GQEu87d\\\\\\\/P4\\\\\\\/foMaO0vbxr+Qn4AiF8TVBQ2UAylU67i7e08VO3mZ6ZVPzH1ZYO46za2j2uvmKRyXb5k6YRmuylYWn2emQB713xahRlStADgVL04NurW1i4xgXq2AE0GjG64pnxQsNcNJtaH8TGA2jtsbSwdM+rw+8Ynl8YPNBRIFc9ykwBvODqbIi9WowReCjl0XwWd2g3wSK+\\\\\\\/ZTbPv4BZRG3OYkJd283HpHYfPXOQUQz5irQIjV6FDCW5W7KO9MXEwZZNLiEyMMmDcyshaSH6cluWbsE6B46FDyJC7L2LR7gJQRRtdqY\\\\\\\/wlGQ5LbFzzy2Jk5f7RVLIQRXNzTHM3OozRwBYYcorFGY\\\\\\\/b7jYkNZMgtVho0OA5EJ+PUj3phvboSBC6zAmYyYf+gJG9Iz4bulT8hOvSHN7BcB+dHrh3c0uB7bYUynp4DNlaTwx7DJziJpnU\\\\\\\/MdXj6IHj0+dDEZU6MsfUByz5Kdp2GVzwvfV8wLFD941pwgWU0qgJ\\\\\\\/AOpVubx6zvNdj4rtm33KGFPXtthydLhIY+0YFRq658j32TZ0S6wuVa7leYiXE1HuJqLtW33Cs3w2wmIIMGAeRsm9FO01078u8tE7gnJkCc1kpgxXW+ADy+h0hoTkBilDqL8yBRV\\\\\\\/URiLJxT8CtXeA\\\\\\\/9eIyVJZ0sQFljvoJ1QgoiMdYTE6icTrUqAeqqKBd1XHsIHXDj3QkoFd6deJ78q\\\\\\\/PloUpHXTNXgfCBTjnGUidtiUoIvtepp+jtJHqCqxhNouJIpQv9rGERH19FhExdR6syQu4oCfaSQ6hZUCtEzsWWiQzWVWUCNEN2NdfpdoigGF56yXSKu7aQgtmm6v4wiRGpSb+EsJ1EfK6rOqOVwZpJKp9RRv1QwqdWyYkRrxxxtUEcBzezk8nBog41Jm0NC4ds07tmz9iGAX4DYy66hNiGU+qGXJ3w\\\\\\\/9Kvc6lTx5Ae+h4mMfs1UH+K7VqIzWxy9MfBA7HfiJVUR+qL9HP0XsK+J2q0DSUM7tiI0ERlyj85TLPKO+lwty4HxpHMkA5PUYIfbwRsPw44SfEJg1TCvoM9Gkdpb346nNJJ+etumaUcSTc9jRWW3rzXhyFubxB11S1RGOxNUyoAyQn6o73rJlxt4fMXTf5rtpHuQ7UG13W6psrGs5RuXFecWJRkFjQfT4C2J63Q\\\\\\\/EnavSGu1jDO1CTwLv3PTK8sPRsraRF6NHGKuNjZaPl1W8SsK24BMxjwteZkekzXa27i7ghWi\\\\\\\/zOm8xCTR0Af+ncIpBOsdyecH2DV2k2V5ZtmuSiZXJY80uW40yviuvpRZwBVMDxV4ZT3SQGvuCNMebXKDXG97Gj6TdRwCN7EDF8hxY8fluS+9BCP7MMCN7Q3LGx9FDWQLE92QkFho+VAIaRG1tFdA4cJvKSM7JORvHu38B7KVFwYyAq7\\\\\\\/oWrz8NHBWXIddZdXyCTDxyDjBzmF7joixoQb2yvimWGUXbE5BVWigXSJMHDBXH9091ziPap+HXThTERdrrJ2K14iSEr1gl+Lkxr\\\\\\\/3f0didP1lysqknXZ\\\\\\\/vA2QGZFy4Efi2ojYUbESWI4qu\\\\\\\/jj9LfFxWqUlUuUaMblroLKMoWgABG4N8vGOFg+CzYwWIw+EF73vh9lX8nxX1\\\\\\\/DPi+kn0rSvQwpLlumabidA9z2nlWZHX7rXcV8ZBfVajO85C+kcoRlghzAs0l0cxRK\\\\\\\/BcC3UzejdZQdWGEE2FsTkwYcekpC8ftyXobgOJzwLe7rfXtf12nDB9KekrBzTOsNaDOYU7A0uXeiXyqGQwACnj1nd2bIsLKPjgmm0BlveLpGDn+xn+t9nvXfSe4ysXAstMOsMYQEriSBGAzuQP1G+5j75ydbLMaeolQSxfoxLwrP1FJN8D0pVCNN8hd+3u24f\\\\\\\/Am9vmMlNwmbVvSpi40AeOE\\\\\\\/tQrTG8oeTF0vguwEwF7tVaiRJIQf1nPqrTShjnY1dcaIFrBmzICNx7jkqGgHOI926Opt8Z6JUlXRrCLr1wyu9sLdgO4dvua4yYx3jk8Ct9\\\\\\\/mWWdF+n3UmG4h8q\\\\\\\/YP7bjh0pcUMLDE+oxFQ6eSWhcB7H928EJp+SdoJe2qrRmI5gUSe+0DicCczPd3qUbkbgP\\\\\\\/JbMMl1f6WFF0X4J+NVWnQDvQZDRIhCgyMaiFa5xMsXlqs2dd6dB2SOUcZ20PXKTWLSsfgKlWTEBWqawIYkyraDhpCkzkj4GV4wm5FDBCbNHoGjY1YMUo+FvScl+J2SDolmr8i1F2Sg0YZcTE8PAjEvOrgYqPk+Y4R96bWG5h50mFmrrh6t6d6fmlT8UqTvqt\\\\\\\/dPFCqpDNio3EbfsOAZUmNfYZnvO0BvkdFjv+0LVr49Rl1yt\\\\\\\/tBmlE4CrPZRkoyQ\\\\\\\/dTnsvXNoxFKeH5RMLzWFXqB9exdpOVJVsGgShGORhkOu0NIQz0FJ7ja4BsKo0itCezXV0je5dQvi5kmd+v6EWbBz24DVcqa1i2sDhpLJhHZJeH2W4y4meDfbvHSnt8nB1s4OeydZVw07dXTRYgUlnm8a5HFcLkn9JAEusz6Z8ON70ebxuAqQIIA55VQXk+pHsGxRVPwPexiSKGsuwU3OXoD\\\\\\\/y1scFSo\\\\\\\/nDfLdWugEs0+my\\\\\\\/n5++V0oPvYlK5v7RgA3Xef2xm7zNoYIhd0\\\\\\\/NEbs3dCvAW1XwuAwN7Famui\\\\\\\/P6n0Spnj6cPmYIqaGKAU46tCnAGev\\\\\\\/g\\\\\\\/rZCJq8siXAVyqCkiSBCKRAFCgAxxgtW8cFX\\\\\\\/MIKOgdKjmFlZNF+cyqshgvTv1iRvgn8yhflVvjKju8h63WvtIcgiQTA73E9cjhHsfPEpaPXKFWTar+S2QTIWE6FukkaSZ9ES7iT3jyIIDZGtidz3HShLwWj7S6jKTHPhXgoeyt4S2mPpecXLN1FTeYacYCDS6rjnygPYupUt1sfQVWGaXptsqfOujEjCZaVxIKh5OFZF7C3CchQIh6RnHV+H4c\\\\\\\/OQtLedKEbgoggSeco+dm0CgTqRdV89JTer+cHJBY5ynAmZZy5dTWIEwqKv6jsJ+XkX84Jub\\\\\\\/WQHQH\\\\\\\/y7GhE\\\\\\\/UdMxj1NBN5sxdCX0wRNyNsxeUCYMIWECIgpfgQiMorwBirXTYGy19rd777JD0\\\\\\\/Q5agOljXUQYE0P6uQTP2mol5Plynk674Dx1AgVbD2k1xc9Al4mScOhhH7sqpwVMuE\\\\\\\/vTlT0PXaeyHJp7IoOcmkyf\\\\\\\/iRsKRJk+6BoAd4pIoOySSy94HXfwiWlNdeqJrlryCgSFXLgC0zVomGR5eji12I1RuI5+I+vZx8oriQMIImEd8vB8bc+PqGBw09tbRPWXBrlDKvia5V\\\\\\\/4zCmq1aaQPnI1bUeNnZuarbsSwPfrqhGm4haV0Hqtf0e6jgKf4WjQ7UlASonwDojIxmMB3q\\\\\\\/hjMx6SZafDTILvG8W+b5QXf68mXYprPvY3ZdxVl75nYjbjtXBg3Nu6pqDJoaf4ivkplSMItf+4rwERiHuH2I5yXCAYTMuMAu4czPn3+eI2Bhy5h4H97WI5VX\\\\\\\/4ckV7HM9iremIzW2wd8lGzSpk1bqTu+oDC1ClXMXZu5beP6\\\\\\\/l6RgR90XPYEckmEpzIRfDUBg1fXiu7XWYbKNvkZS3Fd2vFstOs6ICmde8YIFyzTPnmD+RHPwO5ChQftPW7dXK3Qg0IjFTJh7PpJJQEbhEThxvXzk5TX2bmG+CBHtbFPOGqW8mzHiJ\\\\\\\/6BAkQHWrw9SZsGyQZpaoG4k19t6DAjWkiEAjlUwHLXEfPK2REViXDeeWR2UPpsLpAi\\\\\\\/qXojUydrJyFt2YU4F9P\\\\\\\/xncKY2mFdfe7Xmd5LNbFoLCHXoHuLDm\\\\\\\/dL7sWghWHOo3hPah4DWi9\\\\\\\/w\\\\\\\/\\\\\\\/cw9CTf6v+wvgHV9JDaAm9Kkr6WmNa9k1QUF4yHzOo4EP8e\\\\\\\/mObF6bcLV3zWPx+\\\\\\\/KoSy8Es+tRDoL1nEfVruuEbk5YeKRzgIRw+PD4KYrMDfPsK4Hu\\\\\\\/OOgt+ZkZrBD\\\\\\\/b00NzXiKQ\\\\\\\/mjzedNFM8zCbVUPvU8KB5B+BMU9LFyWdXdL0ReX6nUO+H3hWvw9OYQduJWCtLMOT+\\\\\\\/BWTKxvnfL9bkZ+lGGQgjWwz\\\\\\\/9zJ5B6GRUE3FyVVAlFArpV+I2CQPCjpbmwsWZV8gp\\\\\\\/2Iz8T8e5qxC2ZhiXR7ZytiZ7oOmReEZj5HzNn0+U9yWCj\\\\\\\/mRFX+Eha1tx2XQ\\\\\\\/XaQisy3xdTI6pefCOqPYz35KH\\\\\\\/XaWKHeceFLNxYW1Agb8umuMQmPKOZ9U8pM8X+7vV1YaPNJyPi\\\\\\\/7V6DQviGKlkN7w4VacVE9WtB2l1BEZALTZ5GgTk3Qi8+Sowt\\\\\\\/suUNor4McV9pOPHVllx2XgEqZs\\\\\\\/EZKrzKLp5tIKizmbEyl7GBg\\\\\\\/Bf\\\\\\\/ElXwyujRCS9ptHVjgGiw6Cq4dAr\\\\\\\/nkae1rW3D98YrlC1fVC+MhnfPTDHpJ+9iALiEZTbp\\\\\\\/12TabBxmiEOOLD5bv67+lPXkqATz13jXOj2E5peqp7AwnorPYWxoB8YtvC2E+QlI30VAqBp6TtdJNKeLjgCmfFvVSnogFF0zQ726SvkzUAJpPmRblsb2rctMzBveA\\\\\\\/U9IVGeXHkcEu5clmHpI2sK4qvoss7HYKg\\\\\\\/Axoi45qLX3Ixom5nbJrSBk9RjAdy9uvBHhI5qFOdbFvBbGhR+cBESgxzjm+1M0AuyjxFw7w382JYXi6Y97Wp8n\\\\\\\/VE9uQPH0WLHMbMEpnZ1YJjkupY82Vzvke\\\\\\\/1E8dqLAJcdFrTg7i3bM9UUlVy2hBfAa+Rqsf4wplUwpOiGMI3LpAsWpJO+KOaaVrcKhnw7\\\\\\\/Orh\\\\\\\/PP4W4HTsrVK+9NKw4DinbWDQFIRwshjkYpjp5d3KfHjMIJtqOcDo2Gm3QAGEpUv2RCHaHD0XGYmIhZxrhwfIeeH3yPnx9V6lxOr8WO6F9t4gbIL\\\\\\\/4g2o08zVh8TSaWX\\\\\\\/n0enaRJV39CwWUwmpKM4RlUIjis5WoWWMXnZsE4jnDSQiFnCTH6qDqb\\\\\\\/t+cBGQakNaNjMTqDOa5RZPQK5tXojSX4G8LElORoA1vqR7CvBN2e\\\\\\\/T6N1e1EzCvs98LFK\\\\\\\/BiBFV9DW2MropG+9wOXhXUQAL3Qc+uAZNfEdhawTrP8n+kt8RQFvRl7P+rx61GEIKyqP2t9Tyo4RRkaw9v60ugp+fJTj1QodHvjwXWD99mS2XIBP5u2gjxEt+\\\\\\\/ZP7ud7p3nREbZo9NnVK8rMHNkO59CO2WeLz9f68j9mFAV+wA58T7V3pT0FaT\\\\\\\/kCde87J9+6jruk5sMk1zUPkXNuBx1BLHcParAPWw9uu1kR7ZDZ4xjgyyqlSOY9feUe2taRc0zZiQQShlonygh6JYHUMTkNP1WY7Qcq0543XCYMcIDuRlOsVHuyxuqGEUvnGumm+M1cTYIJOBI4lS3DgDARsKBY16LXxIkZFBsvAN0Nx4iAmaBqbazSDwLMZTkcYfdE4DqI4RNvap7TYu6ixMjyn25dNm04nbuXsNX9EpnBvML0fYE+xfxgEkLAptn8073zta1wDwBYqIfHJxfj6wTfhqoDIPWkK2BmyNm8WfxHc+HIApao2tMRCLvoGzWNS8oWz3NMxbsZGXOvIXMsnC116scjD9zAyvVtqITpWp7XRysa1\\\\\\\/pAybNJ6DfU4iqo51UHSo2oNNoBSRID2q48gs3sBPehcarK6nB7E0ShQBpeZ3qKRc+rtxsuGB0TZSYZWfIuPpvDWmB2nBXyAyhQCEt2qZYzCYZbvEk6rm8hYYG619YOeLorr8+KlGKUuPWkDcvI7HRy8p4jIIsdG2EEHEJKueyBn87L2LXXNYBntIIcvi2SLNLUVHZz4rdWYjO12CTUzBjTmqzdMHx+48NPNCiljNhCPHLTyLELyhiYb4RiFtBIqUjhOSV9yKBfSZaVjXmVoa4LMIQ7X8Usv0Aa9vrnLXRMqMnshovas\\\\\\\/6YXqik\\\\\\\/2iRqfkIdaiukfXslSH5M2l9Gvi\\\\\\\/pARR4egZGwNQyHVIm27JcRNFJU4Wx+JBWXXBkpRhXzDMh1PZeHRMhZnzDuOjBKKGlfaEzpaukCpkTiZwl\\\\\\\/DIPHcoEFCrs3h7UAzF9smzp3hA1He0T7hlOo7UAyE0KiZSc1xqSu0eicfDtDWtC3jOYzZdvnlIrk5WUCFM5u40XntUUV6iJYlLh4\\\\\\\/ZhiclWej3rqWLYS9mWfZohBy+u3uc21vSgo9S6Tw0Ftm8zBaoWnoaoi3b3YtLzuEg8vkG+KE\\\\\\\/rBh5IZWT1327tvKFsjIXzXRQN330DZpnLnpropSVY37XyZy9OzMtPavXKO3\\\\\\\/xxhfMYWLuBEuepExJCPOnZoQcFNn5cVEGfYAb+eJOhOdS72ZaoBnmDFQs9qLTwp380Jw0pHY7IT6m8Jym3xJ0Bj03Fzmyx9FGexTTUENb10zVd7Nl42x\\\\\\\/kfY0JV22EitvbJzO98V\\\\\\\/8UkHG08Y7cxkKNXJGaFy2xnlC1QpxtflMzb2mK\\\\\\\/kxXpLn2trJ74VkqmqAhY27N50pAt6vi7hHlFvMe+zXUz0ylVHAFuoWohwYnRs2rGafUcqcFAH\\\\\\\/Pmrn7xrcZi1EIuXH5Ru0bWnSOIvbQn9+4oKZ+suTXR3eSUWZFEGcKWj58cn5eDfGDPDBYmaUAz1\\\\\\\/w3xc0Q4M0HwGSqO18ik8Fpi6k0CoWlPk+ZZqcPZFc+Nw74qDCfHSWBb9JeulL2TiOna0LDAbFXQlq\\\\\\\/+Dg8qfJ00JbYZTzWdBjyjlIOGO+izCb0NwTFxbPTZ60kw\\\\\\\/J0VYzr9Cs5kCjFciuyCAaAcEg3t8RYpvKKUYXPpcYt\\\\\\\/UQyguX+yo9LjtSu6COMCdn8v09yeqQ1t+yEY1NPjNjxG0w\\\\\\\/ohxkmNekisa7nhbgK4pvfnFPx2LublSl+s7aG+SAFY8JRQoHUMPMK1VD2tpfUduMSk1M2Z8GZWpevIiPE8av90iqy7elrPO+cPCp9BHBcr4I5IMtQd7aqxrx7m58s2mhYPgi5AjC\\\\\\\/xwhNRsCmHh0mMoE1QSidQmdyEGNl2AZ0Q9n+2\\\\\\\/9r2yzT3\\\\\\\/Yez9oq7z+GJH7L72g1UScUPf\\\\\\\/ikIXt+HnLoXh4ehMKVwvUaaslZsnQLS3uAVoo5MMhU8trgXFCPtXAfy5DEv56FIjVY226yhA4B2+iFF12Cx1Gmq1To7+3krFoavjyuZkkZwvMNGFDWEAVDBqAo95if1TTqiq9W0Rr9o5rVXXiGJekVIsp0TbRwCqzsyQqE5QyVIQ7BxHEFME36yjwRyb80rE93yR4Ux9jB9iNbe2qmmDhu5TC7csmG2OzC+On1AvJ7kGoOSA9\\\\\\\/gSJ6MuuS43YdRB6OVuv7AMVCUOmYgSMViwOUEhjRYK8j6gfQQj6P5NBQy7lWTPa2Xzlk71TA4\\\\\\\/+h+XW\\\\\\\/f9JfdjQ+zqa+95Ap6F8QcZC63dBnj3VVleNcPYzZIoTC+wT4PAcoT40AJVhGFNvf8T4pj6ARS12gH1u5oupLsGbHL62N+2ikI4eSy1e1rzLQVsQlm+15WOeIblXiRULU7Ws7fXzTrYTezruVQf0XsEny8+nvS8V2TJPknYnMs0Lu6LdxiKitySAaDaLmayFSTaNHwvpgLl1LAmYx\\\\\\\/ggn22OgtYrMgkkq\\\\\\\/ZuRJTp9dpc3YqTBGt2Yczd9\\\\\\\/50hpNamXDmVlEjWTSHhp4hSRKeJvg7bJTuJgJOq1O9fXnnFXrA\\\\\\\/xnjluOhRwf6qbCcYcVPquJOOB6XK5riSt8h4h2iyIdKBXILEGk+2IFbnjuQjjEPKrgTyasnvS5dFapOX\\\\\\\/bhNU0BAXHcKI4ALFV0i9k9b6NQn9IfgMforOSNNnobtu1GmyqNHM3oL1JhObZIITazEpZCJJk28jT7\\\\\\\/Ozj5ph0mY8yQZ8N3C8SkzbhdzsPlU0z6PWizHhQizRcwMRWY3F\\\\\\\/9uaLOHi73Iad5i8BEaGR1J85BR08SKx7bWF3B12gNu6wB9pNLTMnb4GQ20njBcTZuaEQXjzlLK53QBxr1QBOdY2DIfR3jF2MzXXfb\\\\\\\/34HzAujgwUFF2Og0TOYWVTUPhTDCKx+cFBrbSHjxZRDMe6UoWqCfPiR+IsFnDW5W7Z7IHo0ZjtfTu0GPx1BbzGlx3rUM2Q1kY1vS6FzNaCPd879C4wkCsTCfNN5q06WF7by+LseChe5GpyY7N\\\\\\\/JzGm+xFd1QfgH7tAuzOyZtxV5wNC8kvBeMYIabzEGo+YvaDKe6rjH1vNFP0ZJ02Das+HeETxzKQNxKtkJvvtxTanMglUlELgZ25iTOuOctKK+NVeRgbsQuBckD4pq4XMtuPdcWhkd50JOSPHs5srAdhRqzC4ph42m+\\\\\\\/9g5p1IhFt5YnAKoNoqq44CPWoOBQb76qS16XMrlkXwdP8I9vwr6Za6JNKhKH5B0BjH2t2ktikI3zFrMFsuVi5EOHPsEaxCMSRn298u2h+yDy61DQLjRBfx8C5ltpW4siBK6sf\\\\\\\/\\\\\\\/ZCnigd8NtnUnRVeRXp\\\\\\\/e8BSGP7RiHRFXO53EPWeYVVRWCzyPDLFxDFFYSntxRtDk\\\\\\\/fL8\\\\\\\/m+0dqcsu3riPuQDg04AXeEOVoIbBBNYgGvKQLDKS6WJ6RHS4FYE6+Stux9INGv7jZoNFjDY03gf8ZP88JoslrmwUCUnsWeVs034THJNnsFV6qm2AzHnd46TBNPTbNifUoQf2NuJ97jagzrCcZXpD1OHd3RPk2PJL2VOt23TRSYK3nUweqbx9nvMqMjPOXfja+mzNcXel+Qg5I9KLQbDtAgZCSacMM\\\\\\\/+pn6TckNB9H4XOtuskFWyyMtkXkFuegeF7Gm5FFC0bGBG2SB1td6T7K27aPBW+FsfYdXoeEzT2P2dfKv1FKmFP\\\\\\\/uC13NYh+IPvAFFZdZyTcCL7TFNkC4cuOeD6NIMTqvjvfS+xq9rorqy4LKA+qBTeEKuskLKfKYjh0Bwc5jHg0PJAz0nE4WZ+pj8SH29jTOKxiD4FTWkTcAzIPrAI9kSgTMhzgX58+NzWNoYuIWBxn5BqSTQMzVuoDqlyXeRUqh3JCiBEbvLMcA8DacUSuzKtf98LkXeieNwydCHHqR4Gh6NTDSQVyVoN4ScWwH19NC6fwvPaun2\\\\\\\/S7NcUXxr7vjOSonG8lAPhlXINujU+5vzFwfkDGxEo1MX4S0PrYOseMghzl4y85zBo\\\\\\\/rESblUns5zp2pmFdCEaaVG8Qny\\\\\\\/La6eqFf4QQ7MiXgWNpJOIa\\\\\\\/GiGp6iWMQCAFX1ffpUmqFp2khut8Dc4vQUc2KwF+EXD9dLFdy7HNVWCxgBMHCgT7tJqOVN89isiGWOvuePg7B1gz+dpWTmuRrpDGbCftxEfRPwV7yAzpuqzbpkErHaYJX4uTpIpdCmsUsdpSh\\\\\\\/hz0Y5EUD0YtvThIjIRHKsqgThxLhDk4V8P9uQ7upOreB1v2PArZfLG+QJulGSMwJ+KcgtcU4AMwqAyTMUrp7J9zszR52Ho7ffEa3cBDRVE3garbWvNf1p9kvuYBw\\\\\\\/Lf3t0LzSgek9HvnoX7B7pW6Ry2BWfr4YOCWH3rtTtlFB2ffmeNpRjy7Chl4G3BgDQpiQ2ygm82+wADqftB+W0tVDXbxC0uHfUMtPGgaUZ5fAX8S8OKy7naOmszJDHcIIsji9scjlV9vW\\\\\\\/fM7OB5PNsge4DUoTs4I7CYuto+phfhMPRV6E1fCPcYmyBrVKcaAjs4CsSyTnsDp0r0x9+JF\\\\\\\/bMe2dIeTo6yYVuFGaXcQyrCmKpvcgPDEsVXd\\\\\\\/ca9La5FtEJqMnOSHqGqBFi\\\\\\\/0B1f6TybET\\\\\\\/TeXIQOy7x7Diekl\\\\\\\/Iy4gaLG7gnk19\\\\\\\/8RR5Pufv4TiH76GW9\\\\\\\/ZTiGkI7VtnGrHD3D86+2pzrquixvDZQDyYPh90UHJb0Y1\\\\\\\/DJlwp60M2GzTKBAv9ev7y9AFA7mq8LnrjCAFzJTNrWJQZY\\\\\\\/ODwVdYRH64iYzJG00AS6VH9mfDnHutvSs0J4qYC5oWEzmk682UetZa4Car9mntEb+EW2tG9KDxUlLBN\\\\\\\/O\\\\\\\/02K2ph\\\\\\\/QYiAg0tgDHaYQl90F\\\\\\\/h5zD1Y6VOZFx99ouHQlGu913gWsPR42PoedbyxAS2pNFV03qkq+CRd9ZpjO61\\\\\\\/o22D1evR7UO8BqO7appQFT9OY+CbPRnPdZv0KYHc658i\\\\\\\/xDAznLIniZM5JGxs7g+B2\\\\\\\/z5BuPw\\\\\\\/K\\\\\\\/HrJTsu0OtbneQ3mw6ivp267kMRDUG96mWJIayURhdktqumD8utJeikIRQwXaN5Koth+lfD1uKPZnA6Luip5zU\\\\\\\/g0LH1ukOS+snt0oE7YCwAMCc+yA+UT1NhgNpqsjzokaOOJTew3GX5vBO2Gpyt36DSsOd4zlJ3aGzRcfkyTlZyGoITbP4gHxaRXxgG+DdIKAmX6Pm8L+2HTsH9IvXiZUK7msGxRVmmHDswg6+Ixt4MvbtLyD4apGW\\\\\\\/SfUWEQXuEIYivXjHboHT6pgRtAFIXY9hJWatioQPqzhBoUnZt1cwtwmWgVr+MHDTwFpzge0+2ZUnB5AUKGSwvSuqFuEnhcBINjncmWhhx3L1GwsnZIWPlhQMYhkzPWT4I4HJDQeBPgD4pvvMzCSEO5xmTFqlQe1ms4J7Hk0YtSuHw4pv4mnRsG8UkndQAFvNgCzSSePedZ7sf3LPK+ewxXfjNzMkj885UJ\\\\\\\/UfynYwpuzqpwu9RbJLrbowrWj7PlR+URDjNaZ6HKjjWcQ+HDfbgG9jNlF5f5Hzmamhgk4WdHcThkNtYWEoC9quhBw47E94je\\\\\\\/7r6jQBhKEe2ca\\\\\\\/bbx\\\\\\\/cO2UYETF7kGeRrAj6iomvm9f1\\\\\\\/kfOHXkaZyPVamXO7b30YYMN6i5dq+Hmaihokr563EBMq0Rnlsw1IS0Ce58Wu3wCEYbNzJpUnPOiFmMZvaKLidVeBRI37VwxGaZn6ScPO5xe+CG5s2LFKicxegFfMOQxcIA57Oh\\\\\\\/tqkuqcxhXcZZCCh9eEhRzMR07e82SVelfCqMZOnMs6454VQs7No2EOEKotU6ppvdmleVa9Wdo9FVd5JPIVgbNsp47cLXQRlqzNpi4fX+tZrinwetfPocUo6uJRzDTdNlsW9fEIJbK2VlkFmJJlNrNy20HAELNO9rylgtrPpv7o1k\\\\\\\/9xGOxdwuj9eeVmHLcA0R\\\\\\\/UNfenkxZtIcyUFzrMxUoIRCJZtPzWrUOtyJQ8wpxdfuNbgwPd1PEqZGfKnvl\\\\\\\/D5\\\\\\\/ADBqIMAudwnFP2Y5AhWBiqA97M2T4YFj6DF7QyxAEsO2Mam49otg0qpw2+BVKx\\\\\\\/6YfqYv7AxnOgw\\\\\\\/kQDo3PwASVYXWQS8MYxr0LBmjjcHKyXLnmFzBSnlbd6Grl47kHqS+Kl2MaP\\\\\\\/GqXI1U+qFjiXj8L8v+goNIGdaq+7heEp6TvS2Yj5iNZW1JE16NY76xmPOFu7oQnAWwCkKWd3hRpHUk1kOYNhOkeeFXVULpGIOqjSBse0WSe0JJoLy5D3M70rYBJJL4r7n\\\\\\\/NQYP8ERsr\\\\\\\/JV5vKmlIMXLMn\\\\\\\/cJ9c3nZ36A6RyNk3NsISeHI9p1x+mSnJSkIB0u1NVy9YWZJsa0\\\\\\\/Yoft+B\\\\\\\/cyhc\\\\\\\/3auDnIkZTHnLudz196KDI6XiOFzw+NEcU0Rf\\\\\\\/G1ja+OGbTknFQa14ZUSpstTcIYhibwwfXhbxHmZDYzq43tYecI8QBFV49lSKwgwq6O61eanXcTl86Uxl1BOXsEQFr1Z\\\\\\\/KRlydIsHrrb4b6d116791LnDA79Z9uH4ntzbyO9s9E4+2zDhnBvcbQqC\\\\\\\/QlO5+WRxTaqbdG+wyu8M8Y5HnkbiOC\\\\\\\/TDJnIbZpQYsU6cziERC5xxhMMzb+Qz85yNp9QgCtYXRGD4k+y4VMw+RTwtazXdvOL9cWELhiq9GtIOj\\\\\\\/2ERDdhG\\\\\\\/BHRsVrAuMx6Ab7X9pGGoAGylOiZRbsNsHmL4fc7bri65QOR+KRxVUrR09ZmkHnuXjG9T1QWQBL0o9aOY1VnpFm6mL5CXA6PjzY4vDMmyDAhX51vqM9+kCrpuJRo69FQgrwLjJ4CnvYWUQuEvycblQNbuiTZM\\\\\\\/YtbFYJy9grE9Z2CE3a14iGp5OHqEp9zHGZTya1F60Z9\\\\\\\/zb5GHWGUAZ9EdfL84ut4AIqTgRRemZVvd76nadHtuv94viLlijFQcuIt1MIglo\\\\\\\/I5Se8VIW+h0kAGcdycN\\\\\\\/qPHZTX5HCOwKPHmdcU9u3XZXEmiH1HKyeu1pHaH7B7uDnNM0u3HGZCCYfpsyxjVesb4AhaLDvtCvb2+IDxBdvNqhklwH4umCrMp1BJzN9Xl4H2emmgVVc8xoilRD1am6Y5xRIxzehclyW6ZYJD\\\\\\\/UdFRXFKEq7HyRBhYZr1cIyYkqEAibbysKkQIc8mN39cqOG+sd9W9QixV3QjmMjmweYNdrWI9fRDnKFZSsJwZ+gXbD2ICa5bVfIy11xNsYdu+idupycvBIsU0o8BvxJTPQayfShguYQKHvt7luysDOXxwYSfhY7jp9INx3H91XieXpGxRECxiGKpyZqNjx60joEjhTzICClRkkhkwlNrz4Y3+LJWGDDS2kszF3pdOf+tpy25GyQ58RsO5Ni5Fy2tV6Wmxc5L2VVu2Naz7AEeshw8wVD9PkKytD2xNozFb045zNhC+KHZ\\\\\\\/vRYY7kd5OKbd931x18PtN1vfg56lblmgnp60s0SvjF1nQXSb9AlbdovkYX56BA3YznjDTE2FhIEF+UlyguqiAc7Vm6QlZi9taNuysXK4vzA\\\\\\\/1fnaVeqaRvFSPuFGffGjL5X3ZvPcnmSQcbac4qjUoH3FjGja2YKrvrHB5FMn\\\\\\\/YJgfGPtkCh2Ets1sxTVk6\\\\\\\/Xmocpi7I9lWXVtg70Tt9IfQGOE0e5l2ri\\\\\\\/FDxLpeGkgwaXd4\\\\\\\/1UMCAi5wyimLr8WE44PxplLLqqXQNcVrX8NymAKbyq4u0wetCCQ43Uq+UJNF2Mr1a37583jFB4qlIqYd84vxzMGtwk5MQ7MvTKjBRId6zdkTRfbnwgKzIOZxC1Krws\\\\\\\/TkubyzfwFIhUJ8zbSggzysiOEm5njxKjd3qFF4EDbK7tBzavkD35KxRxXEw95jZdtj9Yuz6I4MANZ4JwX0SZXaYtDbdFZg\\\\\\\/jJHteExuyD78mfJHURplgNkGs4sVPhOHmGMq6905DjlJvuvb17AIR1FjO7+\\\\\\\/p+q90L8WHAQwTdk5KvkykvJu0MzPVwygCBgkkzAargXtsvUKEE3\\\\\\\/VFpX+pWB4HhqzDKZZ7zkOTDavXaytIp9RjuUwbDuzXeN0QYQ1asASeyHlwdLOmjHMXAEeDzAyLWhp8lbVR08cxrYWPEJKtbc1yCcXQhVfFXJ2n9PR1EQQ1HiGTu+cCz8RCAH7xxz8vYc5S336pG2HUN9Deaot+hcTAh4WCupIlwo7OCKALhCJum6a4g79K\\\\\\\/hpqRG\\\\\\\/RScW3CBKDFZ12a7i2kp6+rTtRLcGuPDKG94gqaaiSZm2JiCTatcTyLpS75sEaYsQwadk2PeafKOUp\\\\\\\/uy6fZf5bMO2fyRWZeOV\\\\\\\/3DCQwdzhM98l\\\\\\\/1pIdW0Wgc00FauJ1Qj81rtfQsYBcdmTWbQ7Fea7dIvY6Mm4657DrBByVZ+yZZR2XVNa0l2Q0AoSzXX9bDPXEtLmnG\\\\\\\/0d5+MfFJHNbheufF95q7RhnlBCYMSJADA7Dmees4ss6eD2+LTYeQgPy6yUrDQmXy33sZzNIWDLHPvVqiFuYBTr4PPRt0t6BcbYiQfkYdXShRt5ALBfjEmB5AlH6rxR0WXQbepQgAlkRrkUgY3sX1tqtDg+KLUYi61kQPhlVIZqbhkkfEVLrVCcKKZKkKSVMBaHxiuYA1Ms6VQrLMb0ozgcY1dzGaCn9OODNaR+D6xsSfLMsbbdZ3TnF21KHKSE9ii0Pa7ScxDIEATo4J\\\\\\\/eRYDZUSGoCTMPMScvhKoh5Qq8Ez6T826rpM8o2qO6LInRJ1g6AE4Eb\\\\\\\/iyMTlIvo7u40nDAANLZeoXsEetYORHVzjMYecEBoc4jmP+2boS8r+sCb0bNvHe2teu4Exe3LVgtDAiV2eVl8D+N6DeqOIVqncYctCNylCzud5yD6phNJjr2R5iUm1hXRx9lWSBar+mXy18TpXHzMamjf\\\\\\\/M4ltKXF4ErIc89N6TDW1DuHxFFOoDBeTvSTjy\\\\\\\/vxRZ2Zrbv1ptYqU5TPtBiUgbORITTRyjn2Me3K8fSdzW9le0rI0vMODK2CdlzqUbWGLsBjb5eimVDru5nLUTOWhPyQ4IzWyKSJATTeJsP1t3GHCRXQh73Y5Ir3gqg0Y4m\\\\\\\/6xzUN0fANNaxuKUaKKXychcBWo0lihaIxLAV5Dh3d9bm8CC8SylGufwUUuVmKnCY0RXQMeby29lsI\\\\\\\/AMJ\\\\\\\/SCT5q8uHP\\\\\\\/yF\\\\\\\/aY1TpoumZlCZ9fMG6ZzCGDjtHgIsbU2u0Bgv3NsvuaD3R+tTDN6RFWRD8l+qwvqW9f3oDB3J1upq4t1O\\\\\\\/u8cQYBsqDHoHh1IkLXONnYsjYBdys\\\\\\\/WDcJk63w2qHbhU4E+kRCYztZDTfa6qToDKaf7eLs3\\\\\\\/saNZrFC+1Wt5Rh+C91kaAnfbmyOK4NVc34T3Dze\\\\\\\/L1idtljYs5yC5+0Z2J0P86qRXvE5551LzgKMJAv9y5hPHLBPU13rbrTX9jjwntpikgTUfpNUpQxUP5MIu40ki4KEueoSuEUTEgz7LLZEEajsJ0z2gNY5DK4B3eQiLFgNe6TtKvCUtbg1Kjj0PVBYwARnwFG+OWMjMPXr\\\\\\\/faO2Ef2lJ8qqjbu6AvevB9b1E1qmxZxuPy1YO6CLgKug0ziOjxt8VqYIbRwWUEnfzCGOgzeE7sK4r4NEgfx21rb6iXq3liyCTzx3E5pYUDBsdmFv+TiYo6VWXJJB5IP7Cq8Y3CYV2qD06H729OHOA1nWwh2bzm7Xah0186fL+s2aK00i6+jx3tpRKNsieeFNdlkePx\\\\\\\/8Nfax4nd4tlFG4gES8\\\\\\\/ATRSYd9YhKM0x9AUJ74o25CvIfIeDhZMQ4XVsbDhE5Kj0Jm4dd8vBk6sXbfJhXi\\\\\\\/AuCW9VeXgIvyCdIkD4JF\\\\\\\/mvn98jPpKJ4Pgaj64WWtEFXpOj1sl\\\\\\\/MV2R2YAofd8k+NnGeSIjx2qP0+SH1X6\\\\\\\/IgPT0xqIyHiKDC5xdv\\\\\\\/zAtP1RD0YI+sd8L1NJNb1xdcJC+h8Uk49OXMNx9nspnkh1Sogl3wNEAO\\\\\\\/YaTpxyDxWX2Pe78naIFcHlMW6DLIJPWnCfNO\\\\\\\/C\\\\\\\/wP7\\\\\\\/er2q+qinzF8PP3nWQNKdEMXMhJz5aht1IBWH5lTVhOhqgVwdhwDOdJ5frwANRpHPMOP7LiFp4CqR40u49zZLf5eGWi4iAdGOH\\\\\\\/sh4pxhKHjQtnVSeccXTLZSvptm+6LwV1gYvfdpt7sUexdijpDoFzhrFEheTjPFWOthn6R07nr+QgVFTNHePW81t\\\\\\\/L7m8PM1tJf6Swzbigq5USpZAI73Skv3iQyOLpDkkU29uKWBSEJkY38ZutGbYNBIJV9+Tli0er\\\\\\\/M5PCw3Dt7JQE7eNwpwNsYYQwzTM\\\\\\\/Ghr\\\\\\\/Nju7TEl6oSRzP6vdDMJdRN8jNfReaPKBsjSR1ExrVISsXCYrUtOQStEpI5c6WdUIIS3dgmmkKTS+syEBeWTwklFWJZ\\\\\\\/RRlADE4eZeuxW6x4gikAaEMriSh8oAl6AndXu0mS\\\\\\\/UJzAbLduwS44imRK\\\\\\\/F+Ep9xiSSyRf3DGwn5kXHe8j4tB6ibs2NCvXIm+uRJ8OKncBsdEZ6EW1XxePJw0QtXdPZtpxaPhSVPY72kOoKsfyoQlBAImj4wHLVkKuggPELurFYjc7Ow+VB\\\\\\\/CvM2Icq\\\\\\\/lN0eg4k1Fhs3WcQCAKbS+lIl1RzFJjUm+RIEdi3vvIflfO14pSS7ePJTRSA\\\\\\\/d7XwLrhwNhGt4kCoTT4FbpqWRoj\\\\\\\/tw1Xnf3SaG75ShHjvZQWkBEnV6ZDFo618vWmP+vpE1tW9EvLYSHg67oPPH+\\\\\\\/CgqZj4i\\\\\\\/RnuJ89eLggEZ5g\\\\\\\/YPwLNV1837ac0cn50fyOQqrEe99+eLnzzFoaKAcb0+wemRAvQhHBcGLtwnfflRZNMrls4uC3W7ecBirwdzMK3rD+RMpeUaGt4aqlSdiG+3PUK\\\\\\\/Q0vPziwUm0Sd2jizuSfVoOlaQtbtN6WMdx6LYPd7PCDY8V+JoSV3dSMZ995xFhLVRIF\\\\\\\/SmSN6L9Prt98KVtVxSRz576GK0TL73EFB8Stfbx6p4FqkQWK6wKsS0b6C8IUcPTjzM2Lgo5YBaJpIlsnHQm2gr5doJdEDjE+Njkbbj9YRZX2lySsiwI8ogVMzrHu973ty2TUXeghS+60T9Fei1nxxUHlkblRao00MbH5pYWAUbnXjSdKAeS\\\\\\\/4iLiieFIo5lkZU57ZDkliV3jNlHtIopPyXcpu9\\\\\\\/b0llWVz\\\\\\\/XucCudyTXOOdvXNyshNCu1wULKPzvfCEjLMZ9V9vJNjd2oDHt657N5vt8gSSguXKGuWdjJ6mK91xWISTUacYvLUTCyT7lUvEwH+wdMnRv4jbcQgzFL50mOhs7mR1ACvARqj13fvzNZFuXTjcqFbajqb+bFxfBJCwh2DubT91SMlMhARkI5hrPL+ssMuej\\\\\\\/lHCSRjPK6\\\\\\\/WC97XvzOhQKrhdGxeLIFvZY0v5SYGn+y8aiZNBBI0OnpVBPGwqsnnIBXAXQsy6UV6Rjm1Gm0QBMbmqwA6APAHXj\\\\\\\/XG0jNOl11Eg+k1vFGtIZjpQX6kSObhQZIeXW6wv3AKhlU\\\\\\\/Kxb6q0R3iOamdEGWqdeKJbotKd8\\\\\\\/E8TSWnX1YriwKPST\\\\\\\/4glfzFdYUfiPOcYz0bfCz\\\\\\\/KI4AEc4DZMCA8qsHpvcUEnDEsS75J+Eu1IIFcJXboeOHhxOBsPHS56pYMzU24t0mDON4+zz+Vic8cYNwlQbJunmZrC6sTuaZrQSwNvh563aT1dsN++5A59gr4pXYb0eTMlh\\\\\\\/O48lyAwR1tL9vzVLVSLjiiPRIoyld5XDseM8JV04qFFGR3l3+kj53VPRNwneOuCfbzwEkySuIoWiZIlTxwcDOnfjhSMuTS\\\\\\\/15NBQ\\\\\\\/O6CtEBkSnr9MSFcxL06glYhgeZS7XYxFCWI4KSfsYem3MM6G48n6DH4AHLi1hL5HymDKyzK0ciV4ZFR7sRyG37Hn3cTr+y8wAJ+Ok7VQnHJa71vQAXRKSJnrcdJsXnIi0diW3hw36vRt1M91baOuEcaPzkT8yaGOjMeYmLXuN5xoeWBrhnCgpxvF5Z2xGS+9iqkKBVmSA5OML4lovgL4Y\\\\\\\/eNrZp9zghUnI1FlsQJS\\\\\\\/YUlYvrHRIaNoiMWn+l83irQl9lwJNoRpEpPeu0p\\\\\\\/3bYAf1Mfjq9FF77lTya+AhE3ig73aiWq5JY8jjubxUgHcWEjcV5k3MlevEFeI\\\\\\\/WwbLcAJkIRAKvzOXIACMI25VChpqQHnzlsZUJn3cqSQaHoveU2SGbBhiaNxupZldI9YS04UCFtuk1w4JUcCex6KXDT3zqhcvnaHQgBZqw2yyu8O+0Pn5jlUwvvQZBxavA5RuSg7MzHSFIUnIa+NJ1t9ntv\\\\\\\/wjdJl210\\\\\\\/RusATCWsuunjY+VTpf2a8nR+meQZGRWsVFRrIMC6Ymn5xTaqODKO8=\\\u0022,\\\u0022iv\\\u0022:\\\u0022Q\\\\\\\/\\\\\\\/9YHYeBikNvSX2RjMd\\\\\\\/A==\\\u0022,\\\u0022salt\\\u0022:\\\u002216be9cf9ae1a90f43b11f5dd5fd4d8ab\\\u0022}\u0022,\u0022hmac\u0022:\u00229be8c35c116c58b003edfe61d1ee29bb8c731206f6f35011b58e09e97b25ae89\u0022}","new-045c4b66-ef61-4973-b675-87bf21057e8c":"{\u0022encrypted\u0022:\u0022{\\\u0022encrypted\\\u0022:\\\u0022ZOVOe02IHtdSbwYuU4YmFxfqk4+0PjIGPZnN\\\\\\\/4HCOVzvCeoVEejpo1T1k1wXdKrPfT96D9\\\\\\\/smqT500hxeG379Fj1TY6bq+8juougyZ8JmQNu1+cyypNMhgAuJcGITi8yoYd\\\\\\\/T8M1Ash6K0dl2O3tv3lVzrlHxGalolZgo7JXjGGDN266gSu7AxH\\\\\\\/bleG2zNOI98aGOft7WBD6pLgW8Ghi7NkrnkM6Geg6aqkdBgUIOD9y\\\\\\\/GgcQIxaWeiZpH\\\\\\\/MNxGAjps+RCez1yGhhOGm7RlVdoUALDCVocRCluE2hpUUfyEPP2J+Ec2AJxUYy8OK4HIdJBS0iLLk1nkxyKC6lumj9APg4QFsyP+LjFfc1jcMteSzwZsTehe\\\\\\\/aOgSy79j2nuXz2BYs2OtCBz5AaJzQdnip8JhYQ16aX7PRgw0DE78q0TWfBqptuLb+ZuJv2289k6nNY7MLqeKUmA4C6X81BUwXoL2tjpz+ospvfFtKWM95oNa68l7Mg7y5hT69nfmO\\\\\\\/paGMjxPdLdynpWLEiqr+bTMYD47SLZAtFXNFzxCniJ+1THY75zhps0kvq5KcD7lMSEl4yeCXtx9R09aMoJm2XQcyGAWpzGgiSa9DjrNJ0ugy0U21CubsWr9jTijIRcRCETKQe\\\\\\\/bpzYrJ6kBdexqPVANKEMA\\\\\\\/+jLtXN+H4MMcRHCmBWk81482bHwmRctiNwtUgoFVDk0s3RIqqRdWPAJNc3DUK9UpgzV5RX51GDKXlxB9zBgHMc6Xh2ACg3fh1Vvdh3gUAHnJfM0xQBEn43vvOYow4pieZawBnV9rrho133HmHwizlUO5h093hFiKAToncUdjwxp01YgFRhLmTl4UGvI9c39NJIl7hh\\\\\\\/Uoc7WGW0osy+JLdVvZtawF+EpZjR2qMk7e2MP8V\\\\\\\/MEXdRNuT8NRBhfO9H7ETZXzU13RZiR4cBCDzfJMaPf5ulECNAWf96275ei5ThR0zbE9rgDgMQjORv2HBptQBjKfm1FL+33ash8dsIxI3e03lugCJdf2DwoToxdSpLeAil84Oc4lHRdpfnz513U4RIGTrKK1cQyRdvqs6lEkZWuIEkn857E7D3Fk14uupzFfN55+IUdQyhYPe2Y7A7BcHh3trsKLNpYbZzyHYEB7QtLUXGeu0TJ2WoUr+yjoWWyMK92X8nM+W8rGA2fAu\\\\\\\/Z5H4JFobguY0tfw2AHNHF6wcUZX3910DjCZcj8eoTOC23X70dkF2Cr7uAWmiUjmxhvZTKRZtEc7\\\\\\\/JNggYAILL8mh023QzfmnjwqXBl8mxZnAG3IR+eMBdhUy5rrVEO17n9fqgkT5Cx5R8j6mEItVZLyzraFKlSSJmOIS\\\\\\\/Js2upap7GkJtZZDcjOTBM4n5I0IQLr12vRQsP2yScuWbzpsdwu5N3zWH7gZ\\\\\\\/aGy6yYtsIwPTXT0fr6+YoJqLZOmdT2YgmwmcQvXDg27CAupbPx7fEwa4vV1SoGTS\\\\\\\/JtTW\\\\\\\/Xd85tONybqfEXyecJGyKKMMauXCPSKEYHCH11VaIAjg5p3ZfGoorOojHqvsiUK\\\\\\\/fVw4OmTj2rRNdUKy94GGBqjUW+351WQ8Ms6U7z3zf5AbQL+glnsJfQHspW5Vf02c3\\\\\\\/hrT84LdtGrm3bsqz3b2DzNbI7C1ME+LfeBtpRuEvXgmG8+WsuE7AaVYSOgFV5n3LO5oNGr4wo4ZqVG9f0MHq0IuUR1BsWkbfGDk7E1qJBEcdgFaOQsFuyTvzIyUN0vkNUt38CrHJvPpfnpBK2RJexBKqAyGzr+gNwCZAAWnPTOcyTg18\\\\\\\/OZ0x2OjyXrl+7HFYPIgtTmJtFNAxpHeHwfqpZoSQXizQn11KbXbxU6A2gIY830llZtCzAKTfFBqNYtODvWROUAQWatuOogwxKurm+e8n62Y5Ue3\\\\\\\/cd1VdjWwaGP0OR+TJ0Z2pszyv+EYgHRi6nJ11YS71ZE4LIFTF9z5nBsQr93x7SBHQeu52Y3UFG5jpl6YMQJPDus5SustGs6iX0P4EAJtfPwtAzRx+BIDgtgQBSHk3f22\\\\\\\/PIGwvkSRBrIjarwHssPwo2HH6ZJahZs3QP79dgMVlANPjcXfdych6IL47xrYyDc5orbJnIpYLDf1CfM3q94p3Sg3UUtOhNPrrwH0+8J7R2arf0SYvOk26+wznIk0MQOLhT0+ZE=\\\u0022,\\\u0022iv\\\u0022:\\\u0022Woqn+B+xNJO14dmtGRwTtg==\\\u0022,\\\u0022salt\\\u0022:\\\u002216be9cf9ae1a90f43b11f5dd5fd4d8ab\\\u0022}\u0022,\u0022hmac\u0022:\u002273c2a8f372eb6a6599cb27aad6d798065661ae7783299a9237144fef534692c6\u0022}"},"ws_fl":{"width":100,"height":21},"ws_gpo":{"size":"","annotation":"","lang":"","callback":"","width":300},"panels_accordion":{"highwire_article_accordion_container":{"heightStyle":"content","autoHeight":false,"collapsible":0,"region_accordion_id":"highwire_article_accordion_container","active":0,"animated":"slide"}},"color":{"logo":"https:\/\/www.jneurosci.org\/sites\/default\/files\/jneuro%20logo.png"},"HighWireFoxycart":{"link_text":"Add to Cart (%short-price)","link_icon":"icon-shopping-cart"},"highwire_ahah":{"highwire-inst-branding-0":"\/highwire\/inst_branding\/markup\/inst_logo"},"nice_menus_options":{"delay":800,"speed":"fast"},"eu_cookie_compliance":{"popup_enabled":true,"popup_agreed_enabled":false,"popup_hide_agreed":false,"popup_clicking_confirmation":true,"popup_scrolling_confirmation":false,"popup_html_info":"\u003Cdiv\u003E\n  \u003Cdiv class =\u0022popup-content info\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n      \u003Cp\u003ESfN uses cookies to provide you with a secure and custom website experience. Please read our privacy policy for more details. \u003Ca href=\u0022\/content\/privacy-policy\u0022\u003ELearn more\u003C\/a\u003E\u003C\/p\u003E    \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022agree-button eu-cookie-compliance-default-button\u0022\u003EI Accept\u003C\/button\u003E\n                \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E","use_mobile_message":false,"mobile_popup_html_info":"\u003Cdiv\u003E\n  \u003Cdiv class =\u0022popup-content info\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n          \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022agree-button eu-cookie-compliance-default-button\u0022\u003EI Accept\u003C\/button\u003E\n                \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E\n","mobile_breakpoint":"768","popup_html_agreed":"\u003Cdiv\u003E\n  \u003Cdiv class=\u0022popup-content agreed\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n      \u003Cp\u003E\u0026lt;h2\u0026gt;Thank you for accepting cookies\u0026lt;\/h2\u0026gt;\u0026lt;p\u0026gt;You can now hide this message or find out more about cookies.\u0026lt;\/p\u0026gt;\u003C\/p\u003E\n    \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022hide-popup-button eu-cookie-compliance-hide-button\u0022\u003EHide\u003C\/button\u003E\n          \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E","popup_use_bare_css":false,"popup_height":"auto","popup_width":"100%","popup_delay":1000,"popup_link":"\/content\/privacy-policy","popup_link_new_window":1,"popup_position":null,"popup_language":"en","store_consent":false,"better_support_for_screen_readers":0,"reload_page":0,"domain":"","popup_eu_only_js":0,"cookie_lifetime":365,"cookie_session":false,"disagree_do_not_show_popup":0,"method":"default","whitelisted_cookies":"","withdraw_markup":"\u003Cbutton type=\u0022button\u0022 class=\u0022eu-cookie-withdraw-tab\u0022\u003EPrivacy settings\u003C\/button\u003E\n\u003Cdiv class=\u0022eu-cookie-withdraw-banner\u0022\u003E\n  \u003Cdiv class=\u0022popup-content info\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n      \u003Cp\u003E\u0026lt;h2\u0026gt;We use cookies on this site to enhance your user experience\u0026lt;\/h2\u0026gt;\u0026lt;p\u0026gt;You have given your consent for us to set cookies.\u0026lt;\/p\u0026gt;\u003C\/p\u003E\n    \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022eu-cookie-withdraw-button\u0022\u003EWithdraw consent\u003C\/button\u003E\n    \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E\n","withdraw_enabled":false},"highwireResponsive":{"enquire_enabled":1,"breakpoints_configured":1,"breakpoints":{"zero":"all and (min-width: 0px)","xsmall":"all and (min-width: 380px)","narrow":"all and (min-width: 768px) and (min-device-width: 768px), (max-device-width: 800px) and (min-width: 768px) and (orientation:landscape)","normal":"all and (min-width: 980px) and (min-device-width: 980px), all and (max-device-width: 1024px) and (min-width: 1024px) and (orientation:landscape)","wide":"all and (min-width: 1220px)"}},"omega":{"layouts":{"primary":"normal","order":["narrow","normal","wide"],"queries":{"narrow":"all and (min-width: 768px) and (min-device-width: 768px), (max-device-width: 800px) and (min-width: 768px) and (orientation:landscape)","normal":"all and (min-width: 980px) and (min-device-width: 980px), all and (max-device-width: 1024px) and (min-width: 1024px) and (orientation:landscape)","wide":"all and (min-width: 1220px)"}}}});
//--><!]]>
</script>
    <!--[if lt IE 9]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <script type="text/javascript" async="" src="https://googleads.g.doubleclick.net/pagead/viewthroughconversion/952157035/?random=1717583159288&amp;cv=9&amp;fst=1717583159288&amp;num=1&amp;guid=ON&amp;resp=GooglemKTybQhCsO&amp;eid=375603261%2C466465925%2C512247838&amp;u_h=600&amp;u_w=800&amp;u_ah=600&amp;u_aw=800&amp;u_cd=24&amp;u_his=1&amp;u_tz=-300&amp;u_java=false&amp;u_nplug=5&amp;u_nmime=2&amp;sendb=1&amp;ig=1&amp;frm=0&amp;url=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long&amp;tiba=Dual%20Neural%20Routing%20of%20Visual%20Facilitation%20in%20Speech%20Processing%20%7C%20Journal%20of%20Neuroscience&amp;hn=www.googleadservices.com&amp;rfmt=3&amp;fmt=4"></script><meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A/ERL66fN363FkXxgDc6F1+ucRUkAhjEca9W3la6xaLnD2Y1lABsqmdaJmPNaUKPKVBRpyMKEhXYl7rSvrQw+AkAAACNeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MTkzNTk5OTksImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A6OdGH3fVf4eKRDbXb4thXA4InNqDJDRhZ8U533U/roYjp4Yau0T3YSuc63vmAs/8ga1cD0E3A7LEq6AXk1uXgsAAACTeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MTkzNTk5OTksImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><script type="application/json" id="user">{"type":"institution","name":"University of Texas Libraries","privileges":[{"privilege-set":"IBASIC","expires":"2025-03-31T23:59:59.999-07:00"}]}</script><script src="https://pagead2.googlesyndication.com/pagead/managed/js/gpt/m202405300101/pubads_impl.js" async=""></script><style>#gs-casa-r,#gs-casa-c,#gs-casa-b,#gs-casa-f,#gs-casa-h,#gs-casa-r::before,#gs-casa-c::before,#gs-casa-b::before,#gs-casa-f::before,#gs-casa-h::before,#gs-casa-r::after,#gs-casa-c::after,#gs-casa-b::after,#gs-casa-f::after,#gs-casa-h::after{background:transparent;border:0;box-sizing:content-box;content:normal;font-family:Arial,sans-serif;font-weight:normal;letter-spacing:normal;line-height:normal;margin:0;opacity:1;outline:none;overflow:visible;padding:0;pointer-events:auto;text-decoration:none;text-transform:none;transition:none;vertical-align:baseline;z-index:0}#gs-casa-r{height:0;position:absolute;right:0;top:0;width:0;z-index:2147483647}#gs-casa-c{bottom:100px;height:110px;overflow:hidden;pointer-events:none;position:fixed;right:0;width:116px}#gs-casa-c.gs-casa-top{bottom:75%;position:fixed}#gs-casa-c.gs-casa-mid{position:absolute;bottom:0}#gs-casa-b{animation:gs-casa-a-l-ent .225s cubic-bezier(.0,.0,.2,1) forwards;perspective:1px;position:absolute;right:0;text-align:center;top:20px;width:96px}#gs-casa-b::before,#gs-casa-b::after{border-radius:8px 0 0 8px;content:"";height:100%;left:0;perspective:1px;position:absolute;top:0;transform:translate3d(0,0,0);transition:opacity .2s;width:100%;z-index:-1}#gs-casa-b::before{box-shadow:0 0px 2px 0 rgba(0,0,0,.14),0 2px 2px 0 rgba(0,0,0,.12),0 4px 15px 0 rgba(0,0,0,.2);opacity:1}#gs-casa-b::after{box-shadow:0 8px 10px 1px rgba(0,0,0,.14),0 3px 14px 3px rgba(0,0,0,.12),0 4px 15px 0 rgba(0,0,0,.2);opacity:0}#gs-casa-b:active::before{opacity:0}#gs-casa-b:active::after{opacity:1}#gs-casa-f,#gs-casa-h{display:block;overflow:hidden;padding-left:4px}#gs-casa-f{background-color:#424242;border-radius:8px 0 0 0;color:#fff;font-size:18px;height:54px;line-height:54px;word-spacing:-2px}#gs-casa-h{background-color:#777;border-radius:0 0 0 8px;color:#e0e0e0;font-size:11px;height:16px;line-height:16px}@keyframes gs-casa-a-l-ent{0%{transform:translate3d(96px,0,0)}100%{transform:translate3d(0,0,0)}}.gs-casa-touch #gs-casa-c{bottom:30vh;position:fixed;transform:translate(0,48px)}@media (max-width:599px),(max-height:599px){#gs-casa-c,#gs-casa-c.gs-casa-top,#gs-casa-c.gs-casa-mid{border-radius:6px 0 0 6px;bottom:30vh;height:96px;position:fixed;transform:translate(0,48px);width:92px}#gs-casa-b{width:72px}#gs-casa-f,#gs-casa-h{padding-left:3px}#gs-casa-f{border-radius:6px 0 0 0;font-size:14px;height:44px;line-height:44px}#gs-casa-h{border-radius:0 0 0 6px;font-size:9px;height:12px;line-height:12px}@keyframes gs-casa-a-l-ent{0%{transform:translate3d(72px,0,0)}100%{transform:translate3d(0,0,0)}}}</style><script charset="utf-8" src="https://platform.twitter.com/js/button.856debeac157d9669cf51e73a08fbc93.js"></script><link rel="stylesheet" type="text/css" href="https://css.trendmd.com/trendmd.min.css" media="all"><script src="https://www.googletagmanager.com/gtag/js?id=G-G5TCNFJCYP"></script></head>
  <body class="html not-front not-logged-in page-node page-node- page-node-370480 node-type-highwire-article context-content hw-default-jcode-jneuro hw-article-type-research-article hw-article-category-articles omega-mediaqueries-processed omega-equalheights-processed eu-cookie-compliance-processed hw-responsive-layout-wide responsive-layout-wide"><div id="omega-media-query-dummy"><style media="all">#omega-media-query-dummy { position: relative; z-index: -1; }</style><!--[if (lt IE 9)&(!IEMobile)]><style media="all">#omega-media-query-dummy { z-index: 1; }</style><![endif]--><style media="all and (min-width: 768px) and (min-device-width: 768px), (max-device-width: 800px) and (min-width: 768px) and (orientation:landscape)">#omega-media-query-dummy { z-index: 0; }</style><style media="all and (min-width: 980px) and (min-device-width: 980px), all and (max-device-width: 1024px) and (min-width: 1024px) and (orientation:landscape)">#omega-media-query-dummy { z-index: 1; }</style><style media="all and (min-width: 1220px)">#omega-media-query-dummy { z-index: 2; }</style></div>
<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-T845VD6" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script type="text/javascript">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0];var j=d.createElement(s);var dl=l!='dataLayer'?'&l='+l:'';j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;j.type='text/javascript';j.async=true;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-T845VD6');</script>
<!-- End Google Tag Manager -->
    <div id="skip-link">
      <a href="#main-content" class="element-invisible element-focusable">Skip to main content</a>
    </div>
        <div class="page clearfix page-box-shadows footer-borders panels-page panels-layout-jcore_2col" id="page">
      <header id="section-header" class="section section-header">
  <div id="zone-superheader-wrapper" class="zone-wrapper zone-superheader-wrapper clearfix mobile-only print-hidden">  
  <div id="zone-superheader" class="zone zone-superheader clearfix mobile-only print-hidden container-30">
    <div class="grid-30 region region-superheader" id="region-superheader">
  <div class="region-inner region-superheader-inner">
    <div class="block block-panels-mini block-responsive-menu block-panels-mini-responsive-menu odd block-without-title" id="block-panels-mini-responsive-menu">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <div class="panel-display panel-1col clearfix" id="mini-panel-responsive_menu">
  <div class="panel-panel panel-col">
    <div><div id="unique-id3" class="highwire-responsive-toggle-group"><ul class="highwire-responsive-toggle-triggers"><li class="trigger-0"><span class="icon-reorder"></span><span class="element-invisible">Main menu</span></li><li class="trigger-1"><span class="icon-gear"></span><span class="element-invisible">User menu</span></li><li class="trigger-2"><span class="icon-search"></span><span class="element-invisible">Search</span></li></ul><div class="panel-pane pane-panels-mini pane-responsive-menu-main-menu">
  
        <h2 class="pane-title"><span class="icon-reorder"></span><span class="element-invisible">Main menu</span></h2>
    
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-responsive_menu_main_menu">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-menu-tree pane-main-menu">
  
      
  
  <div class="pane-content">
    <div class="menu-block-wrapper menu-block-ctools-main-menu-1 menu-name-main-menu parent-mlid-main-menu:0 menu-level-1">
  <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf menu-mlid-754" role="menuitem"><a href="/" data-hide-link-title="0" class="" data-icon-position="">HOME</a></li>
<li class="expanded active-trail menu-mlid-863" role="menuitem"><a href="/content/by/year" data-hide-link-title="0" class="active active-trail" data-icon-position="">CONTENT</a><nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf menu-mlid-757" role="menuitem"><a href="/content/early/recent" data-hide-link-title="0" class="" data-icon-position="">Early Release</a></li>
<li class="leaf menu-mlid-1063" role="menuitem"><a href="/content/featured-research" data-hide-link-title="0" class="" data-icon-position="">Featured</a></li>
<li class="menu-mlid-756" role="menuitem"><a href="/content/current" data-hide-link-title="0" class="" data-icon-position="">Current Issue</a></li>
<li class="leaf menu-mlid-758" role="menuitem"><a href="/content/by/year" data-hide-link-title="0" class="" data-icon-position="">Issue Archive</a></li>
<li class="leaf menu-mlid-878" role="menuitem"><a href="/content/collections" data-hide-link-title="0" class="" data-icon-position="">Collections</a></li>
<li class="last leaf menu-mlid-1182" role="menuitem"><a href="https://www.jneurosci.org/podcast" data-hide-link-title="0" class="" data-icon-position="">Podcast</a></li>
</ul></nav></li>
<li class="leaf menu-mlid-772" role="menuitem"><a href="/alerts" data-hide-link-title="0" class="" data-icon-position="">ALERTS</a></li>
<li class="expanded menu-mlid-760" role="menuitem"><a href="/content/information-authors" data-hide-link-title="0" class="" data-icon-position="">FOR AUTHORS</a><nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf menu-mlid-1181" role="menuitem"><a href="https://www.jneurosci.org/content/information-authors" data-hide-link-title="0" class="" data-icon-position="">Information for Authors</a></li>
<li class="leaf menu-mlid-1051" role="menuitem"><a href="/content/information-authors#fees" data-hide-link-title="0" class="" data-icon-position="">Fees</a></li>
<li class="leaf menu-mlid-1052" role="menuitem"><a href="/content/jneurosci-journal-club" data-hide-link-title="0" class="" data-icon-position="">Journal Clubs</a></li>
<li class="leaf menu-mlid-1056" role="menuitem"><a href="/content/eletters" data-hide-link-title="0" class="" data-icon-position="">eLetters</a></li>
<li class="leaf menu-mlid-1054" role="menuitem"><a href="http://jneurosci.msubmit.net/" data-hide-link-title="0" class="" data-icon-position="">Submit</a></li>
<li class="last leaf menu-mlid-1188" role="menuitem"><a href="/content/special-collections" data-hide-link-title="0" class="" data-icon-position="">Special Collections</a></li>
</ul></nav></li>
<li class="expanded menu-mlid-1037" role="menuitem"><a href="/content/editorial-board" data-hide-link-title="0" class="" data-icon-position="">EDITORIAL BOARD</a><nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf menu-mlid-1184" role="menuitem"><a href="https://www.jneurosci.org/content/editorial-board" data-hide-link-title="0" class="" data-icon-position="">Editorial Board</a></li>
<li class="leaf menu-mlid-1185" role="menuitem"><a href="https://www.jneurosci.org/content/ecr-board" data-hide-link-title="0" class="" data-icon-position="">ECR Advisory Board</a></li>
<li class="last leaf menu-mlid-1183" role="menuitem"><a href="https://www.jneurosci.org/content/journal-staff" data-hide-link-title="0" class="" data-icon-position="">Journal Staff</a></li>
</ul></nav></li>
<li class="expanded menu-mlid-766" role="menuitem"><a href="/content/about-jneurosci" data-hide-link-title="0" class="" data-icon-position="">ABOUT</a><nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf menu-mlid-767" role="menuitem"><a href="/content/about-jneurosci" data-hide-link-title="0" class="" data-icon-position="">Overview</a></li>
<li class="leaf menu-mlid-903" role="menuitem"><a href="/content/advertising-jneurosci" data-hide-link-title="0" class="" data-icon-position="">Advertise</a></li>
<li class="leaf menu-mlid-771" role="menuitem"><a href="/content/media" data-hide-link-title="0" class="" data-icon-position="">For the Media</a></li>
<li class="leaf menu-mlid-899" role="menuitem"><a href="/content/rights-permissions" data-hide-link-title="0" class="" data-icon-position="">Rights and Permissions</a></li>
<li class="leaf menu-mlid-1035" role="menuitem"><a href="/content/privacy-policy" data-hide-link-title="0" class="" data-icon-position="">Privacy Policy</a></li>
<li class="leaf menu-mlid-773" role="menuitem"><a href="/feedback" data-hide-link-title="0" class="" data-icon-position="">Feedback</a></li>
<li class="last leaf menu-mlid-1187" role="menuitem"><a href="https://www.jneurosci.org/about/accessibility" data-hide-link-title="0" class="" data-icon-position="">Accessibility</a></li>
</ul></nav></li>
<li class="last leaf menu-mlid-1070" role="menuitem"><a href="https://www.jneurosci.org/site/subscriptions" data-hide-link-title="0" class="" data-icon-position="">SUBSCRIBE</a></li>
</ul></nav></div>
  </div>

  
  </div>
</div>
  </div>
</div>
  </div>

  
  </div>
<div class="panel-pane pane-panels-mini pane-responsive-menu-user-menu">
  
        <h2 class="pane-title"><span class="icon-gear"></span><span class="element-invisible">User menu</span></h2>
    
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-responsive_menu_user_menu">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-menu-tree pane-user-menu">
  
      
  
  <div class="pane-content">
    <div class="menu-block-wrapper menu-block-ctools-user-menu-1 menu-name-user-menu parent-mlid-user-menu:0 menu-level-1">
  <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf menu-mlid-17" role="menuitem"><a href="/user/logout?current=node/370480" class="" data-icon-position="" data-hide-link-title="0">Log out</a></li>
<li class="leaf menu-mlid-785" role="menuitem"><a href="/user/login?destination=/content/29/43/13445%3Fvariant%3Dlong" data-hide-link-title="0" class="" data-icon-position="">Log in</a></li>
<li class="last leaf menu-mlid-1088" role="menuitem"><a href="/cart" class="link-icon-only link-icon"><span class="icon-shopping-cart"></span> <span class="title element-invisible">My Cart</span></a></li>
</ul></nav></div>
  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-inst-branding float-me-right">
  
      
  
  <div class="pane-content">
    <div id="highwire-inst-branding-0" class="highwire-inst-branding highwire-ahah-processed"></div>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-user-identities">
  
      
  
  <div class="pane-content">
    <div class="highwire-user-message highwire-user-message-once-processed" data-separator="|"><span class="highwire-user-institution" data-id-type="institution" data-identity="a%3A2%3A%7Bs%3A4%3A%22show%22%3Bi%3A1%3Bs%3A7%3A%22message%22%3Bs%3A50%3A%22Institution%3A%20%5Bidentity%3Ainstitutional_display_name%5D%22%3B%7D">Institution: University of Texas Libraries</span></div>  </div>

  
  </div>
</div>
  </div>
</div>
  </div>

  
  </div>
<div class="panel-pane pane-panels-mini pane-responsive-menu-search">
  
        <h2 class="pane-title"><span class="icon-search"></span><span class="element-invisible">Search</span></h2>
    
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-responsive_menu_search">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-highwire-seach-qsearch-nocontext">
  
      
  
  <div class="pane-content">
    <form class="highwire-quicksearch button-style-mini button-style-mini" action="/content/29/43/13445.long" method="post" id="highwire-search-qsearch-nocontext-form" accept-charset="UTF-8"><div><div class="form-item form-item-label-invisible form-type-textfield form-item-keywords">
  <label class="element-invisible" for="quick_search_header_keywords_627506347">Search for this keyword </label>
 <input placeholder="Search..." type="text" id="quick_search_header_keywords_627506347" name="keywords" value="" size="60" maxlength="128" class="form-text">
</div>
<div class="button-wrapper button-mini"><span class="icon-search"></span><input data-icon-only="1" data-font-icon="icon-search" data-icon-position="after" type="submit" id="quick_search_header_submit_21778916" name="op" value="Search" class="form-submit"></div><input type="hidden" name="form_build_id" value="form-35EiXfBVJg14-TQiJrRcgD6ULgNiS-QJ7B-Yy2GZFqI">
<input type="hidden" name="form_id" value="highwire_search_qsearch_nocontext_form">
</div></form>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-custom pane-1 highwire-responsive-advanced-search-link pane-menu-tree">
  
      
  
  <div class="pane-content">
    <ul class="menu">
  <li><a href="/search" title="Advanced search">Advanced search</a></li>
  </ul>  </div>

  
  </div>
</div>
  </div>
</div>
  </div>

  
  </div>
</div></div>
  </div>
</div>
    </div>
  </div>
</div><div class="block block-panels-mini block-hw-small-logo block-panels-mini-hw-small-logo even block-without-title" id="block-panels-mini-hw-small-logo">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <div class="panel-display panel-1col clearfix" id="mini-panel-hw_small_logo">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-small-logo">
  
      
  
  <div class="pane-content">
    <a href="/" class="" data-icon-position="" data-hide-link-title="0"><img src="https://www.jneurosci.org/sites/default/files/mobile-logo.png" alt="Journal of Neuroscience" title="Journal of Neuroscience"></a>  </div>

  
  </div>
</div>
  </div>
</div>
    </div>
  </div>
</div>  </div>
</div>  </div>
</div><div id="zone-advertising-top-wrapper" class="zone-wrapper zone-advertising-top-wrapper clearfix">  
  <div id="zone-advertising-top" class="zone zone-advertising-top clearfix container-30">
    <div class="grid-28 suffix-1 prefix-1 region region-ad-top" id="region-ad-top">
  <div class="region-inner region-ad-top-inner">
    <div class="block block-system block-menu block-user-menu block-system-user-menu odd block-without-title" id="block-system-user-menu">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf" role="menuitem"><a href="/user/logout?current=node/370480" class="" data-icon-position="" data-hide-link-title="0">Log out</a></li>
<li class="leaf" role="menuitem"><a href="/user/login?destination=/content/29/43/13445%3Fvariant%3Dlong" data-hide-link-title="0" class="" data-icon-position="">Log in</a></li>
<li class="last leaf" role="menuitem"><a href="/cart" class="link-icon-only link-icon"><span class="icon-shopping-cart"></span> <span class="title element-invisible">My Cart</span></a></li>
</ul></nav>    </div>
  </div>
</div><div class="block block-panels-mini block-advertisement-top-banner block-panels-mini-advertisement-top-banner even block-without-title" id="block-panels-mini-advertisement-top-banner">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <div class="panel-display panel-1col clearfix" id="mini-panel-advertisement_top_banner">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-snippet pane-top-ad-snippet">
  
      
  
  <div class="pane-content">
    <div class="snippet top-ad-snippet" id="top-ad-snippet">
  
      
  <div class="snippet-content">
    <script type="text/javascript">if (!window.AdButler){(function(){var s = document.createElement("script"); s.async = true; s.type = "text/javascript";s.src = 'https://servedbyadbutler.com/app.js';var n = document.getElementsByTagName("script")[0]; n.parentNode.insertBefore(s, n);}());}</script>
<script type="text/javascript">
var AdButler = AdButler || {}; AdButler.ads = AdButler.ads || [];
var abkw = window.abkw || '';
var plc540736 = window.plc540736 || 0;
document.write('<'+'div id="placement_540736_'+plc540736+'"></'+'div>');
AdButler.ads.push({handler: function(opt){ AdButler.register(183357, 540736, [728,90], 'placement_540736_'+opt.place, opt); }, opt: { place: plc540736++, keywords: abkw, domain: 'servedbyadbutler.com', click:'CLICK_MACRO_PLACEHOLDER' }});
</script><script async="" type="text/javascript" src="https://servedbyadbutler.com/adserve/;ID=183357;size=728x90;setID=540736;type=async;domid=placement_540736_0;place=0;pid=243486;sw=800;sh=600;spr=1;rnd=243486;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long;atf=1;click=CLICK_MACRO_PLACEHOLDER"></script><div id="placement_540736_0"><div id="placement_540736_0_ins" style="margin:0;padding:0;" eligible-callback="https://servedbyadbutler.com/adserve/;MID=183357;type=e959fb862;placementID=2310141;setID=540736;channelID=0;CID=0;BID=521680266;TAID=0;place=0;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long;mt=1717583159438405;hc=0fc5a91f114d0c432d4fdfe45c490f0909c06f83" viewable-callback="https://servedbyadbutler.com/adserve/;MID=183357;type=v959fb862;placementID=2310141;setID=540736;channelID=0;CID=0;BID=521680266;TAID=0;place=0;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long;mt=1717583159438391;hc=3a65b9be30da3da37db34e499b502689e6250a6d" viewable="true"><a href="https://servedbyadbutler.com/redirect.spark?MID=183357&amp;plid=2310141&amp;setID=540736&amp;channelID=0&amp;CID=0&amp;banID=521680266&amp;PID=0&amp;textadID=0&amp;tc=1&amp;scheduleID=2229777&amp;adSize=728x90&amp;mt=1717583159438346&amp;sw=800&amp;sh=600&amp;spr=1&amp;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long&amp;hc=c8f3579aa53b44b55190826d590eb9b2f42e8724&amp;location=" target="_blank" rel="nofollow"><img src="https://servedbyadbutler.com/getad.img/;libID=4053482" alt="" title="" border="0" style="width:100%; max-width:728px"></a></div></div>
  </div>

</div>
  </div>

  
  </div>
</div>
  </div>
</div>
    </div>
  </div>
</div>  </div>
</div>  </div>
</div>  
  <div id="zone-branding" class="zone zone-branding clearfix mobile-hidden print-display-block container-30">
    <div class="grid-19 prefix-1 region region-branding print-display-block" id="region-branding">
  <div class="region-inner region-branding-inner">
        <div class="branding-data clearfix">
            <div class="logo-img">
        <a href="/" rel="home" class="" data-icon-position="" data-hide-link-title="0"><img alt="Journal of Neuroscience" src="https://www.jneurosci.org/sites/default/files/jneuro%20logo.png"></a>      </div>
                </div>
          </div>
</div><div class="grid-9 suffix-1 region region-branding-second print-hidden" id="region-branding-second">
  <div class="region-inner region-branding-second-inner">
    <div class="block block-panels-mini block-jnl-sfneneuro-search-box block-panels-mini-jnl-sfneneuro-search-box odd block-without-title" id="block-panels-mini-jnl-sfneneuro-search-box">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <div class="panel-display panel-1col clearfix" id="mini-panel-jnl_sfneneuro_search_box">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-highwire-seach-qsearch-nocontext no-margin-bottom">
  
      
  
  <div class="pane-content">
    <form class="highwire-quicksearch button-style-mini button-style-mini" action="/content/29/43/13445.long" method="post" id="highwire-search-qsearch-nocontext-form--2" accept-charset="UTF-8"><div><div class="form-item form-item-label-invisible form-type-textfield form-item-keywords">
  <label class="element-invisible" for="quick_search_header_keywords_1188173708">Search for this keyword </label>
 <input placeholder="search" type="text" id="quick_search_header_keywords_1188173708" name="keywords" value="" size="60" maxlength="128" class="form-text">
</div>
<div class="button-wrapper button-mini"><span class="icon-search"></span><input data-icon-only="1" data-font-icon="icon-search" data-icon-position="after" type="submit" id="quick_search_header_submit_781893014" name="op" value="Search" class="form-submit"></div><input type="hidden" name="form_build_id" value="form-SZNcKVnGm2cqWc1SBq_-bjmiRiC02klQaHYopmY52cs">
<input type="hidden" name="form_id" value="highwire_search_qsearch_nocontext_form">
</div></form>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-custom pane-2">
  
      
  
  <div class="pane-content">
    <p><a href="/search">Advanced Search</a></p>  </div>

  
  </div>
</div>
  </div>
</div>
    </div>
  </div>
</div><div class="block block-panels-mini block-submit-an-article block-panels-mini-submit-an-article even block-without-title" id="block-panels-mini-submit-an-article">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <div class="panel-display panel-1col clearfix" id="mini-panel-submit_an_article">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-snippet pane-submit-an-article-button">
  
      
  
  <div class="pane-content">
    <div class="snippet submit-an-article-button" id="submit-an-article-button">
  
      
  <div class="snippet-content">
    <style type="text/css">.header-update-button {
    padding: 4px;
    border: 0px;
    width: 100%;
    margin-top: 20px;
    border-radius: 8px; -webkit-border-radius: 8px; -moz-border-radius: 8px;
    background-color: #104b7d;
    font-size: 22px;	
}
.header-update-button a {
    color: #ffffff;
    text-decoration: none;
}
</style>
<div class="rtecenter header-update-button"><a href="http://jneurosci.msubmit.net/" target="_blank"><strong>Submit a Manuscript</strong></a></div>
  </div>

</div>
  </div>

  
  </div>
</div>
  </div>
</div>
    </div>
  </div>
</div>  </div>
</div>  </div>
  
  <div id="zone-menu" class="zone zone-menu clearfix mobile-hidden container-30">
    <div class="grid-28 suffix-1 prefix-1 region region-menu main-menu-active-caret" id="region-menu">
  <div class="region-inner region-menu-inner">
        <div class="block block-nice-menus block-1 block-nice-menus-1 odd block-without-title" id="block-nice-menus-1">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <nav class="menubar-nav"><ul class="nice-menu nice-menu-down nice-menu-main-menu nice-menus-processed sf-js-enabled sf-arrows" id="nice-menu-1" role="menu"><li class="menu-754 menu-path-front first odd " role="menuitem"><a href="/" data-hide-link-title="0" class="" data-icon-position="">HOME</a></li>
<li class="menu-863 menuparent  menu-path-content-by-year active-trail  even" role="menuitem"><a href="/content/by/year" data-hide-link-title="0" class="active sf-with-ul" data-icon-position="">CONTENT</a><ul role="menu" style="display: none;"><li class="menu-757 menu-path-content-early-recent first odd " role="menuitem"><a href="/content/early/recent" data-hide-link-title="0" class="" data-icon-position="">Early Release</a></li>
<li class="menu-1063 menu-path-node-640291  even " role="menuitem"><a href="/content/featured-research" data-hide-link-title="0" class="" data-icon-position="">Featured</a></li>
<li class="menu-756 menu-path-content-current  odd " role="menuitem"><a href="/content/current" data-hide-link-title="0" class="" data-icon-position="">Current Issue</a></li>
<li class="menu-758 menu-path-content-by-year  even " role="menuitem"><a href="/content/by/year" data-hide-link-title="0" class="" data-icon-position="">Issue Archive</a></li>
<li class="menu-878 menu-path-node-57587  odd " role="menuitem"><a href="/content/collections" data-hide-link-title="0" class="" data-icon-position="">Collections</a></li>
<li class="menu-1182 menu-path-sjneurosciorg-podcast  even last" role="menuitem"><a href="https://www.jneurosci.org/podcast" data-hide-link-title="0" class="" data-icon-position="">Podcast</a></li>
</ul></li>
<li class="menu-772 menu-path-alerts  odd " role="menuitem"><a href="/alerts" data-hide-link-title="0" class="" data-icon-position="">ALERTS</a></li>
<li class="menu-760 menuparent  menu-path-node-1  even" role="menuitem"><a href="/content/information-authors" data-hide-link-title="0" class="sf-with-ul" data-icon-position="">FOR AUTHORS</a><ul role="menu" style="display: none;"><li class="menu-1181 menu-path-sjneurosciorg-content-information-authors first odd " role="menuitem"><a href="https://www.jneurosci.org/content/information-authors" data-hide-link-title="0" class="" data-icon-position="">Information for Authors</a></li>
<li class="menu-1051 menu-path-node-1  even " role="menuitem"><a href="/content/information-authors#fees" data-hide-link-title="0" class="" data-icon-position="">Fees</a></li>
<li class="menu-1052 menu-path-node-637969  odd " role="menuitem"><a href="/content/jneurosci-journal-club" data-hide-link-title="0" class="" data-icon-position="">Journal Clubs</a></li>
<li class="menu-1056 menu-path-node-637970  even " role="menuitem"><a href="/content/eletters" data-hide-link-title="0" class="" data-icon-position="">eLetters</a></li>
<li class="menu-1054 menu-path-jneuroscimsubmitnet-  odd " role="menuitem"><a href="http://jneurosci.msubmit.net/" data-hide-link-title="0" class="" data-icon-position="">Submit</a></li>
<li class="menu-1188 menu-path-node-682697  even last" role="menuitem"><a href="/content/special-collections" data-hide-link-title="0" class="" data-icon-position="">Special Collections</a></li>
</ul></li>
<li class="menu-1037 menuparent  menu-path-node-348426  odd" role="menuitem"><a href="/content/editorial-board" data-hide-link-title="0" class="sf-with-ul" data-icon-position="">EDITORIAL BOARD</a><ul role="menu" style="display: none;"><li class="menu-1184 menu-path-sjneurosciorg-content-editorial-board first odd " role="menuitem"><a href="https://www.jneurosci.org/content/editorial-board" data-hide-link-title="0" class="" data-icon-position="">Editorial Board</a></li>
<li class="menu-1185 menu-path-sjneurosciorg-content-ecr-board  even " role="menuitem"><a href="https://www.jneurosci.org/content/ecr-board" data-hide-link-title="0" class="" data-icon-position="">ECR Advisory Board</a></li>
<li class="menu-1183 menu-path-sjneurosciorg-content-journal-staff  odd last" role="menuitem"><a href="https://www.jneurosci.org/content/journal-staff" data-hide-link-title="0" class="" data-icon-position="">Journal Staff</a></li>
</ul></li>
<li class="menu-766 menuparent  menu-path-node-7  even" role="menuitem"><a href="/content/about-jneurosci" data-hide-link-title="0" class="sf-with-ul" data-icon-position="">ABOUT</a><ul role="menu" style="display: none;"><li class="menu-767 menu-path-node-7 first odd " role="menuitem"><a href="/content/about-jneurosci" data-hide-link-title="0" class="" data-icon-position="">Overview</a></li>
<li class="menu-903 menu-path-node-616275  even " role="menuitem"><a href="/content/advertising-jneurosci" data-hide-link-title="0" class="" data-icon-position="">Advertise</a></li>
<li class="menu-771 menu-path-node-9  odd " role="menuitem"><a href="/content/media" data-hide-link-title="0" class="" data-icon-position="">For the Media</a></li>
<li class="menu-899 menu-path-node-640113  even " role="menuitem"><a href="/content/rights-permissions" data-hide-link-title="0" class="" data-icon-position="">Rights and Permissions</a></li>
<li class="menu-1035 menu-path-node-632763  odd " role="menuitem"><a href="/content/privacy-policy" data-hide-link-title="0" class="" data-icon-position="">Privacy Policy</a></li>
<li class="menu-773 menu-path-node-10  even " role="menuitem"><a href="/feedback" data-hide-link-title="0" class="" data-icon-position="">Feedback</a></li>
<li class="menu-1187 menu-path-sjneurosciorg-about-accessibility  odd last" role="menuitem"><a href="https://www.jneurosci.org/about/accessibility" data-hide-link-title="0" class="" data-icon-position="">Accessibility</a></li>
</ul></li>
<li class="menu-1070 menu-path-sjneurosciorg-site-subscriptions  odd last" role="menuitem"><a href="https://www.jneurosci.org/site/subscriptions" data-hide-link-title="0" class="" data-icon-position="">SUBSCRIBE</a></li>
</ul></nav>
    </div>
  </div>
</div>  </div>
</div>
  </div>
  
  <div id="zone-header" class="zone zone-header clearfix container-30">
  	      </div>
</header>    
      <section id="section-content" class="section section-content">
    
  <div id="zone-content" class="zone zone-content clearfix container-30">    
        
    <div class="grid-28 suffix-1 prefix-1 region region-content" id="region-content">
  <div class="region-inner region-content-inner">
    <a id="main-content"></a>
                        <div class="block block-system block-main block-system-main odd block-without-title" id="block-system-main">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <div class="panel-display panels-960-layout jcore-2col-layout">
	  <div class="panel-row-wrapper panel-row-first clearfix">
		
		<div class="top-wrapper">
			<div class="panel-panel panel-region-top">
			  <div class="inside"><div class="panel-pane pane-highwire-node-pager">
  
      
  
  <div class="pane-content">
    <div class="pager highwire-pager pager-mini clearfix highwire-node-pager highwire-article-pager"><span class="pager-prev"><a href="/content/29/43/13710" title="β-Catenin Signaling Levels in Progenitors Influence the Laminar Cell Fates of Projection Neurons" rel="prev" class="pager-link-prev link-icon"><span class="icon-circle-arrow-left"></span> <span class="title">Previous</span></a></span><span class="pager-next"><a href="/content/29/43/13465" title="Brain Hemispheres Selectively Track the Expected Value of Contralateral Options" rel="next" class="pager-link-next link-icon-right link-icon"><span class="title">Next</span> <span class="icon-circle-arrow-right"></span></a></span></div>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-article-citation">
  
      
  
  <div class="pane-content">
    <div class="highwire-article-citation highwire-citation-type-highwire-article node370480" data-node-nid="370480" id="node-370480--21522934263" data-pisa="jneuro;29/43/13445" data-pisa-master="jneuro;29/43/13445" data-apath="/jneuro/29/43/13445.atom" data-hw-author-tooltip-instance="highwire_author_tooltip"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jnl-eneuro-styles-article-title-complete-plus clearfix has-author-tooltip highwire-citation-highwire-article-top-a">
  
  
      <div class="highwire-cite-overline"><span class="highwire-cite-metadata-fa-ca-prefix highwire-cite-metadata"><span class="featured-article">Featured Article</span></span><span class="separator-pipe"></span><span class="highwire-cite-metadata-art-cat highwire-cite-metadata"><span class="wrapper">Articles, Behavioral/Systems/Cognitive</span></span></div>
  
      <div class="highwire-cite-access"><span class="highwire-citation-access highwire-citation-access-check ac-processed" data-pisa-id="jneuro;29/43/13445" data-atom-uri="/jneuro/29/43/13445.atom" data-request-view="full"></span></div>
  
      <h1 class="highwire-cite-title" id="page-title">Dual Neural Routing of Visual Facilitation in Speech Processing</h1>  
    	<div class="highwire-cite-authors"><span class="highwire-citation-authors"><span class="highwire-citation-author first" data-delta="0">Luc H. Arnal</span>, <span class="highwire-citation-author" data-delta="1">Benjamin Morillon</span>, <span class="highwire-citation-author" data-delta="2">Christian A. Kell</span> and <span class="highwire-citation-author" data-delta="3">Anne-Lise Giraud</span></span></div>
  
    	<div class="highwire-cite-metadata"><span class="highwire-cite-metadata-journal highwire-cite-metadata">Journal of Neuroscience </span><span class="highwire-cite-metadata-date highwire-cite-metadata">28 October 2009,  </span><span class="highwire-cite-metadata-volume highwire-cite-metadata">29 </span><span class="highwire-cite-metadata-issue highwire-cite-metadata">(43) </span><span class="highwire-cite-metadata-pages highwire-cite-metadata">13445-13453; </span><span class="highwire-cite-metadata-doi highwire-cite-metadata">DOI: https://doi.org/10.1523/JNEUROSCI.3194-09.2009 </span></div>
  
  
    	<div class="highwire-cite-extras"><span class="highwire-foxycart-add-to-cart-ahah highwire-foxycart-add-to-cart-ahah" data-text="Add to Cart (%short-price)" data-apath="/jneuro/29/43/13445.atom" data-type="link" data-font-icon="icon-shopping-cart" data-parent-id="349256" data-foxy-id="1"></span></div>
  
</div>
<div id="hw-article-author-popups-node-370480--21522934263" style="display: none;"><div class="author-tooltip-0"><div class="author-tooltip-name">Luc H. Arnal </div><ul class="author-tooltip-find-more"><li class="author-tooltip-gs-link first"><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=author&amp;author%5B0%5D=Luc%2BH.%2BArnal%2B" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on Google Scholar</a></li><li class="author-tooltip-pubmed-link"><a href="/lookup/external-ref?access_num=Arnal%20LH&amp;link_type=AUTHORSEARCH" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on PubMed</a></li><li class="author-site-search-link last"><a href="/search/author1%3ALuc%2BH.%2BArnal%2B" rel="nofollow" class="" data-icon-position="" data-hide-link-title="0">Search for this author on this site</a></li></ul></div><div class="author-tooltip-1"><div class="author-tooltip-name">Benjamin Morillon </div><ul class="author-tooltip-find-more"><li class="author-tooltip-gs-link first"><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=author&amp;author%5B0%5D=Benjamin%2BMorillon%2B" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on Google Scholar</a></li><li class="author-tooltip-pubmed-link"><a href="/lookup/external-ref?access_num=Morillon%20B&amp;link_type=AUTHORSEARCH" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on PubMed</a></li><li class="author-site-search-link last"><a href="/search/author1%3ABenjamin%2BMorillon%2B" rel="nofollow" class="" data-icon-position="" data-hide-link-title="0">Search for this author on this site</a></li></ul></div><div class="author-tooltip-2"><div class="author-tooltip-name">Christian A. Kell </div><ul class="author-tooltip-find-more"><li class="author-tooltip-gs-link first"><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=author&amp;author%5B0%5D=Christian%2BA.%2BKell%2B" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on Google Scholar</a></li><li class="author-tooltip-pubmed-link"><a href="/lookup/external-ref?access_num=Kell%20CA&amp;link_type=AUTHORSEARCH" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on PubMed</a></li><li class="author-site-search-link last"><a href="/search/author1%3AChristian%2BA.%2BKell%2B" rel="nofollow" class="" data-icon-position="" data-hide-link-title="0">Search for this author on this site</a></li></ul></div><div class="author-tooltip-3"><div class="author-tooltip-name">Anne-Lise Giraud </div><ul class="author-tooltip-find-more"><li class="author-tooltip-gs-link first"><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=author&amp;author%5B0%5D=Anne-Lise%2BGiraud%2B" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on Google Scholar</a></li><li class="author-tooltip-pubmed-link"><a href="/lookup/external-ref?access_num=Giraud%20A&amp;link_type=AUTHORSEARCH" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Find this author on PubMed</a></li><li class="author-site-search-link last"><a href="/search/author1%3AAnne-Lise%2BGiraud%2B" rel="nofollow" class="" data-icon-position="" data-hide-link-title="0">Search for this author on this site</a></li></ul></div></div></div>  </div>

  
  </div>
</div>
			</div>
		</div>
	
	</div> <!-- /.panel-row-wrapper -->	
	  
  <div class="panel-row-wrapper clearfix">
		
		<div class="main-content-wrapper grid-17 suffix-1 alpha">
			<div class="panel-panel panel-region-content">
			  <div class="inside"><div class="panel-pane pane-highwire-panel-tabs pane-panels-ajax-tab-tabs">
  
      
  
  <div class="pane-content">
    <div class="item-list"><ul class="tabs inline panels-ajax-tab"><li class="first active"><a href="/content/29/43/13445" class="panels-ajax-tab-tab panels-ajax-tabs-once-processed panels-ajax-tabs-processed panels-ajax-tabs-first-loaded hw-panels-ajax-tabs-once-processed" data-panel-name="jnl_sfneneuro_tab_art" data-target-id="highwire_article_tabs" data-entity-context="node:370480" data-trigger="" data-url-enabled="1" style="cursor: pointer;">Article</a><a href="/panels_ajax_tab/jnl_sfneneuro_tab_art/node:370480/1" rel="nofollow" style="display:none" class="js-crawler-link"></a></li><li><a href="/content/29/43/13445/tab-figures-data" class="panels-ajax-tab-tab panels-ajax-tabs-once-processed panels-ajax-tabs-processed hw-panels-ajax-tabs-once-processed" data-panel-name="jnl_sfneneuro_tab_data" data-target-id="highwire_article_tabs" data-entity-context="node:370480" data-trigger="tab-figures-data" data-url-enabled="1" style="cursor: pointer;">Figures &amp; Data</a><a href="/panels_ajax_tab/jnl_sfneneuro_tab_data/node:370480/1" rel="nofollow" style="display:none" class="js-crawler-link"></a></li><li><a href="/content/29/43/13445/tab-article-info" class="panels-ajax-tab-tab panels-ajax-tabs-once-processed panels-ajax-tabs-processed hw-panels-ajax-tabs-once-processed" data-panel-name="jnl_sfneneuro_tab_info" data-target-id="highwire_article_tabs" data-entity-context="node:370480" data-trigger="tab-article-info" data-url-enabled="1" style="cursor: pointer;">Info &amp; Metrics</a><a href="/panels_ajax_tab/jnl_sfneneuro_tab_info/node:370480/1" rel="nofollow" style="display:none" class="js-crawler-link"></a></li><li><a href="/content/29/43/13445/tab-e-letters" class="panels-ajax-tab-tab panels-ajax-tabs-once-processed panels-ajax-tabs-processed hw-panels-ajax-tabs-once-processed" data-panel-name="jnl_sfneneuro_tab_elets" data-target-id="highwire_article_tabs" data-entity-context="node:370480" data-trigger="tab-e-letters" data-url-enabled="1" style="cursor: pointer;">eLetters</a><a href="/panels_ajax_tab/jnl_sfneneuro_tab_elets/node:370480/1" rel="nofollow" style="display:none" class="js-crawler-link"></a></li><li class="last"><a href="/content/jneuro/29/43/13445.full.pdf" class="panels-ajax-tab-tab panels-ajax-tabs-once-processed panels-ajax-tabs-processed hw-panels-ajax-tabs-once-processed" data-panel-name="jnl_sfneneuro_tab_pdf" data-target-id="highwire_article_tabs" data-entity-context="node:370480" data-trigger="tab-pdf" data-url-enabled="1" style="cursor: pointer;" target="_blank"><i class="icon-file-alt"></i> PDF</a><a href="/panels_ajax_tab/jnl_sfneneuro_tab_pdf/node:370480/1" rel="nofollow" style="display:none" class="js-crawler-link"></a></li></ul></div>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-panel-tabs-container">
  
      
  
  <div class="pane-content">
    <div data-panels-ajax-tab-preloaded="jnl_sfneneuro_tab_art" id="panels-ajax-tab-container-highwire_article_tabs" class="panels-ajax-tab-container"><div class="panels-ajax-tab-loading" style="display:none"><img class="loading" src="https://www.jneurosci.org/sites/all/modules/contrib/panels_ajax_tab/images/loading.gif" alt="Loading" title="Loading"></div><div class="panels-ajax-tab-wrap-jnl_sfneneuro_tab_art"><div class="panel-display panel-1col clearfix">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-highwire-markup">
  
      
  
  <div class="pane-content">
    <div class="highwire-markup"><div xmlns="http://www.w3.org/1999/xhtml" class="content-block-markup" data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" xmlns:xhtml="http://www.w3.org/1999/xhtml"><div class="article fulltext-view"><span class="highwire-journal-article-marker-start"></span><div class="section abstract" id="abstract-1"><h2>Abstract</h2>
            <p id="p-1">Viewing our interlocutor facilitates speech perception, unlike for instance when we telephone. Several neural routes and mechanisms could account for this phenomenon. Using magnetoencephalography, we show that when seeing the interlocutor, latencies of auditory responses (M100) are the shorter the more predictable speech is from visual input, whether the auditory signal was congruent or not. Incongruence of auditory and visual input affected auditory responses ∼20 ms after latency shortening was detected, indicating that initial content-dependent auditory facilitation by vision is followed by a feedback signal that reflects the error between expected and received auditory input (prediction error). We then used functional magnetic resonance imaging and confirmed that distinct routes of visual information to auditory processing underlie these two functional mechanisms. Functional connectivity between visual motion and auditory areas depended on the degree of visual predictability, whereas connectivity between the superior temporal sulcus and both auditory and visual motion areas was driven by audiovisual (AV) incongruence. These results establish two distinct mechanisms by which the brain uses potentially predictive visual information to improve auditory perception. A fast direct corticocortical pathway conveys visual motion parameters to auditory cortex, and a slower and indirect feedback pathway signals the error between visual prediction and auditory input.</p>
         </div><div class="section intro" id="sec-1">
         <h2>Introduction</h2>
         <p id="p-2">Psychological and neurophysiological data show that visual speech improves auditory speech recognition and processing (<a id="xref-ref-34-1" class="xref-bibr" href="#ref-34">Sumby and Polack, 1954</a>; <a id="xref-ref-36-1" class="xref-bibr" href="#ref-36">von Kriegstein et al., 2008</a>). In most ecological settings, auditory input lags visual input, i.e., mouth movements and speech-associated gestures, by ∼150 ms (<a id="xref-ref-11-1" class="xref-bibr" href="#ref-11">Chandrasekaran et al., 2009</a>). This lag allows the brain to anticipate auditory signals, resulting in speeding up early cortical auditory responses (<a id="xref-ref-6-1" class="xref-bibr" href="#ref-6">Besle et al., 2004</a>; <a id="xref-ref-35-1" class="xref-bibr" href="#ref-35">van Wassenhove et al., 2005</a>; <a id="xref-ref-33-1" class="xref-bibr" href="#ref-33">Stekelenburg and Vroomen, 2007</a>). Physiological and anatomical studies in humans and monkeys indicate several routes by which visual input might influence auditory information processing (<a id="xref-ref-22-1" class="xref-bibr" href="#ref-22">Kayser et al., 2007</a>; <a id="xref-ref-12-1" class="xref-bibr" href="#ref-12">Driver and Noesselt, 2008</a>; <a id="xref-ref-32-1" class="xref-bibr" href="#ref-32">Schroeder et al., 2008</a>). The most common view is that the visual system indirectly reaches the auditory system via a feedback from “supramodal” areas (<a id="xref-ref-16-1" class="xref-bibr" href="#ref-16">Ghazanfar et al., 2005</a>) in which auditory and visual inputs converge. As it responds to both auditory and visual inputs, and more specifically to audiovisual speech combinations (<a id="xref-ref-8-1" class="xref-bibr" href="#ref-8">Calvert and Campbell, 2003</a>; <a id="xref-ref-29-1" class="xref-bibr" href="#ref-29">Miller and D'Esposito, 2005</a>), the middle part of the superior temporal sulcus (STS) is the most likely feedback provider to auditory cortex in a speech context. (<a id="xref-ref-8-2" class="xref-bibr" href="#ref-8">Calvert and Campbell, 2003</a>; <a id="xref-ref-2-1" class="xref-bibr" href="#ref-2">Beauchamp et al., 2004a</a>,<a id="xref-ref-3-1" class="xref-bibr" href="#ref-3">b</a>; <a id="xref-ref-19-1" class="xref-bibr" href="#ref-19">Hertrich et al., 2007</a>; <a id="xref-ref-17-1" class="xref-bibr" href="#ref-17">Ghazanfar et al., 2008</a>; <a id="xref-ref-21-1" class="xref-bibr" href="#ref-21">Kayser and Logothetis, 2009</a>). Current views on multisensory integration (<a id="xref-ref-12-2" class="xref-bibr" href="#ref-12">Driver and Noesselt, 2008</a>; <a id="xref-ref-32-2" class="xref-bibr" href="#ref-32">Schroeder et al., 2008</a>) however suggest that there might be at least one additional cortical pathway by which visual input could influence auditory processing (<a id="xref-fig-1-1" class="xref-fig" href="#F1">Fig. 1</a>
            <em>A</em>), a direct corticocortical input to auditory cortex from visual cortex (<a id="xref-ref-13-1" class="xref-bibr" href="#ref-13">Falchier et al., 2002</a>; <a id="xref-ref-31-1" class="xref-bibr" href="#ref-31">Rockland and Ojima, 2003</a>; <a id="xref-ref-10-1" class="xref-bibr" href="#ref-10">Cappe and Barone, 2005</a>). Here, we assume that we can distinguish the contribution of direct corticocortical versus feedback pathways (<a id="xref-fig-1-2" class="xref-fig" href="#F1">Fig. 1</a>, pathways 1 and 2) by exploring the degree of specificity of auditory processing facilitation by visual input.</p>
         <div id="F1" class="fig pos-float odd"><div class="highwire-figure"><div class="fig-inline-img-wrapper"><div class="fig-inline-img"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F1.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Neuroanatomical model of auditory facilitation by concurrent visual input and related predictions. A , Two anatomical pathways are proposed for the routing of visual information (green arrows) to auditory areas (A) (red arrows representing routing of auditory information): pathway (1) is a direct corticocortical pathway from visual cortices (V) and pathway (2) is a feedback pathway from multisensory STS. B , Time course of evoked components for auditory (red), visual (green), and AV (blue) stimuli. Neuronal facilitation is assessed by measuring amplitude reduction and latency anticipation of the M100A peak in the AV–V versus A conditions. C , Predictions on the origin of M100A facilitation as a function of (1) viseme dependency and (2) mismatch when audio and visual syllables are not congruent." class="highwire-fragment fragment-images colorbox-load highwireFiguresMarkupProcessor-processed cboxElement" rel="gallery-fragment-images-497562102" data-figure-caption="<div class=&quot;highwire-markup&quot;>Neuroanatomical model of auditory facilitation by concurrent visual input and related predictions. A , Two anatomical pathways are proposed for the routing of visual information (green arrows) to auditory areas (A) (red arrows representing routing of auditory information): pathway (1) is a direct corticocortical pathway from visual cortices (V) and pathway (2) is a feedback pathway from multisensory STS. B , Time course of evoked components for auditory (red), visual (green), and AV (blue) stimuli. Neuronal facilitation is assessed by measuring amplitude reduction and latency anticipation of the M100A peak in the AV–V versus A conditions. C , Predictions on the origin of M100A facilitation as a function of (1) viseme dependency and (2) mismatch when audio and visual syllables are not congruent.</div>" data-icon-position="" data-hide-link-title="0"><span class="hw-responsive-img"><img class="highwire-fragment fragment-image  lazyloaded" alt="Figure 1." src="https://www.jneurosci.org/content/jneuro/29/43/13445/F1.medium.gif" data-src="https://www.jneurosci.org/content/jneuro/29/43/13445/F1.medium.gif" width="440" height="229"><noscript><img class="highwire-fragment fragment-image" alt="Figure 1." src="https://www.jneurosci.org/content/jneuro/29/43/13445/F1.medium.gif" width="440" height="229"/></noscript></span></a></div></div><ul class="highwire-figure-links inline"><li class="download-fig first"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F1.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 1." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li class="new-tab"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F1.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li class="download-ppt last"><a href="/highwire/powerpoint/511980" class="highwire-figure-link highwire-figure-link-ppt" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div class="fig-caption" xmlns:xhtml="http://www.w3.org/1999/xhtml"><span class="fig-label">Figure 1.</span> 
               <p id="p-3" class="first-child">Neuroanatomical model of auditory facilitation by concurrent visual input and related predictions. <strong>
                     <em>A</em>
                  </strong>, Two anatomical pathways are proposed for the routing of visual information (green arrows) to auditory areas (A) (red arrows representing routing of auditory information): pathway (1) is a direct corticocortical pathway from visual cortices (V) and pathway (2) is a feedback pathway from multisensory STS. <strong>
                     <em>B</em>
                  </strong>, Time course of evoked components for auditory (red), visual (green), and AV (blue) stimuli. Neuronal facilitation is assessed by measuring amplitude reduction and latency anticipation of the M100A peak in the AV–V versus A conditions. <strong>
                     <em>C</em>
                  </strong>, Predictions on the origin of M100A facilitation as a function of (1) viseme dependency and (2) mismatch when audio and visual syllables are not congruent.</p>
            <div class="sb-div caption-clear"></div></div></div>
         <p id="p-4">We investigated the two possible routing of a visual signal on auditory speech processing by recording early visual (M170V) and auditory (M100A) evoked responses to natural (congruent) and to nonmatching (incongruent) audiovisual syllables using magnetoencephalography (MEG). First, we measured viseme specificity (dependence on lip movements associated with a syllable) of M100A facilitation; second, we examined the dependence of this effect upon audiovisual congruence (neural mismatch). We hypothesized that pathways 1 and 2 should both induce a facilitation that depends on those specific mouth movements that are being used for pronunciation (i.e., viseme-dependent facilitation), but should yield distinct incongruence effects. Direct corticocortical projections arising from visual cortex convey visual information, e.g., visual motion, but no detailed phonological information. pathway 1 is hence expected to induce either no neural mismatch or a mismatch effect that does not exhibit viseme dependency. Conversely, as pathway 2 originates in a region which, among other functions, underpins audiovisual integration of phonological inputs (<a id="xref-ref-2-2" class="xref-bibr" href="#ref-2">Beauchamp et al., 2004a</a>; <a id="xref-ref-1-1" class="xref-bibr" href="#ref-1">Barraclough et al., 2005</a>; <a id="xref-ref-20-1" class="xref-bibr" href="#ref-20">Hickok and Poeppel, 2007</a>), it is expected to induce a viseme-dependent neural mismatch.</p>
         <p id="p-5">We further distinguished between pathways 1 and 2 using a complementary approach. We collected functional MRI data using similar stimuli as in the MEG experiment, with a slightly different paradigm (1) to assess viseme dependency of hemodynamic responses in motion visual cortex and middle STS and (2) to examine the neuroanatomical plausibility of each route using functional connectivity.</p>
      </div><div class="section materials-methods" id="sec-2">
         <h2>Materials and Methods</h2>
         <div id="sec-3" class="subsection">
            
            <div id="sec-4" class="subsection">
               <h4>Ethics statement</h4>
               <p id="p-6">All subjects gave written informed consent to take part in these studies that were approved of by the local ethics committee (Comité Consultatifs de Protection des Personnes se prêtant à des Recherches Biomédicales Paris-Cochin, # RBM 01-04).</p>
            </div>
            <div id="sec-5" class="subsection">
               <h4>Participants</h4>
               <p id="p-7">Thirty-four French native subjects without known neurological or sensory disorder participated in two behavioral pilot experiments and two neuroimaging experiments. Fifteen participants (eight females; age range: 20–53 years) took part in the behavioral experiments. Fifteen other subjects (right-handed, 10 females; age range: 20–28 years) participated in the MEG experiment, and 16 in the fMRI experiment (right-handed, 7 females; age range: 21–26 years). Twelve of them participated in both neuroimaging studies.</p>
            </div>
            <div id="sec-6" class="subsection">
               <h4>Stimuli and behavioral studies</h4>
               <p id="p-8">Audiovisual, audio-only, and visual-only stimuli were extracted from digital videos of a male speaker pronouncing consonant/vowel (CV) syllables (C /a/ syllables) (supplemental Figs. 1 and 2, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). Videos were edited in Adobe Premier Pro into a 720/576 pixel movie with a digitization rate of 60 images/s (1 frame = 16.7 ms). Stereo soundtracks were digitized in Adobe Audition at 44.1 kHz with 16-bit resolution. Stimulus presentation was coordinated with Presentation software (Neurobehavioral Systems).</p>
               <p id="p-9">The two behavioral experiments, referred to as “predictability” and “incongruence” experiments, served to establish a gradient of visual predictability and perceived incongruence, respectively, which we subsequently used in the MEG study. In the predictability pilot experiment participants performed a five-alternative forced-choice experiment in which they were asked to repeat syllables randomly presented in the visual modality only. Mean recognition rates were used as an index of visual predictability (<a id="xref-ref-35-2" class="xref-bibr" href="#ref-35">van Wassenhove et al., 2005</a>). The pilot incongruence study was conducted in the same subjects, who were then asked to quantify perceived incongruence of AV congruent (AVc) or incongruent (AVi) pairs on a four-step (0–3) subjective scale (<a id="xref-ref-4-1" class="xref-bibr" href="#ref-4">Bernstein et al., 2008a</a>). At the end of each trial, subjects were asked to verbally report which syllable had been perceived. Incongruent combinations yielding McGurk fused or combined illusory percepts (<a id="xref-ref-27-1" class="xref-bibr" href="#ref-27">McGurk and MacDonald, 1976</a>; <a id="xref-ref-35-3" class="xref-bibr" href="#ref-35">van Wassenhove et al., 2005</a>) were excluded. We used identical selection criteria for the stimuli used in the fMRI study, and individual recognition scores were assessed online during fMRI recordings.</p>
               <p id="p-10">We selected CV syllables with different places of articulation to enhance a gradient in their visual predictive power. The visual and auditory tracks of each syllable were combined to yield the 4 following conditions: auditory (A), visual (V), AVc, and AVi. In the A condition the sound track was presented with a video of a still face, and in the V condition the speaking face was presented in silence. Incongruent pairs of syllables were created by dubbing the visual track randomly with a nonmatching auditory track. Stimulus mean duration was 5.3 s for the MEG experiment, and 11 s for the fMRI study including varying interstimulus intervals. In both MEG and fMRI designs trials began with a fixation cross on a black screen located at the center of mouth to prevent gaze shift when the face appeared. Videos lasted 2 s, with auditory onset (AO) 1 s after the video began. Details on stimuli and experimental design are provided additionally in supplemental Figures 1 and 2, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material.</p>
            </div>
            <div id="sec-7" class="subsection">
               <h4>MEG study</h4>
               <div id="sec-8" class="subsection">
                  <h5>Experimental procedures.</h5>
                  <p id="p-11">Participants sat at a distance of 1 m from the monitor, the movie subtending 10.5° (horizontal) and 8.5° (vertical) visual angles. Videos were projected on a white screen with a Mitsubishi X120 videoprojector, in a dimly lit room. Sounds were presented at a comfortable hearing level individually set before the experiment (mean = 30 dB sensation level) via Promold earphones (International Aquatic Trade).</p>
                  <p id="p-12">During MEG recordings, subjects performed an unrelated target detection task. They were presented with six possible syllables (/ga/, /ta/, /la/, /pa/, /ja/, /fa/) and were asked to report by keypress whether the presented syllable was a /fa/ (not included in the visual prediction gradient) regardless of the input condition (A, V, or AV) or perceived audiovisual congruence (AVc, AVi). To prevent eye movements, subjects were asked to fixate the cross and blink only after giving their motor response (after the video). Thus, only fewer than 5% of trials were contaminated by eye movement artifacts and were excluded. Stimuli were presented in a pseudorandomized order, with 54 repetitions of each.</p>
               </div>
               <div id="sec-9" class="subsection">
                  <h5>Recordings.</h5>
                  <p id="p-13">Continuous cerebral activity was recorded with a whole-head MEG system (Omega 151, CTF Systems), with 151 axial gradiometers over the scalp, at a sampling rate of 1250 Hz and low-pass filtered online at 300 Hz. Three small coils were attached to reference landmarks on the participant's face: at the left and right preauricular points and at the nasion. At the beginning of each block, the head position relative to the coordinate system of the MEG helmet was calculated from the position of those coils to register possible head movements during the experimental session. Eye movements and blinks were monitored with four ocular electrodes (Viasys Healthcare). They were automatically marked when they exceeded the mean by 2 SDs. This technique however does not detect microsaccades. One supplementary electrode was used to monitor cardiac activity.</p>
               </div>
               <div id="sec-10" class="subsection">
                  <h5>Data processing.</h5>
                  <p id="p-14">Data preprocessing, analysis, and visualization were performed using in-house software (<a href="http://cogimage.dsi.cnrs.fr/logiciels/">http://cogimage.dsi.cnrs.fr/logiciels/</a>). We rejected off-line trials that were contaminated by eye or head movement, muscle contractions, or electromagnetic artifacts. Artifacts related to cardiac activity were eliminated by using a heartbeat trace matched filter. Two subjects were excluded from the data analysis due to poor recording quality. High-pass (0.15 Hz) and low-pass (30 Hz) filters were applied to the continuous recorded signal. Event-related fields (ERFs) were obtained by averaging epochs on a 3 s interval surrounding AO (2 s before and 1 s after) and baseline corrected (still face) on the interval (−900; −300 ms) relative to AO, to ensure that the correction occurred before lip movement onset.</p>
               </div>
               <div id="sec-11" class="subsection">
                  <h5>Behavioral and MEG data analysis.</h5>
                  <p id="p-15">Visual predictability was assessed by measuring recognition rates of each syllable when presented in the visual modality only and tested by repeated-measures ANOVA (factor: viseme; five levels: /ga/, /ta/, /la/, /pa/, /ja/). For each audiovisual combination we also tested for potential interactions between predictability and perceived congruence (factor: viseme; five levels: /ga/, /ta/, /la/, /pa/, /ja/, and congruence; two levels: AVi vs AVc pairs).</p>
                  <p id="p-16">ERF analysis focused on visual facilitation effects on M100A. Thus, for each subject, we pooled the three left temporal channels in which auditory M100 amplitude was maximal. This provided an objective criterion to focus the analysis on M100 source, as we probed visual facilitation on this component. Peak latency and amplitude were extracted for M100A (from 50 to 130 ms relative to AO) in A, AVc, and AVi conditions. To compare these three conditions, time series corresponding to the V condition were subtracted from AV time series. For each syllable, we calculated latency and amplitude differences between A and AV-V M100A peaks. Viseme specificity of latency anticipation and amplitude change of M100A was assessed by computing two-way ANOVAs with repeated-measurement factors as follows: viseme (five levels: /ga/, /ta/, /la/, /pa/, /ja/) and congruence (two levels: AVc, AVi). If there was a significant (<em>p</em> &lt; 0.05) viseme dependency of latency and/or amplitude on M100A facilitation, we further tested whether this effect was due to visual predictability by correlating viseme-dependent facilitation with the related behavioral recognition rate (Pearson's regression analysis). Significance was assumed at <em>p</em> &lt; 0.05.</p>
                  <p id="p-17">To identify the level at which visual and auditory inputs are compared, we searched for a main effect of incongruence at the topographical level by comparing grand-averaged AVc (average of all AVc syllables) with AVi (average of all AVi combinations) conditions. Paired <em>t</em> tests (two tailed, AVi vs AVc) were performed on each MEG sensor to identify the spatiotemporal windows at which incongruence yielded significant effects. Sensors showing the highest <em>T</em> values (minimum <em>T</em> &gt; 3) during a period exceeding 20 ms were computed together. The mean magnitude of the neuromagnetic activity induced by each condition for each window was then extracted and repeated-measures ANOVAs were performed with the following factors: congruence (two levels: AVc, AVi) and viseme (five levels: /ga/, /ta/, /la/, /pa/, /ja/). We checked that these incongruence effects were related to prediction error (discrepancy between expected and incoming auditory input, i.e., perceive incongruence) using a regression analysis in which amplitude differences between AVi and AVc signals were compared with the perceived differences between AVi and AVc conditions. For each of the time windows we obtained, interaction effects between predictability and incongruence were tested by entering amplitude of the evoked response for each syllable as dependent variable into a univariate general linear model with visual predictability as covariate and incongruence as random variable.</p>
               </div>
               <div id="sec-12" class="subsection">
                  <h5>MEG source estimations.</h5>
                  <p id="p-18">Cortical current density time series were estimated individually at each of the 10,000 sources normally distributed over the cortical surface, by using the linear minimum-norm estimator available in the BrainVisa software (<a href="http://brainvisa.info/">http://brainvisa.info/</a>). For each condition, source estimations were individually projected on the MNI template, by matching spatial positions of three coils with corresponding landmarks on the template. Current source time series were then normalized individually by computing <em>Z</em> scores with respect to their baseline (−600 ms; −300 ms) for each condition, before subsequently averaging each condition across subjects. <em>Z</em> score maps were then thresholded above <em>Z</em> = 10 for subsequent analysis and interpretation. We considered cortical activations significant when they exceeded this threshold (deviating from baseline with <em>p</em> &lt; 0.01, uncorrected). Time course of mean (<em>n</em> = 15) <em>Z</em> scores maps at the group level are shown in the supplemental videos, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material (decelerated over the −200 to 500 ms time period). Visualization of spatiotemporal cortical activity was optimized by setting the maximum threshold at 90% of the maximum amplitude of each of the three main components [M170V (−200; 50 ms), M100A (50; 180 ms), and M400 (180; 500 ms), delays are given relative to AO].</p>
               </div>
            </div>
            <div id="sec-13" class="subsection">
               <h4>fMRI study</h4>
               <div id="sec-14" class="subsection">
                  <h5>Stimuli.</h5>
                  <p id="p-19">Methods of stimulus acquisition, edition, and presentation were the same as those used in the MEG experiment. Specific stimulus combinations are provided in supplemental Figure 2<em>B</em>, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material. During MRI acquisition, subjects lay comfortably supine and wore headphones for noise protection and delivery of acoustic stimuli. Visual stimuli were presented on a screen and viewed through a mirror.</p>
               </div>
               <div id="sec-15" class="subsection">
                  <h5>Experimental procedures.</h5>
                  <p id="p-20">During fMRI recordings, subjects were presented videos of a speaker's face pronouncing six syllables (supplemental Fig. 2, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). The soundtrack was either turned off (V) or on, in which case it could either be congruent to the video (AVc) or incongruent (AVi). A video of the speaker's still face with soundtrack (A), or without (still-face video; null), served as control conditions. The task was to determine whether the seen and/or heard stimulus corresponded to a written syllable presented subsequently. Individual syllable predictability scores (recognition rate of each syllable when presented in the visual modality only) were assessed online during fMRI acquisition. These scores were computed for each syllable and normalized within subjects to be related to the fMRI time series.</p>
               </div>
               <div id="sec-16" class="subsection">
                  <h5>fMRI measurements and data processing.</h5>
                  <p id="p-21">Functional images were collected with a Siemens Allegra 3.0 T scanner by acquisition of 980 volumes (four sessions of 245 volumes) of a gradient echo planar imaging (EPI) sequence. Images were parameterized as follows: matrix size, 64 × 64; voxel size, 3 × 3 × 3 mm; echo time, 30 ms; repetition time, 2400 ms. A functional image volume comprised 39 contiguous slices which ensured that the whole brain was within the field of view. Additionally, we acquired a T1 sequence to exclude subjects with possible structural brain anomalies.</p>
                  <p id="p-22">Imaging data were processed and analyzed with SPM5 (Wellcome Department of Imaging Neuroscience, University College of London, UK, <a href="http://www.fil.ion.ucl.ac.uk/spm/software/spm5/">http://www.fil.ion.ucl.ac.uk/spm/software/spm5/</a>). EPI images were spatially preprocessed (realignment, normalization; smoothed with an 8 mm full width at half-maximum isotropic Gaussian kernel) using standard parameters of SPM5. The data were analyzed in the framework of the general linear model. Auditory, visual, audiovisual (AVc and AVi), and null (still-face video) conditions were modeled independently for each syllable as boxcar functions of 2 s and convolved with a classical hemodynamic response function. We analyzed the contrast: speaking faces (V) for all syllables &gt; still faces (null) to determine which regions responded specifically to orofacial movements (speech motion localizer). To probe brain regions that responded to visual predictability, V, AVc, and AVi events conditions were weighted with normalized individual predictability scores for each viseme. Contrasts were calculated at the first level and entered in a second level analysis, with subjects treated as random variable (one-sample <em>t</em> test, <em>p</em> &lt; 0.001 uncorrected).</p>
               </div>
               <div id="sec-17" class="subsection">
                  <h5>Psychophysiological interaction analyses.</h5>
                  <p id="p-23">Functional connectivity was assessed using a procedure implemented in SPM5 for the study of psychophysiological interactions (PPIs) (<a id="xref-ref-15-1" class="xref-bibr" href="#ref-15">Friston et al., 1997</a>). This technique detects changes in the coupling between two brain regions, depending on a factor, here visual syllable predictability. The PPI were computed across the three regions of interest (ROIs): left motion-sensitive cortex, auditory cortex including Heschl's gyrus, and middle STS. The individual time series were extracted from the peak voxel that responded in the appropriate functional contrast in motion-sensitive cortex and in auditory cortex within a radius of 10 mm from the group maxima in the anatomical borders of the probe region. Due to too-widespread individual responses, the ROI in the STS was used only as a target. The regressor for the PPI was computed individually as the product of the extracted time series and a vector coding for the parametric effect of visual predictability (individual recognition score for each syllable). In addition to the PPI regressor and the region-of-interest time series, our model included the main effects of parametric predictability and effects of no interest (movement regressors). We probed an effect of visual predictability on functional connectivity by testing (<em>t</em> test) for a correlation between activity in each region and PPI regressors. We assessed functional connectivity pairwise across left motion-sensitive cortex, auditory cortex, and STS and report maxima appearing within 2-cm-radius spheres surrounding these regions of interest with a threshold of <em>p</em> ≤ 0.01, uncorrected.</p>
               </div>
            </div>
         </div>
      </div><div class="section results" id="sec-18">
         <h2>Results</h2>
         <div id="sec-19" class="subsection">
            <h3>Gradient of visual syllable predictability</h3>
            <p id="p-24">In the MEG experiment we used five syllables (/ga/, /ta/, /la/, /pa/, /ja/) that were randomly presented to the subjects in auditory (sound plus still face), visual (silent video), and audiovisual conditions (supplemental Fig. 1, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). When presented in the visual modality only, in a pilot behavioral experiment, these five syllables yielded recognition rates ranging from 38 to 99.3% (repeated-measures ANOVA: <em>F</em>
               <sub>(4,56)</sub> = 83.604, <em>p</em> = 0.000) (<a id="xref-fig-2-1" class="xref-fig" href="#F2">Fig. 2</a>). Such a broad gradient of visual predictability was a requirement to use these stimuli to assess viseme dependency in neural effects.</p>
            <div id="F2" class="fig pos-float odd"><div class="highwire-figure"><div class="fig-inline-img-wrapper"><div class="fig-inline-img"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F2.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Predictability of syllables /ga/, /ta/, /la/, /pa/, and /ja/, presented visually (V) and ordered by increasing predictability. The predictive power of five visual syllables was assessed by measuring recognition rates in 15 subjects. Error bars indicate SEM. **p < 0.01, ***p < 0.001." class="highwire-fragment fragment-images colorbox-load highwireFiguresMarkupProcessor-processed cboxElement" rel="gallery-fragment-images-497562102" data-figure-caption="<div class=&quot;highwire-markup&quot;>Predictability of syllables /ga/, /ta/, /la/, /pa/, and /ja/, presented visually (V) and ordered by increasing predictability. The predictive power of five visual syllables was assessed by measuring recognition rates in 15 subjects. Error bars indicate SEM. **p < 0.01, ***p < 0.001.</div>" data-icon-position="" data-hide-link-title="0"><span class="hw-responsive-img"><img class="highwire-fragment fragment-image lazyload" alt="Figure 2." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.jneurosci.org/content/jneuro/29/43/13445/F2.medium.gif" width="440" height="420"><noscript><img class="highwire-fragment fragment-image" alt="Figure 2." src="https://www.jneurosci.org/content/jneuro/29/43/13445/F2.medium.gif" width="440" height="420"/></noscript></span></a></div></div><ul class="highwire-figure-links inline"><li class="download-fig first"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F2.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 2." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li class="new-tab"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F2.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li class="download-ppt last"><a href="/highwire/powerpoint/511982" class="highwire-figure-link highwire-figure-link-ppt" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div class="fig-caption"><span class="fig-label">Figure 2.</span> 
                  <p id="p-25" class="first-child">Predictability of syllables /ga/, /ta/, /la/, /pa/, and /ja/, presented visually (V) and ordered by increasing predictability. The predictive power of five visual syllables was assessed by measuring recognition rates in 15 subjects. Error bars indicate SEM. **<em>p</em> &lt; 0.01, ***<em>p</em> &lt; 0.001.</p>
               <div class="sb-div caption-clear"></div></div></div>
         </div>
         <div id="sec-20" class="subsection">
            <h3>Viseme dependency of M100 facilitation</h3>
            <p id="p-26">Early cortical evoked responses (EEG P2) typically have shorter latencies in audiovisual relative to auditory condition (<a id="xref-ref-35-4" class="xref-bibr" href="#ref-35">van Wassenhove et al., 2005</a>; <a id="xref-ref-33-2" class="xref-bibr" href="#ref-33">Stekelenburg and Vroomen, 2007</a>). We confirmed decreased latency of event-related MEG responses, detectable as early as 100 ms poststimulus (M100A) when facial movements accompany corresponding speech sounds (<em>F</em>
               <sub>(1,14)</sub> = 22.7, <em>p</em> = 0.000) (<a id="xref-fig-3-1" class="xref-fig" href="#F3">Fig. 3</a>
               <em>A</em>). This anticipation was viseme-dependent (<em>F</em>
               <sub>(4,56)</sub> = 4.35, <em>p</em> = 0.003) (<a id="xref-fig-3-2" class="xref-fig" href="#F3">Fig. 3</a>
               <em>B</em>), and strictly followed the visual predictability gradient established behaviorally. Latency reduction was stronger for syllables that are associated with large and unambiguous mouth movements (high visual predictability: /ja/) than for syllables associated with ambiguous facial movement (low visual predictability: /ga/) (Pearson's <em>r</em> = 0.30, <em>p</em> = 0.009). Anticipation of M100A by visual input was also accompanied by a change in M100 amplitude (<em>F</em>
               <sub>(4,56)</sub> = 4.06, <em>p</em> = 0.006) (<a id="xref-fig-3-3" class="xref-fig" href="#F3">Fig. 3</a>
               <em>C</em>) that affected all syllables (<em>F</em>
               <sub>(1,14)</sub> = 8.84, <em>p</em> = 0.010), without precisely following the behavioral visual predictability gradient (<em>r</em> = 0.11, <em>p</em> = 0.332) (<a id="xref-fig-3-4" class="xref-fig" href="#F3">Fig. 3</a>
               <em>C</em>).</p>
            <div id="F3" class="fig pos-float odd"><div class="highwire-figure"><div class="fig-inline-img-wrapper"><div class="fig-inline-img"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F3.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Facilitation of early auditory response by visual input. A , Auditory evoked response (M100A) latency (A, dark bar) was globally reduced by visual syllables whether they matched the sound (AVc, gray bar) or not (AVi, white bar). B , M100A latency reduction [A-(AV–V)], represented as a function of visual predictability (Fig. 2), shows a significant viseme dependency but no effect of incongruence. M100 latency reduction is proportional to visual predictability in both AVc (black dashed line) and AVi (gray dashed line) combinations. No significant difference between AVc and AVi regression slopes was found. C , M100A amplitude change (positive values correspond to a reduction of M100A in AV–V vs A condition) indicates a significant effect of syllables but no viseme dependency or incongruence effect. D , Perceived incongruence for AVc and AVi combinations. Note that comparisons focus on the visual syllable (for example PaAVc is compared with PaAVi, e.g., PaV/GaA) (supplemental Fig. 1B, available at www.jneurosci.org as supplemental material). Perceived incongruence for AVi pairs correlates positively with visual predictability (gray dashed line), whereas perceived incongruence for AVc pairs correlates negatively with visual predictability (black dashed line, interaction significant). Error bars indicate SEM. *p < 0.05, **p < 0.01, ***p < 0.001." class="highwire-fragment fragment-images colorbox-load highwireFiguresMarkupProcessor-processed cboxElement" rel="gallery-fragment-images-497562102" data-figure-caption="<div class=&quot;highwire-markup&quot;>Facilitation of early auditory response by visual input. A , Auditory evoked response (M100A) latency (A, dark bar) was globally reduced by visual syllables whether they matched the sound (AVc, gray bar) or not (AVi, white bar). B , M100A latency reduction [A-(AV–V)], represented as a function of visual predictability (Fig. 2), shows a significant viseme dependency but no effect of incongruence. M100 latency reduction is proportional to visual predictability in both AVc (black dashed line) and AVi (gray dashed line) combinations. No significant difference between AVc and AVi regression slopes was found. C , M100A amplitude change (positive values correspond to a reduction of M100A in AV–V vs A condition) indicates a significant effect of syllables but no viseme dependency or incongruence effect. D , Perceived incongruence for AVc and AVi combinations. Note that comparisons focus on the visual syllable (for example PaAVc is compared with PaAVi, e.g., PaV/GaA) (supplemental Fig. 1B, available at www.jneurosci.org as supplemental material). Perceived incongruence for AVi pairs correlates positively with visual predictability (gray dashed line), whereas perceived incongruence for AVc pairs correlates negatively with visual predictability (black dashed line, interaction significant). Error bars indicate SEM. *p < 0.05, **p < 0.01, ***p < 0.001.</div>" data-icon-position="" data-hide-link-title="0"><span class="hw-responsive-img"><img class="highwire-fragment fragment-image lazyload" alt="Figure 3." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.jneurosci.org/content/jneuro/29/43/13445/F3.medium.gif" width="440" height="329"><noscript><img class="highwire-fragment fragment-image" alt="Figure 3." src="https://www.jneurosci.org/content/jneuro/29/43/13445/F3.medium.gif" width="440" height="329"/></noscript></span></a></div></div><ul class="highwire-figure-links inline"><li class="download-fig first"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F3.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 3." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li class="new-tab"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F3.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li class="download-ppt last"><a href="/highwire/powerpoint/511983" class="highwire-figure-link highwire-figure-link-ppt" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div class="fig-caption"><span class="fig-label">Figure 3.</span> 
                  <p id="p-27" class="first-child">Facilitation of early auditory response by visual input. <strong>
                        <em>A</em>
                     </strong>, Auditory evoked response (M100A) latency (A, dark bar) was globally reduced by visual syllables whether they matched the sound (AVc, gray bar) or not (AVi, white bar). <strong>
                        <em>B</em>
                     </strong>, M100A latency reduction [A-(AV–V)], represented as a function of visual predictability (<a id="xref-fig-2-2" class="xref-fig" href="#F2">Fig. 2</a>), shows a significant viseme dependency but no effect of incongruence. M100 latency reduction is proportional to visual predictability in both AVc (black dashed line) and AVi (gray dashed line) combinations. No significant difference between AVc and AVi regression slopes was found. <strong>
                        <em>C</em>
                     </strong>, M100A amplitude change (positive values correspond to a reduction of M100A in AV–V vs A condition) indicates a significant effect of syllables but no viseme dependency or incongruence effect. <strong>
                        <em>D</em>
                     </strong>, Perceived incongruence for AVc and AVi combinations. Note that comparisons focus on the visual syllable (for example PaAVc is compared with PaAVi, e.g., PaV/GaA) (supplemental Fig. 1<em>B</em>, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). Perceived incongruence for AVi pairs correlates positively with visual predictability (gray dashed line), whereas perceived incongruence for AVc pairs correlates negatively with visual predictability (black dashed line, interaction significant). Error bars indicate SEM. *<em>p</em> &lt; 0.05, **<em>p</em> &lt; 0.01, ***<em>p</em> &lt; 0.001.</p>
               <div class="sb-div caption-clear"></div></div></div>
         </div>
         <div id="sec-21" class="subsection">
            <h3>M100 insensitivity to mismatch</h3>
            <p id="p-28">We examined whether direct corticocortical and feedback schemes can be distinguished on the basis of incongruence effects. As auditory and visual speech information converge on the STS (<a id="xref-ref-9-1" class="xref-bibr" href="#ref-9">Calvert et al., 1997</a>), feedback signal from the STS to auditory cortex should convey a phonologically more detailed prediction than one from visual areas, which should merely convey the amount and timing of facial movements. Because the more detailed the predictive signal, the stronger the mismatch when expectation is not met, we assume audiovisual mismatch to interact with facilitation proportionally to audiovisual incongruence. Thus, we expected audiovisual incongruence to interact with the early facilitation effect only if the latter was mediated by a feedback route (pathway 2), but not if was driven by a direct input from visual regions (pathway 1).</p>
            <p id="p-29">We also measured changes on auditory M100 amplitude and latency induced by the presence of visual syllables, when visual and auditory inputs were incongruent. Incongruence was generated by randomly combining the five visual and sound tracks of the videos, while excluding McGurk combinations, which resulted in five distinct levels of perceived incongruence (<a id="xref-fig-3-5" class="xref-fig" href="#F3">Fig. 3</a>
               <em>D</em>). In the second pilot behavioral experiment, we established that visual predictability determined the perceived level of incongruence in physically incongruent syllables. In other words, the most predictive viseme yielded the strongest incongruence sensation (Pearson's <em>r</em> = 0.78, <em>p</em> = 0.000) (<a id="xref-fig-3-6" class="xref-fig" href="#F3">Fig. 3</a>
               <em>D</em>). We further observed that physically congruent syllables could also evoke an incongruent percept when visual information was ambiguous, i.e., in the least predictable visual syllables (<em>r</em> = −0.53, <em>p</em> = 0.000) (<a id="xref-fig-3-7" class="xref-fig" href="#F3">Fig. 3</a>
               <em>D</em>). When comparing responses evoked by incongruent and congruent stimuli, we did not detect neural mismatch effects on M100 peak neither in amplitude [<em>F</em>
               <sub>(1,14)</sub> = 0.03, <em>p</em> = 0.864) (<a id="xref-fig-3-8" class="xref-fig" href="#F3">Fig. 3</a>
               <em>C</em>), nor in latency (<em>F</em>
               <sub>(1,14)</sub> = 0.01, <em>p</em> = 0.906) (<a id="xref-fig-3-9" class="xref-fig" href="#F3">Fig. 3</a>
               <em>A</em>,<em>B</em>)], which confirms previous observations (<a id="xref-ref-33-3" class="xref-bibr" href="#ref-33">Stekelenburg and Vroomen, 2007</a>). Audiovisual mismatch did not alter viseme dependency of M100 facilitation, neither in amplitude (<em>F</em>
               <sub>(4,56)</sub> = 3.57, <em>p</em> = 0.011) (<a id="xref-fig-3-10" class="xref-fig" href="#F3">Fig. 3</a>
               <em>C</em>) nor in latency (<em>F</em>
               <sub>(4,56)</sub> = 3.80, <em>p</em> = 0.008) (<a id="xref-fig-3-11" class="xref-fig" href="#F3">Fig. 3</a>
               <em>B</em>). This result implies that speech was facilitated only as a function of the physical characteristics of the visual input and regardless of its discordance with the auditory input. Our results hence suggest that facilitation corresponds to a viseme-dependent signal that reflects the relative predictability of facial motion, but conveys only imprecise phonological information. Alternatively facilitation could occur at a too early stage of auditory processing to take full benefit of a phonological prediction.</p>
         </div>
         <div id="sec-22" class="subsection">
            <h3>Time course of neural mismatch</h3>
            <p id="p-30">As we found no effect of audiovisual incongruence on M100 and no interaction between incongruence and M100 latency shortening, we examined the time course of neural mismatch in MEG responses to determine when physical mismatch between auditory and visual stimuli was reflected in cortical responses. When we compared the time course of responses evoked by incongruent versus congruent stimuli, we found that significant amplitude changes were evoked by the mismatch between auditory and visual inputs (<a id="xref-fig-4-1" class="xref-fig" href="#F4">Fig. 4</a>). The earliest mismatch effect (<em>F</em>
               <sub>(1,14)</sub> = 25.4, <em>p</em> = 0.000) was detected ∼120 ms after voice onset (<a id="xref-fig-4-2" class="xref-fig" href="#F4">Fig. 4</a>
               <em>A</em>), i.e., 20 ms after the facilitation effect. As we also detected a 20 ms difference between the M170 peak to visual syllables in motion-sensitive cortex and the M170 peak in the STS (supplemental Fig. 3, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material), these results are compatible with a phonological signal arising from the STS with a delay relative to the motion signal. Of note, auditory cortex and STS peaked simultaneously in response to visual syllables. This suggests that a motion signal splits between two targets, the auditory cortex and the STS, and is compatible with a secondary feedback subsequently reaching the auditory cortex from the STS. Neural mismatch increased for another 300 ms showing three more maxima at ∼250 ms (<em>F</em>
               <sub>(1,14)</sub> = 8.84, <em>p</em> = 0.010), 370 ms (<em>F</em>
               <sub>(1,14)</sub> = 13.39, <em>p</em> = 0.003) and 460 ms (<em>F</em>
               <sub>(1,14)</sub> = 18.94, <em>p</em> = 0.001) (<a id="xref-fig-4-3" class="xref-fig" href="#F4">Fig. 4</a>
               <em>A</em>), indicating at least three more steps in which visual prediction and bottom-up auditory signal are being compared. A repeated 100 ms delay between successive mismatch maxima is suggestive of iterative loops of interactions between motion-sensitive cortex, auditory cortex and the STS. At each iteration, the strength of the interaction between viseme predictability and neural mismatch increased. This interaction effect became statistically significant and additionally correlated with perceived incongruence at ∼350 ms (<a id="xref-fig-4-4" class="xref-fig" href="#F4">Fig. 4</a>
               <em>B</em>,<em>C</em>). Dynamic source reconstructions show that auditory cortex/STS/motion cortex loops occur when audiovisual convergence is not reached, i.e., when syllables are presented visually only (supplemental Video 1, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material), and when audio and visual tracks do not match (supplemental Video 2, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). When ambiguity is low, i.e., in response to auditory only or to congruent stimuli, neural activity flows toward anterior regions in the ventral temporal cortex (supplemental Video 3, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). Although source reconstructions are only qualitative evidence, the timing of neural mismatch supports a secondary feedback signal from the STS to the auditory cortex.</p>
            <div id="F4" class="fig pos-float odd"><div class="highwire-figure"><div class="fig-inline-img-wrapper"><div class="fig-inline-img"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F4.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Effect of incongruence on ERFs across time. A , Scalp topographies within the four time windows in which neural incongruence effect was detected (paired t test; grand average of AVi vs AVc conditions, with the overall sum of stimuli in AVi and AVc conditions physically the same) (supplemental Fig. 1A, available at www.jneurosci.org as supplemental material). B , Effect of incongruence on viseme dependency of neural response amplitude, tested across those five selected sensors (black dots on topographies) showing a maximal effect, within the two extreme time windows. Dark and light gray dashed lines represent the correlations between amplitude and predictability in AVc and AVi conditions respectively. C , Parallel between neural responses and behavioral reports related to incongruence. Left axis (dark line) indicates incongruence-by-viseme interaction F values (significant for the last 2 time windows) at the ERF level. The gray line shows that correlation values (Pearson's r, right axis) between ERF amplitude differences and perceived incongruence difference for each AVi versus AVc pair also increases over time. Error bars indicate SEM. n.s., Nonsignificant effect. *p < 0.05, ***p < 0.001." class="highwire-fragment fragment-images colorbox-load highwireFiguresMarkupProcessor-processed cboxElement" rel="gallery-fragment-images-497562102" data-figure-caption="<div class=&quot;highwire-markup&quot;>Effect of incongruence on ERFs across time. A , Scalp topographies within the four time windows in which neural incongruence effect was detected (paired t test; grand average of AVi vs AVc conditions, with the overall sum of stimuli in AVi and AVc conditions physically the same) (supplemental Fig. 1A, available at www.jneurosci.org as supplemental material). B , Effect of incongruence on viseme dependency of neural response amplitude, tested across those five selected sensors (black dots on topographies) showing a maximal effect, within the two extreme time windows. Dark and light gray dashed lines represent the correlations between amplitude and predictability in AVc and AVi conditions respectively. C , Parallel between neural responses and behavioral reports related to incongruence. Left axis (dark line) indicates incongruence-by-viseme interaction F values (significant for the last 2 time windows) at the ERF level. The gray line shows that correlation values (Pearson's r, right axis) between ERF amplitude differences and perceived incongruence difference for each AVi versus AVc pair also increases over time. Error bars indicate SEM. n.s., Nonsignificant effect. *p < 0.05, ***p < 0.001.</div>" data-icon-position="" data-hide-link-title="0"><span class="hw-responsive-img"><img class="highwire-fragment fragment-image lazyload" alt="Figure 4." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.jneurosci.org/content/jneuro/29/43/13445/F4.medium.gif" width="440" height="394"><noscript><img class="highwire-fragment fragment-image" alt="Figure 4." src="https://www.jneurosci.org/content/jneuro/29/43/13445/F4.medium.gif" width="440" height="394"/></noscript></span></a></div></div><ul class="highwire-figure-links inline"><li class="download-fig first"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F4.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 4." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li class="new-tab"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F4.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li class="download-ppt last"><a href="/highwire/powerpoint/511986" class="highwire-figure-link highwire-figure-link-ppt" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div class="fig-caption"><span class="fig-label">Figure 4.</span> 
                  <p id="p-31" class="first-child">Effect of incongruence on ERFs across time. <strong>
                        <em>A</em>
                     </strong>, Scalp topographies within the four time windows in which neural incongruence effect was detected (paired <em>t</em> test; grand average of AVi vs AVc conditions, with the overall sum of stimuli in AVi and AVc conditions physically the same) (supplemental Fig. 1<em>A</em>, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). <strong>
                        <em>B</em>
                     </strong>, Effect of incongruence on viseme dependency of neural response amplitude, tested across those five selected sensors (black dots on topographies) showing a maximal effect, within the two extreme time windows. Dark and light gray dashed lines represent the correlations between amplitude and predictability in AVc and AVi conditions respectively. <strong>
                        <em>C</em>
                     </strong>, Parallel between neural responses and behavioral reports related to incongruence. Left axis (dark line) indicates incongruence-by-viseme interaction <em>F</em> values (significant for the last 2 time windows) at the ERF level. The gray line shows that correlation values (Pearson's <em>r</em>, right axis) between ERF amplitude differences and perceived incongruence difference for each AVi versus AVc pair also increases over time. Error bars indicate SEM. n.s., Nonsignificant effect. *<em>p</em> &lt; 0.05, ***<em>p</em> &lt; 0.001.</p>
               <div class="sb-div caption-clear"></div></div></div>
         </div>
         <div id="sec-23" class="subsection">
            <h3>Visual motion sources</h3>
            <p id="p-32">The temporal dynamics of evoked visual responses provides additional arguments to distinguish between direct corticocortical/pathway 1 and feedback/pathway 2 (supplemental Fig. 3, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material). The earliest evoked response to visually presented syllables (M170) (<a id="xref-fig-1-3" class="xref-fig" href="#F1">Fig. 1</a>
               <em>B</em>) peaked in motion-sensitive visual cortex (in accord with <a id="xref-ref-7-1" class="xref-bibr" href="#ref-7">Besle et al., 2008</a>) earlier than in the STS (paired <em>t</em> test, <em>p</em> = 0.025). Our results thus tend to point to motion-sensitive cortex as the most plausible origin of an early visual prediction signal, further arguing for direct corticocortical pathway 1. Although we emphasized the detection of motion response by using a still-face video as a baseline, we also observed a weak source in V1/V2, which could reflect a complementary influence of earlier visual areas that have been shown to project on auditory cortex in animals (<a id="xref-ref-31-2" class="xref-bibr" href="#ref-31">Rockland and Ojima, 2003</a>; <a id="xref-ref-10-2" class="xref-bibr" href="#ref-10">Cappe and Barone, 2005</a>). Despite their high anatomical plausibility these projections unlikely contribute to M100A facilitation in a viseme-dependent manner.</p>
            <p id="p-33">The amplitude of M170 over the occipital sensors in response to silent videos increased as a function of syllable visual predictability (Pearson's <em>r</em> = 0.46, <em>p</em> = 0.000). The amount of information reaching the auditory cortex from motion-sensitive cortex could thus determine the strength of the facilitation induced by visual signal in this natural audiovisual context. Yet, we could not observe significant statistical relationship between M170V amplitude and the strength of the facilitation, neither on amplitude nor on latency of auditory M100. This may stem from the fact that visually driven correlations between M170 and M100 responses were masked by interindividual variability even after normalization. MEG source reconstruction on the other hand, is moderately reliable to localize the origin of a visual predictive signal (<a id="xref-fig-5-1" class="xref-fig" href="#F5">Fig. 5</a>
               <em>A</em>). Whether response magnitude in motion-sensitive cortex determines the amount of visual facilitation therefore remains unclear.</p>
            <div id="F5" class="fig pos-float odd"><div class="highwire-figure"><div class="fig-inline-img-wrapper"><div class="fig-inline-img"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F5.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Surface renderings of MEG sources and fMRI activations. A , Source reconstruction of M170 peak measured in response to the viseme /pa/ shows that early activity related to lips movements emerges in the temporo-occipital cortex (visual motion cortex, as separately assessed by functional localizer). B , Summary of fMRI findings: parametric increase with syllable visual predictability (green blob) overlaps with the sources of M170 shown in A . Functional connectivity was assessed using PPI with visual syllable recognition rates as the psychological variable. There was a parametric increase of functional connectivity between visual motion cortex and auditory regions surrounding Heschl's gyrus (red blobs). The middle STS showed the opposite effect, i.e., a decrease of functional connectivity as a function of visual predictability (yellow blob and blue blob) when using both visual motion and auditory cortices as seed regions. C , Activity in STS also reflects the amount of prediction error, showing a signal increase for incongruent stimuli (white squares) and a signal decrease for congruent stimuli (gray squares), proportionally to visual predictability. *p < 0.05, **p < 0.01." class="highwire-fragment fragment-images colorbox-load highwireFiguresMarkupProcessor-processed cboxElement" rel="gallery-fragment-images-497562102" data-figure-caption="<div class=&quot;highwire-markup&quot;>Surface renderings of MEG sources and fMRI activations. A , Source reconstruction of M170 peak measured in response to the viseme /pa/ shows that early activity related to lips movements emerges in the temporo-occipital cortex (visual motion cortex, as separately assessed by functional localizer). B , Summary of fMRI findings: parametric increase with syllable visual predictability (green blob) overlaps with the sources of M170 shown in A . Functional connectivity was assessed using PPI with visual syllable recognition rates as the psychological variable. There was a parametric increase of functional connectivity between visual motion cortex and auditory regions surrounding Heschl's gyrus (red blobs). The middle STS showed the opposite effect, i.e., a decrease of functional connectivity as a function of visual predictability (yellow blob and blue blob) when using both visual motion and auditory cortices as seed regions. C , Activity in STS also reflects the amount of prediction error, showing a signal increase for incongruent stimuli (white squares) and a signal decrease for congruent stimuli (gray squares), proportionally to visual predictability. *p < 0.05, **p < 0.01.</div>" data-icon-position="" data-hide-link-title="0"><span class="hw-responsive-img"><img class="highwire-fragment fragment-image lazyload" alt="Figure 5." src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.jneurosci.org/content/jneuro/29/43/13445/F5.medium.gif" width="418" height="440"><noscript><img class="highwire-fragment fragment-image" alt="Figure 5." src="https://www.jneurosci.org/content/jneuro/29/43/13445/F5.medium.gif" width="418" height="440"/></noscript></span></a></div></div><ul class="highwire-figure-links inline"><li class="download-fig first"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F5.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 5." data-icon-position="" data-hide-link-title="0">Download figure</a></li><li class="new-tab"><a href="https://www.jneurosci.org/content/jneuro/29/43/13445/F5.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">Open in new tab</a></li><li class="download-ppt last"><a href="/highwire/powerpoint/511988" class="highwire-figure-link highwire-figure-link-ppt" data-icon-position="" data-hide-link-title="0">Download powerpoint</a></li></ul></div><div class="fig-caption"><span class="fig-label">Figure 5.</span> 
                  <p id="p-34" class="first-child">Surface renderings of MEG sources and fMRI activations. <strong>
                        <em>A</em>
                     </strong>, Source reconstruction of M170 peak measured in response to the viseme /pa/ shows that early activity related to lips movements emerges in the temporo-occipital cortex (visual motion cortex, as separately assessed by functional localizer). <strong>
                        <em>B</em>
                     </strong>, Summary of fMRI findings: parametric increase with syllable visual predictability (green blob) overlaps with the sources of M170 shown in <strong>
                        <em>A</em>
                     </strong>. Functional connectivity was assessed using PPI with visual syllable recognition rates as the psychological variable. There was a parametric increase of functional connectivity between visual motion cortex and auditory regions surrounding Heschl's gyrus (red blobs). The middle STS showed the opposite effect, i.e., a decrease of functional connectivity as a function of visual predictability (yellow blob and blue blob) when using both visual motion and auditory cortices as seed regions. <strong>
                        <em>C</em>
                     </strong>, Activity in STS also reflects the amount of prediction error, showing a signal increase for incongruent stimuli (white squares) and a signal decrease for congruent stimuli (gray squares), proportionally to visual predictability. *<em>p</em> &lt; 0.05, **<em>p</em> &lt; 0.01.</p>
               <div class="sb-div caption-clear"></div></div></div>
         </div>
         <div id="sec-24" class="subsection">
            <h3>Effect of visual predictability on hemodynamic responses</h3>
            <p id="p-35">We used fMRI with similar stimuli as in the MEG experiment (supplemental Fig. 2, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material), but instead of detecting a target syllable subjects had to answer whether the presented stimulus corresponded or not to a syllable proposed in written, e.g., “Pa?”. In the fMRI time series, we probed brain regions in which hemodynamic activity increased parametrically with visual predictability as assessed during MRI acquisition using individual recognition rates for each syllable (visual only). In a whole brain analysis, increasing visual recognition rates of syllables correlated with bilateral activity of lateral extrastriate occipital cortex (<a id="xref-fig-5-2" class="xref-fig" href="#F5">Fig. 5</a>
               <em>B</em>, green blob, <a id="xref-table-wrap-1-1" class="xref-table" href="#T1">Table 1</a>
               <em>a</em>), which according to its coordinates could correspond to V5/hMT+ (<a id="xref-ref-26-1" class="xref-bibr" href="#ref-26">Malikovic et al., 2007</a>). We confirmed the sensitivity to motion of this region by a speech motion functional localizer (see Materials and Methods). This effect is consistent with the above-described correlation between visual predictability and M170 amplitude. Visual predictability enhanced functional connectivity between left motion-sensitive cortex and the left perisylvian region, i.e., rolandic operculum (<a id="xref-fig-5-3" class="xref-fig" href="#F5">Fig. 5</a>
               <em>B</em>, red blob, <a id="xref-table-wrap-1-2" class="xref-table" href="#T1">Table 1</a>
               <em>d</em>), supramarginal gyrus (<em>p</em> = 0.022), and medial auditory posterior insula (<em>p</em> = 0.029). That the target of connectivity from motion-sensitive cortex was not located within the primary auditory cortex fits with intracortical recordings in humans (<a id="xref-ref-7-2" class="xref-bibr" href="#ref-7">Besle et al., 2008</a>), and with anatomical studies in animals showing that fibers arising from motion-sensitive cortex target the belt but not the primary auditory region (<a id="xref-ref-10-3" class="xref-bibr" href="#ref-10">Cappe and Barone, 2005</a>). These results are compatible with our MEG data, and further show that the region that is contacted by visual inputs is normally involved in both expressive and receptive phonology (<a id="xref-ref-20-2" class="xref-bibr" href="#ref-20">Hickok and Poeppel, 2007</a>). Note that PPIs cannot permit to infer directionality. However, as connectivity varied as a parametric function of visual input neural information likely flows from motion-sensitive cortex to auditory cortex.</p>
            <div class="table pos-float" id="T1"><div class="table-inline table-callout-links"><div class="callout"><span>View this table:</span><ul class="callout-links"><li class="view-inline first"><a href="##" class="table-expand-inline highwireTablesMarkupProcessor-processed" data-table-url="/highwire/markup/511990/expansion?postprocessors=highwire_tables%2Chighwire_reclass%2Chighwire_figures%2Chighwire_math%2Chighwire_inline_linked_media%2Chighwire_embed&amp;table-expand-inline=1" data-icon-position="" data-hide-link-title="0">View inline</a></li><li class="view-popup last"><a href="/highwire/markup/511990/expansion?width=1000&amp;height=500&amp;iframe=true&amp;postprocessors=highwire_tables%2Chighwire_reclass%2Chighwire_figures%2Chighwire_math%2Chighwire_inline_linked_media%2Chighwire_embed" class="colorbox colorbox-load table-expand-popup init-colorbox-processed cboxElement" rel="gallery-fragment-tables" data-icon-position="" data-hide-link-title="0">View popup</a></li></ul></div></div><div class="table-caption"><span class="table-label">Table 1.</span> 
                  <p id="p-36" class="first-child">Peak coordinates of activated clusters in the fMRI experiment</p>
               <div class="sb-div caption-clear"></div></div></div>
            <p id="p-38">In contrast, an increase in functional connectivity between left motion-sensitive cortex and the middle STS was found when visual predictability decreased, i.e., when visual syllable ambiguity increased (<a id="xref-fig-5-4" class="xref-fig" href="#F5">Fig. 5</a>
               <em>B</em>, yellow blob, <a id="xref-table-wrap-1-3" class="xref-table" href="#T1">Table 1</a>
               <em>e</em>). Functional connectivity also increased between the left STS and the auditory cortex [near Heschl's gyrus according to cytoarchitectonic templates (<a id="xref-ref-30-1" class="xref-bibr" href="#ref-30">Morosan et al., 2001</a>)] when viseme ambiguity increased (<a id="xref-fig-5-5" class="xref-fig" href="#F5">Fig. 5</a>
               <em>B</em>, blue blob, <a id="xref-table-wrap-1-4" class="xref-table" href="#T1">Table 1</a>
               <em>g</em>). As the STS could not be taken as a source for the functional connectivity analysis, we could not determine whether a feedback from the STS targets the same or a different region than the corticocortical projection from motion-sensitive cortex. However, enhanced neural activity for visual ambiguity was confirmed in this region when directly tracking regions in which activity decreased with visual predictability in natural stimuli (AV congruent stimuli) (<a id="xref-fig-5-6" class="xref-fig" href="#F5">Fig. 5</a>
               <em>C</em>, gray squares) (<em>r</em> = −0.21, <em>p</em> = 0.038) (<a id="xref-table-wrap-1-5" class="xref-table" href="#T1">Table 1</a>
               <em>b</em>), and also when probing effects that covaried positively with predictability when auditory and visual inputs did not match (AV incongruent stimuli) (<a id="xref-fig-5-7" class="xref-fig" href="#F5">Fig. 5</a>
               <em>C</em>) (white squares, <em>r</em> = 0.29, <em>p</em> = 0.004) (<a id="xref-table-wrap-1-6" class="xref-table" href="#T1">Table 1</a>
               <em>c</em>).</p>
         </div>
      </div><div class="section discussion" id="sec-25">
         <h2>Discussion</h2>
         <p id="p-39">We used MEG and fMRI to distinguish the contribution of two possible neural connectivity patterns by which visual speech may facilitate auditory responses. Our MEG design takes advantage of the 150 ms natural delay between visual and auditory onset in natural speech to track independently predictive visual signals and their cross-modal facilitation effect. By selecting visual syllables associated with increasing recognition rates (<a id="xref-ref-35-5" class="xref-bibr" href="#ref-35">van Wassenhove et al., 2005</a>) we implemented an incremental visual prediction and confirmed that the early auditory cortical MEG component (M100) is sped up by the presence of congruent facial movements (<a id="xref-ref-35-6" class="xref-bibr" href="#ref-35">van Wassenhove et al., 2005</a>) proportionally to their visual predictive power. While MEG provided a good temporal resolution to detect an early visual effect in auditory cortex, we used fMRI data to more precisely localize the auditory target of this effect and to explore the role of a potential feedback from the STS to auditory cortex in audiovisual integration.</p>
         <p id="p-40">Viseme dependency of M100 facilitation denotes projections that selectively convey visual motion cues, which could be the case for both a direct corticocortical path from visual to auditory cortex (pathway 1) (<a id="xref-ref-13-2" class="xref-bibr" href="#ref-13">Falchier et al., 2002</a>; <a id="xref-ref-31-3" class="xref-bibr" href="#ref-31">Rockland and Ojima, 2003</a>; <a id="xref-ref-10-4" class="xref-bibr" href="#ref-10">Cappe and Barone, 2005</a>) and a feedback path from the STS (pathway 2). Yet, as viseme-specific facilitation of early auditory response M100 was not influenced by audiovisual incongruence, we assume that visual input drives a fast prediction that does not depend on any audiovisual comparison, hence should not arise from a multimodal region in which auditory and visual speech input are being integrated, e.g., the STS.</p>
         <p id="p-41">FMRI data confirmed that the source of this effect is the motion-sensitive cortex, as syllable visual predictability enhanced connectivity between motion-sensitive cortex and auditory regions. Several authors propose that the direct corticocortical pathway corresponds to a modulatory input to auditory cortex from visual cortex targeting agranular layers (<a id="xref-ref-22-2" class="xref-bibr" href="#ref-22">Kayser et al., 2007</a>, <a id="xref-ref-23-1" class="xref-bibr" href="#ref-23">2008</a>; <a id="xref-ref-25-1" class="xref-bibr" href="#ref-25">Lakatos et al., 2008</a>; <a id="xref-ref-32-3" class="xref-bibr" href="#ref-32">Schroeder et al., 2008</a>). This input could reset the phase of ongoing oscillatory activity, thus bringing the auditory system into a periodically receptive, excitatory state during which auditory neural response is enhanced (<a id="xref-ref-24-1" class="xref-bibr" href="#ref-24">Lakatos et al., 2007</a>). In this framework motion-sensitive cortex could tune neuronal activity in auditory cortex to the forthcoming sound track, with little phonological accuracy, but precise timing. Phase resetting of auditory cortex by visual syllables occurring periodically at the frequency of jaw movements, i.e., the syllabic (theta) rhythm, could account for the behavioral benefit of viewing speaker's lip movements (<a id="xref-ref-34-2" class="xref-bibr" href="#ref-34">Sumby and Polack, 1954</a>; <a id="xref-ref-11-2" class="xref-bibr" href="#ref-11">Chandrasekaran et al., 2009</a>). Given the specificity of the observed effect we believe that a syllable-dependent phase reset from motion-sensitive cortex is a plausible interpretation of our data. Phase resetting, is only one of several possible mechanisms by which visual input could facilitate auditory processing. First, it is not excluded that eye movements (that were only partly monitored in this experiment) could phase-reset auditory activity thereby structuring and facilitating the auditory response (<a id="xref-ref-11-3" class="xref-bibr" href="#ref-11">Chandrasekaran et al., 2009</a>; <a id="xref-ref-28-1" class="xref-bibr" href="#ref-28">Melloni et al., 2009</a>). Second, our results do not prove that input from motion-sensitive cortex is modulatory rather than of feedforward nature. While enhanced firing synchronization can be directly detected in single and multiunit recordings [electrocorticography, local field potential (LFP) recordings], visual “facilitation” of auditory evoked fields recorded from the scalp could reflect other physiological mechanisms as, for instance, neural priming. A sharper response accompanied or not with a reduced latency could reflect that less neurons are responding to the repeated input (<a id="xref-ref-18-1" class="xref-bibr" href="#ref-18">Grill-Spector et al., 2006</a>).</p>
         <p id="p-42">Here, we observed facilitation jointly on M100 amplitude and latency. While latency reduction depended on visual predictability, amplitude reduction did not. It is possible that amplitude reduction is underpinned by a different neural mechanism than latency reduction. M100 amplitude reduction could be determined by the number of phonological solutions (ambiguity) corresponding to a given viseme, e.g., two solutions for a visual /ja/ versus up to six alternatives for a visual /ga/, while latency reduction could be driven by the timing of the mouth movement onset. This remains unclear, as we did not find a correlation between M100 latency reduction and visual onset (<em>r</em> = −0,2; <em>p</em> = 0,88).</p>
         <p id="p-43">When visual and auditory signals were not congruent, the evoked response was enhanced and delayed (mismatch effect). This effect was observed repeatedly, four times, every 100 ms from 120 ms on. That mismatch was observed 20 ms after M100, and does not interfere with the viseme dependency of M100 facilitation, is compatible with a possible additional, feedback mechanism following the direct visual-to-auditory motion signal. The anatomical location of mismatch effects in the MEG dataset varied in time but is generally compatible with the STS being the central point of a periodic audiovisual comparison and a periodic feedback to auditory cortex. Mismatch, hence audiovisual comparison, occurred repeatedly every 100 ms, i.e., around 10 Hz, a frequency that is close to the beta band over which STS and auditory cortex are found to interact using intracortical recordings in animals (<a id="xref-ref-21-2" class="xref-bibr" href="#ref-21">Kayser and Logothetis, 2009</a>). The long 100 ms delay between each audiovisual comparison, relative to a three relay synaptic delay, could reflect cumulated integration times in auditory cortex, STS, and motion-sensitive cortex. FMRI results indicate with higher topographical precision than MEG that the STS serves as a comparator as its activity strictly followed the degree of perceived audiovisual incongruence, and negatively correlated with visual predictability. This double observation speaks to the theory of predictive coding that stipulates that neural activity (as assessed with LFP recordings and fMRI) reflects the difference between predicted and incoming signals, resulting in lower activity when a signal is correctly anticipated (<a id="xref-ref-14-1" class="xref-bibr" href="#ref-14">Friston, 2005</a>). This principle is compatible with a more synchronized neuronal spiking that makes global neural activity appear overall sharper when a stimulus is primed (<a id="xref-ref-18-2" class="xref-bibr" href="#ref-18">Grill-Spector et al., 2006</a>). If we assume that signals from motion-sensitive cortex synchronize auditory cortex neural activity each time a syllable is being pronounced, feedback signals from the STS on the other hand might essentially reflect the attempt to synchronize audio and visual inputs when they do not match. The current experiments only allow us to speculate about the physiological mechanism by which visual prediction and prediction error modulate auditory cortex activity. The most parsimonious account of our observations would be that direct (pathway 1) and indirect (pathway 2) routes yield distinct effects using a similar mechanism.</p>
         <p id="p-44">(1) The direct route might convey direct phase resetting by motion-sensitive cortex resulting in tuning auditory cortex to the upcoming sound regardless of whether auditory and visual inputs match (unsupervised mechanism).</p>
         <p id="p-45">(2) The indirect route might drive phase resetting via the STS in a distinct manner, depending on whether auditory and visual inputs do or do not match. (a) If auditory and visual stimuli do match, the STS receives convergent input from both modalities, and hence sends back a focal feedback to auditory and motion-sensitive cortices, resulting in audiovisual fine-tuning, and possibly further speed-up of auditory processing. We presumably cannot detect such a focal effect in evoked responses that reflect neural synchronization of large neuronal populations. (b) If auditory and visual inputs do not match, the total number of activated STS neurons should be larger than in case (a), i.e., approximately the sum of those recruited by visual and by auditory input. Therefore, the feedback signal should target a larger portion of auditory cortex, hence also improving audiovisual tuning. This tuning process could be successful, e.g., in McGurk, or fail resulting in mismatch perception. Our MEG results, showing four maxima in the neural mismatch, with only the last two significantly correlated to perceived incongruence, likely indicate that it takes several motion cortex/STS/auditory cortex loops (over ∼500 ms) for incongruence to be stably inferred.</p>
         <p id="p-46">This proposal needs to be tested using intracortical recordings in humans and animal models, but altogether both MEG and fMRI results converge to show a fast direct visual-to-auditory predictive mechanism, immediately followed by a secondary feedback involving the STS as a central audiovisual comparator, and working in dual loops with the auditory cortex on one side and the motion-sensitive cortex on the other side (supplemental Video 4, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material).</p>
         <p id="p-47">Although this study focused on cortical circuits within the temporal lobe, i.e., on the STS, <a id="xref-ref-32-4" class="xref-bibr" href="#ref-32">Schroeder et al. (2008)</a>, proposed three additional cerebral sources that could phase reset auditory cortical neurons: the nonspecific thalamus (and possibly also the visual thalamus), the parietal and the prefrontal cortices. As our model only tests for the direct corticocortical and STS feedback pathways we do not rule out a contribution of these other regions. Negative results were obtained when we tested for a possible viseme-dependent response in the thalamus in the fMRI dataset, but given the limitations of the approach, a thalamic contribution to the facilitation effect is not excluded. Regarding parietal and prefrontal input to auditory cortex, dynamic source reconstruction of responses to visual syllables showed that each of these regions responded shortly after stimulus presentation (yet later than motion-sensitive cortex) (supplemental Fig. 3, available at <a href="http://www.jneurosci.org">www.jneurosci.org</a> as supplemental material) (<a id="xref-ref-5-1" class="xref-bibr" href="#ref-5">Bernstein et al., 2008b</a>). The STS was the latest of these three regions to respond, and it peaked simultaneously with the auditory cortex ∼20 ms after the motion-sensitive occipital cortex. The timing of activation in the prefrontal cortex is not compatible with a feedback to auditory cortex, as it peaks too late, but a feedback from the parietal cortex cannot be ruled out. MEG data alone thus suggest that the fastest effect is a direct visual to auditory one (pathway 1), but do not clearly distinguish between several additional feedback sources (pathway 2). Analyses of the fMRI data, on the other hand, showing (1) enhanced connectivity from the STS with both motion-sensitive cortex and the auditory cortex when predictability decreases, and (2) an increase in activity with visual “ambiguity,” confirm the involvement of the STS as a major functional interface between visual and auditory cortices, and a more specific role in audiovisual speech perception than the parietal cortex.</p>
      </div><div class="section fn-group" id="fn-group-1"><h2>Footnotes</h2><ul><li class="fn-other" id="fn-2">
            <p id="p-48">A.-L.G. is funded by Centre Nationale de la Recherche Scientifique. We thank the staff of the Centre de Neuroimagerie de Recherche and the Magnetoencephalography Center (Hôpital de la Pitié-Salpêtrière, Paris), in particular Antoine Ducorps and Denis Schwarz. We are also grateful to Virginie van Wassenhove, Catherine Tallon-Baudry, Goulven Josse, Daniel Abrams, Andreas Kleinschmidt, Pascal Barone, and Andrej Kral for their valuable scientific input.</p>
         </li><li class="corresp" id="corresp-1">Correspondence should be addressed to Luc H. Arnal,
<span class="addr-line">Laboratoire de Neurosciences Cognitives, Département d'Etudes Cognitives, Ecole Normale Supérieure, 29 rue d'Ulm, F-75005 Paris, France.</span> 
               <span class="em-link"><span class="em-addr"><a href="mailto:luc.arnal@ens.fr">luc.arnal@ens.fr</a></span></span>
            </li></ul></div><div class="section ref-list" id="ref-list-1"><h2>References</h2><ol class="cit-list ref-use-labels"><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-1-1" title="View reference in text" id="ref-1">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.1" data-doi="10.1162/0898929053279586"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Barraclough</span>  <span class="cit-name-given-names">NE</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Xiao</span>  <span class="cit-name-given-names">D</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Baker</span>  <span class="cit-name-given-names">CI</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Oram</span>  <span class="cit-name-given-names">MW</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Perrett</span>  <span class="cit-name-given-names">DI</span></span></li></ol><cite>(<span class="cit-pub-date">2005</span>) <span class="cit-article-title">Integration of visual and auditory information by superior temporal sulcus neurons responsive to the sight of actions</span>. <abbr class="cit-jnl-abbrev">J Cogn Neurosci</abbr> <span class="cit-vol">17</span>:<span class="cit-fpage">377</span>–<span class="cit-lpage">391</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Cognitive Neuroscience&amp;rft.stitle=J. Cogn. Neurosci.&amp;rft.issn=0898-929X&amp;rft.aulast=Barraclough&amp;rft.auinit1=N. E.&amp;rft.volume=17&amp;rft.issue=3&amp;rft.spage=377&amp;rft.epage=391&amp;rft.atitle=Integration of Visual and Auditory Information by Superior Temporal Sulcus Neurons Responsive to the Sight of Actions&amp;rft_id=info:doi/10.1162/0898929053279586&amp;rft_id=info:pmid/15813999&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1162/0898929053279586&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=15813999&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=NE+Barraclough&amp;author[1]=D+Xiao&amp;author[2]=CI+Baker&amp;author[3]=MW+Oram&amp;author[4]=DI+Perrett&amp;title=Integration+of+visual+and+auditory+information+by+superior+temporal+sulcus+neurons+responsive+to+the+sight+of+actions&amp;publication_year=2005&amp;journal=J+Cogn+Neurosci&amp;volume=17&amp;pages=377-391" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-2-1" title="View reference in text" id="ref-2">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.2" data-doi="10.1016/S0896-6273(04)00070-4"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Beauchamp</span>  <span class="cit-name-given-names">MS</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Lee</span>  <span class="cit-name-given-names">KE</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Argall</span>  <span class="cit-name-given-names">BD</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Martin</span>  <span class="cit-name-given-names">A</span></span></li></ol><cite>(<span class="cit-pub-date">2004a</span>) <span class="cit-article-title">Integration of auditory and visual information about objects in superior temporal sulcus</span>. <abbr class="cit-jnl-abbrev">Neuron</abbr> <span class="cit-vol">41</span>:<span class="cit-fpage">809</span>–<span class="cit-lpage">823</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Neuron&amp;rft.volume=41&amp;rft.spage=809&amp;rft_id=info:doi/10.1016/S0896-6273(04)00070-4&amp;rft_id=info:pmid/15003179&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/S0896-6273(04)00070-4&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=15003179&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=MS+Beauchamp&amp;author[1]=KE+Lee&amp;author[2]=BD+Argall&amp;author[3]=A+Martin&amp;title=Integration+of+auditory+and+visual+information+about+objects+in+superior+temporal+sulcus&amp;publication_year=2004a&amp;journal=Neuron&amp;volume=41&amp;pages=809-823" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-3-1" title="View reference in text" id="ref-3">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.3" data-doi="10.1038/nn1333"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Beauchamp</span>  <span class="cit-name-given-names">MS</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Argall</span>  <span class="cit-name-given-names">BD</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Bodurka</span>  <span class="cit-name-given-names">J</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Duyn</span>  <span class="cit-name-given-names">JH</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Martin</span>  <span class="cit-name-given-names">A</span></span></li></ol><cite>(<span class="cit-pub-date">2004b</span>) <span class="cit-article-title">Unraveling multisensory integration: patchy organization within human STS multisensory cortex</span>. <abbr class="cit-jnl-abbrev">Nat Neurosci</abbr> <span class="cit-vol">7</span>:<span class="cit-fpage">1190</span>–<span class="cit-lpage">1192</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Nature neuroscience&amp;rft.stitle=Nat Neurosci&amp;rft.aulast=Beauchamp&amp;rft.auinit1=M. S.&amp;rft.volume=7&amp;rft.issue=11&amp;rft.spage=1190&amp;rft.epage=1192&amp;rft.atitle=Unraveling multisensory integration: patchy organization within human STS multisensory cortex.&amp;rft_id=info:doi/10.1038/nn1333&amp;rft_id=info:pmid/15475952&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1038/nn1333&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=15475952&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=MS+Beauchamp&amp;author[1]=BD+Argall&amp;author[2]=J+Bodurka&amp;author[3]=JH+Duyn&amp;author[4]=A+Martin&amp;title=Unraveling+multisensory+integration:+patchy+organization+within+human+STS+multisensory+cortex&amp;publication_year=2004b&amp;journal=Nat+Neurosci&amp;volume=7&amp;pages=1190-1192" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-4-1" title="View reference in text" id="ref-4">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.4" data-doi="10.1016/j.brainres.2008.04.018"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Bernstein</span>  <span class="cit-name-given-names">LE</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Lu</span>  <span class="cit-name-given-names">ZL</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Jiang</span>  <span class="cit-name-given-names">J</span></span></li></ol><cite>(<span class="cit-pub-date">2008a</span>) <span class="cit-article-title">Quantified acoustic-optical speech signal incongruity identifies cortical sites of audiovisual speech processing</span>. <abbr class="cit-jnl-abbrev">Brain Res</abbr> <span class="cit-vol">1242</span>:<span class="cit-fpage">172</span>–<span class="cit-lpage">184</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Brain research&amp;rft.stitle=Brain Res&amp;rft.aulast=Bernstein&amp;rft.auinit1=L. E.&amp;rft.volume=1242&amp;rft.spage=172&amp;rft.epage=184&amp;rft.atitle=Quantified acoustic-optical speech signal incongruity identifies cortical sites of audiovisual speech processing.&amp;rft_id=info:doi/10.1016/j.brainres.2008.04.018&amp;rft_id=info:pmid/18495091&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.brainres.2008.04.018&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=18495091&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=LE+Bernstein&amp;author[1]=ZL+Lu&amp;author[2]=J+Jiang&amp;title=Quantified+acoustic-optical+speech+signal+incongruity+identifies+cortical+sites+of+audiovisual+speech+processing&amp;publication_year=2008a&amp;journal=Brain+Res&amp;volume=1242&amp;pages=172-184" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-5-1" title="View reference in text" id="ref-5">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.5" data-doi="10.1016/j.neuroimage.2007.08.035"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Bernstein</span>  <span class="cit-name-given-names">LE</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Auer</span>  <span class="cit-name-given-names">ET</span>  <span class="cit-name-suffix">Jr</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Wagner</span>  <span class="cit-name-given-names">M</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Ponton</span>  <span class="cit-name-given-names">CW</span></span></li></ol><cite>(<span class="cit-pub-date">2008b</span>) <span class="cit-article-title">Spatiotemporal dynamics of audiovisual speech processing</span>. <abbr class="cit-jnl-abbrev">Neuroimage</abbr> <span class="cit-vol">39</span>:<span class="cit-fpage">423</span>–<span class="cit-lpage">435</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Neuroimage&amp;rft.volume=39&amp;rft.spage=423&amp;rft_id=info:doi/10.1016/j.neuroimage.2007.08.035&amp;rft_id=info:pmid/17920933&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2007.08.035&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=17920933&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=LE+Bernstein&amp;author[1]=ET+Auer&amp;author[2]=M+Wagner&amp;author[3]=CW+Ponton&amp;title=Spatiotemporal+dynamics+of+audiovisual+speech+processing&amp;publication_year=2008b&amp;journal=Neuroimage&amp;volume=39&amp;pages=423-435" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-6-1" title="View reference in text" id="ref-6">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.6" data-doi="10.1111/j.1460-9568.2004.03670.x"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Besle</span>  <span class="cit-name-given-names">J</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Fort</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Delpuech</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Giard</span>  <span class="cit-name-given-names">MH</span></span></li></ol><cite>(<span class="cit-pub-date">2004</span>) <span class="cit-article-title">Bimodal speech: early suppressive visual effects in human auditory cortex</span>. <abbr class="cit-jnl-abbrev">Eur J Neurosci</abbr> <span class="cit-vol">20</span>:<span class="cit-fpage">2225</span>–<span class="cit-lpage">2234</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=The European journal of neuroscience&amp;rft.stitle=Eur J Neurosci&amp;rft.aulast=Besle&amp;rft.auinit1=J.&amp;rft.volume=20&amp;rft.issue=8&amp;rft.spage=2225&amp;rft.epage=2234&amp;rft.atitle=Bimodal speech: early suppressive visual effects in human auditory cortex.&amp;rft_id=info:doi/10.1111/j.1460-9568.2004.03670.x&amp;rft_id=info:pmid/15450102&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1111/j.1460-9568.2004.03670.x&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=15450102&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=J+Besle&amp;author[1]=A+Fort&amp;author[2]=C+Delpuech&amp;author[3]=MH+Giard&amp;title=Bimodal+speech:+early+suppressive+visual+effects+in+human+auditory+cortex&amp;publication_year=2004&amp;journal=Eur+J+Neurosci&amp;volume=20&amp;pages=2225-2234" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-7-1" title="View reference in text" id="ref-7">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.7" data-doi="10.1523/JNEUROSCI.2875-08.2008"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Besle</span>  <span class="cit-name-given-names">J</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Fischer</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Bidet-Caulet</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Lecaignard</span>  <span class="cit-name-given-names">F</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Bertrand</span>  <span class="cit-name-given-names">O</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Giard</span>  <span class="cit-name-given-names">MH</span></span></li></ol><cite>(<span class="cit-pub-date">2008</span>) <span class="cit-article-title">Visual activation and audiovisual interactions in the auditory cortex during speech perception: intracranial recordings in humans</span>. <abbr class="cit-jnl-abbrev">J Neurosci</abbr> <span class="cit-vol">28</span>:<span class="cit-fpage">14301</span>–<span class="cit-lpage">14310</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Neuroscience&amp;rft.stitle=J. Neurosci.&amp;rft.issn=0270-6474&amp;rft.aulast=Besle&amp;rft.auinit1=J.&amp;rft.volume=28&amp;rft.issue=52&amp;rft.spage=14301&amp;rft.epage=14310&amp;rft.atitle=Visual Activation and Audiovisual Interactions in the Auditory Cortex during Speech Perception: Intracranial Recordings in Humans&amp;rft_id=info:doi/10.1523/JNEUROSCI.2875-08.2008&amp;rft_id=info:pmid/19109511&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjExOiIyOC81Mi8xNDMwMSI7czo0OiJhdG9tIjtzOjI0OiIvam5ldXJvLzI5LzQzLzEzNDQ1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=J+Besle&amp;author[1]=C+Fischer&amp;author[2]=A+Bidet-Caulet&amp;author[3]=F+Lecaignard&amp;author[4]=O+Bertrand&amp;author[5]=MH+Giard&amp;title=Visual+activation+and+audiovisual+interactions+in+the+auditory+cortex+during+speech+perception:+intracranial+recordings+in+humans&amp;publication_year=2008&amp;journal=J+Neurosci&amp;volume=28&amp;pages=14301-14310" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-8-1" title="View reference in text" id="ref-8">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.8" data-doi="10.1162/089892903321107828"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Calvert</span>  <span class="cit-name-given-names">GA</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Campbell</span>  <span class="cit-name-given-names">R</span></span></li></ol><cite>(<span class="cit-pub-date">2003</span>) <span class="cit-article-title">Reading speech from still and moving faces: the neural substrates of visible speech</span>. <abbr class="cit-jnl-abbrev">J Cogn Neurosci</abbr> <span class="cit-vol">15</span>:<span class="cit-fpage">57</span>–<span class="cit-lpage">70</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Cognitive Neuroscience&amp;rft.stitle=J. Cogn. Neurosci.&amp;rft.issn=0898-929X&amp;rft.aulast=Calvert&amp;rft.auinit1=G. A.&amp;rft.volume=15&amp;rft.issue=1&amp;rft.spage=57&amp;rft.epage=70&amp;rft.atitle=Reading Speech from Still and Moving Faces: The Neural Substrates of Visible Speech&amp;rft_id=info:doi/10.1162/089892903321107828&amp;rft_id=info:pmid/12590843&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1162/089892903321107828&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=12590843&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=GA+Calvert&amp;author[1]=R+Campbell&amp;title=Reading+speech+from+still+and+moving+faces:+the+neural+substrates+of+visible+speech&amp;publication_year=2003&amp;journal=J+Cogn+Neurosci&amp;volume=15&amp;pages=57-70" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-9-1" title="View reference in text" id="ref-9">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.9" data-doi="10.1126/science.276.5312.593"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Calvert</span>  <span class="cit-name-given-names">GA</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Bullmore</span>  <span class="cit-name-given-names">ET</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Brammer</span>  <span class="cit-name-given-names">MJ</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Campbell</span>  <span class="cit-name-given-names">R</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Williams</span>  <span class="cit-name-given-names">SC</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">McGuire</span>  <span class="cit-name-given-names">PK</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Woodruff</span>  <span class="cit-name-given-names">PW</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Iversen</span>  <span class="cit-name-given-names">SD</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">David</span>  <span class="cit-name-given-names">AS</span></span></li></ol><cite>(<span class="cit-pub-date">1997</span>) <span class="cit-article-title">Activation of auditory cortex during silent lipreading</span>. <abbr class="cit-jnl-abbrev">Science</abbr> <span class="cit-vol">276</span>:<span class="cit-fpage">593</span>–<span class="cit-lpage">596</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Science&amp;rft.stitle=Science&amp;rft.issn=0036-8075&amp;rft.aulast=Calvert&amp;rft.auinit1=G. A.&amp;rft.volume=276&amp;rft.issue=5312&amp;rft.spage=593&amp;rft.epage=596&amp;rft.atitle=Activation of Auditory Cortex During Silent Lipreading&amp;rft_id=info:doi/10.1126/science.276.5312.593&amp;rft_id=info:pmid/9110978&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Mzoic2NpIjtzOjU6InJlc2lkIjtzOjEyOiIyNzYvNTMxMi81OTMiO3M6NDoiYXRvbSI7czoyNDoiL2puZXVyby8yOS80My8xMzQ0NS5hdG9tIjt9czo4OiJmcmFnbWVudCI7czowOiIiO30=" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=GA+Calvert&amp;author[1]=ET+Bullmore&amp;author[2]=MJ+Brammer&amp;author[3]=R+Campbell&amp;author[4]=SC+Williams&amp;author[5]=PK+McGuire&amp;author[6]=PW+Woodruff&amp;author[7]=SD+Iversen&amp;author[8]=AS+David&amp;title=Activation+of+auditory+cortex+during+silent+lipreading&amp;publication_year=1997&amp;journal=Science&amp;volume=276&amp;pages=593-596" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-10-1" title="View reference in text" id="ref-10">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.10" data-doi="10.1111/j.1460-9568.2005.04462.x"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Cappe</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Barone</span>  <span class="cit-name-given-names">P</span></span></li></ol><cite>(<span class="cit-pub-date">2005</span>) <span class="cit-article-title">Heteromodal connections supporting multisensory integration at low levels of cortical processing in the monkey</span>. <abbr class="cit-jnl-abbrev">Eur J Neurosci</abbr> <span class="cit-vol">22</span>:<span class="cit-fpage">2886</span>–<span class="cit-lpage">2902</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=The European journal of neuroscience&amp;rft.stitle=Eur J Neurosci&amp;rft.aulast=Cappe&amp;rft.auinit1=C.&amp;rft.volume=22&amp;rft.issue=11&amp;rft.spage=2886&amp;rft.epage=2902&amp;rft.atitle=Heteromodal connections supporting multisensory integration at low levels of cortical processing in the monkey.&amp;rft_id=info:doi/10.1111/j.1460-9568.2005.04462.x&amp;rft_id=info:pmid/16324124&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1111/j.1460-9568.2005.04462.x&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=16324124&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=C+Cappe&amp;author[1]=P+Barone&amp;title=Heteromodal+connections+supporting+multisensory+integration+at+low+levels+of+cortical+processing+in+the+monkey&amp;publication_year=2005&amp;journal=Eur+J+Neurosci&amp;volume=22&amp;pages=2886-2902" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-11-1" title="View reference in text" id="ref-11">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.11" data-doi="10.1371/journal.pcbi.1000436"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Chandrasekaran</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Trubanova</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Stillittano</span>  <span class="cit-name-given-names">S</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Caplier</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Ghazanfar</span>  <span class="cit-name-given-names">AA</span></span></li></ol><cite>(<span class="cit-pub-date">2009</span>) <span class="cit-article-title">The natural statistics of audiovisual speech</span>. <abbr class="cit-jnl-abbrev">PLoS Comput Biol</abbr> <span class="cit-vol">5</span>:<span class="cit-fpage">e1000436</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.stitle=PLoS Comput Biol&amp;rft.aulast=Chandrasekaran&amp;rft.auinit1=C.&amp;rft.volume=5&amp;rft.issue=7&amp;rft.spage=e1000436&amp;rft.epage=e1000436&amp;rft.atitle=The natural statistics of audiovisual speech.&amp;rft_id=info:doi/10.1371/journal.pcbi.1000436&amp;rft_id=info:pmid/19609344&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1371/journal.pcbi.1000436&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=19609344&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=C+Chandrasekaran&amp;author[1]=A+Trubanova&amp;author[2]=S+Stillittano&amp;author[3]=A+Caplier&amp;author[4]=AA+Ghazanfar&amp;title=The+natural+statistics+of+audiovisual+speech&amp;publication_year=2009&amp;journal=PLoS+Comput+Biol&amp;volume=5" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-12-1" title="View reference in text" id="ref-12">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.12" data-doi="10.1016/j.neuron.2007.12.013"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Driver</span>  <span class="cit-name-given-names">J</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Noesselt</span>  <span class="cit-name-given-names">T</span></span></li></ol><cite>(<span class="cit-pub-date">2008</span>) <span class="cit-article-title">Multisensory interplay reveals crossmodal influences on ‘sensory-specific’ brain regions, neural responses, and judgments</span>. <abbr class="cit-jnl-abbrev">Neuron</abbr> <span class="cit-vol">57</span>:<span class="cit-fpage">11</span>–<span class="cit-lpage">23</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Neuron&amp;rft.volume=57&amp;rft.spage=11&amp;rft_id=info:doi/10.1016/j.neuron.2007.12.013&amp;rft_id=info:pmid/18184561&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.neuron.2007.12.013&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=18184561&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=J+Driver&amp;author[1]=T+Noesselt&amp;title=Multisensory+interplay+reveals+crossmodal+influences+on+‘sensory-specific’+brain+regions,+neural+responses,+and+judgments&amp;publication_year=2008&amp;journal=Neuron&amp;volume=57&amp;pages=11-23" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-13-1" title="View reference in text" id="ref-13">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.13" data-doi="20026562"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Falchier</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Clavagnier</span>  <span class="cit-name-given-names">S</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Barone</span>  <span class="cit-name-given-names">P</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Kennedy</span>  <span class="cit-name-given-names">H</span></span></li></ol><cite>(<span class="cit-pub-date">2002</span>) <span class="cit-article-title">Anatomical evidence of multimodal integration in primate striate cortex</span>. <abbr class="cit-jnl-abbrev">J Neurosci</abbr> <span class="cit-vol">22</span>:<span class="cit-fpage">5749</span>–<span class="cit-lpage">5759</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Neuroscience&amp;rft.stitle=J. Neurosci.&amp;rft.issn=0270-6474&amp;rft.aulast=Falchier&amp;rft.auinit1=A.&amp;rft.volume=22&amp;rft.issue=13&amp;rft.spage=5749&amp;rft.epage=5759&amp;rft.atitle=Anatomical Evidence of Multimodal Integration in Primate Striate Cortex&amp;rft_id=info:doi/20026562&amp;rft_id=info:pmid/12097528&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjEwOiIyMi8xMy81NzQ5IjtzOjQ6ImF0b20iO3M6MjQ6Ii9qbmV1cm8vMjkvNDMvMTM0NDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=A+Falchier&amp;author[1]=S+Clavagnier&amp;author[2]=P+Barone&amp;author[3]=H+Kennedy&amp;title=Anatomical+evidence+of+multimodal+integration+in+primate+striate+cortex&amp;publication_year=2002&amp;journal=J+Neurosci&amp;volume=22&amp;pages=5749-5759" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-14-1" title="View reference in text" id="ref-14">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.14" data-doi="10.1098/rstb.2005.1622"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Friston</span>  <span class="cit-name-given-names">K</span></span></li></ol><cite>(<span class="cit-pub-date">2005</span>) <span class="cit-article-title">A theory of cortical responses</span>. <abbr class="cit-jnl-abbrev">Philos Trans R Soc Lond B Biol Sci</abbr> <span class="cit-vol">360</span>:<span class="cit-fpage">815</span>–<span class="cit-lpage">836</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Philosophical Transactions of the Royal Society B: Biological Sciences&amp;rft.stitle=Phil Trans R Soc B&amp;rft.issn=0080-4622&amp;rft.aulast=Friston&amp;rft.auinit1=K.&amp;rft.volume=360&amp;rft.issue=1456&amp;rft.spage=815&amp;rft.epage=836&amp;rft.atitle=A theory of cortical responses&amp;rft_id=info:doi/10.1098/rstb.2005.1622&amp;rft_id=info:pmid/15937014&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoicm95cHRiIjtzOjU6InJlc2lkIjtzOjEyOiIzNjAvMTQ1Ni84MTUiO3M6NDoiYXRvbSI7czoyNDoiL2puZXVyby8yOS80My8xMzQ0NS5hdG9tIjt9czo4OiJmcmFnbWVudCI7czowOiIiO30=" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=K+Friston&amp;title=A+theory+of+cortical+responses&amp;publication_year=2005&amp;journal=Philos+Trans+R+Soc+Lond+B+Biol+Sci&amp;volume=360&amp;pages=815-836" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-15-1" title="View reference in text" id="ref-15">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.15" data-doi="10.1006/nimg.1997.0291"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Friston</span>  <span class="cit-name-given-names">KJ</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Buechel</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Fink</span>  <span class="cit-name-given-names">GR</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Morris</span>  <span class="cit-name-given-names">J</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Rolls</span>  <span class="cit-name-given-names">E</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Dolan</span>  <span class="cit-name-given-names">RJ</span></span></li></ol><cite>(<span class="cit-pub-date">1997</span>) <span class="cit-article-title">Psychophysiological and modulatory interactions in neuroimaging</span>. <abbr class="cit-jnl-abbrev">Neuroimage</abbr> <span class="cit-vol">6</span>:<span class="cit-fpage">218</span>–<span class="cit-lpage">229</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Neuroimage&amp;rft.volume=6&amp;rft.spage=218&amp;rft_id=info:doi/10.1006/nimg.1997.0291&amp;rft_id=info:pmid/9344826&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1006/nimg.1997.0291&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=9344826&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=KJ+Friston&amp;author[1]=C+Buechel&amp;author[2]=GR+Fink&amp;author[3]=J+Morris&amp;author[4]=E+Rolls&amp;author[5]=RJ+Dolan&amp;title=Psychophysiological+and+modulatory+interactions+in+neuroimaging&amp;publication_year=1997&amp;journal=Neuroimage&amp;volume=6&amp;pages=218-229" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-16-1" title="View reference in text" id="ref-16">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.16" data-doi="10.1523/JNEUROSCI.0799-05.2005"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Ghazanfar</span>  <span class="cit-name-given-names">AA</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Maier</span>  <span class="cit-name-given-names">JX</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Hoffman</span>  <span class="cit-name-given-names">KL</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Logothetis</span>  <span class="cit-name-given-names">NK</span></span></li></ol><cite>(<span class="cit-pub-date">2005</span>) <span class="cit-article-title">Multisensory integration of dynamic faces and voices in rhesus monkey auditory cortex</span>. <abbr class="cit-jnl-abbrev">J Neurosci</abbr> <span class="cit-vol">25</span>:<span class="cit-fpage">5004</span>–<span class="cit-lpage">5012</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Neuroscience&amp;rft.stitle=J. Neurosci.&amp;rft.issn=0270-6474&amp;rft.aulast=Ghazanfar&amp;rft.auinit1=A. A.&amp;rft.volume=25&amp;rft.issue=20&amp;rft.spage=5004&amp;rft.epage=5012&amp;rft.atitle=Multisensory Integration of Dynamic Faces and Voices in Rhesus Monkey Auditory Cortex&amp;rft_id=info:doi/10.1523/JNEUROSCI.0799-05.2005&amp;rft_id=info:pmid/15901781&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjEwOiIyNS8yMC81MDA0IjtzOjQ6ImF0b20iO3M6MjQ6Ii9qbmV1cm8vMjkvNDMvMTM0NDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=AA+Ghazanfar&amp;author[1]=JX+Maier&amp;author[2]=KL+Hoffman&amp;author[3]=NK+Logothetis&amp;title=Multisensory+integration+of+dynamic+faces+and+voices+in+rhesus+monkey+auditory+cortex&amp;publication_year=2005&amp;journal=J+Neurosci&amp;volume=25&amp;pages=5004-5012" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-17-1" title="View reference in text" id="ref-17">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.17" data-doi="10.1523/JNEUROSCI.0541-08.2008"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Ghazanfar</span>  <span class="cit-name-given-names">AA</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Chandrasekaran</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Logothetis</span>  <span class="cit-name-given-names">NK</span></span></li></ol><cite>(<span class="cit-pub-date">2008</span>) <span class="cit-article-title">Interactions between the superior temporal sulcus and auditory cortex mediate dynamic face/voice integration in rhesus monkeys</span>. <abbr class="cit-jnl-abbrev">J Neurosci</abbr> <span class="cit-vol">28</span>:<span class="cit-fpage">4457</span>–<span class="cit-lpage">4469</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Neuroscience&amp;rft.stitle=J. Neurosci.&amp;rft.issn=0270-6474&amp;rft.aulast=Ghazanfar&amp;rft.auinit1=A. A.&amp;rft.volume=28&amp;rft.issue=17&amp;rft.spage=4457&amp;rft.epage=4469&amp;rft.atitle=Interactions between the Superior Temporal Sulcus and Auditory Cortex Mediate Dynamic Face/Voice Integration in Rhesus Monkeys&amp;rft_id=info:doi/10.1523/JNEUROSCI.0541-08.2008&amp;rft_id=info:pmid/18434524&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjEwOiIyOC8xNy80NDU3IjtzOjQ6ImF0b20iO3M6MjQ6Ii9qbmV1cm8vMjkvNDMvMTM0NDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=AA+Ghazanfar&amp;author[1]=C+Chandrasekaran&amp;author[2]=NK+Logothetis&amp;title=Interactions+between+the+superior+temporal+sulcus+and+auditory+cortex+mediate+dynamic+face/voice+integration+in+rhesus+monkeys&amp;publication_year=2008&amp;journal=J+Neurosci&amp;volume=28&amp;pages=4457-4469" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-18-1" title="View reference in text" id="ref-18">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.18" data-doi="10.1016/j.tics.2005.11.006"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Grill-Spector</span>  <span class="cit-name-given-names">K</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Henson</span>  <span class="cit-name-given-names">R</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Martin</span>  <span class="cit-name-given-names">A</span></span></li></ol><cite>(<span class="cit-pub-date">2006</span>) <span class="cit-article-title">Repetition and the brain: neural models of stimulus-specific effects</span>. <abbr class="cit-jnl-abbrev">Trends Cogn Sci</abbr> <span class="cit-vol">10</span>:<span class="cit-fpage">14</span>–<span class="cit-lpage">23</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Trends in cognitive sciences&amp;rft.stitle=Trends Cogn Sci&amp;rft.aulast=Grill-Spector&amp;rft.auinit1=K.&amp;rft.volume=10&amp;rft.issue=1&amp;rft.spage=14&amp;rft.epage=23&amp;rft.atitle=Repetition and the brain: neural models of stimulus-specific effects.&amp;rft_id=info:doi/10.1016/j.tics.2005.11.006&amp;rft_id=info:pmid/16321563&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.tics.2005.11.006&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=16321563&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=K+Grill-Spector&amp;author[1]=R+Henson&amp;author[2]=A+Martin&amp;title=Repetition+and+the+brain:+neural+models+of+stimulus-specific+effects&amp;publication_year=2006&amp;journal=Trends+Cogn+Sci&amp;volume=10&amp;pages=14-23" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-19-1" title="View reference in text" id="ref-19">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.19" data-doi="10.1016/j.neuropsychologia.2006.09.019"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Hertrich</span>  <span class="cit-name-given-names">I</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Mathiak</span>  <span class="cit-name-given-names">K</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Lutzenberger</span>  <span class="cit-name-given-names">W</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Menning</span>  <span class="cit-name-given-names">H</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Ackermann</span>  <span class="cit-name-given-names">H</span></span></li></ol><cite>(<span class="cit-pub-date">2007</span>) <span class="cit-article-title">Sequential audiovisual interactions during speech perception: a whole-head MEG study</span>. <abbr class="cit-jnl-abbrev">Neuropsychologia</abbr> <span class="cit-vol">45</span>:<span class="cit-fpage">1342</span>–<span class="cit-lpage">1354</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Neuropsychologia&amp;rft.volume=45&amp;rft.spage=1342&amp;rft_id=info:doi/10.1016/j.neuropsychologia.2006.09.019&amp;rft_id=info:pmid/17067640&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.neuropsychologia.2006.09.019&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=17067640&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=I+Hertrich&amp;author[1]=K+Mathiak&amp;author[2]=W+Lutzenberger&amp;author[3]=H+Menning&amp;author[4]=H+Ackermann&amp;title=Sequential+audiovisual+interactions+during+speech+perception:+a+whole-head+MEG+study&amp;publication_year=2007&amp;journal=Neuropsychologia&amp;volume=45&amp;pages=1342-1354" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-20-1" title="View reference in text" id="ref-20">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.20" data-doi="10.1038/nrn2113"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Hickok</span>  <span class="cit-name-given-names">G</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Poeppel</span>  <span class="cit-name-given-names">D</span></span></li></ol><cite>(<span class="cit-pub-date">2007</span>) <span class="cit-article-title">The cortical organization of speech processing</span>. <abbr class="cit-jnl-abbrev">Nat Rev Neurosci</abbr> <span class="cit-vol">8</span>:<span class="cit-fpage">393</span>–<span class="cit-lpage">402</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Nature reviews. Neuroscience&amp;rft.stitle=Nat Rev Neurosci&amp;rft.aulast=Hickok&amp;rft.auinit1=G.&amp;rft.volume=8&amp;rft.issue=5&amp;rft.spage=393&amp;rft.epage=402&amp;rft.atitle=The cortical organization of speech processing.&amp;rft_id=info:doi/10.1038/nrn2113&amp;rft_id=info:pmid/17431404&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1038/nrn2113&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=17431404&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=G+Hickok&amp;author[1]=D+Poeppel&amp;title=The+cortical+organization+of+speech+processing&amp;publication_year=2007&amp;journal=Nat+Rev+Neurosci&amp;volume=8&amp;pages=393-402" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-21-1" title="View reference in text" id="ref-21">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.21"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Kayser</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Logothetis</span>  <span class="cit-name-given-names">NK</span></span></li></ol><cite>(<span class="cit-pub-date">2009</span>) <span class="cit-article-title">Directed interactions between auditory and superior temporal cortices and their role in sensory integration</span>. <abbr class="cit-jnl-abbrev">Front Integr Neurosci</abbr> <span class="cit-vol">3</span>:<span class="cit-fpage">7</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.stitle=Front Integr Neurosci&amp;rft.aulast=Kayser&amp;rft.auinit1=C.&amp;rft.volume=3&amp;rft.spage=7&amp;rft.epage=7&amp;rft.atitle=Directed Interactions Between Auditory and Superior Temporal Cortices and their Role in Sensory Integration.&amp;rft_id=info:pmid/19503750&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=19503750&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=C+Kayser&amp;author[1]=NK+Logothetis&amp;title=Directed+interactions+between+auditory+and+superior+temporal+cortices+and+their+role+in+sensory+integration&amp;publication_year=2009&amp;journal=Front+Integr+Neurosci&amp;volume=3" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-22-1" title="View reference in text" id="ref-22">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.22" data-doi="10.1523/JNEUROSCI.4737-06.2007"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Kayser</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Petkov</span>  <span class="cit-name-given-names">CI</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Augath</span>  <span class="cit-name-given-names">M</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Logothetis</span>  <span class="cit-name-given-names">NK</span></span></li></ol><cite>(<span class="cit-pub-date">2007</span>) <span class="cit-article-title">Functional imaging reveals visual modulation of specific fields in auditory cortex</span>. <abbr class="cit-jnl-abbrev">J Neurosci</abbr> <span class="cit-vol">27</span>:<span class="cit-fpage">1824</span>–<span class="cit-lpage">1835</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Neuroscience&amp;rft.stitle=J. Neurosci.&amp;rft.issn=0270-6474&amp;rft.aulast=Kayser&amp;rft.auinit1=C.&amp;rft.volume=27&amp;rft.issue=8&amp;rft.spage=1824&amp;rft.epage=1835&amp;rft.atitle=Functional Imaging Reveals Visual Modulation of Specific Fields in Auditory Cortex&amp;rft_id=info:doi/10.1523/JNEUROSCI.4737-06.2007&amp;rft_id=info:pmid/17314280&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjk6IjI3LzgvMTgyNCI7czo0OiJhdG9tIjtzOjI0OiIvam5ldXJvLzI5LzQzLzEzNDQ1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=C+Kayser&amp;author[1]=CI+Petkov&amp;author[2]=M+Augath&amp;author[3]=NK+Logothetis&amp;title=Functional+imaging+reveals+visual+modulation+of+specific+fields+in+auditory+cortex&amp;publication_year=2007&amp;journal=J+Neurosci&amp;volume=27&amp;pages=1824-1835" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-23-1" title="View reference in text" id="ref-23">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.23" data-doi="10.1093/cercor/bhm187"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Kayser</span>  <span class="cit-name-given-names">C</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Petkov</span>  <span class="cit-name-given-names">CI</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Logothetis</span>  <span class="cit-name-given-names">NK</span></span></li></ol><cite>(<span class="cit-pub-date">2008</span>) <span class="cit-article-title">Visual modulation of neurons in auditory cortex</span>. <abbr class="cit-jnl-abbrev">Cereb Cortex</abbr> <span class="cit-vol">18</span>:<span class="cit-fpage">1560</span>–<span class="cit-lpage">1574</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Cereb Cortex&amp;rft_id=info:doi/10.1093/cercor/bhm187&amp;rft_id=info:pmid/18180245&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6NjoiY2VyY29yIjtzOjU6InJlc2lkIjtzOjk6IjE4LzcvMTU2MCI7czo0OiJhdG9tIjtzOjI0OiIvam5ldXJvLzI5LzQzLzEzNDQ1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=C+Kayser&amp;author[1]=CI+Petkov&amp;author[2]=NK+Logothetis&amp;title=Visual+modulation+of+neurons+in+auditory+cortex&amp;publication_year=2008&amp;journal=Cereb+Cortex&amp;volume=18&amp;pages=1560-1574" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-24-1" title="View reference in text" id="ref-24">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.24" data-doi="10.1016/j.neuron.2006.12.011"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Lakatos</span>  <span class="cit-name-given-names">P</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Chen</span>  <span class="cit-name-given-names">CM</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">O'Connell</span>  <span class="cit-name-given-names">MN</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Mills</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Schroeder</span>  <span class="cit-name-given-names">CE</span></span></li></ol><cite>(<span class="cit-pub-date">2007</span>) <span class="cit-article-title">Neuronal oscillations and multisensory interaction in primary auditory cortex</span>. <abbr class="cit-jnl-abbrev">Neuron</abbr> <span class="cit-vol">53</span>:<span class="cit-fpage">279</span>–<span class="cit-lpage">292</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Neuron&amp;rft.volume=53&amp;rft.spage=279&amp;rft_id=info:doi/10.1016/j.neuron.2006.12.011&amp;rft_id=info:pmid/17224408&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.neuron.2006.12.011&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=17224408&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=P+Lakatos&amp;author[1]=CM+Chen&amp;author[2]=MN+O'Connell&amp;author[3]=A+Mills&amp;author[4]=CE+Schroeder&amp;title=Neuronal+oscillations+and+multisensory+interaction+in+primary+auditory+cortex&amp;publication_year=2007&amp;journal=Neuron&amp;volume=53&amp;pages=279-292" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-25-1" title="View reference in text" id="ref-25">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.25" data-doi="10.1126/science.1154735"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Lakatos</span>  <span class="cit-name-given-names">P</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Karmos</span>  <span class="cit-name-given-names">G</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Mehta</span>  <span class="cit-name-given-names">AD</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Ulbert</span>  <span class="cit-name-given-names">I</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Schroeder</span>  <span class="cit-name-given-names">CE</span></span></li></ol><cite>(<span class="cit-pub-date">2008</span>) <span class="cit-article-title">Entrainment of neuronal oscillations as a mechanism of attentional selection</span>. <abbr class="cit-jnl-abbrev">Science</abbr> <span class="cit-vol">320</span>:<span class="cit-fpage">110</span>–<span class="cit-lpage">113</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Science&amp;rft.stitle=Science&amp;rft.issn=0036-8075&amp;rft.aulast=Lakatos&amp;rft.auinit1=P.&amp;rft.volume=320&amp;rft.issue=5872&amp;rft.spage=110&amp;rft.epage=113&amp;rft.atitle=Entrainment of Neuronal Oscillations as a Mechanism of Attentional Selection&amp;rft_id=info:doi/10.1126/science.1154735&amp;rft_id=info:pmid/18388295&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Mzoic2NpIjtzOjU6InJlc2lkIjtzOjEyOiIzMjAvNTg3Mi8xMTAiO3M6NDoiYXRvbSI7czoyNDoiL2puZXVyby8yOS80My8xMzQ0NS5hdG9tIjt9czo4OiJmcmFnbWVudCI7czowOiIiO30=" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=P+Lakatos&amp;author[1]=G+Karmos&amp;author[2]=AD+Mehta&amp;author[3]=I+Ulbert&amp;author[4]=CE+Schroeder&amp;title=Entrainment+of+neuronal+oscillations+as+a+mechanism+of+attentional+selection&amp;publication_year=2008&amp;journal=Science&amp;volume=320&amp;pages=110-113" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-26-1" title="View reference in text" id="ref-26">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.26" data-doi="10.1093/cercor/bhj181"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Malikovic</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Amunts</span>  <span class="cit-name-given-names">K</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Schleicher</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Mohlberg</span>  <span class="cit-name-given-names">H</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Eickhoff</span>  <span class="cit-name-given-names">SB</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Wilms</span>  <span class="cit-name-given-names">M</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Palomero-Gallagher</span>  <span class="cit-name-given-names">N</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Armstrong</span>  <span class="cit-name-given-names">E</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Zilles</span>  <span class="cit-name-given-names">K</span></span></li></ol><cite>(<span class="cit-pub-date">2007</span>) <span class="cit-article-title">Cytoarchitectonic analysis of the human extrastriate cortex in the region of V5/MT+: a probabilistic, stereotaxic map of area hOc5</span>. <abbr class="cit-jnl-abbrev">Cereb Cortex</abbr> <span class="cit-vol">17</span>:<span class="cit-fpage">562</span>–<span class="cit-lpage">574</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Cereb Cortex&amp;rft_id=info:doi/10.1093/cercor/bhj181&amp;rft_id=info:pmid/16603710&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6NjoiY2VyY29yIjtzOjU6InJlc2lkIjtzOjg6IjE3LzMvNTYyIjtzOjQ6ImF0b20iO3M6MjQ6Ii9qbmV1cm8vMjkvNDMvMTM0NDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=A+Malikovic&amp;author[1]=K+Amunts&amp;author[2]=A+Schleicher&amp;author[3]=H+Mohlberg&amp;author[4]=SB+Eickhoff&amp;author[5]=M+Wilms&amp;author[6]=N+Palomero-Gallagher&amp;author[7]=E+Armstrong&amp;author[8]=K+Zilles&amp;title=Cytoarchitectonic+analysis+of+the+human+extrastriate+cortex+in+the+region+of+V5/MT+:+a+probabilistic,+stereotaxic+map+of+area+hOc5&amp;publication_year=2007&amp;journal=Cereb+Cortex&amp;volume=17&amp;pages=562-574" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-27-1" title="View reference in text" id="ref-27">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.27" data-doi="10.1038/264746a0"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">McGurk</span>  <span class="cit-name-given-names">H</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">MacDonald</span>  <span class="cit-name-given-names">J</span></span></li></ol><cite>(<span class="cit-pub-date">1976</span>) <span class="cit-article-title">Hearing lips and seeing voices</span>. <abbr class="cit-jnl-abbrev">Nature</abbr> <span class="cit-vol">264</span>:<span class="cit-fpage">746</span>–<span class="cit-lpage">748</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Nature&amp;rft.stitle=Nature&amp;rft.issn=0028-0836&amp;rft.aulast=McGurk&amp;rft.auinit1=H.&amp;rft.volume=264&amp;rft.issue=5588&amp;rft.spage=746&amp;rft.epage=748&amp;rft.atitle=Hearing lips and seeing voices.&amp;rft_id=info:doi/10.1038/264746a0&amp;rft_id=info:pmid/1012311&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1038/264746a0&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=1012311&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=H+McGurk&amp;author[1]=J+MacDonald&amp;title=Hearing+lips+and+seeing+voices&amp;publication_year=1976&amp;journal=Nature&amp;volume=264&amp;pages=746-748" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-28-1" title="View reference in text" id="ref-28">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.28" data-doi="10.1016/j.tics.2009.03.007"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Melloni</span>  <span class="cit-name-given-names">L</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Schwiedrzik</span>  <span class="cit-name-given-names">CM</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Rodriguez</span>  <span class="cit-name-given-names">E</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Singer</span>  <span class="cit-name-given-names">W</span></span></li></ol><cite>(<span class="cit-pub-date">2009</span>) <span class="cit-article-title">(Micro)Saccades, corollary activity and cortical oscillations</span>. <abbr class="cit-jnl-abbrev">Trends Cogn Sci</abbr> <span class="cit-vol">13</span>:<span class="cit-fpage">239</span>–<span class="cit-lpage">245</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Trends in cognitive sciences&amp;rft.stitle=Trends Cogn Sci&amp;rft.aulast=Melloni&amp;rft.auinit1=L.&amp;rft.volume=13&amp;rft.issue=6&amp;rft.spage=239&amp;rft.epage=245&amp;rft.atitle=(Micro)Saccades, corollary activity and cortical oscillations.&amp;rft_id=info:doi/10.1016/j.tics.2009.03.007&amp;rft_id=info:pmid/19428286&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.tics.2009.03.007&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=19428286&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=L+Melloni&amp;author[1]=CM+Schwiedrzik&amp;author[2]=E+Rodriguez&amp;author[3]=W+Singer&amp;title=(Micro)Saccades,+corollary+activity+and+cortical+oscillations&amp;publication_year=2009&amp;journal=Trends+Cogn+Sci&amp;volume=13&amp;pages=239-245" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-29-1" title="View reference in text" id="ref-29">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.29" data-doi="10.1523/JNEUROSCI.0896-05.2005"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Miller</span>  <span class="cit-name-given-names">LM</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">D'Esposito</span>  <span class="cit-name-given-names">M</span></span></li></ol><cite>(<span class="cit-pub-date">2005</span>) <span class="cit-article-title">Perceptual fusion and stimulus coincidence in the cross-modal integration of speech</span>. <abbr class="cit-jnl-abbrev">J Neurosci</abbr> <span class="cit-vol">25</span>:<span class="cit-fpage">5884</span>–<span class="cit-lpage">5893</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Neuroscience&amp;rft.stitle=J. Neurosci.&amp;rft.issn=0270-6474&amp;rft.aulast=Miller&amp;rft.auinit1=L. M.&amp;rft.volume=25&amp;rft.issue=25&amp;rft.spage=5884&amp;rft.epage=5893&amp;rft.atitle=Perceptual Fusion and Stimulus Coincidence in the Cross-Modal Integration of Speech&amp;rft_id=info:doi/10.1523/JNEUROSCI.0896-05.2005&amp;rft_id=info:pmid/15976077&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjEwOiIyNS8yNS81ODg0IjtzOjQ6ImF0b20iO3M6MjQ6Ii9qbmV1cm8vMjkvNDMvMTM0NDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=LM+Miller&amp;author[1]=M+D'Esposito&amp;title=Perceptual+fusion+and+stimulus+coincidence+in+the+cross-modal+integration+of+speech&amp;publication_year=2005&amp;journal=J+Neurosci&amp;volume=25&amp;pages=5884-5893" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-30-1" title="View reference in text" id="ref-30">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.30"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Morosan</span>  <span class="cit-name-given-names">P</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Rademacher</span>  <span class="cit-name-given-names">J</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Schleicher</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Amunts</span>  <span class="cit-name-given-names">K</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Schormann</span>  <span class="cit-name-given-names">T</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Zilles</span>  <span class="cit-name-given-names">K</span></span></li></ol><cite>(<span class="cit-pub-date">2001</span>) <span class="cit-article-title">Human primary auditory cortex: cytoarchitectonic subdivisions and mapping into a spatial reference system</span>. <abbr class="cit-jnl-abbrev">Neuroimage</abbr> <span class="cit-vol">13</span>:<span class="cit-fpage">684</span>–<span class="cit-lpage">701</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Neuroimage&amp;rft.volume=13&amp;rft.spage=684&amp;rft_id=info:pmid/11305897&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=11305897&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=P+Morosan&amp;author[1]=J+Rademacher&amp;author[2]=A+Schleicher&amp;author[3]=K+Amunts&amp;author[4]=T+Schormann&amp;author[5]=K+Zilles&amp;title=Human+primary+auditory+cortex:+cytoarchitectonic+subdivisions+and+mapping+into+a+spatial+reference+system&amp;publication_year=2001&amp;journal=Neuroimage&amp;volume=13&amp;pages=684-701" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-31-1" title="View reference in text" id="ref-31">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.31" data-doi="10.1016/S0167-8760(03)00121-1"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Rockland</span>  <span class="cit-name-given-names">KS</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Ojima</span>  <span class="cit-name-given-names">H</span></span></li></ol><cite>(<span class="cit-pub-date">2003</span>) <span class="cit-article-title">Multisensory convergence in calcarine visual areas in macaque monkey</span>. <abbr class="cit-jnl-abbrev">Int J Psychophysiol</abbr> <span class="cit-vol">50</span>:<span class="cit-fpage">19</span>–<span class="cit-lpage">26</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=International Journal of Psychophysiology&amp;rft.stitle=International Journal of Psychophysiology&amp;rft.aulast=Rockland&amp;rft.auinit1=K. S.&amp;rft.volume=50&amp;rft.issue=1-2&amp;rft.spage=19&amp;rft.epage=26&amp;rft.atitle=Multisensory convergence in calcarine visual areas in macaque monkey.&amp;rft_id=info:doi/10.1016/S0167-8760(03)00121-1&amp;rft_id=info:pmid/14511833&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/S0167-8760(03)00121-1&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=14511833&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=KS+Rockland&amp;author[1]=H+Ojima&amp;title=Multisensory+convergence+in+calcarine+visual+areas+in+macaque+monkey&amp;publication_year=2003&amp;journal=Int+J+Psychophysiol&amp;volume=50&amp;pages=19-26" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-32-1" title="View reference in text" id="ref-32">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.32" data-doi="10.1016/j.tics.2008.01.002"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Schroeder</span>  <span class="cit-name-given-names">CE</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Lakatos</span>  <span class="cit-name-given-names">P</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Kajikawa</span>  <span class="cit-name-given-names">Y</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Partan</span>  <span class="cit-name-given-names">S</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Puce</span>  <span class="cit-name-given-names">A</span></span></li></ol><cite>(<span class="cit-pub-date">2008</span>) <span class="cit-article-title">Neuronal oscillations and visual amplification of speech</span>. <abbr class="cit-jnl-abbrev">Trends Cogn Sci</abbr> <span class="cit-vol">12</span>:<span class="cit-fpage">106</span>–<span class="cit-lpage">113</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Trends in cognitive sciences&amp;rft.stitle=Trends Cogn Sci&amp;rft.aulast=Schroeder&amp;rft.auinit1=C. E.&amp;rft.volume=12&amp;rft.issue=3&amp;rft.spage=106&amp;rft.epage=113&amp;rft.atitle=Neuronal oscillations and visual amplification of speech.&amp;rft_id=info:doi/10.1016/j.tics.2008.01.002&amp;rft_id=info:pmid/18280772&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1016/j.tics.2008.01.002&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=18280772&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=CE+Schroeder&amp;author[1]=P+Lakatos&amp;author[2]=Y+Kajikawa&amp;author[3]=S+Partan&amp;author[4]=A+Puce&amp;title=Neuronal+oscillations+and+visual+amplification+of+speech&amp;publication_year=2008&amp;journal=Trends+Cogn+Sci&amp;volume=12&amp;pages=106-113" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-33-1" title="View reference in text" id="ref-33">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.33" data-doi="10.1162/jocn.2007.19.12.1964"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Stekelenburg</span>  <span class="cit-name-given-names">JJ</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Vroomen</span>  <span class="cit-name-given-names">J</span></span></li></ol><cite>(<span class="cit-pub-date">2007</span>) <span class="cit-article-title">Neural correlates of multisensory integration of ecologically valid audiovisual events</span>. <abbr class="cit-jnl-abbrev">J Cogn Neurosci</abbr> <span class="cit-vol">19</span>:<span class="cit-fpage">1964</span>–<span class="cit-lpage">1973</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Journal of Cognitive Neuroscience&amp;rft.stitle=J. Cogn. Neurosci.&amp;rft.issn=0898-929X&amp;rft.aulast=Stekelenburg&amp;rft.auinit1=J. J.&amp;rft.volume=19&amp;rft.issue=12&amp;rft.spage=1964&amp;rft.epage=1973&amp;rft.atitle=Neural correlates of multisensory integration of ecologically valid audiovisual events.&amp;rft_id=info:doi/10.1162/jocn.2007.19.12.1964&amp;rft_id=info:pmid/17892381&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1162/jocn.2007.19.12.1964&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/external-ref?access_num=17892381&amp;link_type=MED&amp;atom=%2Fjneuro%2F29%2F43%2F13445.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline"><span>PubMed</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=JJ+Stekelenburg&amp;author[1]=J+Vroomen&amp;title=Neural+correlates+of+multisensory+integration+of+ecologically+valid+audiovisual+events&amp;publication_year=2007&amp;journal=J+Cogn+Neurosci&amp;volume=19&amp;pages=1964-1973" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-34-1" title="View reference in text" id="ref-34">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.34" data-doi="10.1121/1.1907309"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">Sumby</span>  <span class="cit-name-given-names">WH</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Polack</span>  <span class="cit-name-given-names">I</span></span></li></ol><cite>(<span class="cit-pub-date">1954</span>) <span class="cit-article-title">Perceptual amplification of speech sounds by visual cues</span>. <abbr class="cit-jnl-abbrev">J Acoust Soc Am</abbr> <span class="cit-vol">26</span>:<span class="cit-fpage">212</span>–<span class="cit-lpage">215</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=J Acoust Soc Am&amp;rft.volume=26&amp;rft.spage=212&amp;rft_id=info:doi/10.1121/1.1907309&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/external-ref?access_num=10.1121/1.1907309&amp;link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref"><span>CrossRef</span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=WH+Sumby&amp;author[1]=I+Polack&amp;title=Perceptual+amplification+of+speech+sounds+by+visual+cues&amp;publication_year=1954&amp;journal=J+Acoust+Soc+Am&amp;volume=26&amp;pages=212-215" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-35-1" title="View reference in text" id="ref-35">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.35" data-doi="10.1073/pnas.0408949102"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">van Wassenhove</span>  <span class="cit-name-given-names">V</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Grant</span>  <span class="cit-name-given-names">KW</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Poeppel</span>  <span class="cit-name-given-names">D</span></span></li></ol><cite>(<span class="cit-pub-date">2005</span>) <span class="cit-article-title">Visual speech speeds up the neural processing of auditory speech</span>. <abbr class="cit-jnl-abbrev">Proc Natl Acad Sci U S A</abbr> <span class="cit-vol">102</span>:<span class="cit-fpage">1181</span>–<span class="cit-lpage">1186</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Proc Natl Acad Sci U S A&amp;rft_id=info:doi/10.1073/pnas.0408949102&amp;rft_id=info:pmid/15647358&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6NDoicG5hcyI7czo1OiJyZXNpZCI7czoxMDoiMTAyLzQvMTE4MSI7czo0OiJhdG9tIjtzOjI0OiIvam5ldXJvLzI5LzQzLzEzNDQ1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=V+van Wassenhove&amp;author[1]=KW+Grant&amp;author[2]=D+Poeppel&amp;title=Visual+speech+speeds+up+the+neural+processing+of+auditory+speech&amp;publication_year=2005&amp;journal=Proc+Natl+Acad+Sci+U+S+A&amp;volume=102&amp;pages=1181-1186" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li><li><span class="ref-label ref-label-empty"></span><a class="rev-xref-ref" href="#xref-ref-36-1" title="View reference in text" id="ref-36">↵</a>
            <div class="cit ref-cit ref-journal google_scholar_link-processed custom-js-processed" id="cit-29.43.13445.36" data-doi="10.1073/pnas.0710826105"><div class="cit-metadata"><ol class="cit-auth-list"><li><span class="cit-auth"><span class="cit-name-surname">von Kriegstein</span>  <span class="cit-name-given-names">K</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Dogan</span>  <span class="cit-name-given-names">O</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Grüter</span>  <span class="cit-name-given-names">M</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Giraud</span>  <span class="cit-name-given-names">AL</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Kell</span>  <span class="cit-name-given-names">CA</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Grüter</span>  <span class="cit-name-given-names">T</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Kleinschmidt</span>  <span class="cit-name-given-names">A</span></span>, </li><li><span class="cit-auth"><span class="cit-name-surname">Kiebel</span>  <span class="cit-name-given-names">SJ</span></span></li></ol><cite>(<span class="cit-pub-date">2008</span>) <span class="cit-article-title">Simulation of talking faces in the human brain improves auditory speech recognition</span>. <abbr class="cit-jnl-abbrev">Proc Natl Acad Sci U S A</abbr> <span class="cit-vol">105</span>:<span class="cit-fpage">6747</span>–<span class="cit-lpage">6752</span>.</cite></div><div class="cit-extra"><a href="/highwire/openurl?rft.jtitle=Proc Natl Acad Sci U S A&amp;rft_id=info:doi/10.1073/pnas.0710826105&amp;rft_id=info:pmid/18436648&amp;rft.genre=article&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;ctx_ver=Z39.88-2004&amp;url_ver=Z39.88-2004&amp;url_ctx_fmt=info:ofi/fmt:kev:mtx:ctx&amp;redirect_url=https://search.lib.utexas.edu/openurl/01UTAU_INST/01UTAU_INST:SEARCH?" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url insertImage-processed"><img src="https://www.jneurosci.org/highwire/inst_branding/image/cea101a9-c194-4c77-a4b1-06115155c44f-20130321">Find It @UT</a><a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6NDoicG5hcyI7czo1OiJyZXNpZCI7czoxMToiMTA1LzE4LzY3NDciO3M6NDoiYXRvbSI7czoyNDoiL2puZXVyby8yOS80My8xMzQ0NS5hdG9tIjt9czo4OiJmcmFnbWVudCI7czowOiIiO30=" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink"><span><span class="cit-reflinks-abstract">Abstract</span><span class="cit-sep cit-reflinks-variant-name-sep">/</span><span class="cit-reflinks-full-text"><span class="free-full-text">FREE </span>Full Text</span></span></a><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=article&amp;author[0]=K+von Kriegstein&amp;author[1]=O+Dogan&amp;author[2]=M+Grüter&amp;author[3]=AL+Giraud&amp;author[4]=CA+Kell&amp;author[5]=T+Grüter&amp;author[6]=A+Kleinschmidt&amp;author[7]=SJ+Kiebel&amp;title=Simulation+of+talking+faces+in+the+human+brain+improves+auditory+speech+recognition&amp;publication_year=2008&amp;journal=Proc+Natl+Acad+Sci+U+S+A&amp;volume=105&amp;pages=6747-6752" class="cit-ref-sprinkles cit-ref-sprinkles-google-scholar cit-ref-sprinkles-google-scholar"><span>Google Scholar</span></a></div></div>
         </li></ol></div><span class="highwire-journal-article-marker-end"></span></div><span class="related-urls"></span></div></div>  </div>

  
  </div>
</div>
  </div>
</div>
</div></div>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-back-to-top">
  
      
  
  <div class="pane-content">
    <a href="#page" class="back-to-top" data-icon-position="" data-hide-link-title="0"><span class="icon-chevron-up"></span> Back to top</a>  </div>

  
  </div>
</div>
			</div>
		</div>
		
		<div class="sidebar-right-wrapper grid-10 omega">
			<div class="panel-panel panel-region-sidebar-right">
			  <div class="inside"><div class="panel-pane pane-panels-mini pane-jnl-sfneneuro-art-issue">
  
        <h2 class="pane-title">In this issue</h2>
    
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-jnl_sfneneuro_art_issue">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-highwire-article-citation">
  
      
  
  <div class="pane-content">
    <div class="highwire-article-citation highwire-citation-type-highwire-issue node349256" data-node-nid="349256" id="node-349256--2404821507" data-pisa="jneuro;29/43" data-pisa-master="jneuro;29/43" data-apath="/jneuro/29/43.atom"><div class="highwire-cite highwire-cite-highwire-issue highwire-citation-jcore-issue-widget clearfix">
    
      <div class="highwire-cite-highlight"><a href="/content/29/43" class="highlight-image-linked"><img class="highlight-image" src="https://www.jneurosci.org/sites/default/files/styles/medium/public/highwire/jneuro/29/43.cover.gif?itok=m4sYazql" alt="The Journal of Neuroscience: 29 (43)"></a></div>
  
  <div class="highwire-cite-col">
      
      
          <a href="/content/29/43" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">Journal of Neuroscience</span></a>      
      
        	<div class="highwire-cite-metadata"><span class="highwire-cite-metadata-volume highwire-cite-metadata">Vol. 29</span>, <span class="highwire-cite-metadata-issue highwire-cite-metadata">Issue 43 </span><div class="highwire-cite-metadata-pubdate highwire-cite-metadata">28 Oct 2009 </div></div>
      
      
        	<div class="highwire-cite-extras"><div class="highwire-article-citation-variant-list"><ul class="links variants-list"><li class="toc first"><a href="/content/29/43.toc" class="highwire-variant-link variant-toc " title="Table of Contents" rel="alternate" type="text/html" data-icon-position="" data-hide-link-title="0">Table of Contents</a></li><li class="tocpdf"><a href="/content/29/43.toc.pdf" class="highwire-variant-link variant-tocpdf " title="Table of Contents (PDF)" rel="alternate" type="application/pdf" data-icon-position="" data-hide-link-title="0">Table of Contents (PDF)</a></li><li class="cover-expansion"><a href="/content/29/43.cover-expansion" class="highwire-variant-link variant-cover-expansion " title="About the Cover" rel="alternate" data-icon-position="" data-hide-link-title="0">About the Cover</a></li><li class="index-by-author last"><a href="/content/29/43.index-by-author" class="highwire-variant-link variant-index-by-author " title="Index by author" rel="alternate" data-icon-position="" data-hide-link-title="0">Index by author</a></li></ul></div></div>
      </div>

</div></div>  </div>

  
  </div>
</div>
  </div>
</div>
  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-panels-mini pane-jnl-sfneneuro-art-tools">
  
      
  
  <div class="pane-content">
    <div id="mini-panel-jnl_sfneneuro_art_tools" class="highwire-2col-stacked panel-display">
	  
  <div class="panel-row-wrapper clearfix">
		<div class="content-left-wrapper content-column">
          <div class="panel-panel panel-region-content-left">
            <div class="inside"><div class="panel-pane pane-minipanel-dialog-link pane-jnl-sfneneuro-art-email">
  
      
  
  <div class="pane-content">
    <div class="minipanel-dialog-wrapper"><div class="minipanel-dialog-link-link"><a href="/" oncontextmenu="javascript: return false;" class="minipanel-dialog-link-trigger link-icon minipanel-dialog-link-trigger-processed" title="Share this Article"><span class="icon-envelope"></span> <span class="title">Email</span></a></div></div>  </div>

  
  </div>
<div class="panel-pane pane-highwire-variant-link">
  
      
  
  <div class="pane-content">
    <a href="/content/jneuro/29/43/13445.full-text.print" target="_blank" class="link-icon"><span class="icon-print"></span> <span class="title">Print</span></a>  </div>

  
  </div>
<div class="panel-pane pane-highwire-variant-link text-no-wrap">
  
      
  
  <div class="pane-content">
    <a href="/content/jneuro/29/43/13445.full-text.pdf" target="_blank" class="link-icon"><span class="icon-external-link"></span> <span class="title">View Full Page PDF</span></a>  </div>

  
  </div>
<div class="panel-pane pane-minipanel-dialog-link pane-jnl-sfneneuro-cite-tool">
  
      
  
  <div class="pane-content">
    <div class="minipanel-dialog-wrapper"><div class="minipanel-dialog-link-link"><a href="/highwire/citation/370480/download" oncontextmenu="javascript: return false;" class="minipanel-dialog-link-trigger link-icon minipanel-dialog-link-trigger-processed" title="Citation Tools"><span class="icon-globe"></span> <span class="title">Citation Tools</span></a></div></div>  </div>

  
  </div>
<div class="panel-pane pane-highwire-article-add-comments">
  
      
  
  <div class="pane-content">
    <a href="/content/29/43/13445.tab-e-letters" class="highwire-article-respond-to-article link-icon highwire-article-respond-to-article-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_elets" data-is-tab-link="true"><span class="icon-comment"></span> <span class="title">Respond to this article</span></a>  </div>

  
  </div>
<div class="panel-pane pane-panels-mini pane-article-toolbox-perms-link hw-article-permission-link">
  
      
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-article_toolbox_perms_link">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-snippet pane-jnl-sfneneuro-request-permissions pane-highwire-permission-link">
  
      
  
  <div class="pane-content">
    <div class="snippet jnl-sfneneuro-request-permissions" id="jnl-sfneneuro-request-permissions">
  
      
  <div class="snippet-content">
    <div><a href="http://www.jneurosci.org/content/rights-permissions" target="_blank" class="highwire-permission-link link-icon"><i class="icon-copyright"> </i> <span class="title">Request Permissions</span></a></div>  </div>

</div>
  </div>

  
  </div>
</div>
  </div>
</div>
  </div>

  
  </div>
</div>
          </div>
        </div>
        
        <div class="content-right-wrapper content-column">
          <div class="panel-panel panel-region-content-right">
            <div class="inside"><div class="panel-pane pane-highwire-share-link highwire_clipboard_link_ajax" id="shareit">
  
      
  
  <div class="pane-content">
    <a href="/" class="link-icon"><span class="icon-share-alt"></span> <span class="title">Share</span></a>  </div>

  
  </div>
<div class="panel-pane pane-panels-mini pane-jnl-sfneneuro-share highwire_clipboard_form_ajax_shareit">
  
      
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-jnl_sfneneuro_share">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-highwire-article-citation large-margin-bottom">
  
      
  
  <div class="pane-content">
    <div class="highwire-article-citation highwire-citation-type-highwire-article node370480--3" data-node-nid="370480" id="share-node-370480--41667327341" data-pisa="jneuro;29/43/13445" data-pisa-master="jneuro;29/43/13445" data-apath="/jneuro/29/43/13445.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jnl-eneuro-styles-jcore-standard-plus clearfix">
  
  
  
  
      <div class="highwire-cite-title">Dual Neural Routing of Visual Facilitation in Speech Processing</div>  
    	<div class="highwire-cite-authors"><span class="highwire-citation-authors"><span class="highwire-citation-author first" data-delta="0">Luc H. Arnal</span>, <span class="highwire-citation-author" data-delta="1">Benjamin Morillon</span>, <span class="highwire-citation-author" data-delta="2">Christian A. Kell</span>, <span class="highwire-citation-author" data-delta="3">Anne-Lise Giraud</span></span></div>
  
    	<div class="highwire-cite-metadata"><span class="highwire-cite-metadata-journal highwire-cite-metadata">Journal of Neuroscience </span><span class="highwire-cite-metadata-date highwire-cite-metadata">28 October 2009, </span><span class="highwire-cite-metadata-volume highwire-cite-metadata">29 </span><span class="highwire-cite-metadata-issue highwire-cite-metadata">(43) </span><span class="highwire-cite-metadata-pages highwire-cite-metadata">13445-13453; </span><span class="highwire-cite-metadata-doi highwire-cite-metadata"><span class="label">DOI:</span> 10.1523/JNEUROSCI.3194-09.2009 </span></div>
  
  
  
</div>
</div>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-article-clipboard-copy large-margin-bottom">
  
      
  
  <div class="pane-content">
    <div class="clipboard-copy">
  <span class="label-url">
    <label for="dynamic">Share This Article:</label>
  </span>
  <span class="input-text-url">
    <input type="text" id="dynamic" value="https://www.jneurosci.org/content/29/43/13445" size="50">
  </span>
  <span class="copy-button button">
    <button id="copy-dynamic" class="clipboardjs-button" data-clipboard-target="#dynamic" data-clipboard-alert-style="tooltip" data-clipboard-alert-text="Copied!">Copy</button>
  </span>
</div>
  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-service-links">
  
      
  
  <div class="pane-content">
    <div class="service-links"><a href="/highwire_log/share/reddit?link=http%3A%2F%2Freddit.com%2Fsubmit%3Furl%3Dhttps%253A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445%26title%3DDual%2520Neural%2520Routing%2520of%2520Visual%2520Facilitation%2520in%2520Speech%2520Processing" id="reddit" title="Submit this post on reddit.com" class="service-links-reddit" rel="nofollow" data-icon-position="" data-hide-link-title="0" data-log-redirect-set="true"><img src="https://www.jneurosci.org/sites/all/modules/highwire/highwire/images/reddit.png" alt="Reddit logo"></a> <a href="/highwire_log/share/twitter?link=http%3A%2F%2Ftwitter.com%2Fshare%3Furl%3Dhttps%253A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445%26text%3DDual%2520Neural%2520Routing%2520of%2520Visual%2520Facilitation%2520in%2520Speech%2520Processing" id="twitter" title="Share this on Twitter" class="service-links-twitter" rel="nofollow" data-icon-position="" data-hide-link-title="0" data-log-redirect-set="true"><img src="https://www.jneurosci.org/sites/all/modules/highwire/highwire/images/twitter.png" alt="Twitter logo"></a> <a href="/highwire_log/share/facebook?link=http%3A%2F%2Fwww.facebook.com%2Fsharer.php%3Fu%3Dhttps%253A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445%26t%3DDual%2520Neural%2520Routing%2520of%2520Visual%2520Facilitation%2520in%2520Speech%2520Processing" id="facebook" title="Share on Facebook" class="service-links-facebook" rel="nofollow" data-icon-position="" data-hide-link-title="0" data-log-redirect-set="true"><img src="https://www.jneurosci.org/sites/all/modules/highwire/highwire/images/fb-blue.png" alt="Facebook logo"></a> <a href="/highwire_log/share/mendeley?link=http%3A%2F%2Fwww.mendeley.com%2Fimport%2F%3Furl%3Dhttps%253A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445%26title%3DDual%2520Neural%2520Routing%2520of%2520Visual%2520Facilitation%2520in%2520Speech%2520Processing" id="mendeley" title="Share on Mendeley" class="service-links-mendeley" rel="nofollow" data-icon-position="" data-hide-link-title="0" data-log-redirect-set="true"><img src="https://www.jneurosci.org/sites/all/modules/highwire/highwire/images/mendeley.png" alt="Mendeley logo"></a></div>  </div>

  
  </div>
</div>
  </div>
</div>
  </div>

  
  </div>
<div class="panel-pane pane-service-links">
  
      
  
  <div class="pane-content">
    <div class="service-links"><div class="item-list"><ul><li class="first"><iframe id="twitter-widget-0" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" class="twitter-share-button twitter-share-button-rendered twitter-tweet-button" title="X Post Button" src="https://platform.twitter.com/widgets/tweet_button.2f70fb173b9000da126c79afe2098f02.en.html#dnt=false&amp;id=twitter-widget-0&amp;lang=en&amp;original_referer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long&amp;size=m&amp;text=Dual%20Neural%20Routing%20of%20Visual%20Facilitation%20in%20Speech%20Processing&amp;time=1717583159631&amp;type=share&amp;url=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445" style="position: static; visibility: visible; width: 65px; height: 20px;" data-url="https://www.jneurosci.org/content/29/43/13445"></iframe></li><li><iframe src="//www.facebook.com/plugins/like.php?href=https%3A//www.jneurosci.org/content/29/43/13445&amp;layout=button_count&amp;show_faces=false&amp;action=like&amp;colorscheme=light&amp;width=100&amp;height=21&amp;font=&amp;locale=" scrolling="no" frameborder="0" allowtransparency="true" title="Like this page on Facebook" class="service-links-facebook-like" style="border: none; overflow: hidden; width: 100px; height: 21px;"></iframe></li><li class="last"><div id="___plusone_0" style="position: absolute; width: 450px; left: -10000px;"><iframe ng-non-bindable="" frameborder="0" hspace="0" marginheight="0" marginwidth="0" scrolling="no" style="position:absolute;top:-10000px;width:450px;margin:0px;border-style:none" tabindex="0" vspace="0" width="100%" id="I0_1717583159427" name="I0_1717583159427" src="https://apis.google.com/u/0/se/0/_/+1/fastbutton?usegapi=1&amp;width=300&amp;origin=https%3A%2F%2Fwww.jneurosci.org&amp;url=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445&amp;gsrc=3p&amp;ic=1&amp;jsh=m%3B%2F_%2Fscs%2Fabc-static%2F_%2Fjs%2Fk%3Dgapi.lb.en.6jI6mC1Equ4.O%2Fam%3DAAAQ%2Fd%3D1%2Frs%3DAHpOoo-79kMK-M6Si-J0E_6fI_9RBHBrwQ%2Fm%3D__features__#_methods=onPlusOne%2C_ready%2C_close%2C_open%2C_resizeMe%2C_renderstart%2Concircled%2Cdrefresh%2Cerefresh&amp;id=I0_1717583159427&amp;_gfid=I0_1717583159427&amp;parent=https%3A%2F%2Fwww.jneurosci.org&amp;pfname=&amp;rpctoken=13266117" data-gapiattached="true"></iframe></div><g:plusone href="https://www.jneurosci.org/content/29/43/13445" width="300" data-gapiscan="true" data-gapistub="true"></g:plusone></li></ul></div></div>  </div>

  
  </div>
</div>
          </div>
        </div>
	</div> <!-- /.panel-row-wrapper -->	
	
	</div>

  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-article-nav mobile-hidden pane-style-alt-content">
  
        <h2 class="pane-title">Jump to section</h2>
    
  
  <div class="pane-content">
    <div class="highwire-list-wrapper highwire-article-nav highwire-nav-float highwire-article-nav-processed highwire-nav-float-processed"><div class="highwire-list"><ul data-highwire-float="1" data-highwire-float-class="grid-10 alpha omega"><li class="parent first odd"><a href="/content/29/43/13445" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-is-tab-link="true" data-icon-position="" data-hide-link-title="0">Article</a><div class="highwire-list"><ul><li class="first odd"><a href="#abstract-1" class="highwire-article-nav-jumplink first hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-icon-position="" data-hide-link-title="0">Abstract</a></li><li class="even"><a href="#sec-1" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-icon-position="" data-hide-link-title="0">Introduction</a></li><li class="odd"><a href="#sec-2" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-icon-position="" data-hide-link-title="0">Materials and Methods</a></li><li class="even"><a href="#sec-18" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-icon-position="" data-hide-link-title="0">Results</a></li><li class="odd"><a href="#sec-25" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-icon-position="" data-hide-link-title="0">Discussion</a></li><li class="even"><a href="#fn-group-1" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-icon-position="" data-hide-link-title="0">Footnotes</a></li><li class="last odd"><a href="#ref-list-1" class="highwire-article-nav-jumplink last hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_art" data-icon-position="" data-hide-link-title="0">References</a></li></ul></div></li><li class="even"><a href="/content/29/43/13445/tab-figures-data" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_data" data-is-tab-link="true" data-icon-position="" data-hide-link-title="0">Figures &amp; Data</a></li><li class="odd"><a href="/content/29/43/13445/tab-article-info" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_info" data-is-tab-link="true" data-icon-position="" data-hide-link-title="0">Info &amp; Metrics</a></li><li class="even"><a href="/content/29/43/13445/tab-e-letters" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_elets" data-is-tab-link="true" data-icon-position="" data-hide-link-title="0">eLetters</a></li><li class="last odd"><a href="/content/29/43/13445.full.pdf" class="highwire-article-nav-jumplink hw-panels-ajax-tabs-once-processed" data-icon-position="" data-hide-link-title="0" target="_blank"><i class="icon-file-alt"></i> PDF</a></li></ul></div></div>  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-panels-mini pane-jnl-sfneneuro-tab-elets-sidebar">
  
        <h2 class="pane-title">Responses to this article</h2>
    
  
  <div class="pane-content">
    <div class="panel-display highwire-1col-stacked-layout" id="mini-panel-jnl_sfneneuro_tab_elets_sidebar">
	  <div class="panel-row-wrapper panel-row-first clearfix">
		
		<div class="top-wrapper">
			<div class="panel-panel panel-region-top">
			  <div class="inside"><div class="panel-pane pane-highwire-article-add-comments">
  
      
  
  <div class="pane-content">
    <a href="/content/29/43/13445.tab-e-letters" class="highwire-article-respond-to-article link-icon highwire-article-respond-to-article-processed" data-panel-ajax-tab="jnl_sfneneuro_tab_elets" data-is-tab-link="true"><span class="icon-comment"></span> <span class="title">Respond to this article</span></a>  </div>

  
  </div>
</div>
			</div>
		</div>
	
	</div> <!-- /.panel-row-wrapper -->	
	  
  <div class="panel-row-wrapper clearfix">
		
		<div class="content-wrapper">
			<div class="panel-panel panel-region-content">
			  <div class="inside"><div class="panel-pane pane-highwire-articles-comments highwire-comments-anchor-list no-margin-bottom">
  
        <h3 class="pane-title">Jump to comment:</h3>
    
  
  <div class="pane-content">
    No eLetters have been published for this article.  </div>

  
  </div>
</div>
			</div>
		</div>
	
	</div> <!-- /.panel-row-wrapper -->	
	
	</div>

  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-panels-mini pane-jnl-sfneneuro-accordion">
  
      
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-jnl_sfneneuro_accordion">
  <div class="panel-panel panel-col">
    <div><div id="highwire_article_accordion_container" class="ui-accordion ui-widget ui-helper-reset" role="tablist"><h3 class="ui-accordion-header ui-helper-reset ui-state-default ui-accordion-header-active ui-state-active ui-corner-top ui-accordion-icons" role="tab" id="ui-accordion-highwire_article_accordion_container-header-0" aria-controls="ui-accordion-highwire_article_accordion_container-panel-0" aria-selected="true" tabindex="0"><span class="ui-accordion-header-icon ui-icon ui-icon-triangle-1-s"></span><i class="icon-file"></i> Related Articles</h3><div class="ui-accordion-content ui-helper-reset ui-widget-content ui-corner-bottom ui-accordion-content-active" id="ui-accordion-highwire_article_accordion_container-panel-0" aria-labelledby="ui-accordion-highwire_article_accordion_container-header-0" role="tabpanel" style="display: block;" aria-expanded="true" aria-hidden="false"><div class="panels-ajax-pane panels-ajax-pane-new-eb60520a-88cb-4bbd-bc54-af436f4995f5 panels-ajax-pane-once-processed" data-pid="new-eb60520a-88cb-4bbd-bc54-af436f4995f5"><!--?xml version="1.0" encoding="UTF-8" ?-->
    <div class="panels-ajax-pane-html" version="HTML+RDFa+MathML 1.1" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/terms/" xmlns:foaf="http://xmlns.com/foaf/0.1/" xmlns:og="http://ogp.me/ns#" xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#" xmlns:sioc="http://rdfs.org/sioc/ns#" xmlns:sioct="http://rdfs.org/sioc/types#" xmlns:skos="http://www.w3.org/2004/02/skos/core#" xmlns:xsd="http://www.w3.org/2001/XMLSchema#" xmlns:mml="http://www.w3.org/1998/Math/MathML">
  <div class="panels-ajax-pane-head"><link type="text/css" rel="stylesheet" href="https://www.jneurosci.org/sites/default/files/advagg_css/css__Wz1GudemGmdBDJBhh7ASJQYBkEzH25n5pSrde4GjjJE__qEyxHMyhzAbjzjDfmRDqenjhc99hrFq94ejFcihnUP8__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.css" media="all">
</div><div class="panels-ajax-pane-body"><div class="panels-ajax-pane-panel panels-ajax-pane-panel-"><div class="highwire-list highwire-related-articles highwire-article-citation-list"><ul class="highwire-related-articles-list"><li class="first last odd"><div class="highwire-article-citation highwire-citation-type-highwire-article node370510" data-node-nid="370510" id="related-node-370510--2426009070" data-pisa="jneuro;29/43/i" data-pisa-master="jneuro;29/43/i" data-apath="/jneuro/29/43/i.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jcore-standard-title-only clearfix">
  
  
  
  
      <a href="/content/29/43/i" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">This Week in The Journal</span></a>  
  
  
  
  
</div>
</div></li></ul></div><div class="highwire-list-footer"><div class="highwire-related-articles-footer"><ul class="links inline"><li class="related-pubmed first"><a href="/lookup/external-ref?link_type=MED_NBRS&amp;access_num=19864557" target="_blank" class="" data-icon-position="" data-hide-link-title="0">PubMed</a></li><li class="related-google-scholar last"><a href="/lookup/google-scholar?link_type=googlescholar&amp;gs_type=related&amp;author%5B0%5D=Luc%2BH.%2BArnal&amp;author%5B1%5D=Benjamin%2BMorillon&amp;author%5B2%5D=Christian%2BA.%2BKell&amp;author%5B3%5D=Anne-Lise%2BGiraud&amp;title=Dual%2BNeural%2BRouting%2Bof%2BVisual%2BFacilitation%2Bin%2BSpeech%2BProcessing&amp;publication_year=2009&amp;path=content/29/43/13445" target="_blank" class="" data-icon-position="" data-hide-link-title="0">Google Scholar</a></li></ul></div></div></div></div></div></div></div><h3 class="ui-accordion-header ui-helper-reset ui-state-default ui-corner-all ui-accordion-icons" role="tab" id="ui-accordion-highwire_article_accordion_container-header-1" aria-controls="ui-accordion-highwire_article_accordion_container-panel-1" aria-selected="false" tabindex="-1"><span class="ui-accordion-header-icon ui-icon ui-icon-triangle-1-e"></span><i class="icon-retweet"></i> Cited By...</h3><div class="ui-accordion-content ui-helper-reset ui-widget-content ui-corner-bottom" id="ui-accordion-highwire_article_accordion_container-panel-1" aria-labelledby="ui-accordion-highwire_article_accordion_container-header-1" role="tabpanel" aria-expanded="false" aria-hidden="true" style="display: none;"><div class="panels-ajax-pane panels-ajax-pane-new-045c4b66-ef61-4973-b675-87bf21057e8c panels-ajax-pane-once-processed" data-pid="new-045c4b66-ef61-4973-b675-87bf21057e8c"></div></div><h3 class="ui-accordion-header ui-helper-reset ui-state-default ui-corner-all ui-accordion-icons" role="tab" id="ui-accordion-highwire_article_accordion_container-header-2" aria-controls="ui-accordion-highwire_article_accordion_container-panel-2" aria-selected="false" tabindex="-1"><span class="ui-accordion-header-icon ui-icon ui-icon-triangle-1-e"></span><i class="icon-caret-right"></i> More in this TOC Section</h3><div class="ui-accordion-content ui-helper-reset ui-widget-content ui-corner-bottom" id="ui-accordion-highwire_article_accordion_container-panel-2" aria-labelledby="ui-accordion-highwire_article_accordion_container-header-2" role="tabpanel" aria-expanded="false" aria-hidden="true" style="display: none;"><div class="highwire-list"><div class="highwire-articles-in-toc articles"><h3 class="highwire-toc-heading">Articles</h3>
<div class="highwire-list highwire-article-citation-list"><ul><li class="first odd"><div class="highwire-article-citation highwire-citation-type-highwire-article node616508" data-node-nid="616508" id="node-616508--21727718989" data-pisa="jneuro;36/41/10654" data-pisa-master="jneuro;36/41/10654" data-apath="/jneuro/36/41/10654.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jcore-standard-title-only clearfix">
  
  
  
  
      <a href="/content/36/41/10654" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">Memory Retrieval Has a Dynamic Influence on the Maintenance Mechanisms That Are Sensitive to ζ-Inhibitory Peptide (ZIP)</span></a>  
  
  
  
  
</div>
</div></li><li class="even"><div class="highwire-article-citation highwire-citation-type-highwire-article node616509" data-node-nid="616509" id="node-616509--2330995663" data-pisa="jneuro;36/41/10673" data-pisa-master="jneuro;36/41/10673" data-apath="/jneuro/36/41/10673.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jcore-standard-title-only clearfix">
  
  
  
  
      <a href="/content/36/41/10673" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">Neurophysiological Evidence for a Cortical Contribution to the Wakefulness-Related Drive to Breathe Explaining Hypocapnia-Resistant Ventilation in Humans</span></a>  
  
  
  
  
</div>
</div></li><li class="last odd"><div class="highwire-article-citation highwire-citation-type-highwire-article node616510" data-node-nid="616510" id="node-616510--21077766115" data-pisa="jneuro;36/41/10510" data-pisa-master="jneuro;36/41/10510" data-apath="/jneuro/36/41/10510.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jcore-standard-title-only clearfix">
  
  
  
  
      <a href="/content/36/41/10510" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">Monomeric Alpha-Synuclein Exerts a Physiological Role on Brain ATP Synthase</span></a>  
  
  
  
  
</div>
</div></li></ul></div><div class="highwire-list-footer"><a href="/content/by/section/Articles" class="" data-icon-position="" data-hide-link-title="0">Show more <span class="wrapper">Articles</span>
</a></div></div><div class="highwire-articles-in-toc behavioral-systems-cognitive"><h3 class="highwire-toc-heading">Behavioral/Systems/Cognitive</h3>
<div class="highwire-list highwire-article-citation-list"><ul><li class="first odd"><div class="highwire-article-citation highwire-citation-type-highwire-article node378792" data-node-nid="378792" id="node-378792--260019175" data-pisa="jneuro;32/50/17970" data-pisa-master="jneuro;32/50/17970" data-apath="/jneuro/32/50/17970.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jcore-standard-title-only clearfix">
  
  
  
  
      <a href="/content/32/50/17970" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">Identification and Characterization of a Sleep-Active Cell Group in the Rostral Medullary Brainstem</span></a>  
  
  
  
  
</div>
</div></li><li class="even"><div class="highwire-article-citation highwire-citation-type-highwire-article node378678" data-node-nid="378678" id="node-378678--2250959091" data-pisa="jneuro;32/50/18137" data-pisa-master="jneuro;32/50/18137" data-apath="/jneuro/32/50/18137.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jcore-standard-title-only clearfix">
  
  
  
  
      <a href="/content/32/50/18137" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">Gravin Orchestrates Protein Kinase A and β2-Adrenergic Receptor Signaling Critical for Synaptic Plasticity and Memory</span></a>  
  
  
  
  
</div>
</div></li><li class="last odd"><div class="highwire-article-citation highwire-citation-type-highwire-article node378794" data-node-nid="378794" id="node-378794--21413364107" data-pisa="jneuro;32/50/18068" data-pisa-master="jneuro;32/50/18068" data-apath="/jneuro/32/50/18068.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jcore-standard-title-only clearfix">
  
  
  
  
      <a href="/content/32/50/18068" class="highwire-cite-linked-title" data-icon-position="" data-hide-link-title="0"><span class="highwire-cite-title">Generation of Intensity Selectivity by Differential Synaptic Tuning: Fast-Saturating Excitation But Slow-Saturating Inhibition</span></a>  
  
  
  
  
</div>
</div></li></ul></div><div class="highwire-list-footer"><a href="/content/by/section/Behavioral/Systems/Cognitive" class="" data-icon-position="" data-hide-link-title="0">Show more <span class="wrapper">Behavioral/Systems/Cognitive</span>
</a></div></div></div></div></div></div>
  </div>
</div>
  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-panels-mini pane-advertisement-rhs">
  
      
  
  <div class="pane-content">
    <div class="panel-display panel-1col clearfix" id="mini-panel-advertisement_rhs">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-snippet pane-rhs-ad-snippet">
  
      
  
  <div class="pane-content">
    <div class="snippet rhs-ad-snippet" id="rhs-ad-snippet">
  
      
  <div class="snippet-content">
    <script type="text/javascript">if (!window.AdButler){(function(){var s = document.createElement("script"); s.async = true; s.type = "text/javascript";s.src = 'https://servedbyadbutler.com/app.js';var n = document.getElementsByTagName("script")[0]; n.parentNode.insertBefore(s, n);}());}</script>
<script type="text/javascript">
var AdButler = AdButler || {}; AdButler.ads = AdButler.ads || [];
var abkw = window.abkw || '';
var plc540737 = window.plc540737 || 0;
document.write('<'+'div id="placement_540737_'+plc540737+'"></'+'div>');
AdButler.ads.push({handler: function(opt){ AdButler.register(183357, 540737, [160,600], 'placement_540737_'+opt.place, opt); }, opt: { place: plc540737++, keywords: abkw, domain: 'servedbyadbutler.com', click:'CLICK_MACRO_PLACEHOLDER' }});
</script><script async="" type="text/javascript" src="https://servedbyadbutler.com/adserve/;ID=183357;size=160x600;setID=540737;type=async;domid=placement_540737_0;place=0;pid=243486;sw=800;sh=600;spr=1;rnd=243486;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long;click=CLICK_MACRO_PLACEHOLDER"></script><div id="placement_540737_0"><div id="placement_540737_0_ins" style="margin:0;padding:0;" eligible-callback="https://servedbyadbutler.com/adserve/;MID=183357;type=e959fb862;placementID=2424072;setID=540737;channelID=0;CID=0;BID=521937434;TAID=0;place=0;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long;mt=1717583159435563;hc=be0fb55e92d969c483b73d2d0083d94473277026" viewable-callback="https://servedbyadbutler.com/adserve/;MID=183357;type=v959fb862;placementID=2424072;setID=540737;channelID=0;CID=0;BID=521937434;TAID=0;place=0;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long;mt=1717583159435555;hc=5bbce63892341f1f9e1880d835bc9b934063946b" viewable="false"><a href="https://servedbyadbutler.com/redirect.spark?MID=183357&amp;plid=2424072&amp;setID=540737&amp;channelID=0&amp;CID=0&amp;banID=521937434&amp;PID=0&amp;textadID=0&amp;tc=1&amp;scheduleID=2342772&amp;adSize=160x600&amp;mt=1717583159435517&amp;sw=800&amp;sh=600&amp;spr=1&amp;referrer=https%3A%2F%2Fwww.jneurosci.org%2Fcontent%2F29%2F43%2F13445.long&amp;hc=f097df35121c07c564f188d7fd60587c7bcbbc0b&amp;location=" target="_blank" rel="nofollow"><img src="https://servedbyadbutler.com/getad.img/;libID=4171683" alt="" title="" border="0" width="160" height="600"></a></div></div>
  </div>

</div>
  </div>

  
  </div>
</div>
  </div>
</div>
  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-highwire-article-trendmd">
  
      
  
  <div class="pane-content">
    <div id="trendmd-suggestions">

<div class="trendmd-widget-container trendmd-widget_title-normal trendmd-widget_body-normal" data-trendmd-journal-id="29307" data-trendmd-article-id="c27fae4d-8d20-42d1-a219-84202014c67a" data-trendmd-swoop="eyJzd2kiOm51bGwsInB1Ym4iOm51bGwsImlubiI6bnVsbH0=" similar-sponsored-merged="true" style="display: block;" data-trendmd-widget-id="0" similar-nonsponsored-merged="true">
  <div class="trendmd-widget trendmd-widget_vertical">
    <div class="trendmd-widget-inner">
        <div class="trendmd-widget-section">
          <div class="trendmd-widget-header">
                          <h3 class="trendmd-widget-header__heading">We recommend</h3>
                      </div>
          <ol class="trendmd-widget-list"><li class="trendmd-widget-list-item">
                <a class="trendmd-widget-list-item__link" data-trendmd-id="87c71f51-8fa4-4c1e-b503-86501665621e" data-trendmd-journal-id="52384" data-trendmd-content-category="Scholarly" data-trendmd-campaign-id="0" data-trendmd-ct="%7B%22i%22:%5B%5D,%22c%22:%5B%5D,%22n%22:%5B%5D%7D" data-trendmd-sponsored="false" href="https://www.eneuro.org/content/early/2019/09/03/ENEURO.0261-19.2019/tab-article-info?utm_source=TrendMD&amp;utm_medium=cpc&amp;utm_campaign=eNeuro_TrendMD_0" rel="nofollow" target="_self" data-trendmd-flags="2" data-trendmd-model-type="0">Distinct mechanisms of imagery differentially influence speech perception</a>
                                <div class="trendmd-widget-list-item__meta">
                                                        <span class="js_authors">Ou Ma ((马欧)) et al.,</span>
                                                        eNeuro,                                                         <span class="js_publication_date">2019</span>
                                  </div>
              </li><li class="trendmd-widget-list-item">
                <a class="trendmd-widget-list-item__link" data-trendmd-id="159eae8c-ef0c-4d37-a373-86b111a8b2e2" data-trendmd-journal-id="29307" data-trendmd-content-category="Scholarly" data-trendmd-campaign-id="0" data-trendmd-ct="%7B%22i%22:%5B%5D,%22c%22:%5B%5D,%22n%22:%5B%5D%7D" data-trendmd-sponsored="false" href="https://www.jneurosci.org/content/40/5/996?utm_source=TrendMD&amp;utm_medium=cpc&amp;utm_campaign=JNeurosci_TrendMD_0" rel="nofollow" target="_self" data-trendmd-flags="2" data-trendmd-model-type="0">Computational Mechanisms for Perceptual Stability using Disparity and Motion Parallax</a>
                                <div class="trendmd-widget-list-item__meta">
                                                        <span class="js_authors">Oliver W. Layton et al.,</span>
                                                        JNeurosci,                                                         <span class="js_publication_date">2020</span>
                                  </div>
              </li></ol>
        </div>
      
        <div class="trendmd-widget-section">
          <div class="trendmd-widget-header">
                      </div>
          <ol class="trendmd-widget-list"><li class="trendmd-widget-list-item">
                <a class="trendmd-widget-list-item__link" data-trendmd-id="a87d7f01-1722-4725-ba2f-dbddb7ac9ab4" data-trendmd-journal-id="52384" data-trendmd-content-category="Scholarly" data-trendmd-campaign-id="0" data-trendmd-ct="%7B%22i%22:%5B%5D,%22c%22:%5B%5D,%22n%22:%5B%5D%7D" data-trendmd-sponsored="false" href="http://www.eneuro.org/content/early/2019/06/06/ENEURO.0082-19.2019?utm_source=TrendMD&amp;utm_medium=cpc&amp;utm_campaign=eNeuro_TrendMD_0" rel="nofollow" target="_self" data-trendmd-flags="2" data-trendmd-model-type="0">Cortical tracking of complex sound envelopes: modeling the changes in response with intensity</a>
                                <div class="trendmd-widget-list-item__meta">
                                                        <span class="js_authors">Denis P. Drennan et al.,</span>
                                                        eNeuro,                                                         <span class="js_publication_date">2019</span>
                                  </div>
              </li><li class="trendmd-widget-list-item">
                <a class="trendmd-widget-list-item__link" data-trendmd-id="d6cd8943-4627-4370-9c1e-7ce4ed2dde77" data-trendmd-journal-id="29307" data-trendmd-content-category="Scholarly" data-trendmd-campaign-id="0" data-trendmd-ct="%7B%22i%22:%5B%5D,%22c%22:%5B%5D,%22n%22:%5B%5D%7D" data-trendmd-sponsored="false" href="https://www.jneurosci.org/content/38/40/8680?utm_source=TrendMD&amp;utm_medium=cpc&amp;utm_campaign=JNeurosci_TrendMD_0" rel="nofollow" target="_self" data-trendmd-flags="2" data-trendmd-model-type="0">Not All Predictions Are Equal: “What” and “When” Predictions Modulate Activity in Auditory Cortex through Different Mechanisms</a>
                                <div class="trendmd-widget-list-item__meta">
                                                        <span class="js_authors">Ryszard Auksztulewicz et al.,</span>
                                                        JNeurosci,                                                         <span class="js_publication_date">2018</span>
                                  </div>
              </li></ol>
        </div>
      
    </div>
    <div class="trendmd-widget-footer">
      <div class="trendmd-widget-footer-inner">
        <div class="trendmd-widget-footer-inner-left">
          <a href="https://www.trendmd.com/how-it-works-readers" target="_blank" class="trendmd-widget-brand">
            <span class="trendmd-widget-brand__recommended">Powered by</span>
            <span class="trendmd-widget-brand__logo trendmd-widget-brand__logo__faded" style="display: inline-block; width: 93px">
              <svg viewBox="0 0 234 57" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                <g id="logo">
                  <path d="M227.7,56.9 L149.7,56.9 C146.7,56.9 143.7,53.8 143.7,50.9 L143.7,6.9 C143.7,4 146.7,0.9 149.7,0.9 L227.7,0.9 C230.7,0.9 233.7,4 233.7,6.9 L233.7,50.9 C233.7,53.9 230.6,56.9 227.7,56.9 L227.7,56.9 Z" id="shape0" fill="#CA2127"></path>
                  <g id="group1" transform="translate(0.000000, 14.000000)" fill="#16325c">
                    <path d="M15.8,5.9 L15.8,29.6 L9.2,29.6 L9.2,5.9 L0.9,5.9 L0.9,0.2 L24.1,0.2 L24.1,5.9 L15.8,5.9 L15.8,5.9 Z" id="shape1"></path>
                    <path d="M50.2,10 C50.2,14.7 48.3,17.7 44.6,19.1 L52,29.6 L44,29.6 L37.5,20.2 L33,20.2 L33,29.6 L26.4,29.6 L26.4,0.2 L37.5,0.2 C42.1,0.2 45.3,1 47.3,2.5 C49.2,4.1 50.2,6.6 50.2,10 L50.2,10 Z M42.3,13.5 C43.1,12.8 43.5,11.6 43.5,10 C43.5,8.4 43.1,7.3 42.2,6.7 C41.4,6.1 39.9,5.8 37.8,5.8 L32.9,5.8 L32.9,14.5 L37.7,14.5 C40,14.6 41.5,14.2 42.3,13.5 L42.3,13.5 Z" id="shape2"></path>
                    <path d="M75.6,0.3 L75.6,6.1 L61,6.1 L61,12.1 L74.1,12.1 L74.1,17.7 L61,17.7 L61,23.8 L76,23.8 L76,29.6 L54.4,29.6 L54.4,0.2 L75.6,0.2 L75.6,0.3 Z" id="shape3"></path>
                    <path d="M99.9,0.3 L106.5,0.3 L106.5,29.7 L99.9,29.7 L85.9,11.3 L85.9,29.7 L79.3,29.7 L79.3,0.3 L85.4,0.3 L99.8,19.2 L99.8,0.3 L99.9,0.3 Z" id="shape4"></path>
                    <path d="M133.6,4.1 C136.4,6.7 137.8,10.2 137.8,14.8 C137.8,19.4 136.4,23 133.7,25.6 C131,28.3 126.8,29.6 121.2,29.6 L111.2,29.6 L111.2,0.2 L121.6,0.2 C126.7,0.3 130.8,1.5 133.6,4.1 L133.6,4.1 Z M128.8,21.6 C130.4,20.1 131.2,17.9 131.2,15 C131.2,12.1 130.4,9.9 128.8,8.3 C127.2,6.7 124.7,6 121.4,6 L117.7,6 L117.7,23.9 L121.9,23.9 C124.8,23.8 127.1,23.1 128.8,21.6 L128.8,21.6 Z" id="shape5"></path>
                  </g>
                  <g id="group2" transform="translate(156.000000, 14.000000)" fill="#FFFFFF">
                    <path d="M26.9,11.1 L19,27.1 L15,27.1 L7.1,11.1 L7.1,29.6 L0.5,29.6 L0.5,0.2 L9.4,0.2 L17,16.3 L24.6,0.2 L33.4,0.2 L33.4,29.6 L26.8,29.6 L26.8,11.1 L26.9,11.1 Z" id="shape6"></path>
                    <path d="M60.6,4.1 C63.4,6.7 64.8,10.2 64.8,14.8 C64.8,19.4 63.4,23 60.7,25.6 C58,28.3 53.8,29.6 48.2,29.6 L38.2,29.6 L38.2,0.2 L48.6,0.2 C53.7,0.3 57.8,1.5 60.6,4.1 L60.6,4.1 Z M55.8,21.6 C57.4,20.1 58.2,17.9 58.2,15 C58.2,12.1 57.4,9.9 55.8,8.3 C54.2,6.7 51.7,6 48.4,6 L44.7,6 L44.7,23.9 L48.9,23.9 C51.8,23.8 54.1,23.1 55.8,21.6 L55.8,21.6 Z" id="shape7"></path>
                  </g>
                </g>
              </svg>
            </span>
          </a>
        </div>
        <div class="trendmd-widget-footer-inner-right">
                    <div class="trendmd-widget-settings"><span class="trendmd-widget-settings__cog"></span>
            <div class="trendmd-widget-settings__modal">
              <ul class="trendmd-widget-settings__list">
                                
                  <li class="trendmd-widget-settings__item">
                    <a href="https://www.trendmd.com/targeting-settings" target="_blank" class="trendmd-widget-settings__link">Targeting settings</a>
                  </li>
                                <li class="trendmd-widget-settings__item trendmd-widget-dns" style="display: block;">
                  <a href="https://www.trendmd.com/personaldata" target="_blank" class="trendmd-widget-settings__link">Do not sell my personal information</a>
                </li>
                                  <li class="trendmd-widget-settings__item">
                    <a href="https://www.trendmd.com/google-analytics" target="_blank" class="trendmd-widget-settings__link">Google Analytics settings</a>
                  </li>
                
                
                              </ul>
            </div>
          </div>
        </div>
        <div class="trendmd-widget-footer-inner-clear"></div>
        <div class="trendmd-widget-footer-inner-bottom">
                      <div class="trendmd-widget-cookie-notification">
              <div class="trendmd-widget-cookie-notification__info"><span>I consent to the use of Google Analytics and related cookies across the TrendMD network (widget, website, blog). For more information, </span><a href="https://www.trendmd.com/google-analytics#" target="_blank">see our Privacy Settings and Terms of Use</a>.</div>
              <div class="trendmd-widget-cookie-notification__actions">
                <button onclick="(function() { window.TrendMD.gdpr().setGaConsent(true); })(); return false;">Yes</button>
                <button onclick="(function() { window.TrendMD.gdpr().setGaConsent(false); })(); return false;">No</button>
                <span></span>
              </div>
            </div>
                  </div>
      </div>
    </div>
  </div>
  
    <div id="trendmd-check">
      <div id="ad-holder"></div>
    </div>
  
</div>
</div>  </div>

  
  </div>
</div>
			<div id="pbgrd-mpur-c" class="panel-pane text-center" style="position: relative; margin: auto; width: 390px;"></div></div>
		</div>
	
	</div> <!-- /.panel-row-wrapper -->	
	
	</div>

    </div>
  </div>
</div>      </div>
</div>  </div>
</section>    
  
      <footer id="section-footer" class="section section-footer">
    
  <div id="zone-postscript" class="zone zone-postscript clearfix container-30">
    <div class="grid-7 prefix-1 region region-postscript-first" id="region-postscript-first">
  <div class="region-inner region-postscript-first-inner">
    <div class="block block-menu block-navigate block-menu-navigate odd block-without-title" id="block-menu-navigate">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf" role="menuitem"><a href="/" data-hide-link-title="0" class="" data-icon-position="">Home</a></li>
<li class="last leaf" role="menuitem"><a href="/alerts" data-hide-link-title="0" class="" data-icon-position="">Alerts</a></li>
</ul></nav>    </div>
  </div>
</div><div class="block block-menu block-menu-social-media block-menu-menu-social-media even block-without-title" id="block-menu-menu-social-media">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf" role="menuitem"><a href="http://www.facebook.com/societyforneuroscience" target="_blank" class="link-icon-only link-icon"><span class="icon-facebook-sign icon-2x"></span> <span class="title element-invisible">Visit Society for Neuroscience on Facebook</span></a></li>
<li class="leaf" role="menuitem"><a href="http://www.twitter.com/sfnjournals" target="_blank" class="link-icon-only link-icon"><span class="hw-icon-x-twitter"></span> <span class="title element-invisible">Follow Society for Neuroscience on Twitter</span></a></li>
<li class="leaf" role="menuitem"><a href="http://www.linkedin.com/groups?home=&amp;gid=131689" target="_blank" class="link-icon-only link-icon"><span class=" icon-linkedin-sign icon-2x"></span> <span class="title element-invisible">Follow Society for Neuroscience on LinkedIn</span></a></li>
<li class="leaf" role="menuitem"><a href="http://www.youtube.com/sfnvideo" target="_blank" class="link-icon-only link-icon"><span class="icon-youtube-sign icon-2x"></span> <span class="title element-invisible">Visit Society for Neuroscience on Youtube</span></a></li>
<li class="last leaf" role="menuitem"><a href="/content/rss" class="link-icon-only link-icon"><span class="icon-rss-sign icon-2x"></span> <span class="title element-invisible">Follow our RSS feeds</span></a></li>
</ul></nav>    </div>
  </div>
</div>  </div>
</div><div class="grid-7 region region-postscript-second" id="region-postscript-second">
  <div class="region-inner region-postscript-second-inner">
    <section class="block block-menu block-menu-articles block-menu-menu-articles odd" id="block-menu-menu-articles">
  <div class="block-inner clearfix">
              <h2 class="block-title">Content</h2>
            
    <div class="content clearfix">
      <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf" role="menuitem"><a href="/content/early/by/section" data-hide-link-title="0" class="" data-icon-position="">Early Release</a></li>
<li class="leaf" role="menuitem"><a href="/content/current" data-hide-link-title="0" class="" data-icon-position="">Current Issue</a></li>
<li class="leaf" role="menuitem"><a href="/content/by/year" data-hide-link-title="0" class="" data-icon-position="">Issue Archive</a></li>
<li class="last leaf" role="menuitem"><a href="/content/collections" data-hide-link-title="0" class="" data-icon-position="">Collections</a></li>
</ul></nav>    </div>
  </div>
</section>  </div>
</div><div class="grid-7 region region-postscript-third" id="region-postscript-third">
  <div class="region-inner region-postscript-third-inner">
    <section class="block block-menu block-menu-for-authors block-menu-menu-for-authors odd" id="block-menu-menu-for-authors">
  <div class="block-inner clearfix">
              <h2 class="block-title">Information</h2>
            
    <div class="content clearfix">
      <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf" role="menuitem"><a href="/content/information-authors" data-hide-link-title="0" class="" data-icon-position="">For Authors</a></li>
<li class="leaf" role="menuitem"><a href="/content/advertising-jneurosci" data-hide-link-title="0" class="" data-icon-position="">For Advertisers</a></li>
<li class="leaf" role="menuitem"><a href="/content/media" data-hide-link-title="0" class="" data-icon-position="">For the Media</a></li>
<li class="last leaf" role="menuitem"><a href="/site/subscriptions" data-hide-link-title="0" class="" data-icon-position="">For Subscribers</a></li>
</ul></nav>    </div>
  </div>
</section>  </div>
</div><div class="grid-7 suffix-1 region region-postscript-fourth" id="region-postscript-fourth">
  <div class="region-inner region-postscript-fourth-inner">
    <section class="block block-menu block-menu-about block-menu-menu-about odd" id="block-menu-menu-about">
  <div class="block-inner clearfix">
              <h2 class="block-title"> About</h2>
            
    <div class="content clearfix">
      <nav class="menubar-nav"><ul class="menu" role="menu"><li class="first leaf" role="menuitem"><a href="/content/about-jneurosci" data-hide-link-title="0" class="" data-icon-position="">About the Journal</a></li>
<li class="leaf" role="menuitem"><a href="/content/editorial-board" data-hide-link-title="0" class="" data-icon-position="">Editorial Board</a></li>
<li class="leaf" role="menuitem"><a href="/content/privacy-policy" data-hide-link-title="0" class="" data-icon-position="">Privacy Policy</a></li>
<li class="leaf" role="menuitem"><a href="/feedback" data-hide-link-title="0" class="" data-icon-position="">Contact</a></li>
<li class="last leaf" role="menuitem"><a href="https://www.jneurosci.org/about/accessibility" data-hide-link-title="0" class="" data-icon-position="">Accessibility</a></li>
</ul></nav>    </div>
  </div>
</section>  </div>
</div>  </div>
  
  <div id="zone-footer" class="zone zone-footer clearfix container-30">
    <div class="grid-28 suffix-1 prefix-1 region region-footer-first" id="region-footer-first">
  <div class="region-inner region-footer-first-inner">
    <div class="block block-panels-mini block-jnl-sfneneuro-foot-info block-panels-mini-jnl-sfneneuro-foot-info odd block-without-title" id="block-panels-mini-jnl-sfneneuro-foot-info">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <div class="panel-display panel-1col clearfix" id="mini-panel-jnl_sfneneuro_foot_info">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-snippet pane-footer-copyright-text">
  
      
  
  <div class="pane-content">
    <div class="snippet footer-copyright-text" id="footer-copyright-text">
  
      
  <div class="snippet-content">
    <div style="float:left;"><img alt="(JNeurosci logo)" src="/sites/default/files/files/JNeurosci_footer_logo_forJCore_386x100.png" style="width: 193px; height: 50px;"></div>

<div style="float:right;"><a href="http://www.sfn.org/" target="_blank"><img alt="(SfN logo)" src="/sites/default/files/files/SfN_footer_logo_forJCore_336x100.png" style="width: 168px; height: 50px;"></a></div>

<div class="rtecenter">
<div style="display: inline-block;">
<p>Copyright © 2024 by the Society for Neuroscience.<br>
<em>JNeurosci</em> Online ISSN: 1529-2401</p>

<p>The ideas and opinions expressed in <em>JNeurosci</em> do not necessarily reflect those of SfN or the <em>JNeurosci</em> Editorial Board. Publication of an advertisement or other product mention in <em>JNeurosci</em> should not be construed as an endorsement of the manufacturer’s claims. SfN does not assume any responsibility for any injury and/or damage to persons or property arising from or related to any use of any material contained in <em>JNeurosci</em>.</p>
</div>
</div>
  </div>

</div>
  </div>

  
  </div>
<div class="panel-separator"></div><div class="panel-pane pane-custom pane-3">
  
      
  
  <div class="pane-content">
    <!-- Google Code for Remarketing Tag --><script type="text/javascript">
/* <![CDATA[ */
var google_conversion_id = 952157035;
var google_custom_params = window.google_tag_params;
var google_remarketing_only = true;
/* ]]> */
</script><script type="text/javascript" src="//www.googleadservices.com/pagead/conversion.js">
</script><noscript>
<div style="display:inline;">
<img height="1" width="1" style="border-style:none;" alt="" src="//googleads.g.doubleclick.net/pagead/viewthroughconversion/952157035/?value=0&amp;guid=ON&amp;script=0"/>
</div>
</noscript>  </div>

  
  </div>
</div>
  </div>
</div>
    </div>
  </div>
</div>  </div>
</div>  </div>
<div id="zone-advertising-bottom-wrapper" class="zone-wrapper zone-advertising-bottom-wrapper clearfix">  
  <div id="zone-advertising-bottom" class="zone zone-advertising-bottom clearfix container-30">
    <div class="grid-28 suffix-1 prefix-1 region region-ad-bottom" id="region-ad-bottom">
  <div class="region-inner region-ad-bottom-inner">
    <div class="block block-block block-1 block-block-1 odd block-without-title" id="block-block-1">
  <div class="block-inner clearfix">
                
    <div class="content clearfix">
      <script async="" src="https://cdn.pbgrd.com/core-sfn.js"></script>    </div>
  </div>
</div>  </div>
</div>  </div>
</div></footer>  </div>    <div class="region region-page-bottom" id="region-page-bottom">
  <div class="region-inner region-page-bottom-inner">
      </div>
</div><script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__FLlKtB_N_653BNdyMMJbbV0U7neAqpNnz7I2l-64CF8__0jSTKCutwwZBjfUCshF_Eeu9C4EiSPwtbXUbrYt0WKM__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js"></script>
<script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__2WRbxlwOW0MEUc_hSWU5MBepQg6Lch6O5SZwefpJ6IE__HCL0YQJqLkOhrLPZZYGqosGvtFsEHMGghHIkSx4y9vA__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js" defer="defer"></script>
<script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__OiUKNGJNZeZddi8TAMOUhkimM_LSuXeOW982hy-ZAYM__eBSIAOQns-hE2yMqiLjusrusX8GxeKQFOQGHm0gccIc__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js"></script><script type="text/javascript" src="//js.trendmd.com/trendmd.min.js" defer="" data-trendmdconfig="{&quot;element&quot;:&quot;#trendmd-suggestions&quot;,&quot;track_id&quot;:&quot;null&quot;}"></script>
<script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__Jd5dsvNznZMdglFu8sSni1wCsUfzvQbApHPAZwt5TY4__65Mqa1DMRwcSvPxjJEn6BXgMm-ckF3oOvkUTG9HRADI__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js" defer="defer"></script>
<script type="text/javascript" src="https://www.jneurosci.org/sites/default/files/advagg_js/js__l86w7eMkrA1WjYM3ZbWg1jE5O8XhGY0xgcgIsr0jSs4__rKZ6Yeawsd-JvIZub5l65VMmaBu8foE8iIeOarHJlLc__zPdAJd15e2TKRVLk_cTe4sxyGdDGDxEIbe77XbuRCDk.js"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
function euCookieComplianceLoadScripts() {}
//--><!]]>
</script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
var eu_cookie_compliance_cookie_name = "";
//--><!]]>
</script>
  

<div id="cboxOverlay" style="display: none;"></div><div id="colorbox" class="" role="dialog" tabindex="-1" style="display: none;"><div id="cboxWrapper"><div><div id="cboxTopLeft" style="float: left;"></div><div id="cboxTopCenter" style="float: left;"></div><div id="cboxTopRight" style="float: left;"></div></div><div style="clear: left;"><div id="cboxMiddleLeft" style="float: left;"></div><div id="cboxContent" style="float: left;"><div id="cboxTitle" class="" style="float: left;"></div><div id="cboxCurrent" style="float: left;"></div><button type="button" id="cboxPrevious"></button><button type="button" id="cboxNext"></button><button id="cboxSlideshow"></button><div id="cboxLoadingOverlay" style="float: left;"></div><div id="cboxLoadingGraphic" style="float: left;"></div></div><div id="cboxMiddleRight" style="float: left;"></div></div><div style="clear: left;"><div id="cboxBottomLeft" style="float: left;"></div><div id="cboxBottomCenter" style="float: left;"></div><div id="cboxBottomRight" style="float: left;"></div></div></div><div style="position: absolute; width: 9999px; visibility: hidden; display: none; max-width: none;"></div></div><div class="ui-dialog ui-widget ui-widget-content ui-corner-all ui-front" tabindex="-1" role="dialog" aria-describedby="ui-id-1" style="display: none;" aria-labelledby="ui-id-2"><div class="ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix"><span id="ui-id-2" class="ui-dialog-title">Share this Article</span><button class="ui-button ui-widget ui-state-default ui-corner-all ui-button-icon-only ui-dialog-titlebar-close" role="button" aria-disabled="false" title="close"><span class="ui-button-icon-primary ui-icon ui-icon-closethick"></span><span class="ui-button-text">close</span></button></div><div class="minipanel-dialog-link-mini ui-dialog-content ui-widget-content" style="" id="ui-id-1"><div class="panel-display panel-1col clearfix" id="mini-panel-jnl_sfneneuro_art_email">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-block pane-forward-form pane-forward">
  
      
  
  <div class="pane-content">
    <form action="/content/29/43/13445.long" method="post" id="forward-form" accept-charset="UTF-8"><div><div id="edit-instructions" class="form-item form-item-label-before form-type-item">
 <p>Thank you for sharing this Journal of Neuroscience article.</p><p>NOTE: We request your email address only to inform the recipient that it was you who recommended this article, and that it is not junk mail. We do not retain these email addresses.</p>
</div>
<div class="form-item form-item-label-before form-type-textfield form-item-email">
  <label for="edit-email">Your Email <span class="form-required" title="This field is required.">*</span></label>
 <input type="text" id="edit-email" name="email" value="" size="58" maxlength="256" class="form-text required">
</div>
<div class="form-item form-item-label-before form-type-textfield form-item-name">
  <label for="edit-name">Your Name <span class="form-required" title="This field is required.">*</span></label>
 <input type="text" id="edit-name" name="name" value="" size="58" maxlength="256" class="form-text required">
</div>
<div class="form-item form-item-label-before form-type-textarea form-item-recipients">
  <label for="edit-recipients">Send To <span class="form-required" title="This field is required.">*</span></label>
 <div class="form-textarea-wrapper resizable textarea-processed resizable-textarea"><textarea id="edit-recipients" name="recipients" cols="50" rows="5" class="form-textarea required"></textarea><div class="grippie"></div></div>
<div class="description">Enter multiple addresses on separate lines or separate them with commas.</div>
</div>
<div id="edit-page" class="form-item form-item-label-before form-type-item">
  <label for="edit-page">You are going to email the following </label>
 <a href="/content/29/43/13445" class="active" data-icon-position="" data-hide-link-title="0">Dual Neural Routing of Visual Facilitation in Speech Processing</a>
</div>
<div id="edit-subject" class="form-item form-item-label-before form-type-item">
  <label for="edit-subject">Message Subject </label>
 (Your Name) has forwarded a page to you from Journal of Neuroscience
</div>
<div id="edit-body" class="form-item form-item-label-before form-type-item">
  <label for="edit-body">Message Body </label>
 (Your Name) thought you would be interested in this article in Journal of Neuroscience.
</div>
<div class="form-item form-item-label-before form-type-textarea form-item-message">
  <label for="edit-message--2">Your Personal Message </label>
 <div class="form-textarea-wrapper resizable textarea-processed resizable-textarea"><textarea id="edit-message--2" name="message" cols="50" rows="10" class="form-textarea"></textarea><div class="grippie"></div></div>
</div>
<input type="hidden" name="path" value="node/370480">
<input type="hidden" name="path_cid" value="">
<input type="hidden" name="forward_footer" value=" ">
<input type="hidden" name="form_build_id" value="form-GcV9M8SqUeB7BVheOQVVYbkmNPWRKgHN5lbZleF0UNY">
<input type="hidden" name="form_id" value="forward_form">
<fieldset class="captcha form-wrapper"><legend><span class="fieldset-legend">CAPTCHA</span></legend><div class="fieldset-wrapper"><div class="fieldset-description">This question is for testing whether or not you are a human visitor and to prevent automated spam submissions.</div><input type="hidden" name="captcha_sid" value="220368426">
<input type="hidden" name="captcha_token" value="2d94929ab2fc3c9ecbb3735fa61f172e">
<input type="hidden" name="captcha_response" value="Google no captcha">
<div class="g-recaptcha recaptcha-processed" data-sitekey="6LfnJVIUAAAAAE-bUOMg0MJGki4lqSvDmhJp19fN" data-theme="light" data-type="image"><div style="width: 304px; height: 78px;"><div><iframe title="reCAPTCHA" width="304" height="78" role="presentation" name="a-t63fnoavjb7b" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="https://www.google.com/recaptcha/api2/anchor?ar=1&amp;k=6LfnJVIUAAAAAE-bUOMg0MJGki4lqSvDmhJp19fN&amp;co=aHR0cHM6Ly93d3cuam5ldXJvc2NpLm9yZzo0NDM.&amp;hl=en&amp;type=image&amp;v=9pvHvq7kSOTqqZusUzJ6ewaF&amp;theme=light&amp;size=normal&amp;cb=u4r33p4orj8i"></iframe></div><textarea id="g-recaptcha-response" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div></div></fieldset>
<div class="form-actions form-wrapper" id="edit-actions"><input type="submit" id="edit-submit" name="op" value="Send Message" class="form-submit"></div></div></form>  </div>

  
  </div>
</div>
  </div>
</div>
</div></div><div class="ui-dialog ui-widget ui-widget-content ui-corner-all ui-front" tabindex="-1" role="dialog" aria-describedby="ui-id-3" style="display: none;" aria-labelledby="ui-id-4"><div class="ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix"><span id="ui-id-4" class="ui-dialog-title">Citation Tools</span><button class="ui-button ui-widget ui-state-default ui-corner-all ui-button-icon-only ui-dialog-titlebar-close" role="button" aria-disabled="false" title="close"><span class="ui-button-icon-primary ui-icon ui-icon-closethick"></span><span class="ui-button-text">close</span></button></div><div class="minipanel-dialog-link-mini ui-dialog-content ui-widget-content" style="" id="ui-id-3"><div class="panel-display panel-1col clearfix" id="mini-panel-jnl_sfneneuro_cite_tool">
  <div class="panel-panel panel-col">
    <div><div class="panel-pane pane-highwire-citation-export">
  
      
  
  <div class="pane-content">
    <div class="highwire-citation-export">  
  <div class="highwire-citation-info">
      <div class="highwire-article-citation highwire-citation-type-highwire-article cite-tool-node370480" data-node-nid="370480" id="citation-node-370480--21640350114" data-pisa="jneuro;29/43/13445" data-pisa-master="jneuro;29/43/13445" data-apath="/jneuro/29/43/13445.atom"><div class="highwire-cite highwire-cite-highwire-article highwire-citation-jnl-eneuro-styles-jcore-standard-plus clearfix">
  
  
  
  
      <div class="highwire-cite-title">Dual Neural Routing of Visual Facilitation in Speech Processing</div>  
    	<div class="highwire-cite-authors"><span class="highwire-citation-authors"><span class="highwire-citation-author first" data-delta="0">Luc H. Arnal</span>, <span class="highwire-citation-author" data-delta="1">Benjamin Morillon</span>, <span class="highwire-citation-author" data-delta="2">Christian A. Kell</span>, <span class="highwire-citation-author" data-delta="3">Anne-Lise Giraud</span></span></div>
  
    	<div class="highwire-cite-metadata"><span class="highwire-cite-metadata-journal highwire-cite-metadata">Journal of Neuroscience </span><span class="highwire-cite-metadata-date highwire-cite-metadata">28 October 2009, </span><span class="highwire-cite-metadata-volume highwire-cite-metadata">29 </span><span class="highwire-cite-metadata-issue highwire-cite-metadata">(43) </span><span class="highwire-cite-metadata-pages highwire-cite-metadata">13445-13453; </span><span class="highwire-cite-metadata-doi highwire-cite-metadata"><span class="label">DOI:</span> 10.1523/JNEUROSCI.3194-09.2009 </span></div>
  
  
  
</div>
</div>  </div>
  <div class="highwire-citation-formats">
  	      <h2>Citation Manager Formats</h2>
        <div class="highwire-citation-formats-links">
      <span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.spage=13445&amp;rft.epage=13453&amp;rft.atitle=Dual%20Neural%20Routing%20of%20Visual%20Facilitation%20in%20Speech%20Processing&amp;rft.volume=29&amp;rft.issue=43&amp;rft.date=2009-10-28%2000%3A00%3A00&amp;rft.stitle=J.%20Neurosci.&amp;rft.jtitle=Journal%20of%20Neuroscience&amp;rft.au=Arnal%2C+Luc+H.&amp;rft.au=Morillon%2C+Benjamin&amp;rft.au=Kell%2C+Christian+A.&amp;rft.au=Giraud%2C+Anne-Lise"></span><ul class="hw-citation-links inline button button-alt button-grid clearfix"><li class="bibtext first"><a href="/highwire/citation/370480/bibtext" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">BibTeX</a></li><li class="bookends"><a href="/highwire/citation/370480/bookends" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">Bookends</a></li><li class="easybib"><a href="/highwire/citation/370480/easybib" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">EasyBib</a></li><li class="endnote-tagged"><a href="/highwire/citation/370480/endnote-tagged" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">EndNote (tagged)</a></li><li class="endnote-8-xml"><a href="/highwire/citation/370480/endnote-8-xml" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">EndNote 8 (xml)</a></li><li class="medlars"><a href="/highwire/citation/370480/medlars" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">Medlars</a></li><li class="mendeley"><a href="/highwire/citation/370480/mendeley" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">Mendeley</a></li><li class="papers"><a href="/highwire/citation/370480/papers" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">Papers</a></li><li class="refworks-tagged"><a href="/highwire/citation/370480/refworks-tagged" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">RefWorks Tagged</a></li><li class="reference-manager"><a href="/highwire/citation/370480/reference-manager" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">Ref Manager</a></li><li class="ris"><a href="/highwire/citation/370480/ris" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">RIS</a></li><li class="zotero last"><a href="/highwire/citation/370480/zotero" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">Zotero</a></li></ul>    </div>
  </div>
</div>
  </div>

  
  </div>
</div>
  </div>
</div>
</div></div><div id="sliding-popup" style="height: auto; width: 100%; bottom: 0px;" class="sliding-popup-bottom"><div>
  <div class="popup-content info">
    <div id="popup-text">
      <p>SfN uses cookies to provide you with a secure and custom website experience. Please read our privacy policy for more details. <a href="/content/privacy-policy">Learn more</a></p>    </div>
    <div id="popup-buttons">
      <button type="button" class="agree-button eu-cookie-compliance-default-button">I Accept</button>
                </div>
  </div>
</div></div><iframe scrolling="no" frameborder="0" allowtransparency="true" src="https://platform.twitter.com/widgets/widget_iframe.2f70fb173b9000da126c79afe2098f02.html?origin=https%3A%2F%2Fwww.jneurosci.org" title="Twitter settings iframe" style="display: none;"></iframe><iframe name="oauth2relay524800189" id="oauth2relay524800189" src="https://accounts.google.com/o/oauth2/postmessageRelay?parent=https%3A%2F%2Fwww.jneurosci.org&amp;jsh=m%3B%2F_%2Fscs%2Fabc-static%2F_%2Fjs%2Fk%3Dgapi.lb.en.6jI6mC1Equ4.O%2Fam%3DAAAQ%2Fd%3D1%2Frs%3DAHpOoo-79kMK-M6Si-J0E_6fI_9RBHBrwQ%2Fm%3D__features__#rpctoken=717802180&amp;forcesecure=1" tabindex="-1" aria-hidden="true" style="width: 1px; height: 1px; position: absolute; top: -100px;"></iframe><img src="https://servedbyadbutler.com/adserve/suid?type=adb" height="0" width="0" border="0" alt="" style="display: none;"><img src="https://servedbyadbutler.com/adserve/suid?type=adb" height="0" width="0" border="0" alt="" style="display: none;"><div id="gs-casa-r"><div id="gs-casa-c"><div id="gs-casa-b"><a id="gs-casa-f" href="https://scholar.google.com/scholar_url?url=https://www.jneurosci.org/content/jneuro/29/43/13445.full.pdf&amp;hl=en&amp;sa=T&amp;oi=ucasa&amp;ct=usl&amp;ei=Nz1gZqDtHdS-6rQPipiTgAc&amp;scisig=AFWwaebo30rABtcE5gjC_Oxs3xmB">PDF</a><a id="gs-casa-h" target="_blank" href="https://scholar.google.com/scholar/help.html#access">Help</a></div></div></div><div style="background-color: rgb(255, 255, 255); border: 1px solid rgb(204, 204, 204); box-shadow: rgba(0, 0, 0, 0.2) 2px 2px 3px; position: absolute; transition: visibility 0s linear 0.3s, opacity 0.3s linear 0s; opacity: 0; visibility: hidden; z-index: 2000000000; left: 0px; top: -10000px;"><div style="width: 100%; height: 100%; position: fixed; top: 0px; left: 0px; z-index: 2000000000; background-color: rgb(255, 255, 255); opacity: 0.05;"></div><div class="g-recaptcha-bubble-arrow" style="border: 11px solid transparent; width: 0px; height: 0px; position: absolute; pointer-events: none; margin-top: -11px; z-index: 2000000000;"></div><div class="g-recaptcha-bubble-arrow" style="border: 10px solid transparent; width: 0px; height: 0px; position: absolute; pointer-events: none; margin-top: -10px; z-index: 2000000000;"></div><div style="z-index: 2000000000; position: relative;"><iframe title="recaptcha challenge expires in two minutes" name="c-t63fnoavjb7b" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="https://www.google.com/recaptcha/api2/bframe?hl=en&amp;v=9pvHvq7kSOTqqZusUzJ6ewaF&amp;k=6LfnJVIUAAAAAE-bUOMg0MJGki4lqSvDmhJp19fN" style="width: 100%; height: 100%;"></iframe></div></div><iframe id="rufous-sandbox" scrolling="no" frameborder="0" allowtransparency="true" allowfullscreen="true" style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: none;" title="Twitter analytics iframe"></iframe><script src="https://cdn.foxycart.com/sn.ecommerce.highwire.org/foxycart.jsonp.sidecart.min.1717365353.js"></script><link rel="stylesheet" media="screen" href="https://cdn.foxycart.com/sn.ecommerce.highwire.org/responsive_styles.1717378965.css"></body></html>