<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Closed-loop training of attention with real-time brain imaging | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"attention;cognitive-control;learning-and-memory;psychology","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/nn.3940"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Megan T deBettencourt","Jonathan D Cohen","Ray F Lee","Kenneth A Norman","Nicholas B Turk-Browne"],"publishedAt":1423440000,"publishedAtString":"2015-02-09","title":"Closed-loop training of attention with real-time brain imaging","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"18","issue":"3"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Closed-loop training of attention with real-time brain imaging","description":"Lapses of attention are commonplace, potentially because they are detected too late to be prevented. The authors use real-time fMRI to provide participants continuous access to their attentional state. Real-time feedback, particularly from frontoparietal cortex, improved sustained attention abilities and modified representations in visual cortex and basal ganglia. Lapses of attention can have negative consequences, including accidents and lost productivity. Here we used closed-loop neurofeedback to improve sustained attention abilities and reduce the frequency of lapses. During a sustained attention task, the focus of attention was monitored in real time with multivariate pattern analysis of whole-brain neuroimaging data. When indicators of an attentional lapse were detected in the brain, we gave human participants feedback by making the task more difficult. Behavioral performance improved after one training session, relative to control participants who received feedback from other participants' brains. This improvement was largest when feedback carried information from a frontoparietal attention network. A neural consequence of training was that the basal ganglia and ventral temporal cortex came to represent attentional states more distinctively. These findings suggest that attentional failures do not reflect an upper limit on cognitive potential and that attention can be trained with appropriate feedback about neural signals.","datePublished":"2015-02-09T00:00:00Z","dateModified":"2015-02-09T00:00:00Z","pageStart":"470","pageEnd":"475","sameAs":"https://doi.org/10.1038/nn.3940","keywords":["Attention","Cognitive control","Learning and memory","Psychology","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig1_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig2_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig3_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig4_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig5_HTML.jpg"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"18","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Megan T deBettencourt","affiliation":[{"name":"Princeton Neuroscience Institute, Princeton University","address":{"name":"Princeton Neuroscience Institute, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Jonathan D Cohen","affiliation":[{"name":"Princeton Neuroscience Institute, Princeton University","address":{"name":"Princeton Neuroscience Institute, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Princeton University","address":{"name":"Department of Psychology, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Ray F Lee","affiliation":[{"name":"Princeton Neuroscience Institute, Princeton University","address":{"name":"Princeton Neuroscience Institute, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Kenneth A Norman","affiliation":[{"name":"Princeton Neuroscience Institute, Princeton University","address":{"name":"Princeton Neuroscience Institute, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Princeton University","address":{"name":"Department of Psychology, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Nicholas B Turk-Browne","affiliation":[{"name":"Princeton Neuroscience Institute, Princeton University","address":{"name":"Princeton Neuroscience Institute, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Princeton University","address":{"name":"Department of Psychology, Princeton University, Princeton, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"ntb@princeton.edu","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/nn.3940">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="Closed-loop training of attention with real-time brain imaging"/>
    <meta name="dc.source" content="Nature Neuroscience 2015 18:3"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2015-02-09"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2015 Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2015 Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Lapses of attention are commonplace, potentially because they are detected too late to be prevented. The authors use real-time fMRI to provide participants continuous access to their attentional state. Real-time feedback, particularly from frontoparietal cortex, improved sustained attention abilities and modified representations in visual cortex and basal ganglia. Lapses of attention can have negative consequences, including accidents and lost productivity. Here we used closed-loop neurofeedback to improve sustained attention abilities and reduce the frequency of lapses. During a sustained attention task, the focus of attention was monitored in real time with multivariate pattern analysis of whole-brain neuroimaging data. When indicators of an attentional lapse were detected in the brain, we gave human participants feedback by making the task more difficult. Behavioral performance improved after one training session, relative to control participants who received feedback from other participants&#39; brains. This improvement was largest when feedback carried information from a frontoparietal attention network. A neural consequence of training was that the basal ganglia and ventral temporal cortex came to represent attentional states more distinctively. These findings suggest that attentional failures do not reflect an upper limit on cognitive potential and that attention can be trained with appropriate feedback about neural signals."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2015-02-09"/>
    <meta name="prism.volume" content="18"/>
    <meta name="prism.number" content="3"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="470"/>
    <meta name="prism.endingPage" content="475"/>
    <meta name="prism.copyright" content="2015 Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/nn.3940"/>
    <meta name="prism.doi" content="doi:10.1038/nn.3940"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/nn.3940.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/nn.3940"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="Closed-loop training of attention with real-time brain imaging"/>
    <meta name="citation_volume" content="18"/>
    <meta name="citation_issue" content="3"/>
    <meta name="citation_publication_date" content="2015/03"/>
    <meta name="citation_online_date" content="2015/02/09"/>
    <meta name="citation_firstpage" content="470"/>
    <meta name="citation_lastpage" content="475"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/nn.3940"/>
    <meta name="DOI" content="10.1038/nn.3940"/>
    <meta name="size" content="169473"/>
    <meta name="citation_doi" content="10.1038/nn.3940"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/nn.3940&amp;api_key="/>
    <meta name="description" content="Lapses of attention are commonplace, potentially because they are detected too late to be prevented. The authors use real-time fMRI to provide participants continuous access to their attentional state. Real-time feedback, particularly from frontoparietal cortex, improved sustained attention abilities and modified representations in visual cortex and basal ganglia. Lapses of attention can have negative consequences, including accidents and lost productivity. Here we used closed-loop neurofeedback to improve sustained attention abilities and reduce the frequency of lapses. During a sustained attention task, the focus of attention was monitored in real time with multivariate pattern analysis of whole-brain neuroimaging data. When indicators of an attentional lapse were detected in the brain, we gave human participants feedback by making the task more difficult. Behavioral performance improved after one training session, relative to control participants who received feedback from other participants&#39; brains. This improvement was largest when feedback carried information from a frontoparietal attention network. A neural consequence of training was that the basal ganglia and ventral temporal cortex came to represent attentional states more distinctively. These findings suggest that attentional failures do not reflect an upper limit on cognitive potential and that attention can be trained with appropriate feedback about neural signals."/>
    <meta name="dc.creator" content="deBettencourt, Megan T"/>
    <meta name="dc.creator" content="Cohen, Jonathan D"/>
    <meta name="dc.creator" content="Lee, Ray F"/>
    <meta name="dc.creator" content="Norman, Kenneth A"/>
    <meta name="dc.creator" content="Turk-Browne, Nicholas B"/>
    <meta name="dc.subject" content="Attention"/>
    <meta name="dc.subject" content="Cognitive control"/>
    <meta name="dc.subject" content="Learning and memory"/>
    <meta name="dc.subject" content="Psychology"/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Psychol.; citation_title=A taxonomy of external and internal attention; citation_author=MM Chun, JD Golomb, NB Turk-Browne; citation_volume=62; citation_publication_date=2011; citation_pages=73-101; citation_doi=10.1146/annurev.psych.093008.100427; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Q. J. Exp. Psychol.; citation_title=The breakdown of vigilance during prolonged visual search; citation_author=NH Mackworth; citation_volume=1; citation_publication_date=1948; citation_pages=6-21; citation_doi=10.1080/17470214808416738; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=N. Engl. J. Med.; citation_title=Association between cellular-telephone calls and motor vehicle collisions; citation_author=DA Redelmeier, RJ Tibshirani; citation_volume=336; citation_publication_date=1997; citation_pages=453-458; citation_doi=10.1056/NEJM199702133360701; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=N. Engl. J. Med.; citation_title=Modafinil for excessive sleepiness associated with shift-work sleep disorder; citation_author=CA Czeisler; citation_volume=353; citation_publication_date=2005; citation_pages=476-486; citation_doi=10.1056/NEJMoa041292; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Behav. Res. Methods Instrum. Comput.; citation_title=Microcomputer analyses of performance on a portable, simple visual RT task during sustained operations; citation_author=DF Dinges, JW Powell; citation_volume=17; citation_publication_date=1985; citation_pages=652-655; citation_doi=10.3758/BF03200977; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Brain Res. Brain Res. Rev.; citation_title=The cognitive neuroscience of sustained attention: where top-down meets bottom-up; citation_author=M Sarter, B Givens, JP Bruno; citation_volume=35; citation_publication_date=2001; citation_pages=146-160; citation_doi=10.1016/S0165-0173(01)00044-3; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Rare items often missed in visual searches; citation_author=JM Wolfe, TS Horowitz, NM Kenner; citation_volume=435; citation_publication_date=2005; citation_pages=439-440; citation_doi=10.1038/435439a; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Dissociation in performance of children with ADHD and high-functioning autism on a task of sustained attention; citation_author=KA Johnson; citation_volume=45; citation_publication_date=2007; citation_pages=2234-2245; citation_doi=10.1016/j.neuropsychologia.2007.02.019; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=&#39;Oops!&#39;: performance correlates of everyday attentional failures in traumatic brain injured and normal subjects; citation_author=IH Robertson, T Manly, J Andrade, BT Baddeley, J Yiend; citation_volume=35; citation_publication_date=1997; citation_pages=747-758; citation_doi=10.1016/S0028-3932(97)00015-8; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Neural measures of individual differences in selecting and tracking multiple moving objects; citation_author=T Drew, EK Vogel; citation_volume=28; citation_publication_date=2008; citation_pages=4183-4191; citation_doi=10.1523/JNEUROSCI.0556-08.2008; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Biomed. Eng.; citation_title=Principles of a brain-computer interface (BCI) based on real-time functional magnetic resonance imaging (fMRI); citation_author=N Weiskopf; citation_volume=51; citation_publication_date=2004; citation_pages=966-970; citation_doi=10.1109/TBME.2004.827063; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Decoding fMRI brain states in real-time; citation_author=SM LaConte; citation_volume=56; citation_publication_date=2011; citation_pages=440-454; citation_doi=10.1016/j.neuroimage.2010.06.052; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Real-time fMRI neurofeedback: progress and challenges; citation_author=J Sulzer; citation_volume=76; citation_publication_date=2013; citation_pages=386-399; citation_doi=10.1016/j.neuroimage.2013.03.033; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Beyond mind-reading: multi-voxel pattern analysis of fMRI data; citation_author=KA Norman, SM Polyn, GJ Detre, JV Haxby; citation_volume=10; citation_publication_date=2006; citation_pages=424-430; citation_doi=10.1016/j.tics.2006.07.005; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Control over brain activation and pain learned by using real-time functional MRI; citation_author=RC deCharms; citation_volume=102; citation_publication_date=2005; citation_pages=18626-18631; citation_doi=10.1073/pnas.0505210102; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Perceptual learning incepted by decoded fMRI neurofeedback without stimulus presentation; citation_author=K Shibata, T Watanabe, Y Sasaki, M Kawato; citation_volume=334; citation_publication_date=2011; citation_pages=1413-1415; citation_doi=10.1126/science.1212003; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=When the brain is prepared to learn: enhancing human learning using real-time fMRI; citation_author=JJ Yoo; citation_volume=59; citation_publication_date=2012; citation_pages=846-852; citation_doi=10.1016/j.neuroimage.2011.07.063; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Roles of default-mode network and supplementary motor area in human vigilance performance: evidence from real-time fMRI; citation_author=O Hinds; citation_volume=109; citation_publication_date=2013; citation_pages=1250-1258; citation_doi=10.1152/jn.00533.2011; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Neurology; citation_title=Pupil size and spontaneous pupillary waves associated with alertness, drowsiness, and sleep; citation_author=RE Yoss, NJ Moyer, RW Hollenhorst; citation_volume=20; citation_publication_date=1970; citation_pages=545-554; citation_doi=10.1212/WNL.20.6.545; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Atten. Percept. Psychophys.; citation_title=Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task; citation_author=M Rosenberg, S Noonan, J DeGutis, M Esterman; citation_volume=75; citation_publication_date=2013; citation_pages=426-439; citation_doi=10.3758/s13414-012-0413-x; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=fMRI evidence for objects as the units of attentional selection; citation_author=KM O&#39;Craven, PE Downing, N Kanwisher; citation_volume=401; citation_publication_date=1999; citation_pages=584-587; citation_doi=10.1038/44134; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Top-down attention switches coupling between low-level and high-level areas of human visual cortex; citation_author=N Al-Aidroos, CP Said, NB Turk-Browne; citation_volume=109; citation_publication_date=2012; citation_pages=14675-14680; citation_doi=10.1073/pnas.1202095109; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=The neural bases of momentary lapses in attention; citation_author=DH Weissman, KC Roberts, KM Visscher, MG Woldorff; citation_volume=9; citation_publication_date=2006; citation_pages=971-978; citation_doi=10.1038/nn1727; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Neural predictors of moment-to-moment fluctuations in cognitive flexibility; citation_author=AB Leber, NB Turk-Browne, MM Chun; citation_volume=105; citation_publication_date=2008; citation_pages=13592-13597; citation_doi=10.1073/pnas.0805423105; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Neurosci.; citation_title=An integrative theory of prefrontal cortex function; citation_author=EK Miller, JD Cohen; citation_volume=24; citation_publication_date=2001; citation_pages=167-202; citation_doi=10.1146/annurev.neuro.24.1.167; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Neurobiol.; citation_title=Top-down control of visual attention; citation_author=B Noudoost, MH Chang, NA Steinmetz, T Moore; citation_volume=20; citation_publication_date=2010; citation_pages=183-190; citation_doi=10.1016/j.conb.2010.02.003; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Confounds in multivariate pattern analysis: theory and rule representation case study; citation_author=MT Todd, LE Nystrom, JD Cohen; citation_volume=77; citation_publication_date=2013; citation_pages=157-165; citation_doi=10.1016/j.neuroimage.2013.03.039; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Distributed and overlapping representations of faces and objects in ventral temporal cortex; citation_author=JV Haxby; citation_volume=293; citation_publication_date=2001; citation_pages=2425-2430; citation_doi=10.1126/science.1063736; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Adaptive coding of task-relevant information in human frontoparietal cortex; citation_author=A Woolgar, A Hampshire, R Thompson, J Duncan; citation_volume=31; citation_publication_date=2011; citation_pages=14592-14599; citation_doi=10.1523/JNEUROSCI.2616-11.2011; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Functional interactions as big data in the human brain; citation_author=NB Turk-Browne; citation_volume=342; citation_publication_date=2013; citation_pages=580-584; citation_doi=10.1126/science.1238409; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Attention and biased competition in multi-voxel object representations; citation_author=L Reddy, NG Kanwisher, R VanRullen; citation_volume=106; citation_publication_date=2009; citation_pages=21447-21452; citation_doi=10.1073/pnas.0907330106; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Neural mechanisms of object-based attention; citation_author=D Baldauf, R Desimone; citation_volume=344; citation_publication_date=2014; citation_pages=424-427; citation_doi=10.1126/science.1247003; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Neural Comput.; citation_title=Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia; citation_author=RC O&#39;Reilly, M Frank; citation_volume=18; citation_publication_date=2006; citation_pages=283-328; citation_doi=10.1162/089976606775093909; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Regulation of parkinsonian motor behaviours by optogenetic control of basal ganglia circuitry; citation_author=AV Kravitz; citation_volume=466; citation_publication_date=2010; citation_pages=622-626; citation_doi=10.1038/nature09159; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Rev.; citation_title=A computational model of inhibitory control in frontal cortex and basal ganglia; citation_author=TV Wiecki, MJ Frank; citation_volume=120; citation_publication_date=2013; citation_pages=329-355; citation_doi=10.1037/a0031542; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=Neurobiol. Learn. Mem.; citation_title=The role of the basal ganglia in learning and memory: insight from Parkinson&#39;s disease; citation_author=K Foerde, D Shohamy; citation_volume=96; citation_publication_date=2011; citation_pages=624-636; citation_doi=10.1016/j.nlm.2011.08.006; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis; citation_author=MJ Frank, D Badre; citation_volume=22; citation_publication_date=2012; citation_pages=509-526; citation_doi=10.1093/cercor/bhr114; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Q. J. Exp. Psychol. (Hove); citation_title=Different predictors of multiple-target search accuracy between nonprofessional and professional visual searchers; citation_author=AT Biggs, SR Mitroff; citation_volume=67; citation_publication_date=2014; citation_pages=1335-1348; citation_doi=10.1080/17470218.2013.859715; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Neural mechanisms of the cognitive model of depression; citation_author=SG Disner, CG Beevers, EAP Haigh, AT Beck; citation_volume=12; citation_publication_date=2011; citation_pages=467-477; citation_doi=10.1038/nrn3027; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Dev. Neuropsychol.; citation_title=Executive function profile of children with attention deficit hyperactivity disorder; citation_author=T Shallice; citation_volume=21; citation_publication_date=2002; citation_pages=43-71; citation_doi=10.1207/S15326942DN2101_3; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Differential coupling of visual cortex with default network or frontal-parietal network based on goals; citation_author=JZ Chadick, A Gazzaley; citation_volume=14; citation_publication_date=2011; citation_pages=830-832; citation_doi=10.1038/nn.2823; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=The effect of attention on repetition suppression and multivoxel pattern similarity; citation_author=KS Moore, D-J Yi, M Chun; citation_volume=25; citation_publication_date=2013; citation_pages=1305-1314; citation_doi=10.1162/jocn_a_00387; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Control of object-based attention in human cortex; citation_author=JT Serences, J Schwarzbach, SM Courtney, X Golay, S Yantis; citation_volume=14; citation_publication_date=2004; citation_pages=1346-1357; citation_doi=10.1093/cercor/bhh095; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Stat. Sci.; citation_title=Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy; citation_author=B Efron, R Tibshirani; citation_volume=1; citation_publication_date=1986; citation_pages=54-75; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=Front. Psychol.; citation_title=Robust correlation analyses: false positive and power validation using a new open source Matlab toolbox; citation_author=CR Pernet, RR Wilcox, GA Rousselet; citation_volume=3; citation_publication_date=2013; citation_pages=606; citation_doi=10.3389/fpsyg.2012.00606; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=Hum. Brain Mapp.; citation_title=Nonparametric permutation tests for functional neuroimaging: a primer with examples; citation_author=TE Nichols, AP Holmes; citation_volume=15; citation_publication_date=2002; citation_pages=1-25; citation_doi=10.1002/hbm.1058; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference; citation_author=SM Smith, TE Nichols; citation_volume=44; citation_publication_date=2009; citation_pages=83-98; citation_doi=10.1016/j.neuroimage.2008.03.061; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Gen.; citation_title=Measuring recognition memory; citation_author=W Donaldson; citation_volume=121; citation_publication_date=1992; citation_pages=275-277; citation_doi=10.1037/0096-3445.121.3.275; citation_id=CR48"/>
    <meta name="citation_author" content="deBettencourt, Megan T"/>
    <meta name="citation_author_institution" content="Princeton Neuroscience Institute, Princeton University, Princeton, USA"/>
    <meta name="citation_author" content="Cohen, Jonathan D"/>
    <meta name="citation_author_institution" content="Princeton Neuroscience Institute, Princeton University, Princeton, USA"/>
    <meta name="citation_author_institution" content="Department of Psychology, Princeton University, Princeton, USA"/>
    <meta name="citation_author" content="Lee, Ray F"/>
    <meta name="citation_author_institution" content="Princeton Neuroscience Institute, Princeton University, Princeton, USA"/>
    <meta name="citation_author" content="Norman, Kenneth A"/>
    <meta name="citation_author_institution" content="Princeton Neuroscience Institute, Princeton University, Princeton, USA"/>
    <meta name="citation_author_institution" content="Department of Psychology, Princeton University, Princeton, USA"/>
    <meta name="citation_author" content="Turk-Browne, Nicholas B"/>
    <meta name="citation_author_institution" content="Princeton Neuroscience Institute, Princeton University, Princeton, USA"/>
    <meta name="citation_author_institution" content="Department of Psychology, Princeton University, Princeton, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Closed-loop training of attention with real-time brain imaging"/>
    <meta name="twitter:description" content="Nature Neuroscience - Lapses of attention are commonplace, potentially because they are detected too late to be prevented. The authors use real-time fMRI to provide participants continuous access..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig1_HTML.jpg"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/nn.3940"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Closed-loop training of attention with real-time brain imaging - Nature Neuroscience"/>
    <meta property="og:description" content="Lapses of attention are commonplace, potentially because they are detected too late to be prevented. The authors use real-time fMRI to provide participants continuous access to their attentional state. Real-time feedback, particularly from frontoparietal cortex, improved sustained attention abilities and modified representations in visual cortex and basal ganglia."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig1_HTML.jpg"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=nn.3940;doi=10.1038/nn.3940;techmeta=36,57,59;subjmeta=1310,1595,2150,2649,378,477,631;kwrd=Attention,Cognitive+control,Learning+and+memory,Psychology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=-1937202111&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.3940%26doi%3D10.1038/nn.3940%26techmeta%3D36,57,59%26subjmeta%3D1310,1595,2150,2649,378,477,631%26kwrd%3DAttention,Cognitive+control,Learning+and+memory,Psychology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=-1937202111&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.3940%26doi%3D10.1038/nn.3940%26techmeta%3D36,57,59%26subjmeta%3D1310,1595,2150,2649,378,477,631%26kwrd%3DAttention,Cognitive+control,Learning+and+memory,Psychology"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/nn.3940'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Closed-loop training of attention with real-time brain imaging
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3940.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2015-02-09">09 February 2015</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Closed-loop training of attention with real-time brain imaging</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Megan_T-deBettencourt-Aff1" data-author-popup="auth-Megan_T-deBettencourt-Aff1" data-author-search="deBettencourt, Megan T">Megan T deBettencourt</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jonathan_D-Cohen-Aff1-Aff2" data-author-popup="auth-Jonathan_D-Cohen-Aff1-Aff2" data-author-search="Cohen, Jonathan D">Jonathan D Cohen</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ray_F-Lee-Aff1" data-author-popup="auth-Ray_F-Lee-Aff1" data-author-search="Lee, Ray F">Ray F Lee</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kenneth_A-Norman-Aff1-Aff2" data-author-popup="auth-Kenneth_A-Norman-Aff1-Aff2" data-author-search="Norman, Kenneth A">Kenneth A Norman</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 5 authors for this article" title="Show all 5 authors for this article"></li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Nicholas_B-Turk_Browne-Aff1-Aff2" data-author-popup="auth-Nicholas_B-Turk_Browne-Aff1-Aff2" data-author-search="Turk-Browne, Nicholas B" data-corresp-id="c1">Nicholas B Turk-Browne<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup></li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>18</b>,<span class="u-visually-hidden">pages </span>470475 (<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">17k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">194 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">282 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/nn.3940/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/attention" data-track="click" data-track-action="view subject" data-track-label="link">Attention</a></li><li class="c-article-subject-list__subject"><a href="/subjects/cognitive-control" data-track="click" data-track-action="view subject" data-track-label="link">Cognitive control</a></li><li class="c-article-subject-list__subject"><a href="/subjects/learning-and-memory" data-track="click" data-track-action="view subject" data-track-label="link">Learning and memory</a></li><li class="c-article-subject-list__subject"><a href="/subjects/psychology" data-track="click" data-track-action="view subject" data-track-label="link">Psychology</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs2" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs2">Abstract</h2><div class="c-article-section__content" id="Abs2-content"><p>Lapses of attention can have negative consequences, including accidents and lost productivity. Here we used closed-loop neurofeedback to improve sustained attention abilities and reduce the frequency of lapses. During a sustained attention task, the focus of attention was monitored in real time with multivariate pattern analysis of whole-brain neuroimaging data. When indicators of an attentional lapse were detected in the brain, we gave human participants feedback by making the task more difficult. Behavioral performance improved after one training session, relative to control participants who received feedback from other participants' brains. This improvement was largest when feedback carried information from a frontoparietal attention network. A neural consequence of training was that the basal ganglia and ventral temporal cortex came to represent attentional states more distinctively. These findings suggest that attentional failures do not reflect an upper limit on cognitive potential and that attention can be trained with appropriate feedback about neural signals.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3940.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3940.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41583-024-00796-z/MediaObjects/41583_2024_796_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41583-024-00796-z?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41583-024-00796-z">Preparatory activity and the expansive null-space
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">05 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Mark M. Churchland &amp; Krishna V. Shenoy</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41562-024-01838-3/MediaObjects/41562_2024_1838_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41562-024-01838-3?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41562-024-01838-3">The direction of theta and alpha travelling waves modulates human memory processing
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">08 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Uma R. Mohan, Honghui Zhang,  Joshua Jacobs</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41562-023-01811-6/MediaObjects/41562_2023_1811_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41562-023-01811-6?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41562-023-01811-6">Biomimetic versus arbitrary motor control strategies for bionic hand skill learning
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">18 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Hunter R. Schone, Malcolm Udeozor,  Chris I. Baker</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'topic',
                        model: 'visits_v2',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711582677,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>Our ability to sustain attention over long periods of time is limited, both in the laboratory<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Chun, M.M., Golomb, J.D. &amp; Turk-Browne, N.B. A taxonomy of external and internal attention. Annu. Rev. Psychol. 62, 73101 (2011)." href="/articles/nn.3940#ref-CR1" id="ref-link-section-d30636411e419">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Mackworth, N.H. The breakdown of vigilance during prolonged visual search. Q. J. Exp. Psychol. 1, 621 (1948)." href="/articles/nn.3940#ref-CR2" id="ref-link-section-d30636411e422">2</a></sup> and in the real world<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Redelmeier, D.A. &amp; Tibshirani, R.J. Association between cellular-telephone calls and motor vehicle collisions. N. Engl. J. Med. 336, 453458 (1997)." href="/articles/nn.3940#ref-CR3" id="ref-link-section-d30636411e426">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Czeisler, C.A. et al. Modafinil for excessive sleepiness associated with shift-work sleep disorder. N. Engl. J. Med. 353, 476486 (2005)." href="/articles/nn.3940#ref-CR4" id="ref-link-section-d30636411e429">4</a></sup>. This has been demonstrated using vigilance tasks in which participants monitor for and detect infrequent stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Dinges, D.F. &amp; Powell, J.W. Microcomputer analyses of performance on a portable, simple visual RT task during sustained operations. Behav. Res. Methods Instrum. Comput. 17, 652655 (1985)." href="/articles/nn.3940#ref-CR5" id="ref-link-section-d30636411e433">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Sarter, M., Givens, B. &amp; Bruno, J.P. The cognitive neuroscience of sustained attention: where top-down meets bottom-up. Brain Res. Brain Res. Rev. 35, 146160 (2001)." href="/articles/nn.3940#ref-CR6" id="ref-link-section-d30636411e436">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Wolfe, J.M., Horowitz, T.S. &amp; Kenner, N.M. Rare items often missed in visual searches. Nature 435, 439440 (2005)." href="/articles/nn.3940#ref-CR7" id="ref-link-section-d30636411e439">7</a></sup>. Behavior in these tasks is predictive of attention disorders<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Johnson, K.A. et al. Dissociation in performance of children with ADHD and high-functioning autism on a task of sustained attention. Neuropsychologia 45, 22342245 (2007)." href="/articles/nn.3940#ref-CR8" id="ref-link-section-d30636411e443">8</a></sup> and is reliable over time<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Robertson, I.H., Manly, T., Andrade, J., Baddeley, B.T. &amp; Yiend, J. 'Oops!': performance correlates of everyday attentional failures in traumatic brain injured and normal subjects. Neuropsychologia 35, 747758 (1997)." href="/articles/nn.3940#ref-CR9" id="ref-link-section-d30636411e447">9</a></sup>. Within the normal population, there is considerable variability in attentional abilities as measured by these tasks, and this variability is related to other perceptual and mnemonic processes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Drew, T. &amp; Vogel, E.K. Neural measures of individual differences in selecting and tracking multiple moving objects. J. Neurosci. 28, 41834191 (2008)." href="/articles/nn.3940#ref-CR10" id="ref-link-section-d30636411e452">10</a></sup>. We hypothesized that lapses in these tasksand in lifeoccur because humans do not adequately monitor how well they are attending from moment to moment. Lapses emerge gradually and may be detected too late, after the chain of events that produces behavioral errors has been initiated. Accordingly, one way to train sustained attention might be to provide a more sensitive feedback signal, such that participants can learn to sense upcoming lapses earlier and prevent them from manifesting in behavior.</p><p>To pursue this approach, we created a continuous feedback signal customized to each participant, reflecting moment-to-moment variations in their sustained attention. Participants were presented with a series of composite stimuli containing a mixture of information relevant and irrelevant to the task. Online analysis was used to track their attentional state, operationalized as the amount of task-relevant information active in their brains minus the amount of task-irrelevant information. Finally, this measure was provided to participants as feedback by altering the appearance of the next stimulus. When participants were attending well (that is, more task-relevant information was detected in their brains), we increased the proportion of task-relevant information in the stimulus. Conversely, when they were attending poorly (that is, more task-irrelevant information was detected), we reduced the proportion of task-relevant information in the stimulus. In this way, we amplified the consequences of their attentional state, rewarding them with a stronger stimulus and an easier task for staying focused and punishing them with a degraded stimulus and a more difficult task for lapsing. We hypothesized that this would make attentional lapses more salient and that participants would be able to exploit this feedback to learn to improve their sustained attention.</p><p>For online analysis, we combined real-time functional magnetic resonance imaging (rtfMRI)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Weiskopf, N. et al. Principles of a brain-computer interface (BCI) based on real-time functional magnetic resonance imaging (fMRI). IEEE Trans. Biomed. Eng. 51, 966970 (2004)." href="/articles/nn.3940#ref-CR11" id="ref-link-section-d30636411e462">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="LaConte, S.M. Decoding fMRI brain states in real-time. Neuroimage 56, 440454 (2011)." href="/articles/nn.3940#ref-CR12" id="ref-link-section-d30636411e465">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Sulzer, J. et al. Real-time fMRI neurofeedback: progress and challenges. Neuroimage 76, 386399 (2013)." href="/articles/nn.3940#ref-CR13" id="ref-link-section-d30636411e468">13</a></sup> with multivariate pattern analysis (MVPA)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Norman, K.A., Polyn, S.M., Detre, G.J. &amp; Haxby, J.V. Beyond mind-reading: multi-voxel pattern analysis of fMRI data. Trends Cogn. Sci. 10, 424430 (2006)." href="/articles/nn.3940#ref-CR14" id="ref-link-section-d30636411e472">14</a></sup>. The rtfMRI component of the system involved immediately acquiring measurements of the blood oxygen leveldependent (BOLD) response over the whole brain. This technique has been used previously to display univariate activity for pain regulation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="deCharms, R.C. et al. Control over brain activation and pain learned by using real-time functional MRI. Proc. Natl. Acad. Sci. USA 102, 1862618631 (2005)." href="/articles/nn.3940#ref-CR15" id="ref-link-section-d30636411e476">15</a></sup>, to display multivariate activity for inducing perceptual learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Shibata, K., Watanabe, T., Sasaki, Y. &amp; Kawato, M. Perceptual learning incepted by decoded fMRI neurofeedback without stimulus presentation. Science 334, 14131415 (2011)." href="/articles/nn.3940#ref-CR16" id="ref-link-section-d30636411e480">16</a></sup> and to trigger stimulus presentation based on univariate activity in brain regions associated with memory encoding<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Yoo, J.J. et al. When the brain is prepared to learn: enhancing human learning using real-time fMRI. Neuroimage 59, 846852 (2012)." href="/articles/nn.3940#ref-CR17" id="ref-link-section-d30636411e484">17</a></sup> and vigilance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Hinds, O. et al. Roles of default-mode network and supplementary motor area in human vigilance performance: evidence from real-time fMRI. J. Neurophysiol. 109, 12501258 (2013)." href="/articles/nn.3940#ref-CR18" id="ref-link-section-d30636411e489">18</a></sup>. Our approach was related to these latter triggering designs, in the sense that brain states were used to control stimuli rather than controlling a separate feedback scale or gauge, but differed in that the stimulus triggered by a brain state at one moment in time influenced the brain state at the next moment, which in turn influenced the next stimulus, and so on. In other words, after a stimulus was triggered, the trial did not end and there was no delay imposed before the next stimulus could be triggered<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Yoo, J.J. et al. When the brain is prepared to learn: enhancing human learning using real-time fMRI. Neuroimage 59, 846852 (2012)." href="/articles/nn.3940#ref-CR17" id="ref-link-section-d30636411e493">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Hinds, O. et al. Roles of default-mode network and supplementary motor area in human vigilance performance: evidence from real-time fMRI. J. Neurophysiol. 109, 12501258 (2013)." href="/articles/nn.3940#ref-CR18" id="ref-link-section-d30636411e496">18</a></sup>. This approach of continually updating task stimuli as they perturb brain states has been referred to as closed-loop<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="LaConte, S.M. Decoding fMRI brain states in real-time. Neuroimage 56, 440454 (2011)." href="/articles/nn.3940#ref-CR12" id="ref-link-section-d30636411e500">12</a></sup>. The MVPA component of the system decoded differences in whole-brain BOLD activity patterns reflecting attention to the task-relevant versus task-irrelevant stimuli. The combination of MVPA and rtfMRI is well suited for rapidly decoding distributed cognitive processes such as attention.</p><p>There are other, simpler ways of delivering real-time feedback: for example, based on electroencephalography (EEG), eye tracking or manual responses. We used rtfMRI for two reasons. First, in combination with advanced analytical techniques, fMRI may provide more direct access to internal brain states. For instance, we sought to identify which specific kind of information a participant was attending to over time rather than whether they were attentive in general (often called alertness, arousal or mindfulness), as is reflected in pupil size<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Yoss, R.E., Moyer, N.J. &amp; Hollenhorst, R.W. Pupil size and spontaneous pupillary waves associated with alertness, drowsiness, and sleep. Neurology 20, 545554 (1970)." href="/articles/nn.3940#ref-CR19" id="ref-link-section-d30636411e507">19</a></sup> and response time variability<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Rosenberg, M., Noonan, S., DeGutis, J. &amp; Esterman, M. Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task. Atten. Percept. Psychophys. 75, 426439 (2013)." href="/articles/nn.3940#ref-CR20" id="ref-link-section-d30636411e511">20</a></sup>. Second, by using fMRI, we not only gain a sensitive neural measure for feedback but also the ability to characterize the neural mechanisms that support attention training. We take advantage of this opportunity by considering both how training alters the brain and which brain regions provide useful feedback signals for training. We do not claim that this is the only or best approach for training attention, but simply that it may prove valuable because of its sensitivity, its ability to generate neuroscientific data that can help constrain our interpretation, and its potential to lay the foundation for further advances in the use of other methods.</p><p>This study involved three sessions on different days: behavioral pre-training, rtfMRI training and behavioral post-training (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig6">Supplementary Fig. 1</a>). Participants performed the same sustained attention task in all sessions, viewing blocks of face/scene composite stimuli. Before each block, they were cued to attend to one task-relevant category (for example, scenes) and were instructed to ignore the other, task-irrelevant category (in this case, faces). Within the task-relevant category, they responded ('go' trial) if the image was from a specified target subcategory that appeared with high frequency throughout the study (for example, indoor scenes; 90% of trials). They withheld their response ('no-go' trial) for the other, infrequent lure subcategory (in this case, outdoor scenes; 10%)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Robertson, I.H., Manly, T., Andrade, J., Baddeley, B.T. &amp; Yiend, J. 'Oops!': performance correlates of everyday attentional failures in traumatic brain injured and normal subjects. Neuropsychologia 35, 747758 (1997)." href="/articles/nn.3940#ref-CR9" id="ref-link-section-d30636411e522">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Rosenberg, M., Noonan, S., DeGutis, J. &amp; Esterman, M. Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task. Atten. Percept. Psychophys. 75, 426439 (2013)." href="/articles/nn.3940#ref-CR20" id="ref-link-section-d30636411e525">20</a></sup>. Sustained attention was assessed behaviorally using signal detection measures. The average false alarm rate from the behavioral pre-training session was 0.31 (s.e.m. = 0.03). In other words, college-aged adults made 30% errors in an ostensibly trivial task, which demonstrates that sustained attention abilities were limited at the start of the study, as expected.</p><p>During the rtfMRI training session, each of several training runs contained eight blocks of the sustained attention task in a counterbalanced design. The first four, 'stable' blocks were used for MVPA training and the last four, 'feedback' blocks were used for neurofeedback. During the stable blocks, composite stimuli were presented with a mixture of 50% face and 50% scene. A whole-brain classifier was trained over a moving window of recent stable blocks to discriminate attention to faces versus scenes. This attentional manipulation is known to elicit distinct patterns of neural activity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="O'Craven, K.M., Downing, P.E. &amp; Kanwisher, N. fMRI evidence for objects as the units of attentional selection. Nature 401, 584587 (1999)." href="/articles/nn.3940#ref-CR21" id="ref-link-section-d30636411e532">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Al-Aidroos, N., Said, C.P. &amp; Turk-Browne, N.B. Top-down attention switches coupling between low-level and high-level areas of human visual cortex. Proc. Natl. Acad. Sci. USA 109, 1467514680 (2012)." href="/articles/nn.3940#ref-CR22" id="ref-link-section-d30636411e535">22</a></sup>. During feedback blocks, the trained classifier was used to decode in real time which category was being attended. The output was then used to update the mixture of the composite stimulus for the next trial (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig1">Fig. 1</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Real-time pipeline."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1: Real-time pipeline.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3940/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig1_HTML.jpg?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig1_HTML.jpg" alt="figure 1" loading="lazy" width="685" height="248"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>(<b>a</b>) During feedback blocks, each brain volume (green) was acquired, preprocessed with masking, smoothing and <i>z</i>-scoring, and analyzed during the next volume with a multivariate classifier trained on volumes from recent stable blocks in which faces (blue) or scenes (pink) were attended. The result was averaged with the results for the two preceding volumes and used to update the stimulus shown to the participant on trials in the subsequent volume. (<b>b</b>) The classifier output indicated how attentive the participant was to the task-relevant versus task-irrelevant categories. This output was converted to a mixture proportion using a sigmoidal transfer function: less attention to the task-relevant category resulted in a decrease in the proportion of that category's image in the composite stimulus on the next trial. These values were updated throughout the block as attention fluctuated over time.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3940/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Real-time neurofeedback</h3><p>The classifier's output would be useful for training attention only if it provided an accurate measurement of attentional state (that is, attention to face versus scene). To assess the validity of this measure, we performed <i>n</i>-fold cross-validation on the stable blocks. Note that bottom-up stimulation in these blocks was identical at the category level regardless of whether participants were instructed to attend to faces or to scenes. The average decoding accuracy was 0.78 (s.e.m. = 0.02), which was highly reliable relative to chance (0.50) across participants (<i>P</i> &lt; 0.00001, bootstrap resampling). This robust decoding validated our measure of top-down attentional state.</p><p>As a further preliminary step, we sought to verify that the classifier's output was meaningfully related to participants' behavior (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig2">Fig. 2</a>). Across participants, there was a strong positive correlation between decoding accuracy in the stable blocks and performance in the earlier behavioral pre-training session (<i>r</i> = 0.70, <i>P</i> = 0.000008, Spearman rank correlation). This relationship was also evident within participants<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Weissman, D.H., Roberts, K.C., Visscher, K.M. &amp; Woldorff, M.G. The neural bases of momentary lapses in attention. Nat. Neurosci. 9, 971978 (2006)." href="/articles/nn.3940#ref-CR23" id="ref-link-section-d30636411e601">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Leber, A.B., Turk-Browne, N.B. &amp; Chun, M.M. Neural predictors of moment-to-moment fluctuations in cognitive flexibility. Proc. Natl. Acad. Sci. USA 105, 1359213597 (2008)." href="/articles/nn.3940#ref-CR24" id="ref-link-section-d30636411e604">24</a></sup>: behavioral accuracy on no-go trialsthat is, whether participants correctly withheld their response or responded incorrectlycould be predicted using the classifier evidence for the task-relevant category from the brain volumes immediately preceding trial onset (correct rejection: mean evidence = 0.78, s.e.m. = 0.02; false alarm: mean evidence = 0.74, s.e.m. = 0.02; <i>P</i> &lt; 0.00001). This effect remained robust after controlling for response time (RT) differences (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig7">Supplementary Figs. 2</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig8">3</a>). This further confirmed that the classifier provided a predictive and behaviorally relevant measure of attention.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Brain-behavior relationship."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2: Brain-behavior relationship.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3940/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="685" height="343"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>To verify that the classifier could provide useful feedback, we examined how predictive it was of behavior. (<b>a</b>) Across participants, average decoding accuracy from the stable blocks of the rtfMRI session (determined by offline MVPA with <i>n</i>-fold cross-validation) was highly correlated with behavioral performance in the pre-training session. (<b>b</b>) Within participants, there was greater classifier output for the task-relevant category than for the task-irrelevant category before correctly rejecting than before false alarming to a lure trial. Error bars represent 1 s.e.m.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3940/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>The feedback blocks used real-time classifier output to modulate the proportion of task-relevant versus task-irrelevant information in the composite stimuli. As outlined above, the proportion of the task-relevant stimulus on the next trial was increased when there was greater neural evidence of the task-relevant category in the preceding trial, whereas it was decreased when there was greater neural evidence of the task-irrelevant category (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3940#MOESM47">Supplementary Video 1</a>). The motivation for weakening the task-relevant image when measures of attention waned was to amplify and externalize the consequences of the participant's attentional state, providing them with an error signal, with the goal of increasing their self-monitoring ability. The oppositestrengthening the task-relevant image when attention lapsedmight have stabilized performance at that moment, but it may also have incentivized such lapses by making the task easier, thus undermining learning. The precise mapping between classifier output and mixture proportion was controlled by a sigmoidal transfer function (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig9">Supplementary Fig. 4</a>).</p><h3 class="c-article__sub-heading" id="Sec4">Training effects in behavior</h3><p>The rtfMRI neurofeedback produced a significant training effect: behavioral sensitivity improved from the pre-training session to the post-training session (<i>P</i> = 0.01; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig3">Fig. 3</a>). This improvement was quantitatively related to what happened during the training session, as it could be predicted by the extent to which a participant's neurofeedback became more positive over time (<i>r</i> = 0.78, <i>P</i> = 0.002). To further verify that improved sensitivity was the result of accurate neurofeedback, we collected data from 16 control participants who were each uniquely matched in age, gender and handedness to one of the 16 feedback participants. During the pre-training session, there was no difference between the groups in false alarm rate (<i>P</i> = 0.72) or sensitivity (<i>P</i> = 0.90). Control participants were given identical instructions and underwent the same procedure, except that, during the feedback blocks, their feedback was yoked to their matched participant in the experimental group, rather than to measures of their own attentional state. This yoking ensured that control participants were exposed to the same overall stimulus statistics and variations in task difficulty. Their sensitivity did not reliably increase from pre- to post-training (<i>P</i> = 0.26), and the change was weaker than in the feedback group (<i>P</i> = 0.04). This interaction reflected a reliable difference in the change in false alarm rate between groups (<i>P</i> = 0.007).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Change in behavior."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3: Change in behavior.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3940/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig3_HTML.jpg?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig3_HTML.jpg" alt="figure 3" loading="lazy" width="675" height="975"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Behavioral performance in the sustained attention task, as indexed by a non-parametric measure of sensitivity (<i>A</i>), is plotted for the pre-training and post-training sessions. Participants who received accurate neurofeedback about their attentional state improved as a result of training, even though the feedback was no longer present in the post-training session. Control participants who received neurofeedback from other participants' brains did not improve. A reliable group difference in improvement shows that accurate feedback boosted performance above and beyond practice effects and stimulus exposure. Error bars represent 1 within-subject s.e.m.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3940/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Rather than a benefit of accurate neurofeedback, the difference between groups could reflect a generic practice effect in the feedback group that was stymied by inaccurate neurofeedback in the control group. If so, then an improvement in sensitivity should be found even without feedback. We therefore ran a behavioral experiment with a new group of 16 participants who completed the same procedure but received only stable blocks. Unlike the feedback group, their sensitivity did not increase from pre- to post-training (<i>P</i> = 0.67), inconsistent with this alternative account. In addition, accurate neurofeedback may have been effective simply because it resonated with a participant's attentional state and increased task engagement and motivation. If so, then feedback about any reliable measure of attention should be useful for training. We therefore ran a second behavioral experiment that was closely matched to the fMRI study, in which a new group of 16 participants received feedback based on RT (which was robustly related to attention; see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.3940#Sec8">Methods</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig7">Supplementary Fig. 2</a>), along with a new group of 16 control participants who received yoked RT feedback. Unlike in the fMRI study, the change in sensitivity from pre- to post-training was not stronger in the feedback group than in the control group (<i>P</i> = 0.29), suggesting that not all correlates of attention are sufficient for training.</p><h3 class="c-article__sub-heading" id="Sec5">Training effects in the brain</h3><p>One advantage of using whole-brain fMRI to provide feedback is that we could also gain insight into the neural changes induced by training. In particular, we hypothesized that learning via neurofeedback might strengthen and differentiate the two attentional states, such that they would become more discriminable in the brain from pre- to post-training. This might occur both in areas that represent attended stimulus features<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="O'Craven, K.M., Downing, P.E. &amp; Kanwisher, N. fMRI evidence for objects as the units of attentional selection. Nature 401, 584587 (1999)." href="/articles/nn.3940#ref-CR21" id="ref-link-section-d30636411e738">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Al-Aidroos, N., Said, C.P. &amp; Turk-Browne, N.B. Top-down attention switches coupling between low-level and high-level areas of human visual cortex. Proc. Natl. Acad. Sci. USA 109, 1467514680 (2012)." href="/articles/nn.3940#ref-CR22" id="ref-link-section-d30636411e741">22</a></sup> and in areas that represent task goals and control attention<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Miller, E.K. &amp; Cohen, J.D. An integrative theory of prefrontal cortex function. Annu. Rev. Neurosci. 24, 167202 (2001)." href="/articles/nn.3940#ref-CR25" id="ref-link-section-d30636411e745">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Noudoost, B., Chang, M.H., Steinmetz, N.A. &amp; Moore, T. Top-down control of visual attention. Curr. Opin. Neurobiol. 20, 183190 (2010)." href="/articles/nn.3940#ref-CR26" id="ref-link-section-d30636411e748">26</a></sup>. Although MVPA over the whole brain can be hard to interpret<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Todd, M.T., Nystrom, L.E. &amp; Cohen, J.D. Confounds in multivariate pattern analysis: theory and rule representation case study. Neuroimage 77, 157165 (2013)." href="/articles/nn.3940#ref-CR27" id="ref-link-section-d30636411e752">27</a></sup>, this differentiation analysis tested for a very specific effect that would be hard to explain parsimoniously on the basis of generic confounds: namely, regions that showed an improvement in classification as a result of training that was greater for the feedback relative to control groups.</p><p>We trained and tested classifiers on the first and last run of the rtfMRI training session (stable blocks) to distinguish attention to faces versus scenes and measured the change in cross-validation accuracy. Whole-brain classification (the basis for neurofeedback) showed a greater increase in accuracy from pre- to post-training in the feedback group than in the control group (<i>P</i> = 0.01). This interaction was present when the same analysis was performed separately in an anatomical mask of the frontal lobe (<i>P</i> = 0.02) and occipital lobe (<i>P</i> = 0.04), and it was trending in the temporal and parietal lobes (<i>P</i> = 0.09 and 0.08, respectively). Searchlight analyses further identified specific areas where activity patterns showed this interaction (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig4">Fig. 4</a>). The largest clusters were found in fusiform and parahippocampal gyri of ventral temporal cortex and in subcortical structures including the basal ganglia (striatum, globus pallidus) and amygdala (all <i>P</i> &lt; 0.05, randomization test with threshold-free cluster correction).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Searchlight analyses."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4: Searchlight analyses.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3940/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig4_HTML.jpg?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig4_HTML.jpg" alt="figure 4" loading="lazy" width="685" height="164"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>(<b>a</b>) Voxel-wise analyses were conducted to identify brain regions whose surrounding activity patterns for the two attentional states became more separable after neurofeedback training. We computed cross-validation accuracy for classifiers trained to decode face and scene attention from RT-residualized BOLD data using a sphere with a 1-voxel radius centered on each voxel. Increased separability was quantified as the difference in accuracy between the end (run <i>n</i>) and start (run 1) of the fMRI session. (<b>b</b>) A greater increase in classifier accuracy for the feedback group relative to the control group (<i>P</i> &lt; 0.05, randomization test with threshold-free cluster correction; Montreal Neurological Institute (MNI) <i>x</i>, <i>y</i>, <i>z</i> coordinates in mm) was observed in left ventral temporal cortex (34, 24, 25) and left basal ganglia (18, 4, 5). Small clusters (not shown) were obtained in left lateral temporal cortex (50, 45, 25; 51, 36, 20; 48, 42, 28) and left anterior temporal lobe (26, 22, 32).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3940/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec6">Contribution of specific brain systems</h3><p>Beyond investigating the consequences of training in the brain, the fMRI data can also be used to infer which brain regions were involved in the training process itself. Specifically, we examined which regions contributed to the whole-brain feedback and how these contributions affected behavioral training. This analysis consisted of three steps. First, we identified neural signals that could have been used to provide more targeted feedback from particular brain regions. Second, for each participant, we correlated these signals with whole-brain classifier output to quantify the extent to which the actual feedback that the participant received reflected information that was present within these regions. Third, we related these correlations to individual differences in the behavioral training effect to assess which regions were most useful for training. In sum, if we had based the feedback on specific brain regions rather than the whole brain, how similar, and how useful, would this feedback have been?</p><p>Perhaps the simplest neural measure of when attention is allocated to faces versus scenes is the relative univariate activity of visual areas with selectivity for these categories, the fusiform face area (FFA) and the parahippocampal place area (PPA)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="O'Craven, K.M., Downing, P.E. &amp; Kanwisher, N. fMRI evidence for objects as the units of attentional selection. Nature 401, 584587 (1999)." href="/articles/nn.3940#ref-CR21" id="ref-link-section-d30636411e831">21</a></sup>, respectively. This is analogous to the approach used in several previous rtfMRI studies, in which the average activity from one or more regions of interest (ROIs) was returned as feedback<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Weiskopf, N. et al. Principles of a brain-computer interface (BCI) based on real-time functional magnetic resonance imaging (fMRI). IEEE Trans. Biomed. Eng. 51, 966970 (2004)." href="/articles/nn.3940#ref-CR11" id="ref-link-section-d30636411e835">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="deCharms, R.C. et al. Control over brain activation and pain learned by using real-time functional MRI. Proc. Natl. Acad. Sci. USA 102, 1862618631 (2005)." href="/articles/nn.3940#ref-CR15" id="ref-link-section-d30636411e838">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Yoo, J.J. et al. When the brain is prepared to learn: enhancing human learning using real-time fMRI. Neuroimage 59, 846852 (2012)." href="/articles/nn.3940#ref-CR17" id="ref-link-section-d30636411e841">17</a></sup>. The difference in univariate activity for task-relevant versus task-irrelevant ROIs (for example, PPA minus FFA for scene attention) was weakly but reliably correlated with the difference in whole-brain multivariate evidence for these categories over time (mean <i>r</i> = 0.25, s.e.m. = 0.02; <i>P</i> &lt; 0.00001). That is, on average, <span class="stix"></span>6% of variance in the whole-brain signal used for real-time feedback was explained by the relative activity levels of FFA and PPA. Individual differences in the size of the behavioral training effect were unrelated to this reliance on information in FFA versus PPA for feedback (<i>r</i> = 0.04, <i>P</i> = 0.89).</p><p>Information about visual categories is also represented outside peak category-selective areas, in patterns of activity distributed over regions of occipitotemporal cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Haxby, J.V. et al. Distributed and overlapping representations of faces and objects in ventral temporal cortex. Science 293, 24252430 (2001)." href="/articles/nn.3940#ref-CR28" id="ref-link-section-d30636411e861">28</a></sup>. Likewise, under attentionally demanding conditions, distributed activity patterns over frontoparietal regions linked to cognitive control contain stimulus-specific information<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Woolgar, A., Hampshire, A., Thompson, R. &amp; Duncan, J. Adaptive coding of task-relevant information in human frontoparietal cortex. J. Neurosci. 31, 1459214599 (2011)." href="/articles/nn.3940#ref-CR29" id="ref-link-section-d30636411e865">29</a></sup>. Therefore, classifiers applied to these 'perceptual' and 'attentional' networks of regions in occipitotemporal and frontoparietal cortices, respectively (constrained functionally, see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.3940#Sec8">Methods</a>), provide additional neural measures of when attention was allocated to faces versus scenes (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig5">Fig. 5</a>). The difference in multivariate evidence for task-relevant versus task-irrelevant categories in the whole brain was reliably correlated with the difference in multivariate evidence for these categories in the perceptual network (mean <i>r</i> = 0.77, s.e.m. = 0.02; <i>P</i> &lt; 0.00001) and attentional network (mean <i>r</i> = 0.83, s.e.m. = 0.01; <i>P</i> &lt; 0.00001), although the correlation with the attentional network was significantly stronger (<i>P</i> = 0.04).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Potential sources of feedback."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5: Potential sources of feedback.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3940/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig5_HTML.jpg?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig5_HTML.jpg" alt="figure 5" loading="lazy" width="685" height="613"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>(<b>a</b>) Real-time whole-brain classifier output from the feedback blocks of a representative run for a single participant: evidence for each category (top) and evidence for the task-relevant minus task-irrelevant categories (bottom). (<b>b</b>) Offline classifier output for the same blocks from a perceptual network in occipitotemporal cortex (left) and an attentional network in frontoparietal cortex (right). The output from the whole-brain classifier was correlated with the outputs of the perceptual network classifier (<i>r</i><sub>wp</sub>) and attentional network classifier (<i>r</i><sub>wa</sub>) over time during the feedback blocks of each run. These correlations were averaged across runs within each participant to produce a measure of the extent to which the participant's real-time feedback relied on information in each network. (<b>c</b>) This measure of reliance on each network was in turn correlated with the change in behavioral <i>A</i> from pre- to post-training to assess whether feedback from each network was useful for training.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3940/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>To assess whether the information contained in each network served as useful feedback for training, we related individual differences in these whole-brain/network correlations to the size of the training effect across participants. Behavioral improvement was unrelated to reliance on the perceptual network (<i>r</i> = 0.29, <i>P</i> = 0.27) but positively related to reliance on the attentional network (<i>r</i> = 0.60, <i>P</i> = 0.02).</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7">Discussion</h2><div class="c-article-section__content" id="Sec7-content"><p>We found that moment-to-moment feedback about attentional state could enhance sustained attention abilities. We used closed-loop neurofeedback from MVPA as a type of cognitive prosthetic, facilitating participants' ability to detect neural signals that indicated an impending attentional lapse by displaying them visually in a form that was directly relevant to the task. In other words, we provided a neural error signal so that participants could learn to better monitor and evaluate the state of their attention.</p><p>MVPA has become widespread because of its ability to read out the informational contents of the brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Norman, K.A., Polyn, S.M., Detre, G.J. &amp; Haxby, J.V. Beyond mind-reading: multi-voxel pattern analysis of fMRI data. Trends Cogn. Sci. 10, 424430 (2006)." href="/articles/nn.3940#ref-CR14" id="ref-link-section-d30636411e959">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Turk-Browne, N.B. Functional interactions as big data in the human brain. Science 342, 580584 (2013)." href="/articles/nn.3940#ref-CR30" id="ref-link-section-d30636411e962">30</a></sup>. However, classifiers exploit any predictive variance that distinguishes between classes, and they are thus susceptible to confounding factors<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Todd, M.T., Nystrom, L.E. &amp; Cohen, J.D. Confounds in multivariate pattern analysis: theory and rule representation case study. Neuroimage 77, 157165 (2013)." href="/articles/nn.3940#ref-CR27" id="ref-link-section-d30636411e966">27</a></sup>. Our design allowed us to assess whether whole-brain classifier output truly reflected attentional statethe cognitive variable of interestusing behavior as the yardstick: when provided as feedback, classifier output was useful for improving attention-dependent performance.</p><p>By using fMRI for cognitive training, we gained important insights about the underlying neural mechanisms. We first identified brain regions that were affected by training, including frontal cortex, ventral temporal cortex and basal ganglia (striatum and globus pallidus), which came to represent the attentional states more distinctively as a result of feedback. We interpret the increased neural separation in these regions as reflective of the two component processes in our sustained attention task. First, participants needed to select the image from the task-relevant category when confronted with a composite stimulus. Increased neural separation of face and scene attention in frontal cortex may reflect learning of better task or control representations for each category, which in turn enabled stronger top-down modulation of category-selective visual representations in ventral temporal cortex, biasing processing toward the task-relevant image and thereby facilitating its selection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Al-Aidroos, N., Said, C.P. &amp; Turk-Browne, N.B. Top-down attention switches coupling between low-level and high-level areas of human visual cortex. Proc. Natl. Acad. Sci. USA 109, 1467514680 (2012)." href="/articles/nn.3940#ref-CR22" id="ref-link-section-d30636411e973">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Miller, E.K. &amp; Cohen, J.D. An integrative theory of prefrontal cortex function. Annu. Rev. Neurosci. 24, 167202 (2001)." href="/articles/nn.3940#ref-CR25" id="ref-link-section-d30636411e976">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Noudoost, B., Chang, M.H., Steinmetz, N.A. &amp; Moore, T. Top-down control of visual attention. Curr. Opin. Neurobiol. 20, 183190 (2010)." href="/articles/nn.3940#ref-CR26" id="ref-link-section-d30636411e979">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Reddy, L., Kanwisher, N.G. &amp; VanRullen, R. Attention and biased competition in multi-voxel object representations. Proc. Natl. Acad. Sci. USA 106, 2144721452 (2009)." href="/articles/nn.3940#ref-CR31" id="ref-link-section-d30636411e982">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Baldauf, D. &amp; Desimone, R. Neural mechanisms of object-based attention. Science 344, 424427 (2014)." href="/articles/nn.3940#ref-CR32" id="ref-link-section-d30636411e985">32</a></sup>. Second, participants needed to inhibit their prepotent response when the selected image came from the infrequent lure subcategory. Increased neural separation of face and scene attention in basal ganglia may reflect enhanced learning of different stimulusresponse rules within each category, with the striatum directly gating responses to targets and indirectly blocking responses to lures via inhibitory projections to the globus pallidus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Miller, E.K. &amp; Cohen, J.D. An integrative theory of prefrontal cortex function. Annu. Rev. Neurosci. 24, 167202 (2001)." href="/articles/nn.3940#ref-CR25" id="ref-link-section-d30636411e989">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="O'Reilly, R.C. &amp; Frank, M. Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia. Neural Comput. 18, 283328 (2006)." href="/articles/nn.3940#ref-CR33" id="ref-link-section-d30636411e992">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Kravitz, A.V. et al. Regulation of parkinsonian motor behaviours by optogenetic control of basal ganglia circuitry. Nature 466, 622626 (2010)." href="/articles/nn.3940#ref-CR34" id="ref-link-section-d30636411e995">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Wiecki, T.V. &amp; Frank, M.J. A computational model of inhibitory control in frontal cortex and basal ganglia. Psychol. Rev. 120, 329355 (2013)." href="/articles/nn.3940#ref-CR35" id="ref-link-section-d30636411e998">35</a></sup>.</p><p>We next identified brain regions supporting the training process itself, simulating how feedback from these regions related to the real-time feedback. Univariate activity in the FFA and PPA was weakly correlated with whole-brain multivariate evidence, whereas multivariate evidence from a perceptual network in occipitotemporal cortex and multivariate evidence from an attentional network in frontoparietal cortex were strongly correlated. These results suggest that distributed activity patterns contributed more to the training effect than punctate responses in category-selective visual areas. We tested this more directly by exploiting variance in the training effect across participants. Training was predicted by the extent to which feedback relied on information in the attentional network, but not by reliance on information in the perceptual network or the relative activity levels of FFA and PPA. The importance of frontoparietal feedback can be interpreted as evidence that our attention training involved the reinforcement of task representations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Miller, E.K. &amp; Cohen, J.D. An integrative theory of prefrontal cortex function. Annu. Rev. Neurosci. 24, 167202 (2001)." href="/articles/nn.3940#ref-CR25" id="ref-link-section-d30636411e1005">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Noudoost, B., Chang, M.H., Steinmetz, N.A. &amp; Moore, T. Top-down control of visual attention. Curr. Opin. Neurobiol. 20, 183190 (2010)." href="/articles/nn.3940#ref-CR26" id="ref-link-section-d30636411e1008">26</a></sup>, rewarding good states by reducing difficulty and punishing bad states by increasing difficulty. This interpretation is consistent with the observed multivariate changes in frontal cortex and basal ganglia, as these regions and their interaction are critical for feedback-based task learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Foerde, K. &amp; Shohamy, D. The role of the basal ganglia in learning and memory: insight from Parkinson's disease. Neurobiol. Learn. Mem. 96, 624636 (2011)." href="/articles/nn.3940#ref-CR36" id="ref-link-section-d30636411e1012">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Frank, M.J. &amp; Badre, D. Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis. Cereb. Cortex 22, 509526 (2012)." href="/articles/nn.3940#ref-CR37" id="ref-link-section-d30636411e1015">37</a></sup>. It remains an open question whether feedback restricted to occipitotemporal cortex or to FFA and PPA (that is, without access to frontoparietal information) could lead to training.</p><p>The goal of our study was to derive basic science insights into the neural basis of top-down attention and the plasticity of attention-related behavior. In the future, the kind of approach we pursued may find potential applications for training sustained attention in occupational settings (for example, baggage screeners and truck drivers)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Biggs, A.T. &amp; Mitroff, S.R. Different predictors of multiple-target search accuracy between nonprofessional and professional visual searchers. Q. J. Exp. Psychol. (Hove) 67, 13351348 (2014)." href="/articles/nn.3940#ref-CR38" id="ref-link-section-d30636411e1023">38</a></sup> and clinical disorders (for example, attention deficit hyperactivity disorder and negative attentional biases in depression)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Disner, S.G., Beevers, C.G., Haigh, E.A.P. &amp; Beck, A.T. Neural mechanisms of the cognitive model of depression. Nat. Rev. Neurosci. 12, 467477 (2011)." href="/articles/nn.3940#ref-CR39" id="ref-link-section-d30636411e1027">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Shallice, T. et al. Executive function profile of children with attention deficit hyperactivity disorder. Dev. Neuropsychol. 21, 4371 (2002)." href="/articles/nn.3940#ref-CR40" id="ref-link-section-d30636411e1030">40</a></sup>.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Methods</h2><div class="c-article-section__content" id="Sec8-content"><h3 class="c-article__sub-heading" id="Sec9">Participants.</h3><p>Eighty adults (45 female, 75 right-handed, mean age = 20.3 years) participated in the study for monetary compensation. This included 16 participants in each of the following: the fMRI experimental group, the fMRI control group, the no-feedback behavioral group, the RT-feedback behavioral group and the RT-control behavioral group. Each participant in the fMRI control and behavioral groups was matched as closely as possible to the demographics (age, gender and handedness) of a participant in the fMRI experimental group. Power analyses were not performed because of the use of a new paradigm and unknown behavioral and neural effect sizes. The sample size was chosen because it is fairly common for an fMRI study, especially one with multiple groups and sessions. Three additional fMRI participants were excluded because of technical problems with real-time data acquisition, one additional fMRI participant was excluded for falling asleep during several runs and one additional behavioral participant was excluded for low overall performance (3.2 s.d. below the mean in pre-training). For the fMRI participants, the experimenter was not blind to group assignment because of the complexity of data acquisition and analysis, especially the need to ensure that the real-time classification and feedback system was functioning. However, every fMRI participant received the same scripted instructions. All participants had normal or corrected-to-normal visual acuity and provided informed consent to a protocol approved by the Princeton University Institutional Review Board.</p><h3 class="c-article__sub-heading" id="Sec10">Stimuli.</h3><p>Images consisted of grayscale photographs of male and female faces and indoor and outdoor scenes. These images were combined into composite stimuli by averaging pixel intensities using various weightings (for example, 60% face, 40% scene). The stimuli were displayed on a projection screen at the back of the scanner bore (subtending 10  10 of visual angle) and viewed with a mirror attached to the head coil.</p><p>A fixation dot was superimposed on the images and presented during the inter-block intervals of each run, except when text instructions were displayed. Participants were instructed to fixate on this dot, they received practice doing so during their first session, and they were reminded about the importance of fixation before scanning. We did not use an eye tracker to ensure fixation because of the technical complexity of the real-time apparatus and analysis. Aside from this, eye tracking is rarely used in attention studies with overlapping face/scene stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Al-Aidroos, N., Said, C.P. &amp; Turk-Browne, N.B. Top-down attention switches coupling between low-level and high-level areas of human visual cortex. Proc. Natl. Acad. Sci. USA 109, 1467514680 (2012)." href="/articles/nn.3940#ref-CR22" id="ref-link-section-d30636411e1057">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Chadick, J.Z. &amp; Gazzaley, A. Differential coupling of visual cortex with default network or frontal-parietal network based on goals. Nat. Neurosci. 14, 830832 (2011)." href="/articles/nn.3940#ref-CR41" id="ref-link-section-d30636411e1060">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Moore, K.S., Yi, D.-J. &amp; Chun, M. The effect of attention on repetition suppression and multivoxel pattern similarity. J. Cogn. Neurosci. 25, 13051314 (2013)." href="/articles/nn.3940#ref-CR42" id="ref-link-section-d30636411e1063">42</a></sup>, and when it has been used, no differences in eye movements or position across categories were observed<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Serences, J.T., Schwarzbach, J., Courtney, S.M., Golay, X. &amp; Yantis, S. Control of object-based attention in human cortex. Cereb. Cortex 14, 13461357 (2004)." href="/articles/nn.3940#ref-CR43" id="ref-link-section-d30636411e1067">43</a></sup>. In fact, only one participant reported using an eye-movement strategy to perform the task, and this participant showed the smallest training effect of anybody in the feedback group.</p><h3 class="c-article__sub-heading" id="Sec11">Procedure.</h3><p>Participants completed three sessions on different days. The first day was a behavioral pre-training session with two runs of the sustained attention task. The second day was an fMRI session with several runs of the modified real-time neurofeedback version of the sustained attention task. The number of runs varied across participants, depending on how many they could complete within 2 h (range 69 runs). The third day was a behavioral post-training session, otherwise identical to the first session. We attempted to conduct the sessions on three consecutive days, but this was not always possible because of scanner availability and participants' schedules. All participants completed the study within 5 d. The average number of days (and s.e.m.) between the first and second sessions was 1.19 (0.09) and between the second and third sessions was 1.25 (0.09).</p><p>Each task run contained eight blocks. Each block began with a text cue for 1 s that instructed participants which subcategory was the target to which they should respond and, by extension, which category was to be attended. Four of the blocks involved attending to faces and the other four involved attending to scenes. The target subcategories were held constant within each participant (for example, male and indoor) but were counterbalanced across participants. The cue was followed by 1 s of fixation and then a series of 50 trials. Each trial contained a composite face/scene image presented for 1 s with no inter-stimulus interval. Responses were recorded during the first 850 ms of stimulus presentation to allow computation time at the end of the trial. The trial structure followed a response inhibition task design<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Robertson, I.H., Manly, T., Andrade, J., Baddeley, B.T. &amp; Yiend, J. 'Oops!': performance correlates of everyday attentional failures in traumatic brain injured and normal subjects. Neuropsychologia 35, 747758 (1997)." href="/articles/nn.3940#ref-CR9" id="ref-link-section-d30636411e1082">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Rosenberg, M., Noonan, S., DeGutis, J. &amp; Esterman, M. Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task. Atten. Percept. Psychophys. 75, 426439 (2013)." href="/articles/nn.3940#ref-CR20" id="ref-link-section-d30636411e1085">20</a></sup>: 90% of images contained the target subcategory (for example, an indoor scene after an indoor cue) and required a response; the other 10% contained the non-target subcategory (in this case, an outdoor scene) to which responses needed to be withheld. The distribution of the subcategories was the same for the unattended category (for example, 90% male and 10% female after an indoor cue), although these images were irrelevant for determining whether to respond or not. After the last trial, there was a 46 s of fixation before the next block.</p><p>The first run of the rtfMRI session was identical to the runs of the behavioral sessions, with all composite stimuli being an equal mixture of face (50%) and scene (50%) images. Starting with the second run, the first four, 'stable' blocks kept the same equal mixture, but the final four, 'feedback' blocks had variable mixture proportions that depended on the participant's attentional state. Text instructions appeared before the first feedback block to alert participants that neurofeedback was starting. Each of these blocks started with an equal mixture for the first three trials. The mixture proportions for the remaining trials were determined on the basis of real-time MVPA of the fMRI data. They ranged from 17% to 98% of the task-relevant category (83% to 2% of the task-irrelevant category). For half of the participants, the last run of the rtfMRI session was identical to the first run, with all eight blocks using an equal mixture.</p><h3 class="c-article__sub-heading" id="Sec12">Data acquisition.</h3><p>Experiments were run using the Psychophysics Toolbox for Matlab (<a href="http://psychtoolbox.org/">http://psychtoolbox.org/</a>). Neuroimaging data were acquired with a 3 T MRI scanner (Siemens Skyra) using a 16-channel head coil. We first collected a scout anatomical scan to align axial functional slices to the anterior commissureposterior commissure line. Functional images were acquired using a gradient-echo, echo-planar imaging sequence (2 s repetition time, 28 ms echo time, 3 mm isotropic voxel size, 64  64 matrix, 192 mm field of view, 36 slices) that covered most of the brain. At the end of the fMRI session, a high-resolution magnetization-prepared rapid acquisition gradient-echo (MPRAGE) anatomical scan was acquired for offline spatial registration. To improve registration, an additional coplanar T1 fast low angle shot anatomical scan was also acquired.</p><h3 class="c-article__sub-heading" id="Sec13">Statistics.</h3><p>Because some of the data violated the assumption of normality needed for parametric tests, we used nonparametric tests throughout to determine statistical significance. Subject-level bootstrap resampling<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Efron, B. &amp; Tibshirani, R. Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy. Stat. Sci. 1, 5475 (1986)." href="/articles/nn.3940#ref-CR44" id="ref-link-section-d30636411e1116">44</a></sup> was used to assess random-effects reliability for comparisons of a small number of variables to chance or each other; one-sided tests were used for directional hypotheses and two-sided tests for nondirectional hypotheses. Correlations between two variables were estimated with Spearman's rank correlation after applying robust methods to eliminate the disproportionate influence of outliers in small samples<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Pernet, C.R., Wilcox, R.R. &amp; Rousselet, G.A. Robust correlation analyses: false positive and power validation using a new open source Matlab toolbox. Front. Psychol. 3, 606 (2013)." href="/articles/nn.3940#ref-CR45" id="ref-link-section-d30636411e1120">45</a></sup>. Significance testing on voxel-wise brain maps was conducted with a permutation test in FSL's randomise function<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Nichols, T.E. &amp; Holmes, A.P. Nonparametric permutation tests for functional neuroimaging: a primer with examples. Hum. Brain Mapp. 15, 125 (2002)." href="/articles/nn.3940#ref-CR46" id="ref-link-section-d30636411e1124">46</a></sup> and corrected for multiple comparisons using threshold-free cluster enhancement<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Smith, S.M. &amp; Nichols, T.E. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. Neuroimage 44, 8398 (2009)." href="/articles/nn.3940#ref-CR47" id="ref-link-section-d30636411e1128">47</a></sup>. Each control participant was matched to one experimental participant in all respects except for the key manipulation (that is, on demographics, stimuli and number of runs), and so comparisons across groups were performed with a matched-pairs sample design.</p><h3 class="c-article__sub-heading" id="Sec14">Real-time analyses.</h3><p><i>Preprocessing.</i> During the fMRI session, data were reconstructed on the scanner. Prospective acquisition correction and retrospective motion correction were applied. Each motion-corrected volume was transferred to a separate analysis computer in real time. A brain mask was applied to eliminate non-brain voxels. The volume was spatially smoothed in Matlab using a Gaussian kernel with full-width half-maximum (FWHM) = 5 mm. After each grouping of four stable blocks, the BOLD activity of every voxel was <i>z</i>-scored over time. The same normalization was applied during feedback blocks in real time, using the mean and standard deviation from the most recent four stable blocks.</p><p><i>Multivariate pattern analysis</i>. During the fMRI session, we conducted MVPA using penalized logistic regression with L2-norm regularization (penalty = 1). The classifier was trained to distinguish top-down attention to faces and scenes from whole-brain activity patterns. The training examples for the classifier were obtained from a trailing window of stable blocks. For half of the participants, this trailing window included the twelve previous stable blocks and the classifier was trained during a 70-s fixation period between blocks 4 and 5 of the current run. For the other half, the trailing window did not include the stable blocks from the current run and the classifier was trained between runs; the fixation period between blocks 4 and 5 was reduced to 6 s. There were no reliable differences between these groups, and so they were analyzed together. For training the model, all regressors were shifted 4 s forward in time to adjust for the hemodynamic lag.</p><p>The trained model was tested in real time on brain volumes obtained during the feedback blocks. For each volume, the classifier estimated the extent to which the brain activity pattern matched the pattern for the two attentional states on which it was trained (from 0 to 1). The neurofeedback was based on the difference of classifier outputs for the task-relevant category minus task-irrelevant category. These outputs are perfectly anticorrelated in a two-class classifier, such that the difference ranged from 1 to 1. As a result of the anticorrelation, it is difficult to disentangle less attention to the task-relevant category from more attention to the task-irrelevant category (and vice versa). Differences of 1 and 1 should thus be interpreted in relative terms as more attention to the task-irrelevant and task-relevant categories, respectively. Note that if participants were not in either attentional state, the brain activity patterns would contain no signal that the classifier could identify and the classification would be driven by noise; the difference would then be 0 on average. We therefore interpret positive and negative values away from 0 as evidence of selective attention to one category of the composite stimulus.</p><p><i>Neurofeedback</i>. The output of the classifier was used to determine the proportion of the images from the task-relevant and task-irrelevant categories in the composite stimulus on the next trial. The preprocessing and decoding of volume <i>i</i> were performed during volume <i>i</i> + 1 and the classifier output was used to update the stimulus mixture for the two trials in volume <i>i</i> + 2. This resulted in a minimum lag of 2 s (two trials) between data acquisition and feedback. Moreover, classifier output was averaged over a moving window of the preceding three volumes (<i>i</i>  2, <i>i</i>  1 and <i>i</i> for feedback in volume <i>i</i> + 2), meaning that feedback was based on brain states 28 s in the past. Because sustained attention fluctuates slowly<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Rosenberg, M., Noonan, S., DeGutis, J. &amp; Esterman, M. Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task. Atten. Percept. Psychophys. 75, 426439 (2013)." href="/articles/nn.3940#ref-CR20" id="ref-link-section-d30636411e1180">20</a></sup>, we reasoned that this smoothing would provide a better estimate of attentional state by reducing high-frequency noise.</p><p>The average classifier output was mapped to a proportion of the task-relevant category using a sigmoidal transfer function (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig9">Supplementary Figs. 4</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig10">5</a>). The maximum output value (0.98) meant that the task-irrelevant image could be almost completely absent from the composite stimulus. The minimum output value (0.17) meant that the task-relevant image was always present to some degree, even when participants had lapsed completely (giving them a foothold to recover). The inflection point of the logistic function was centered at an input greater than chance (0.60), based on the mean decoding accuracy of a group of pilot participants. This placed the sensitive range of the feedback closer to the typical real-time classifier output values. For follow-up analyses that assessed how the feedback changed over training, we computed the average proportion of the image from the task-relevant category in each training run and calculated the linear slope across runs for each participant.</p><p>Participants were aware of the feedback manipulation. Before the fMRI session, they were told that the images in the second half of most runs would change depending upon their attention, as measured from their brain. Specifically, the task would get easier if they were paying attention and it would get harder if they became inattentive. They were shown examples of how a composite stimulus could change on the basis of whether they were doing a good or bad job of paying attention. Critically, control participants received the exact same instructions. After the study, participants completed a debriefing questionnaire, which included the question: Did you feel that you could control the image with your brain? Overall, 11 of 16 participants in the feedback group reported feeling some degree of brain control, compared to 4 of 16 participants in the control group. Interestingly, the feedback that the control participants received was positively correlated on average with what they would have received on the basis of their own brain activity patterns (mean <i>r</i> = 0.29, s.e.m. = 0.04, <i>P</i> &lt; 0.00001). This correlation suggests that their attentional state was affected by the sham feedback, which in turn determined what feedback they should have received next. Unlike the feedback participants, however, the control participants were only reacting to the feedback and not driving it.</p><h3 class="c-article__sub-heading" id="Sec15">Offline analyses.</h3><p><i>General procedures</i>. Using FSL (<a href="http://fsl.fmrib.ox.ac.uk/">http://fsl.fmrib.ox.ac.uk/</a>), the data were temporally high-pass filtered (200 s period cut-off), motion corrected again, and spatially smoothed with a Gaussian kernel (5 mm FWHM). They were then transformed into standard Montreal Neurological Institute (MNI) space by linearly registering to the MPRAGE images and to the MNI152 standard brain. We conducted offline MVPA using the Princeton Multi-Voxel Pattern Analysis Toolbox (<a href="http://www.pni.princeton.edu/mvpa/">http://www.pni.princeton.edu/mvpa/</a>), with <i>z</i>-scoring over time within each run and the same type of classifier as in the real-time analyses (penalized logistic regression using L2-norm regularization, penalty = 1).</p><p><i>Decoding accuracy</i>. We assessed our ability to decode attentional state within individual participants by classifying the stable blocks, which were uncontaminated by stimulus-based feedback. (In fact, these data served as the training set for real-time classification, but were never subdivided into training and test sets so that classifier accuracy could be estimated with cross-validation.) We trained a classifier using the stable blocks from <i>n</i>  1 runs and tested it on the left-out run, then repeated <i>n</i> times. By averaging over these folds, we obtained a measure of how well we could decode the attentional state of each participant and assessed reliability in the group relative to chance (0.5). We interpreted this decoding accuracy as reflecting the neural separability of attentional states rather than the precision with which the classifier algorithm captured these states <i>per se</i>. That is, low decoding accuracy for a participant does not necessarily mean that his or her classifier itself was inaccurate, but rather that it was accurately tracking poor neural separation between attentional states. Such separation may be related to individual differences in attentional abilities, with poor separation reflecting weaker selection of task-relevant information and/or increased distraction by task-irrelevant information. To verify this interpretation, we correlated decoding accuracy across participants with behavioral sensitivity from the pre-training session. We used <i>A</i> to index sensitivity because of its robustness to the high hit rates that we expected to obtain because of the greater frequency of targets than lures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Donaldson, W. Measuring recognition memory. J. Exp. Psychol. Gen. 121, 275277 (1992)." href="/articles/nn.3940#ref-CR48" id="ref-link-section-d30636411e1247">48</a></sup>.</p><p><i>Predicting behavioral accuracy.</i> For classifier output to provide useful feedback for training purposes, (1) it should be related to behavior on a trial-by-trial basis within participant and (2) this relationship should hold without artificially shifting trials back in time to correct for the hemodynamic lag (which cannot be done in real time). To judge whether these criteria were satisfied, we examined whether the classifier output before a lure trial (averaged over the three preceding volumes, as used to calculate feedback) predicted whether participants correctly withheld their response or incorrectly responded. This relationship was tested with a logistic regression (correct rejection = 1, false alarm = 0), whose slope was reliably positive at the group level (mean slope = 0.67, s.e.m. = 0.11, <i>P</i> &lt; 0.00001). That is, more classifier evidence from volumes 28 s in the pastmost influenced by neural events 612 s in the past, assuming a hemodynamic peak at 4 spredicted behavioral accuracy on the current trial.</p><p>The average RT from the six trials during these volumes also predicted behavioral accuracy in a logistic regression (mean slope = 0.01, s.e.m. = 0.0009, <i>P</i> &lt; 0.00001; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig7">Supplementary Fig. 2</a>). To remove this confound, we averaged the two RTs from each volume, regressed this average out of the raw classifier output and behavioral accuracy across volumes, and then repeated the analysis above in the residuals (using partial correlation rather than logistic regression because behavioral accuracy was no longer binary). The positive relationship between classifier output and behavioral accuracy remained reliable (mean <i>r</i> = 0.06, s.e.m. = 0.01, <i>P</i> &lt; 0.00001; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig8">Supplementary Fig. 3</a>).</p><p><i>Changes in neural discriminability</i>. We performed several analyses to examine whether attention training increased the separation between neural representations of the face and scene attentional states. We operationalized neural separation with decoding accuracy, comparing the first and last runs of the rtfMRI training session to assess training-induced changes. For each of these runs, we trained a classifier to decode attentional state from the stable blocks using a split-half cross-validation procedure. To ensure that classification was not confounded by RT, we averaged the two RTs in every volume of the stable blocks and regressed out the resulting RT time course from the brain data before analysis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Todd, M.T., Nystrom, L.E. &amp; Cohen, J.D. Confounds in multivariate pattern analysis: theory and rule representation case study. Neuroimage 77, 157165 (2013)." href="/articles/nn.3940#ref-CR27" id="ref-link-section-d30636411e1283">27</a></sup>. We calculated the difference in decoding accuracy as the last minus first run for each participant and assessed the reliability of this change at the group level, comparing feedback and control groups. This analysis was performed over the whole brain, within each of the four lobes (defined using the MNI atlas in FSL), and over spherical searchlights (1 voxel radius, 7 voxel maximum volume) centered on every voxel in the brain.</p><p><i>Simulated feedback.</i> For the univariate analysis of FFA and PPA, we localized these areas within each participant by contrasting face and scene attention blocks in the first fMRI run (which had no feedback). FFA and PPA ROIs were defined as 5-mm spheres around the peak face- and scene-selective voxels in right and left lateral fusiform gyri and collateral sulci/parahippocampal gyri, respectively. We then collapsed over hemispheres and averaged the time series of the voxels in each bilateral ROI for all feedback blocks (starting in the second fMRI run). For each block, we calculated the difference over time between the task-relevant ROI (FFA and PPA for face and scene attention, respectively) and the task-irrelevant ROI (PPA and FFA for face and scene attention, respectively) and then concatenated these differences across blocks within each run. To estimate how FFA and PPA activity related to the real-time feedback in each run, we correlated this ROI-derived time series with the difference in whole-brain classifier output for the task-relevant minus task-irrelevant categories (face minus scene evidence for face attention and scene minus face evidence for scene attention) from the same blocks and then averaged across runs. These FFA/PPA to whole-brain correlations were in turn correlated across feedback participants with the improvement in <i>A</i> from pre- to post-training.</p><p>For the multivariate analysis of perceptual and attentional networks, we first defined each network using functional and anatomical criteria. The functional criterion was based on forward-inference meta-analyses from <a href="http://neurosynth.org/">http://neurosynth.org/</a> using the search terms faces OR scenes for the perceptual network and attention for the attentional network. The results were downloaded as voxel-wise masks and thresholded at <i>z</i> = 2.3. The anatomical criterion was based on the MNI atlas in FSL, which was used to generate binary masks of the occipital and temporal lobes for the perceptual network and the frontal and parietal lobes for the attentional network. Voxels that survived the intersection of the functional and anatomical masks were used to train a separate classifier for each network. Other than being performed offline rather than in real time, the rest of the classification procedure was identical to that of the whole-brain classifier, with training for each run based on a moving window of stable blocks and testing occurring volume by volume in the feedback blocks. The classifier output for each network was correlated with the whole-brain classifier output to estimate how much information in that network contributed to the real-time feedback in every run, and these correlations were averaged across runs within each participant. These network/whole-brain correlations were then correlated with the improvement in <i>A</i> from pre- to post-training across feedback participants to assess the usefulness of relying on information in the perceptual and attentional networks for training.</p><h3 class="c-article__sub-heading" id="Sec16">Behavioral control experiments.</h3><p>We recruited three behavioral control participants for each fMRI participant from the feedback group of the main study (total <i>n</i> = 48). They were all demographically matched to the fMRI participant in handedness, gender and age (1 year). In addition, they received the same experimental design, in terms of stimulus order, block order, number of training runs, number of sessions and number of days between sessions. The training session was conducted in a behavioral testing room rather than the scanner. To emulate the contextual change experienced by the fMRI participants in switching environments between pre-/post-training and training, the pre- and post-training sessions were run in a different room in a different part of our building. Across the three groups of participants, we manipulated the nature of the feedback that they received during training. The assignment of control participants to each of these feedback conditions was randomized.</p><p>The no-feedback experiment (<i>n</i> = 16) was identical to the fMRI study, other than being conducted outside the scanner and replacing all feedback blocks with stable blocks. That is, the stimulus mixture proportion remained constant at 50% for both categories during all blocks. As a result of removing the feedback, participants also did not receive instructions about how to interpret varying stimulus proportions and there was no separate, yoked control group.</p><p>The RT-feedback experiment was identical to the fMRI study, other than being conducted outside the scanner and having the feedback controlled by RT rather than whole-brain classifier output. This experiment contained two between-subject conditions, the RT-feedback group (<i>n</i> = 16) and the RT-control group (<i>n</i> = 16). Participants were assigned in matched pairs, with the RT-control participant in each pair receiving feedback yoked to that generated by the matched RT-feedback participant. Thus, by definition, the RT-feedback participant was run before their match. However, the RT-feedback and RT-control participants from different pairs were interleaved and run in the same cohort. Participants in both groups received the same instructions, which were slightly modified from the fMRI study to remove scanner-related references. Not only were participants blind to their condition, but the experimenter was also blind (other than to the first and last participants, who were necessarily RT-feedback and RT-control participants, respectively). A different researcher conducted participant recruitment and scheduling, resulting in a double-blind procedure. (Note that because of the lack of feedback in the no-feedback experiment, the experimenter was aware of whether a participant ended up in that particular group.)</p><p>The feedback regime for the RT-feedback condition was very similar to the fMRI experiment, using RT (instead of fMRI category evidence) as a measure of attentional state. During feedback blocks, the proportion of the task-relevant category increased when participants responded slowly and decreased when they responded quickly. We chose this mapping because RT was faster on trials preceding false alarms than correct rejections (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig7">Supplementary Fig. 2</a>), consistent with habitual responding and worse sustained attention<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Robertson, I.H., Manly, T., Andrade, J., Baddeley, B.T. &amp; Yiend, J. 'Oops!': performance correlates of everyday attentional failures in traumatic brain injured and normal subjects. Neuropsychologia 35, 747758 (1997)." href="/articles/nn.3940#ref-CR9" id="ref-link-section-d30636411e1343">9</a></sup>. More specifically, the feedback was based on the participant's deviation from their average RT, calculated over a trailing window of stable blocks (the same set as used for training data in the fMRI classifier). The stimulus mixture proportion was adjusted using the average of the RTs from the previous six trials, which was equivalent to the three brain volumes that were used for feedback in the fMRI version. A sigmoidal transfer function transformed this value into a stimulus mixture proportion.</p><p>A <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3940#MOESM46">Supplementary Methods Checklist</a> is available.</p></div></div></section>
                </div>
            

            <div>
                <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1"><p class="c-article-references__text" id="ref-CR1">Chun, M.M., Golomb, J.D. &amp; Turk-Browne, N.B. A taxonomy of external and internal attention. <i>Annu. Rev. Psychol.</i> <b>62</b>, 73101 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.psych.093008.100427" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.psych.093008.100427" aria-label="Article reference 1" data-doi="10.1146/annurev.psych.093008.100427">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19575619" aria-label="PubMed reference 1">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20taxonomy%20of%20external%20and%20internal%20attention&amp;journal=Annu.%20Rev.%20Psychol.&amp;doi=10.1146%2Fannurev.psych.093008.100427&amp;volume=62&amp;pages=73-101&amp;publication_year=2011&amp;author=Chun%2CMM&amp;author=Golomb%2CJD&amp;author=Turk-Browne%2CNB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2"><p class="c-article-references__text" id="ref-CR2">Mackworth, N.H. The breakdown of vigilance during prolonged visual search. <i>Q. J. Exp. Psychol.</i> <b>1</b>, 621 (1948).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/17470214808416738" data-track-action="article reference" href="https://doi.org/10.1080%2F17470214808416738" aria-label="Article reference 2" data-doi="10.1080/17470214808416738">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20breakdown%20of%20vigilance%20during%20prolonged%20visual%20search&amp;journal=Q.%20J.%20Exp.%20Psychol.&amp;doi=10.1080%2F17470214808416738&amp;volume=1&amp;pages=6-21&amp;publication_year=1948&amp;author=Mackworth%2CNH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3"><p class="c-article-references__text" id="ref-CR3">Redelmeier, D.A. &amp; Tibshirani, R.J. Association between cellular-telephone calls and motor vehicle collisions. <i>N. Engl. J. Med.</i> <b>336</b>, 453458 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1056/NEJM199702133360701" data-track-action="article reference" href="https://doi.org/10.1056%2FNEJM199702133360701" aria-label="Article reference 3" data-doi="10.1056/NEJM199702133360701">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK2s7mtV2hsA%3D%3D" aria-label="CAS reference 3">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9017937" aria-label="PubMed reference 3">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Association%20between%20cellular-telephone%20calls%20and%20motor%20vehicle%20collisions&amp;journal=N.%20Engl.%20J.%20Med.&amp;doi=10.1056%2FNEJM199702133360701&amp;volume=336&amp;pages=453-458&amp;publication_year=1997&amp;author=Redelmeier%2CDA&amp;author=Tibshirani%2CRJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4"><p class="c-article-references__text" id="ref-CR4">Czeisler, C.A. et al. Modafinil for excessive sleepiness associated with shift-work sleep disorder. <i>N. Engl. J. Med.</i> <b>353</b>, 476486 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1056/NEJMoa041292" data-track-action="article reference" href="https://doi.org/10.1056%2FNEJMoa041292" aria-label="Article reference 4" data-doi="10.1056/NEJMoa041292">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXntVCisL8%3D" aria-label="CAS reference 4">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16079371" aria-label="PubMed reference 4">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Modafinil%20for%20excessive%20sleepiness%20associated%20with%20shift-work%20sleep%20disorder&amp;journal=N.%20Engl.%20J.%20Med.&amp;doi=10.1056%2FNEJMoa041292&amp;volume=353&amp;pages=476-486&amp;publication_year=2005&amp;author=Czeisler%2CCA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5"><p class="c-article-references__text" id="ref-CR5">Dinges, D.F. &amp; Powell, J.W. Microcomputer analyses of performance on a portable, simple visual RT task during sustained operations. <i>Behav. Res. Methods Instrum. Comput.</i> <b>17</b>, 652655 (1985).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/BF03200977" data-track-action="article reference" href="https://doi.org/10.3758%2FBF03200977" aria-label="Article reference 5" data-doi="10.3758/BF03200977">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Microcomputer%20analyses%20of%20performance%20on%20a%20portable%2C%20simple%20visual%20RT%20task%20during%20sustained%20operations&amp;journal=Behav.%20Res.%20Methods%20Instrum.%20Comput.&amp;doi=10.3758%2FBF03200977&amp;volume=17&amp;pages=652-655&amp;publication_year=1985&amp;author=Dinges%2CDF&amp;author=Powell%2CJW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6"><p class="c-article-references__text" id="ref-CR6">Sarter, M., Givens, B. &amp; Bruno, J.P. The cognitive neuroscience of sustained attention: where top-down meets bottom-up. <i>Brain Res. Brain Res. Rev.</i> <b>35</b>, 146160 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0165-0173(01)00044-3" data-track-action="article reference" href="https://doi.org/10.1016%2FS0165-0173%2801%2900044-3" aria-label="Article reference 6" data-doi="10.1016/S0165-0173(01)00044-3">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3MvitlGhtg%3D%3D" aria-label="CAS reference 6">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11336780" aria-label="PubMed reference 6">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20cognitive%20neuroscience%20of%20sustained%20attention%3A%20where%20top-down%20meets%20bottom-up&amp;journal=Brain%20Res.%20Brain%20Res.%20Rev.&amp;doi=10.1016%2FS0165-0173%2801%2900044-3&amp;volume=35&amp;pages=146-160&amp;publication_year=2001&amp;author=Sarter%2CM&amp;author=Givens%2CB&amp;author=Bruno%2CJP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7"><p class="c-article-references__text" id="ref-CR7">Wolfe, J.M., Horowitz, T.S. &amp; Kenner, N.M. Rare items often missed in visual searches. <i>Nature</i> <b>435</b>, 439440 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/435439a" data-track-action="article reference" href="https://doi.org/10.1038%2F435439a" aria-label="Article reference 7" data-doi="10.1038/435439a">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXksVeju7Y%3D" aria-label="CAS reference 7">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15917795" aria-label="PubMed reference 7">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4224304" aria-label="PubMed Central reference 7">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Rare%20items%20often%20missed%20in%20visual%20searches&amp;journal=Nature&amp;doi=10.1038%2F435439a&amp;volume=435&amp;pages=439-440&amp;publication_year=2005&amp;author=Wolfe%2CJM&amp;author=Horowitz%2CTS&amp;author=Kenner%2CNM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8"><p class="c-article-references__text" id="ref-CR8">Johnson, K.A. et al. Dissociation in performance of children with ADHD and high-functioning autism on a task of sustained attention. <i>Neuropsychologia</i> <b>45</b>, 22342245 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuropsychologia.2007.02.019" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuropsychologia.2007.02.019" aria-label="Article reference 8" data-doi="10.1016/j.neuropsychologia.2007.02.019">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17433378" aria-label="PubMed reference 8">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2000292" aria-label="PubMed Central reference 8">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Dissociation%20in%20performance%20of%20children%20with%20ADHD%20and%20high-functioning%20autism%20on%20a%20task%20of%20sustained%20attention&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2007.02.019&amp;volume=45&amp;pages=2234-2245&amp;publication_year=2007&amp;author=Johnson%2CKA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9"><p class="c-article-references__text" id="ref-CR9">Robertson, I.H., Manly, T., Andrade, J., Baddeley, B.T. &amp; Yiend, J. 'Oops!': performance correlates of everyday attentional failures in traumatic brain injured and normal subjects. <i>Neuropsychologia</i> <b>35</b>, 747758 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0028-3932(97)00015-8" data-track-action="article reference" href="https://doi.org/10.1016%2FS0028-3932%2897%2900015-8" aria-label="Article reference 9" data-doi="10.1016/S0028-3932(97)00015-8">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK2szkvVCksA%3D%3D" aria-label="CAS reference 9">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9204482" aria-label="PubMed reference 9">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=%27Oops%21%27%3A%20performance%20correlates%20of%20everyday%20attentional%20failures%20in%20traumatic%20brain%20injured%20and%20normal%20subjects&amp;journal=Neuropsychologia&amp;doi=10.1016%2FS0028-3932%2897%2900015-8&amp;volume=35&amp;pages=747-758&amp;publication_year=1997&amp;author=Robertson%2CIH&amp;author=Manly%2CT&amp;author=Andrade%2CJ&amp;author=Baddeley%2CBT&amp;author=Yiend%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10"><p class="c-article-references__text" id="ref-CR10">Drew, T. &amp; Vogel, E.K. Neural measures of individual differences in selecting and tracking multiple moving objects. <i>J. Neurosci.</i> <b>28</b>, 41834191 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.0556-08.2008" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.0556-08.2008" aria-label="Article reference 10" data-doi="10.1523/JNEUROSCI.0556-08.2008">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXltVOnurk%3D" aria-label="CAS reference 10">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18417697" aria-label="PubMed reference 10">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570324" aria-label="PubMed Central reference 10">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20measures%20of%20individual%20differences%20in%20selecting%20and%20tracking%20multiple%20moving%20objects&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.0556-08.2008&amp;volume=28&amp;pages=4183-4191&amp;publication_year=2008&amp;author=Drew%2CT&amp;author=Vogel%2CEK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11"><p class="c-article-references__text" id="ref-CR11">Weiskopf, N. et al. Principles of a brain-computer interface (BCI) based on real-time functional magnetic resonance imaging (fMRI). <i>IEEE Trans. Biomed. Eng.</i> <b>51</b>, 966970 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TBME.2004.827063" data-track-action="article reference" href="https://doi.org/10.1109%2FTBME.2004.827063" aria-label="Article reference 11" data-doi="10.1109/TBME.2004.827063">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15188865" aria-label="PubMed reference 11">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Principles%20of%20a%20brain-computer%20interface%20%28BCI%29%20based%20on%20real-time%20functional%20magnetic%20resonance%20imaging%20%28fMRI%29&amp;journal=IEEE%20Trans.%20Biomed.%20Eng.&amp;doi=10.1109%2FTBME.2004.827063&amp;volume=51&amp;pages=966-970&amp;publication_year=2004&amp;author=Weiskopf%2CN">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12"><p class="c-article-references__text" id="ref-CR12">LaConte, S.M. Decoding fMRI brain states in real-time. <i>Neuroimage</i> <b>56</b>, 440454 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.06.052" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.06.052" aria-label="Article reference 12" data-doi="10.1016/j.neuroimage.2010.06.052">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20600972" aria-label="PubMed reference 12">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Decoding%20fMRI%20brain%20states%20in%20real-time&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.06.052&amp;volume=56&amp;pages=440-454&amp;publication_year=2011&amp;author=LaConte%2CSM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13"><p class="c-article-references__text" id="ref-CR13">Sulzer, J. et al. Real-time fMRI neurofeedback: progress and challenges. <i>Neuroimage</i> <b>76</b>, 386399 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2013.03.033" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2013.03.033" aria-label="Article reference 13" data-doi="10.1016/j.neuroimage.2013.03.033">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3srgvVWhuw%3D%3D" aria-label="CAS reference 13">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23541800" aria-label="PubMed reference 13">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Real-time%20fMRI%20neurofeedback%3A%20progress%20and%20challenges&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2013.03.033&amp;volume=76&amp;pages=386-399&amp;publication_year=2013&amp;author=Sulzer%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14"><p class="c-article-references__text" id="ref-CR14">Norman, K.A., Polyn, S.M., Detre, G.J. &amp; Haxby, J.V. Beyond mind-reading: multi-voxel pattern analysis of fMRI data. <i>Trends Cogn. Sci.</i> <b>10</b>, 424430 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2006.07.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2006.07.005" aria-label="Article reference 14" data-doi="10.1016/j.tics.2006.07.005">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16899397" aria-label="PubMed reference 14">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Beyond%20mind-reading%3A%20multi-voxel%20pattern%20analysis%20of%20fMRI%20data&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2006.07.005&amp;volume=10&amp;pages=424-430&amp;publication_year=2006&amp;author=Norman%2CKA&amp;author=Polyn%2CSM&amp;author=Detre%2CGJ&amp;author=Haxby%2CJV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15"><p class="c-article-references__text" id="ref-CR15">deCharms, R.C. et al. Control over brain activation and pain learned by using real-time functional MRI. <i>Proc. Natl. Acad. Sci. USA</i> <b>102</b>, 1862618631 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.0505210102" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.0505210102" aria-label="Article reference 15" data-doi="10.1073/pnas.0505210102">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD28Xpt12j" aria-label="CAS reference 15">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16352728" aria-label="PubMed reference 15">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1311906" aria-label="PubMed Central reference 15">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Control%20over%20brain%20activation%20and%20pain%20learned%20by%20using%20real-time%20functional%20MRI&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.0505210102&amp;volume=102&amp;pages=18626-18631&amp;publication_year=2005&amp;author=deCharms%2CRC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16"><p class="c-article-references__text" id="ref-CR16">Shibata, K., Watanabe, T., Sasaki, Y. &amp; Kawato, M. Perceptual learning incepted by decoded fMRI neurofeedback without stimulus presentation. <i>Science</i> <b>334</b>, 14131415 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1212003" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1212003" aria-label="Article reference 16" data-doi="10.1126/science.1212003">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhsFOjt7rJ" aria-label="CAS reference 16">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22158821" aria-label="PubMed reference 16">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3297423" aria-label="PubMed Central reference 16">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceptual%20learning%20incepted%20by%20decoded%20fMRI%20neurofeedback%20without%20stimulus%20presentation&amp;journal=Science&amp;doi=10.1126%2Fscience.1212003&amp;volume=334&amp;pages=1413-1415&amp;publication_year=2011&amp;author=Shibata%2CK&amp;author=Watanabe%2CT&amp;author=Sasaki%2CY&amp;author=Kawato%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17"><p class="c-article-references__text" id="ref-CR17">Yoo, J.J. et al. When the brain is prepared to learn: enhancing human learning using real-time fMRI. <i>Neuroimage</i> <b>59</b>, 846852 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2011.07.063" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2011.07.063" aria-label="Article reference 17" data-doi="10.1016/j.neuroimage.2011.07.063">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21821136" aria-label="PubMed reference 17">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=When%20the%20brain%20is%20prepared%20to%20learn%3A%20enhancing%20human%20learning%20using%20real-time%20fMRI&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2011.07.063&amp;volume=59&amp;pages=846-852&amp;publication_year=2012&amp;author=Yoo%2CJJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18"><p class="c-article-references__text" id="ref-CR18">Hinds, O. et al. Roles of default-mode network and supplementary motor area in human vigilance performance: evidence from real-time fMRI. <i>J. Neurophysiol.</i> <b>109</b>, 12501258 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00533.2011" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00533.2011" aria-label="Article reference 18" data-doi="10.1152/jn.00533.2011">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXltl2gs78%3D" aria-label="CAS reference 18">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23236006" aria-label="PubMed reference 18">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Roles%20of%20default-mode%20network%20and%20supplementary%20motor%20area%20in%20human%20vigilance%20performance%3A%20evidence%20from%20real-time%20fMRI&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00533.2011&amp;volume=109&amp;pages=1250-1258&amp;publication_year=2013&amp;author=Hinds%2CO">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19"><p class="c-article-references__text" id="ref-CR19">Yoss, R.E., Moyer, N.J. &amp; Hollenhorst, R.W. Pupil size and spontaneous pupillary waves associated with alertness, drowsiness, and sleep. <i>Neurology</i> <b>20</b>, 545554 (1970).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1212/WNL.20.6.545" data-track-action="article reference" href="https://doi.org/10.1212%2FWNL.20.6.545" aria-label="Article reference 19" data-doi="10.1212/WNL.20.6.545">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaE3c3htFKmtw%3D%3D" aria-label="CAS reference 19">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=5463609" aria-label="PubMed reference 19">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Pupil%20size%20and%20spontaneous%20pupillary%20waves%20associated%20with%20alertness%2C%20drowsiness%2C%20and%20sleep&amp;journal=Neurology&amp;doi=10.1212%2FWNL.20.6.545&amp;volume=20&amp;pages=545-554&amp;publication_year=1970&amp;author=Yoss%2CRE&amp;author=Moyer%2CNJ&amp;author=Hollenhorst%2CRW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20"><p class="c-article-references__text" id="ref-CR20">Rosenberg, M., Noonan, S., DeGutis, J. &amp; Esterman, M. Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task. <i>Atten. Percept. Psychophys.</i> <b>75</b>, 426439 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/s13414-012-0413-x" data-track-action="article reference" href="https://doi.org/10.3758%2Fs13414-012-0413-x" aria-label="Article reference 20" data-doi="10.3758/s13414-012-0413-x">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23299180" aria-label="PubMed reference 20">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Sustaining%20visual%20attention%20in%20the%20face%20of%20distraction%3A%20a%20novel%20gradual-onset%20continuous%20performance%20task&amp;journal=Atten.%20Percept.%20Psychophys.&amp;doi=10.3758%2Fs13414-012-0413-x&amp;volume=75&amp;pages=426-439&amp;publication_year=2013&amp;author=Rosenberg%2CM&amp;author=Noonan%2CS&amp;author=DeGutis%2CJ&amp;author=Esterman%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21"><p class="c-article-references__text" id="ref-CR21">O'Craven, K.M., Downing, P.E. &amp; Kanwisher, N. fMRI evidence for objects as the units of attentional selection. <i>Nature</i> <b>401</b>, 584587 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/44134" data-track-action="article reference" href="https://doi.org/10.1038%2F44134" aria-label="Article reference 21" data-doi="10.1038/44134">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXmvFCnu74%3D" aria-label="CAS reference 21">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10524624" aria-label="PubMed reference 21">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=fMRI%20evidence%20for%20objects%20as%20the%20units%20of%20attentional%20selection&amp;journal=Nature&amp;doi=10.1038%2F44134&amp;volume=401&amp;pages=584-587&amp;publication_year=1999&amp;author=O%27Craven%2CKM&amp;author=Downing%2CPE&amp;author=Kanwisher%2CN">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22"><p class="c-article-references__text" id="ref-CR22">Al-Aidroos, N., Said, C.P. &amp; Turk-Browne, N.B. Top-down attention switches coupling between low-level and high-level areas of human visual cortex. <i>Proc. Natl. Acad. Sci. USA</i> <b>109</b>, 1467514680 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1202095109" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1202095109" aria-label="Article reference 22" data-doi="10.1073/pnas.1202095109">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XhsVaqu73K" aria-label="CAS reference 22">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22908274" aria-label="PubMed reference 22">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3437858" aria-label="PubMed Central reference 22">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Top-down%20attention%20switches%20coupling%20between%20low-level%20and%20high-level%20areas%20of%20human%20visual%20cortex&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1202095109&amp;volume=109&amp;pages=14675-14680&amp;publication_year=2012&amp;author=Al-Aidroos%2CN&amp;author=Said%2CCP&amp;author=Turk-Browne%2CNB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23"><p class="c-article-references__text" id="ref-CR23">Weissman, D.H., Roberts, K.C., Visscher, K.M. &amp; Woldorff, M.G. The neural bases of momentary lapses in attention. <i>Nat. Neurosci.</i> <b>9</b>, 971978 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1727" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1727" aria-label="Article reference 23" data-doi="10.1038/nn1727">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD28XmtFCmtr0%3D" aria-label="CAS reference 23">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16767087" aria-label="PubMed reference 23">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20neural%20bases%20of%20momentary%20lapses%20in%20attention&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1727&amp;volume=9&amp;pages=971-978&amp;publication_year=2006&amp;author=Weissman%2CDH&amp;author=Roberts%2CKC&amp;author=Visscher%2CKM&amp;author=Woldorff%2CMG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24"><p class="c-article-references__text" id="ref-CR24">Leber, A.B., Turk-Browne, N.B. &amp; Chun, M.M. Neural predictors of moment-to-moment fluctuations in cognitive flexibility. <i>Proc. Natl. Acad. Sci. USA</i> <b>105</b>, 1359213597 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.0805423105" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.0805423105" aria-label="Article reference 24" data-doi="10.1073/pnas.0805423105">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXhtFeqs7fF" aria-label="CAS reference 24">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18757744" aria-label="PubMed reference 24">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2527350" aria-label="PubMed Central reference 24">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20predictors%20of%20moment-to-moment%20fluctuations%20in%20cognitive%20flexibility&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.0805423105&amp;volume=105&amp;pages=13592-13597&amp;publication_year=2008&amp;author=Leber%2CAB&amp;author=Turk-Browne%2CNB&amp;author=Chun%2CMM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25"><p class="c-article-references__text" id="ref-CR25">Miller, E.K. &amp; Cohen, J.D. An integrative theory of prefrontal cortex function. <i>Annu. Rev. Neurosci.</i> <b>24</b>, 167202 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.neuro.24.1.167" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.neuro.24.1.167" aria-label="Article reference 25" data-doi="10.1146/annurev.neuro.24.1.167">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXls1Shsro%3D" aria-label="CAS reference 25">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11283309" aria-label="PubMed reference 25">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20integrative%20theory%20of%20prefrontal%20cortex%20function&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.neuro.24.1.167&amp;volume=24&amp;pages=167-202&amp;publication_year=2001&amp;author=Miller%2CEK&amp;author=Cohen%2CJD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26"><p class="c-article-references__text" id="ref-CR26">Noudoost, B., Chang, M.H., Steinmetz, N.A. &amp; Moore, T. Top-down control of visual attention. <i>Curr. Opin. Neurobiol.</i> <b>20</b>, 183190 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.conb.2010.02.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2010.02.003" aria-label="Article reference 26" data-doi="10.1016/j.conb.2010.02.003">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXlsFCisr8%3D" aria-label="CAS reference 26">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20303256" aria-label="PubMed reference 26">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2901796" aria-label="PubMed Central reference 26">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Top-down%20control%20of%20visual%20attention&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2010.02.003&amp;volume=20&amp;pages=183-190&amp;publication_year=2010&amp;author=Noudoost%2CB&amp;author=Chang%2CMH&amp;author=Steinmetz%2CNA&amp;author=Moore%2CT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27"><p class="c-article-references__text" id="ref-CR27">Todd, M.T., Nystrom, L.E. &amp; Cohen, J.D. Confounds in multivariate pattern analysis: theory and rule representation case study. <i>Neuroimage</i> <b>77</b>, 157165 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2013.03.039" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2013.03.039" aria-label="Article reference 27" data-doi="10.1016/j.neuroimage.2013.03.039">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23558095" aria-label="PubMed reference 27">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Confounds%20in%20multivariate%20pattern%20analysis%3A%20theory%20and%20rule%20representation%20case%20study&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2013.03.039&amp;volume=77&amp;pages=157-165&amp;publication_year=2013&amp;author=Todd%2CMT&amp;author=Nystrom%2CLE&amp;author=Cohen%2CJD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28"><p class="c-article-references__text" id="ref-CR28">Haxby, J.V. et al. Distributed and overlapping representations of faces and objects in ventral temporal cortex. <i>Science</i> <b>293</b>, 24252430 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1063736" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1063736" aria-label="Article reference 28" data-doi="10.1126/science.1063736">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXntlGqsbs%3D" aria-label="CAS reference 28">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11577229" aria-label="PubMed reference 28">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20and%20overlapping%20representations%20of%20faces%20and%20objects%20in%20ventral%20temporal%20cortex&amp;journal=Science&amp;doi=10.1126%2Fscience.1063736&amp;volume=293&amp;pages=2425-2430&amp;publication_year=2001&amp;author=Haxby%2CJV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29"><p class="c-article-references__text" id="ref-CR29">Woolgar, A., Hampshire, A., Thompson, R. &amp; Duncan, J. Adaptive coding of task-relevant information in human frontoparietal cortex. <i>J. Neurosci.</i> <b>31</b>, 1459214599 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2616-11.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2616-11.2011" aria-label="Article reference 29" data-doi="10.1523/JNEUROSCI.2616-11.2011">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhtlCgtr3P" aria-label="CAS reference 29">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21994375" aria-label="PubMed reference 29">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6703398" aria-label="PubMed Central reference 29">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20coding%20of%20task-relevant%20information%20in%20human%20frontoparietal%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2616-11.2011&amp;volume=31&amp;pages=14592-14599&amp;publication_year=2011&amp;author=Woolgar%2CA&amp;author=Hampshire%2CA&amp;author=Thompson%2CR&amp;author=Duncan%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30"><p class="c-article-references__text" id="ref-CR30">Turk-Browne, N.B. Functional interactions as big data in the human brain. <i>Science</i> <b>342</b>, 580584 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1238409" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1238409" aria-label="Article reference 30" data-doi="10.1126/science.1238409">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhs1yrsLzO" aria-label="CAS reference 30">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24179218" aria-label="PubMed reference 30">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3970973" aria-label="PubMed Central reference 30">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20interactions%20as%20big%20data%20in%20the%20human%20brain&amp;journal=Science&amp;doi=10.1126%2Fscience.1238409&amp;volume=342&amp;pages=580-584&amp;publication_year=2013&amp;author=Turk-Browne%2CNB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31"><p class="c-article-references__text" id="ref-CR31">Reddy, L., Kanwisher, N.G. &amp; VanRullen, R. Attention and biased competition in multi-voxel object representations. <i>Proc. Natl. Acad. Sci. USA</i> <b>106</b>, 2144721452 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.0907330106" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.0907330106" aria-label="Article reference 31" data-doi="10.1073/pnas.0907330106">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXjvFKjsr8%3D" aria-label="CAS reference 31">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19955434" aria-label="PubMed reference 31">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2795499" aria-label="PubMed Central reference 31">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Attention%20and%20biased%20competition%20in%20multi-voxel%20object%20representations&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.0907330106&amp;volume=106&amp;pages=21447-21452&amp;publication_year=2009&amp;author=Reddy%2CL&amp;author=Kanwisher%2CNG&amp;author=VanRullen%2CR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32"><p class="c-article-references__text" id="ref-CR32">Baldauf, D. &amp; Desimone, R. Neural mechanisms of object-based attention. <i>Science</i> <b>344</b>, 424427 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1247003" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1247003" aria-label="Article reference 32" data-doi="10.1126/science.1247003">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXmsFWmtLg%3D" aria-label="CAS reference 32">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24763592" aria-label="PubMed reference 32">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20mechanisms%20of%20object-based%20attention&amp;journal=Science&amp;doi=10.1126%2Fscience.1247003&amp;volume=344&amp;pages=424-427&amp;publication_year=2014&amp;author=Baldauf%2CD&amp;author=Desimone%2CR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33"><p class="c-article-references__text" id="ref-CR33">O'Reilly, R.C. &amp; Frank, M. Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia. <i>Neural Comput.</i> <b>18</b>, 283328 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/089976606775093909" data-track-action="article reference" href="https://doi.org/10.1162%2F089976606775093909" aria-label="Article reference 33" data-doi="10.1162/089976606775093909">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16378516" aria-label="PubMed reference 33">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Making%20working%20memory%20work%3A%20a%20computational%20model%20of%20learning%20in%20the%20prefrontal%20cortex%20and%20basal%20ganglia&amp;journal=Neural%20Comput.&amp;doi=10.1162%2F089976606775093909&amp;volume=18&amp;pages=283-328&amp;publication_year=2006&amp;author=O%27Reilly%2CRC&amp;author=Frank%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34"><p class="c-article-references__text" id="ref-CR34">Kravitz, A.V. et al. Regulation of parkinsonian motor behaviours by optogenetic control of basal ganglia circuitry. <i>Nature</i> <b>466</b>, 622626 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature09159" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature09159" aria-label="Article reference 34" data-doi="10.1038/nature09159">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXosVKhsLs%3D" aria-label="CAS reference 34">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20613723" aria-label="PubMed reference 34">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3552484" aria-label="PubMed Central reference 34">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Regulation%20of%20parkinsonian%20motor%20behaviours%20by%20optogenetic%20control%20of%20basal%20ganglia%20circuitry&amp;journal=Nature&amp;doi=10.1038%2Fnature09159&amp;volume=466&amp;pages=622-626&amp;publication_year=2010&amp;author=Kravitz%2CAV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35"><p class="c-article-references__text" id="ref-CR35">Wiecki, T.V. &amp; Frank, M.J. A computational model of inhibitory control in frontal cortex and basal ganglia. <i>Psychol. Rev.</i> <b>120</b>, 329355 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0031542" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0031542" aria-label="Article reference 35" data-doi="10.1037/a0031542">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23586447" aria-label="PubMed reference 35">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20computational%20model%20of%20inhibitory%20control%20in%20frontal%20cortex%20and%20basal%20ganglia&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2Fa0031542&amp;volume=120&amp;pages=329-355&amp;publication_year=2013&amp;author=Wiecki%2CTV&amp;author=Frank%2CMJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36"><p class="c-article-references__text" id="ref-CR36">Foerde, K. &amp; Shohamy, D. The role of the basal ganglia in learning and memory: insight from Parkinson's disease. <i>Neurobiol. Learn. Mem.</i> <b>96</b>, 624636 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.nlm.2011.08.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.nlm.2011.08.006" aria-label="Article reference 36" data-doi="10.1016/j.nlm.2011.08.006">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhsFCqsL%2FN" aria-label="CAS reference 36">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21945835" aria-label="PubMed reference 36">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3772079" aria-label="PubMed Central reference 36">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20the%20basal%20ganglia%20in%20learning%20and%20memory%3A%20insight%20from%20Parkinson%27s%20disease&amp;journal=Neurobiol.%20Learn.%20Mem.&amp;doi=10.1016%2Fj.nlm.2011.08.006&amp;volume=96&amp;pages=624-636&amp;publication_year=2011&amp;author=Foerde%2CK&amp;author=Shohamy%2CD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37"><p class="c-article-references__text" id="ref-CR37">Frank, M.J. &amp; Badre, D. Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis. <i>Cereb. Cortex</i> <b>22</b>, 509526 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhr114" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhr114" aria-label="Article reference 37" data-doi="10.1093/cercor/bhr114">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21693490" aria-label="PubMed reference 37">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Mechanisms%20of%20hierarchical%20reinforcement%20learning%20in%20corticostriatal%20circuits%201%3A%20computational%20analysis&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhr114&amp;volume=22&amp;pages=509-526&amp;publication_year=2012&amp;author=Frank%2CMJ&amp;author=Badre%2CD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38"><p class="c-article-references__text" id="ref-CR38">Biggs, A.T. &amp; Mitroff, S.R. Different predictors of multiple-target search accuracy between nonprofessional and professional visual searchers. <i>Q. J. Exp. Psychol. (Hove)</i> <b>67</b>, 13351348 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/17470218.2013.859715" data-track-action="article reference" href="https://doi.org/10.1080%2F17470218.2013.859715" aria-label="Article reference 38" data-doi="10.1080/17470218.2013.859715">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Different%20predictors%20of%20multiple-target%20search%20accuracy%20between%20nonprofessional%20and%20professional%20visual%20searchers&amp;journal=Q.%20J.%20Exp.%20Psychol.%20%28Hove%29&amp;doi=10.1080%2F17470218.2013.859715&amp;volume=67&amp;pages=1335-1348&amp;publication_year=2014&amp;author=Biggs%2CAT&amp;author=Mitroff%2CSR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39"><p class="c-article-references__text" id="ref-CR39">Disner, S.G., Beevers, C.G., Haigh, E.A.P. &amp; Beck, A.T. Neural mechanisms of the cognitive model of depression. <i>Nat. Rev. Neurosci.</i> <b>12</b>, 467477 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn3027" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn3027" aria-label="Article reference 39" data-doi="10.1038/nrn3027">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXosFegtbk%3D" aria-label="CAS reference 39">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21731066" aria-label="PubMed reference 39">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20mechanisms%20of%20the%20cognitive%20model%20of%20depression&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn3027&amp;volume=12&amp;pages=467-477&amp;publication_year=2011&amp;author=Disner%2CSG&amp;author=Beevers%2CCG&amp;author=Haigh%2CEAP&amp;author=Beck%2CAT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40"><p class="c-article-references__text" id="ref-CR40">Shallice, T. et al. Executive function profile of children with attention deficit hyperactivity disorder. <i>Dev. Neuropsychol.</i> <b>21</b>, 4371 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1207/S15326942DN2101_3" data-track-action="article reference" href="https://doi.org/10.1207%2FS15326942DN2101_3" aria-label="Article reference 40" data-doi="10.1207/S15326942DN2101_3">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12058835" aria-label="PubMed reference 40">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Executive%20function%20profile%20of%20children%20with%20attention%20deficit%20hyperactivity%20disorder&amp;journal=Dev.%20Neuropsychol.&amp;doi=10.1207%2FS15326942DN2101_3&amp;volume=21&amp;pages=43-71&amp;publication_year=2002&amp;author=Shallice%2CT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41"><p class="c-article-references__text" id="ref-CR41">Chadick, J.Z. &amp; Gazzaley, A. Differential coupling of visual cortex with default network or frontal-parietal network based on goals. <i>Nat. Neurosci.</i> <b>14</b>, 830832 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.2823" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.2823" aria-label="Article reference 41" data-doi="10.1038/nn.2823">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXmslSrs7s%3D" aria-label="CAS reference 41">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21623362" aria-label="PubMed reference 41">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3125492" aria-label="PubMed Central reference 41">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Differential%20coupling%20of%20visual%20cortex%20with%20default%20network%20or%20frontal-parietal%20network%20based%20on%20goals&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.2823&amp;volume=14&amp;pages=830-832&amp;publication_year=2011&amp;author=Chadick%2CJZ&amp;author=Gazzaley%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42"><p class="c-article-references__text" id="ref-CR42">Moore, K.S., Yi, D.-J. &amp; Chun, M. The effect of attention on repetition suppression and multivoxel pattern similarity. <i>J. Cogn. Neurosci.</i> <b>25</b>, 13051314 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn_a_00387" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn_a_00387" aria-label="Article reference 42" data-doi="10.1162/jocn_a_00387">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23489143" aria-label="PubMed reference 42">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20attention%20on%20repetition%20suppression%20and%20multivoxel%20pattern%20similarity&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn_a_00387&amp;volume=25&amp;pages=1305-1314&amp;publication_year=2013&amp;author=Moore%2CKS&amp;author=Yi%2CD-J&amp;author=Chun%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43"><p class="c-article-references__text" id="ref-CR43">Serences, J.T., Schwarzbach, J., Courtney, S.M., Golay, X. &amp; Yantis, S. Control of object-based attention in human cortex. <i>Cereb. Cortex</i> <b>14</b>, 13461357 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhh095" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhh095" aria-label="Article reference 43" data-doi="10.1093/cercor/bhh095">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15166105" aria-label="PubMed reference 43">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Control%20of%20object-based%20attention%20in%20human%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhh095&amp;volume=14&amp;pages=1346-1357&amp;publication_year=2004&amp;author=Serences%2CJT&amp;author=Schwarzbach%2CJ&amp;author=Courtney%2CSM&amp;author=Golay%2CX&amp;author=Yantis%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44"><p class="c-article-references__text" id="ref-CR44">Efron, B. &amp; Tibshirani, R. Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy. <i>Stat. Sci.</i> <b>1</b>, 5475 (1986).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Bootstrap%20methods%20for%20standard%20errors%2C%20confidence%20intervals%2C%20and%20other%20measures%20of%20statistical%20accuracy&amp;journal=Stat.%20Sci.&amp;volume=1&amp;pages=54-75&amp;publication_year=1986&amp;author=Efron%2CB&amp;author=Tibshirani%2CR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45"><p class="c-article-references__text" id="ref-CR45">Pernet, C.R., Wilcox, R.R. &amp; Rousselet, G.A. Robust correlation analyses: false positive and power validation using a new open source Matlab toolbox. <i>Front. Psychol.</i> <b>3</b>, 606 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fpsyg.2012.00606" data-track-action="article reference" href="https://doi.org/10.3389%2Ffpsyg.2012.00606" aria-label="Article reference 45" data-doi="10.3389/fpsyg.2012.00606">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23335907" aria-label="PubMed reference 45">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3541537" aria-label="PubMed Central reference 45">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20correlation%20analyses%3A%20false%20positive%20and%20power%20validation%20using%20a%20new%20open%20source%20Matlab%20toolbox&amp;journal=Front.%20Psychol.&amp;doi=10.3389%2Ffpsyg.2012.00606&amp;volume=3&amp;publication_year=2013&amp;author=Pernet%2CCR&amp;author=Wilcox%2CRR&amp;author=Rousselet%2CGA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46"><p class="c-article-references__text" id="ref-CR46">Nichols, T.E. &amp; Holmes, A.P. Nonparametric permutation tests for functional neuroimaging: a primer with examples. <i>Hum. Brain Mapp.</i> <b>15</b>, 125 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/hbm.1058" data-track-action="article reference" href="https://doi.org/10.1002%2Fhbm.1058" aria-label="Article reference 46" data-doi="10.1002/hbm.1058">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11747097" aria-label="PubMed reference 46">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonparametric%20permutation%20tests%20for%20functional%20neuroimaging%3A%20a%20primer%20with%20examples&amp;journal=Hum.%20Brain%20Mapp.&amp;doi=10.1002%2Fhbm.1058&amp;volume=15&amp;pages=1-25&amp;publication_year=2002&amp;author=Nichols%2CTE&amp;author=Holmes%2CAP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47"><p class="c-article-references__text" id="ref-CR47">Smith, S.M. &amp; Nichols, T.E. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. <i>Neuroimage</i> <b>44</b>, 8398 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2008.03.061" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2008.03.061" aria-label="Article reference 47" data-doi="10.1016/j.neuroimage.2008.03.061">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18501637" aria-label="PubMed reference 47">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Threshold-free%20cluster%20enhancement%3A%20addressing%20problems%20of%20smoothing%2C%20threshold%20dependence%20and%20localisation%20in%20cluster%20inference&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2008.03.061&amp;volume=44&amp;pages=83-98&amp;publication_year=2009&amp;author=Smith%2CSM&amp;author=Nichols%2CTE">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48"><p class="c-article-references__text" id="ref-CR48">Donaldson, W. Measuring recognition memory. <i>J. Exp. Psychol. Gen.</i> <b>121</b>, 275277 (1992).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0096-3445.121.3.275" data-track-action="article reference" href="https://doi.org/10.1037%2F0096-3445.121.3.275" aria-label="Article reference 48" data-doi="10.1037/0096-3445.121.3.275">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK3s%2FhvVyqsg%3D%3D" aria-label="CAS reference 48">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1402701" aria-label="PubMed reference 48">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20recognition%20memory&amp;journal=J.%20Exp.%20Psychol.%20Gen.&amp;doi=10.1037%2F0096-3445.121.3.275&amp;volume=121&amp;pages=275-277&amp;publication_year=1992&amp;author=Donaldson%2CW">
                    Google Scholar</a>
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.3940?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>This work was supported by US National Institutes of Health grant R01EY021755, US National Science Foundation (NSF) grant BCS1229597, NSF fellowship DGE1148900 and the John Templeton Foundation. The opinions expressed in this publication are those of the authors and do not necessarily reflect the views of these funding agencies.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey, USA</p><p class="c-article-author-affiliation__authors-list">Megan T deBettencourt,Jonathan D Cohen,Ray F Lee,Kenneth A Norman&amp;Nicholas B Turk-Browne</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Psychology, Princeton University, Princeton, New Jersey, USA</p><p class="c-article-author-affiliation__authors-list">Jonathan D Cohen,Kenneth A Norman&amp;Nicholas B Turk-Browne</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Megan_T-deBettencourt-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Megan T deBettencourt</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Megan%20T%20deBettencourt" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Megan%20T%20deBettencourt" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Megan%20T%20deBettencourt%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Jonathan_D-Cohen-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Jonathan D Cohen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Jonathan%20D%20Cohen" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jonathan%20D%20Cohen" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jonathan%20D%20Cohen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Ray_F-Lee-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Ray F Lee</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Ray%20F%20Lee" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ray%20F%20Lee" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ray%20F%20Lee%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Kenneth_A-Norman-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Kenneth A Norman</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Kenneth%20A%20Norman" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kenneth%20A%20Norman" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kenneth%20A%20Norman%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Nicholas_B-Turk_Browne-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Nicholas B Turk-Browne</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Nicholas%20B%20Turk-Browne" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nicholas%20B%20Turk-Browne" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nicholas%20B%20Turk-Browne%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>M.T.dB., J.D.C., K.A.N. and N.B.T.-B. designed the experiment, discussed the data and wrote the paper. M.T.dB. and R.F.L. developed data acquisition and analysis tools. M.T.dB. collected and analyzed the data. All authors read and commented on the manuscript.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:ntb@princeton.edu">Nicholas B Turk-Browne</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading">Competing interests</h3>
                <p>The authors declare no competing financial interests.</p>
              
            </div></div></section><section data-title="Integrated supplementary information"><div class="c-article-section" id="Sec17-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec17">Integrated supplementary information</h2><div class="c-article-section__content" id="Sec17-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig6"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 1 study procedure." href="/articles/nn.3940/figures/6" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig6_ESM.jpg">Supplementary Figure 1 Study procedure.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>(<b>a</b>) Participants completed three sessions on different days, with different numbers of task runs. (<b>b</b>) Each run contained eight blocks of the sustained attention task. The pre-training, post-training, and stable blocks of the rtfMRI training sessions contained composite stimuli with an equal mixture of faces and scenes. In the feedback blocks of the rtfMRI session, the mixture of images was determined by real-time analysis of brain activity. (<b>c</b>) Each block began with a cue (1 s) that indicated the attended category (e.g., scene) and target subcategory (e.g., indoor). This was followed by a brief fixation period (1 s) and then 50 sequential stimuli (1 s each, no interstimulus interval), of which 90% were targets and 10% were lures. The blocks ended with a fixation period (46 s).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig7"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 2 average rts surrounding lur" href="/articles/nn.3940/figures/7" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig7_ESM.jpg">Supplementary Figure 2 Average RTs surrounding lures.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Green lines correspond to trials around correct rejections (CRs), where there was no behavioral response to the lure (presented at time = 0). Red lines correspond to trials around false alarms (FAs), where participants mistakenly responded to the lure. RTs were significantly slower prior to CRs than FAs (all timepoints, ps &lt; 0.00001), consistent with the idea that FAs occurred when participants started responding habitually and were less attentive to the task. Error bars represent +/1 s.e.m.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 3 removing the influence of r" href="/articles/nn.3940/figures/8" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig8_ESM.jpg">Supplementary Figure 3 Removing the influence of RT.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Both RT and classifier evidence for the task-relevant vs. task-irrelevant category were higher preceding CRs. To verify that the classifier was predictive of behavioral accuracy and not merely correlated with RT, we regressed RT out of classifier output and behavioral accuracy across trials and performed a partial correlation analysis. Green lines correspond to regression fits for feedback participants, and blue lines correspond to regression fits for control participants. The black line is the average fit. The relationship between classifier output and behavioral accuracy remained robust (p &lt; 0.00001).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig9"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 4 classifier-to-stimulus tran" href="/articles/nn.3940/figures/9" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig9_ESM.jpg">Supplementary Figure 4 Classifier-to-stimulus transfer function.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The volume-by-volume classifier output for the task-relevant minus task-irrelevant category was mapped to the proportion of the image from the task-relevant category using a sigmoidal function. The inflection point on the classifier axis was set to 0.60, based on the average decoding accuracy in a pilot study. Given the nonlinearities in the function, this helped calibrate the feedback to a more sensitive range of classifier values. Image proportion ranged from 0.17 to 0.98, preventing the task-relevant image from ever disappearing completely, and providing a foothold for recovery from a serious lapse.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig10"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 5 histogram of feedback." href="/articles/nn.3940/figures/10" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_Article_BFnn3940_Fig10_ESM.jpg">Supplementary Figure 5 Histogram of feedback.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The bottom x-axis refers to proportion of the image from the task-relevant category in each composite stimulus. The y-axis refers to the number of TRs that contained stimuli with this mixture (in bins of width = 0.04) across all feedback blocks from all participants in the feedback group. The top x-axis depicts the correspondence between classifier output and feedback (computed using the transfer function in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3940#Fig9">Supplementary Fig. 4</a>). The most frequent values were in the highest and lowest bins, as well as in the bin including feedback of 0.5. The highest bin reflects cases in which the image from the task-relevant category was 98% of the composite stimulus. The lowest bin reflects cases in which the image from the task-irrelevant category was 83% of the composite stimulus. The bin with 0.5 was frequent because every block began with an equal mixture of the images from the task-relevant and task-irrelevant categories.</p></div></div></div></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Supplementary information</h2><div class="c-article-section__content" id="Sec18-content"><div data-test="supplementary-info"><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM45"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary text and figures" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_BFnn3940_MOESM45_ESM.pdf" data-supp-info-image="">Supplementary Text and Figures</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Supplementary Figures 15 (PDF 1239 kb)</p></div></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM46"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary methods checklist (pdf 484 kb)" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_BFnn3940_MOESM46_ESM.pdf" data-supp-info-image="">Supplementary Methods Checklist (PDF 484 kb)</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM47"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="example neurofeedback block." href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.3940/MediaObjects/41593_2015_BFnn3940_MOESM47_ESM.mov" data-supp-info-image="">Example neurofeedback block.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>This video depicts the real-time data analysis and stimulus-updating procedure during a feedback block. In this block, the participant was instructed to attend to scenes and respond when a scene was indoors. The left window shows what the participant saw. The top-right window shows the real-time fMRI estimate of the participant's attentional state (classifier evidence for task-relevant minus task-irrelevant categories; here, scene minus face outputs). The bottom-right window shows the mixture proportions of the composite stimuli. The mixture was initialized at 50% face/50% scene, and then updated on the basis of a moving window of classifier evidence over the preceding three volumes using a transfer function. (MOV 5100 kb)</p></div></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Closed-loop%20training%20of%20attention%20with%20real-time%20brain%20imaging&amp;author=Megan%20T%20deBettencourt%20et%20al&amp;contentID=10.1038%2Fnn.3940&amp;copyright=Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2015-02-09&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/nn.3940" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/nn.3940" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">deBettencourt, M., Cohen, J., Lee, R. <i>et al.</i> Closed-loop training of attention with real-time brain imaging.
                    <i>Nat Neurosci</i> <b>18</b>, 470475 (2015). https://doi.org/10.1038/nn.3940</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.3940?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2014-10-01">01 October 2014</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-01-09">09 January 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-02-09">09 February 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-03">March 2015</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/nn.3940</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Performance-linked visual feedback slows response times during a sustained attention task" href="https://doi.org/10.1186/s41235-023-00487-w">
                                        Performance-linked visual feedback slows response times during a sustained attention task
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Ashley C. Steinkrauss</li><li>Anjum F. Shaikh</li><li>Jeff Moher</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Cognitive Research: Principles and Implications</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Optimising the classification of feature-based attention in frequency-tagged electroencephalography data" href="https://doi.org/10.1038/s41597-022-01398-z">
                                        Optimising the classification of feature-based attention in frequency-tagged electroencephalography data
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Angela I. Renton</li><li>David R. Painter</li><li>Jason B. Mattingley</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Data</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Basal ganglia-cortical connectivity underlies self-regulation of brain oscillations in humans" href="https://doi.org/10.1038/s42003-022-03665-6">
                                        Basal ganglia-cortical connectivity underlies self-regulation of brain oscillations in humans
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Kazumi Kasahara</li><li>Charles S. DaSalla</li><li>Takashi Hanakawa</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Communications Biology</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Voluntary control of semantic neural representations by imagery with conflicting visual stimulation" href="https://doi.org/10.1038/s42003-022-03137-x">
                                        Voluntary control of semantic neural representations by imagery with conflicting visual stimulation
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Ryohei Fukuma</li><li>Takufumi Yanagisawa</li><li>Haruhiko Kishima</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Communications Biology</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Inducing a mental context for associative memory formation with real-time fMRI neurofeedback" href="https://doi.org/10.1038/s41598-022-25799-7">
                                        Inducing a mental context for associative memory formation with real-time fMRI neurofeedback
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Silvy H. P. Collin</li><li>Philip L. C. van den Broek</li><li>Christian F. Doeller</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2022)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3940.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3940.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    
        <div class="c-article-associated-content__container">
            <section>
                <h2 class="c-article-associated-content__title u-mb-24">Associated content</h2>
                
                    
                    
                        <div class="u-full-height u-mb-24">
                            
    <article class="u-full-height c-card c-card--flush">
        <div class="c-card__layout u-full-height">
            <div class="c-card__body">
                <h3 class="c-card__title">
                    <a href="https://www.nature.com/articles/nn.3962"
                       class="c-card__link u-link-inherit"
                       data-track="click"
                       data-track-action="view article"
                       data-track-category="associated content"
                       
                       data-track-label="news_and_views">Attention: feedback focuses a wandering mind</a>
                </h3>
                
<ul data-test="author-list" class="c-author-list c-author-list--compact">
    <li>Edward Awh</li><li>Edward K Vogel</li>
</ul>

                
    <div class="c-card__section c-meta">
        
            <span class="c-meta__item">Nature Neuroscience</span>
        
        <span class="c-meta__item" data-test="article.type"><span class="c-meta__type">News &amp; Views</span></span>
        
        
            <time class="c-meta__item" datetime="2015-02-24">24 Feb 2015</time>
        
    </div>

            </div>
        </div>
    </article>


                        </div>
                    
                
            </section>
        </div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer[0] = window.dataLayer[0] || {};
            window.dataLayer[0].content = window.dataLayer[0].content || {};
            window.dataLayer[0].content.associatedContentTypes = "news_and_views";
        </script>
    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=nn.3940;doi=10.1038/nn.3940;techmeta=36,57,59;subjmeta=1310,1595,2150,2649,378,477,631;kwrd=Attention,Cognitive+control,Learning+and+memory,Psychology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1525553206&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.3940%26doi%3D10.1038/nn.3940%26techmeta%3D36,57,59%26subjmeta%3D1310,1595,2150,2649,378,477,631%26kwrd%3DAttention,Cognitive+control,Learning+and+memory,Psychology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1525553206&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.3940%26doi%3D10.1038/nn.3940%26techmeta%3D36,57,59%26subjmeta%3D1310,1595,2150,2649,378,477,631%26kwrd%3DAttention,Cognitive+control,Learning+and+memory,Psychology"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter  what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/nn.3940&amp;format=js&amp;last_modified=2015-03-01" async></script>
<img src="/29fsgl4q/article/nn.3940" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>