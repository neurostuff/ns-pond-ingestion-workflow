<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>A functional and perceptual signature of the second visual area in primates | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"extrastriate-cortex;neural-encoding","webtrendsContentCategory":null,"webtrendsContentCollection":"Computational Biology","webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/nn.3402"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Jeremy Freeman","Corey M Ziemba","David J Heeger","Eero P Simoncelli","J Anthony Movshon"],"publishedAt":1368921600,"publishedAtString":"2013-05-19","title":"A functional and perceptual signature of the second visual area in primates","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"16","issue":"7"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":{"id":"tmdlscdqmc"}},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"A functional and perceptual signature of the second visual area in primates","description":"The authors examined neuronal responses in V1 and V2 to synthetic texture stimuli that replicate higher-order statistical dependencies found in natural images. V2, but not V1, responded differentially to these textures, in both macaque (single neurons) and human (fMRI). Human detection of naturalistic structure in the same images was predicted by V2 responses, suggesting a role for V2 in representing natural image structure. There is no generally accepted account of the function of the second visual cortical area (V2), partly because no simple response properties robustly distinguish V2 neurons from those in primary visual cortex (V1). We constructed synthetic stimuli replicating the higher-order statistical dependencies found in natural texture images and used them to stimulate macaque V1 and V2 neurons. Most V2 cells responded more vigorously to these textures than to control stimuli lacking naturalistic structure; V1 cells did not. Functional magnetic resonance imaging (fMRI) measurements in humans revealed differences between V1 and V2 that paralleled the neuronal measurements. The ability of human observers to detect naturalistic structure in different types of texture was well predicted by the strength of neuronal and fMRI responses in V2 but not in V1. Together, these results reveal a particular functional role for V2 in the representation of natural image structure.","datePublished":"2013-05-19T00:00:00Z","dateModified":"2013-05-19T00:00:00Z","pageStart":"974","pageEnd":"981","sameAs":"https://doi.org/10.1038/nn.3402","keywords":["Extrastriate cortex","Neural encoding","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig1_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig2_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig3_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig4_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig5_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig6_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig7_HTML.jpg"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"16","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Jeremy Freeman","affiliation":[{"name":"Center for Neural Science, New York University","address":{"name":"Center for Neural Science, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Present address: Janelia Farm Research Campus, Howard Hughes Medical Institute, Ashburn, Virginia, USA.","address":{"name":"Present address: Janelia Farm Research Campus, Howard Hughes Medical Institute, Ashburn, Virginia, USA., ","@type":"PostalAddress"},"@type":"Organization"}],"email":"freemanj11@janelia.hhmi.org","@type":"Person"},{"name":"Corey M Ziemba","affiliation":[{"name":"Center for Neural Science, New York University","address":{"name":"Center for Neural Science, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"David J Heeger","affiliation":[{"name":"Center for Neural Science, New York University","address":{"name":"Center for Neural Science, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"New York University","address":{"name":"Department of Psychology, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Eero P Simoncelli","affiliation":[{"name":"Center for Neural Science, New York University","address":{"name":"Center for Neural Science, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"New York University","address":{"name":"Department of Psychology, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Howard Hughes Medical Institute, New York University","address":{"name":"Howard Hughes Medical Institute, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Courant Institute of Mathematical Sciences, New York University","address":{"name":"Courant Institute of Mathematical Sciences, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"J Anthony Movshon","affiliation":[{"name":"Center for Neural Science, New York University","address":{"name":"Center for Neural Science, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"New York University","address":{"name":"Department of Psychology, New York University, New York, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/nn.3402">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="A functional and perceptual signature of the second visual area in primates"/>
    <meta name="dc.source" content="Nature Neuroscience 2013 16:7"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2013-05-19"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2013 Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2013 Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="The authors examined neuronal responses in V1 and V2 to synthetic texture stimuli that replicate higher-order statistical dependencies found in natural images. V2, but not V1, responded differentially to these textures, in both macaque (single neurons) and human (fMRI). Human detection of naturalistic structure in the same images was predicted by V2 responses, suggesting a role for V2 in representing natural image structure. There is no generally accepted account of the function of the second visual cortical area (V2), partly because no simple response properties robustly distinguish V2 neurons from those in primary visual cortex (V1). We constructed synthetic stimuli replicating the higher-order statistical dependencies found in natural texture images and used them to stimulate macaque V1 and V2 neurons. Most V2 cells responded more vigorously to these textures than to control stimuli lacking naturalistic structure; V1 cells did not. Functional magnetic resonance imaging (fMRI) measurements in humans revealed differences between V1 and V2 that paralleled the neuronal measurements. The ability of human observers to detect naturalistic structure in different types of texture was well predicted by the strength of neuronal and fMRI responses in V2 but not in V1. Together, these results reveal a particular functional role for V2 in the representation of natural image structure."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2013-05-19"/>
    <meta name="prism.volume" content="16"/>
    <meta name="prism.number" content="7"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="974"/>
    <meta name="prism.endingPage" content="981"/>
    <meta name="prism.copyright" content="2013 Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/nn.3402"/>
    <meta name="prism.doi" content="doi:10.1038/nn.3402"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/nn.3402.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/nn.3402"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="A functional and perceptual signature of the second visual area in primates"/>
    <meta name="citation_volume" content="16"/>
    <meta name="citation_issue" content="7"/>
    <meta name="citation_publication_date" content="2013/07"/>
    <meta name="citation_online_date" content="2013/05/19"/>
    <meta name="citation_firstpage" content="974"/>
    <meta name="citation_lastpage" content="981"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/nn.3402"/>
    <meta name="DOI" content="10.1038/nn.3402"/>
    <meta name="size" content="192347"/>
    <meta name="citation_doi" content="10.1038/nn.3402"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/nn.3402&amp;api_key="/>
    <meta name="description" content="The authors examined neuronal responses in V1 and V2 to synthetic texture stimuli that replicate higher-order statistical dependencies found in natural images. V2, but not V1, responded differentially to these textures, in both macaque (single neurons) and human (fMRI). Human detection of naturalistic structure in the same images was predicted by V2 responses, suggesting a role for V2 in representing natural image structure. There is no generally accepted account of the function of the second visual cortical area (V2), partly because no simple response properties robustly distinguish V2 neurons from those in primary visual cortex (V1). We constructed synthetic stimuli replicating the higher-order statistical dependencies found in natural texture images and used them to stimulate macaque V1 and V2 neurons. Most V2 cells responded more vigorously to these textures than to control stimuli lacking naturalistic structure; V1 cells did not. Functional magnetic resonance imaging (fMRI) measurements in humans revealed differences between V1 and V2 that paralleled the neuronal measurements. The ability of human observers to detect naturalistic structure in different types of texture was well predicted by the strength of neuronal and fMRI responses in V2 but not in V1. Together, these results reveal a particular functional role for V2 in the representation of natural image structure."/>
    <meta name="dc.creator" content="Freeman, Jeremy"/>
    <meta name="dc.creator" content="Ziemba, Corey M"/>
    <meta name="dc.creator" content="Heeger, David J"/>
    <meta name="dc.creator" content="Simoncelli, Eero P"/>
    <meta name="dc.creator" content="Movshon, J Anthony"/>
    <meta name="dc.subject" content="Extrastriate cortex"/>
    <meta name="dc.subject" content="Neural encoding"/>
    <meta name="citation_reference" content="citation_journal_title=Brain Res.; citation_title=The effect of striate cortex cooling on area 18 cells in the monkey; citation_author=PH Schiller, JG Malpeli; citation_volume=126; citation_publication_date=1977; citation_pages=366-369; citation_doi=10.1016/0006-8993(77)90734-X; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Neurosci.; citation_title=The circuitry of V1 and V2: integration of color, form, and motion; citation_author=LC Sincich, JC Horton; citation_volume=28; citation_publication_date=2005; citation_pages=303-326; citation_doi=10.1146/annurev.neuro.28.061604.135731; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Mechanisms of contour perception in monkey visual cortex. II. Contours bridging gaps; citation_author=E Peterhans, RVD Heydt; citation_volume=9; citation_publication_date=1989; citation_pages=1749-1763; citation_doi=10.1523/JNEUROSCI.09-05-01749.1989; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Selectivity for complex shapes in primate visual area V2; citation_author=J Hegd&#233;, DCV Essen; citation_volume=20; citation_publication_date=2000; citation_pages=RC61-RC66; citation_doi=10.1523/JNEUROSCI.20-05-j0001.2000; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=A comparative study of shape representation in macaque visual areas v2 and v4; citation_author=J Hegd&#233;, DCV Essen; citation_volume=17; citation_publication_date=2007; citation_pages=1100-1116; citation_doi=10.1093/cercor/bhl020; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Dynamics of subjective contour formation in the early visual cortex; citation_author=TS Lee, M Nguyen; citation_volume=98; citation_publication_date=2001; citation_pages=1907-1911; citation_doi=10.1073/pnas.98.4.1907; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Vis. Neurosci.; citation_title=Cartesian and non-Cartesian responses in LGN, V1, and V2 cells; citation_author=LE Mahon, RLD Valois; citation_volume=18; citation_publication_date=2001; citation_pages=973-981; citation_doi=10.1017/S0952523801186141; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Representation of angles embedded within contour stimuli in area V2 of macaque monkeys; citation_author=M Ito, H Komatsu; citation_volume=24; citation_publication_date=2004; citation_pages=3313-3324; citation_doi=10.1523/JNEUROSCI.4364-03.2004; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Neurons in monkey visual area V2 encode combinations of orientations; citation_author=A Anzai, X Peng, DC Van Essen; citation_volume=10; citation_publication_date=2007; citation_pages=1313-1321; citation_doi=10.1038/nn1975; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Neuronal responses to texture-defined form in macaque visual area v2; citation_author=Y El-Shamayleh, JA Movshon; citation_volume=31; citation_publication_date=2011; citation_pages=8543-8555; citation_doi=10.1523/JNEUROSCI.5974-10.2011; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Coding of border ownership in monkey visual cortex; citation_author=H Zhou, HS Friedman, RVD Heydt; citation_volume=20; citation_publication_date=2000; citation_pages=6594-6611; citation_doi=10.1523/JNEUROSCI.20-17-06594.2000; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=A specialization for relative disparity in V2; citation_author=OM Thomas, BG Cumming, AJ Parker; citation_volume=5; citation_publication_date=2002; citation_pages=472-478; citation_doi=10.1038/nn837; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Neural representation of natural images in visual area V2; citation_author=BD Willmore, RJ Prenger, JL Gallant; citation_volume=30; citation_publication_date=2010; citation_pages=2102-2114; citation_doi=10.1523/JNEUROSCI.4099-09.2010; citation_id=CR13"/>
    <meta name="citation_reference" content="Simoncelli, E.P. Statistical models for images: compression, restoration and synthesis. 31st Asilomar Conference on Signals, Systems &amp; Computers 1, 673&#8211;678 (IEEE, 1997)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Natural signal statistics and sensory gain control; citation_author=O Schwartz, EP Simoncelli; citation_volume=4; citation_publication_date=2001; citation_pages=819-825; citation_doi=10.1038/90526; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Emergence of complex cell properties by learning to generalize in natural scenes; citation_author=Y Karklin, MS Lewicki; citation_volume=457; citation_publication_date=2009; citation_pages=83-86; citation_doi=10.1038/nature07481; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=On a common circle: natural scenes and Gestalt rules; citation_author=M Sigman, GA Cecchi, CD Gilbert, MO Magnasco; citation_volume=98; citation_publication_date=2001; citation_pages=1935-1940; citation_doi=10.1073/pnas.98.4.1935; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=Vision Res.; citation_title=Edge co-occurrence in natural images predicts contour grouping performance; citation_author=WS Geisler, JS Perry, BJ Super, DP Gallogly; citation_volume=41; citation_publication_date=2001; citation_pages=711-724; citation_doi=10.1016/S0042-6989(00)00277-7; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Int. J. Comput. Vis.; citation_title=A parametric texture model based on joint statistics of complex wavelet coefficients; citation_author=J Portilla, EP Simoncelli; citation_volume=40; citation_publication_date=2000; citation_pages=49-70; citation_doi=10.1023/A:1026553619983; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Metamers of the ventral stream; citation_author=J Freeman, EP Simoncelli; citation_volume=14; citation_publication_date=2011; citation_pages=1195-1201; citation_doi=10.1038/nn.2889; citation_id=CR20"/>
    <meta name="citation_reference" content="Heeger, D.J. &amp; Bergen, J.R. Pyramid-based texture analysis/synthesis. Proceedings of SIGGRAPH 229&#8211;238 (ACM, 1995)."/>
    <meta name="citation_reference" content="citation_journal_title=Pattern Recognit.; citation_title=Attentive texture similarity as a categorization task: comparing texture synthesis models; citation_author=B Balas; citation_volume=41; citation_publication_date=2008; citation_pages=972-982; citation_doi=10.1016/j.patcog.2007.08.007; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Circuits for local and global signal integration in primary visual cortex; citation_author=A Angelucci; citation_volume=22; citation_publication_date=2002; citation_pages=8633-8646; citation_doi=10.1523/JNEUROSCI.22-19-08633.2002; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Visual field maps in human cortex; citation_author=BA Wandell, SO Dumoulin, AA Brewer; citation_volume=56; citation_publication_date=2007; citation_pages=366-383; citation_doi=10.1016/j.neuron.2007.10.012; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Two retinotopic visual areas in human lateral occipital cortex; citation_author=J Larsson, DJ Heeger; citation_volume=26; citation_publication_date=2006; citation_pages=13128-13142; citation_doi=10.1523/JNEUROSCI.1657-06.2006; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Combining sensory information: mandatory fusion within, but not between, senses; citation_author=JM Hillis, MO Ernst, MS Banks, MS Landy; citation_volume=298; citation_publication_date=2002; citation_pages=1627-1630; citation_doi=10.1126/science.1075396; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=Judgm. Decis. Mak.; citation_title=Running experiments on Amazon Mechanical Turk; citation_author=G Paolacci, J Chandler, P Ipeirotis; citation_volume=5; citation_publication_date=2010; citation_pages=411-419; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=Am. Stat.; citation_title=Estimators of relative importance in linear regression based on variance decomposition; citation_author=U Gr&#246;mping; citation_volume=61; citation_publication_date=2007; citation_pages=139-147; citation_doi=10.1198/000313007X188252; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=A neural model of figure-ground organization; citation_author=E Craft, H Sch&#252;tze, E Niebur, R von der Heydt; citation_volume=97; citation_publication_date=2007; citation_pages=4310-4326; citation_doi=10.1152/jn.00203.2007; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Figure-ground mechanisms provide structure for selective attention; citation_author=FT Qiu, T Sugihara, RVD Heydt; citation_volume=10; citation_publication_date=2007; citation_pages=1492-1499; citation_doi=10.1038/nn1989; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Border ownership selectivity in human early visual cortex and its modulation by attention; citation_author=F Fang, H Boyaci, D Kersten; citation_volume=29; citation_publication_date=2009; citation_pages=460-465; citation_doi=10.1523/JNEUROSCI.4628-08.2009; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Activity in primary visual cortex predicts performance in a visual detection task; citation_author=D Ress, BT Backus, DJ Heeger; citation_volume=3; citation_publication_date=2000; citation_pages=940-945; citation_doi=10.1038/78856; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Orientation selectivity of thalamic input to simple cells of cat visual cortex; citation_author=D Ferster, S Chung, H Wheat; citation_volume=380; citation_publication_date=1996; citation_pages=249-252; citation_doi=10.1038/380249a0; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex; citation_author=R Malach; citation_volume=92; citation_publication_date=1995; citation_pages=8135-8139; citation_doi=10.1073/pnas.92.18.8135; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Perception; citation_title=Human sensitivity to phase perturbations in natural images: a statistical framework; citation_author=MG Thomson, DH Foster, RJ Summers; citation_volume=29; citation_publication_date=2000; citation_pages=1057-1069; citation_doi=10.1068/p2867; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Biol.; citation_title=Cortical sensitivity to visual features in natural scenes; citation_author=G Felsen, J Touryan, F Han, Y Dan; citation_volume=3; citation_publication_date=2005; citation_pages=e342; citation_doi=10.1371/journal.pbio.0030342; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=A natural approach to studying vision; citation_author=G Felsen, Y Dan; citation_volume=8; citation_publication_date=2005; citation_pages=1643-1646; citation_doi=10.1038/nn1608; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=In praise of artifice; citation_author=NC Rust, JA Movshon; citation_volume=8; citation_publication_date=2005; citation_pages=1647-1650; citation_doi=10.1038/nn1606; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Motion opponency in visual cortex; citation_author=DJ Heeger, GM Boynton, JB Demb, E Seidemann, WT Newsome; citation_volume=19; citation_publication_date=1999; citation_pages=7162-7174; citation_doi=10.1523/JNEUROSCI.19-16-07162.1999; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Sound texture perception via statistics of the auditory periphery: evidence from sound synthesis; citation_author=JH McDermott, EP Simoncelli; citation_volume=71; citation_publication_date=2011; citation_pages=926-940; citation_doi=10.1016/j.neuron.2011.06.032; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Cortico-cortical projections in mouse visual cortex are functionally target specific; citation_author=LL Glickfeld, ML Andermann, V Bonin, RC Reid; citation_volume=16; citation_publication_date=2013; citation_pages=219-226; citation_doi=10.1038/nn.3300; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=J. Opt. Soc. Am. A; citation_title=Spatiotemporal energy models for the perception of motion; citation_author=EH Adelson, JR Bergen; citation_volume=2; citation_publication_date=1985; citation_pages=284-299; citation_doi=10.1364/JOSAA.2.000284; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Computational models of cortical visual processing; citation_author=DJ Heeger, EP Simoncelli, JA Movshon; citation_volume=93; citation_publication_date=1996; citation_pages=623-627; citation_doi=10.1073/pnas.93.2.623; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Normalization as a canonical neural computation; citation_author=M Carandini, DJ Heeger; citation_volume=13; citation_publication_date=2012; citation_pages=51-62; citation_doi=10.1038/nrn3136; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=How MT cells analyze the motion of visual patterns; citation_author=NC Rust, V Mante, EP Simoncelli, JA Movshon; citation_volume=9; citation_publication_date=2006; citation_pages=1421-1431; citation_doi=10.1038/nn1786; citation_id=CR45"/>
    <meta name="citation_reference" content="Vintch, B., Zaharia, A.Z., Movshon, J.A. &amp; Simoncelli, E.P. Efficient and direct estimation of a neural subunit model for sensory coding. in Advances in Neural Information Processing Systems vol. 25 (eds. Bartlett, P., Pereira, F.C.N., Burges, C.J.C., Bottou, L. &amp; Weinberger, K.Q.), 3113&#8211;3121 (2012)."/>
    <meta name="citation_reference" content="citation_journal_title=Proc. SPIE; citation_title=On seeing stuff: the perception of materials by humans and machines; citation_author=EH Adelson; citation_volume=4299; citation_publication_date=2001; citation_pages=1; citation_doi=10.1117/12.429489; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons; citation_author=JR Cavanaugh, W Bair, JA Movshon; citation_volume=88; citation_publication_date=2002; citation_pages=2530-2546; citation_doi=10.1152/jn.00692.2001; citation_id=CR48"/>
    <meta name="citation_reference" content="citation_journal_title=Magn. Reson. Med.; citation_title=Robust multiresolution alignment of MRI brain volumes; citation_author=O Nestares, DJ Heeger; citation_volume=43; citation_publication_date=2000; citation_pages=705-715; citation_doi=10.1002/(SICI)1522-2594(200005)43:5&lt;705::AID-MRM13&gt;3.0.CO;2-R; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Investigation of low frequency drift in fMRI signal; citation_author=AM Smith; citation_volume=9; citation_publication_date=1999; citation_pages=526-533; citation_doi=10.1006/nimg.1999.0435; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Brain magnetic resonance imaging with contrast dependent on blood oxygenation; citation_author=S Ogawa, TM Lee, AR Kay, DW Tank; citation_volume=87; citation_publication_date=1990; citation_pages=9868-9872; citation_doi=10.1073/pnas.87.24.9868; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Maps of visual space in human occipital cortex are retinotopic, not spatiotopic; citation_author=JL Gardner, EP Merriam, JA Movshon, DJ Heeger; citation_volume=28; citation_publication_date=2008; citation_pages=3988-3999; citation_doi=10.1523/JNEUROSCI.5476-07.2008; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=Percept. Psychophys.; citation_title=The psychometric function: I. Fitting, sampling, and goodness of fit; citation_author=FA Wichmann, NJ Hill; citation_volume=63; citation_publication_date=2001; citation_pages=1293-1313; citation_doi=10.3758/BF03194544; citation_id=CR53"/>
    <meta name="citation_reference" content="citation_journal_title=J. R. Stat. Soc. Ser. C Appl. Stat.; citation_title=Maximum likelihood estimation of observer error-rates using the EM algorithm; citation_author=A Dawid, A Skene; citation_volume=28; citation_publication_date=1979; citation_pages=20-28; citation_id=CR54"/>
    <meta name="citation_author" content="Freeman, Jeremy"/>
    <meta name="citation_author_institution" content="Center for Neural Science, New York University, New York, USA"/>
    <meta name="citation_author_institution" content="Present address: Janelia Farm Research Campus, Howard Hughes Medical Institute, Ashburn, Virginia, USA., "/>
    <meta name="citation_author" content="Ziemba, Corey M"/>
    <meta name="citation_author_institution" content="Center for Neural Science, New York University, New York, USA"/>
    <meta name="citation_author" content="Heeger, David J"/>
    <meta name="citation_author_institution" content="Center for Neural Science, New York University, New York, USA"/>
    <meta name="citation_author_institution" content="Department of Psychology, New York University, New York, USA"/>
    <meta name="citation_author" content="Simoncelli, Eero P"/>
    <meta name="citation_author_institution" content="Center for Neural Science, New York University, New York, USA"/>
    <meta name="citation_author_institution" content="Department of Psychology, New York University, New York, USA"/>
    <meta name="citation_author_institution" content="Howard Hughes Medical Institute, New York University, New York, USA"/>
    <meta name="citation_author_institution" content="Courant Institute of Mathematical Sciences, New York University, New York, USA"/>
    <meta name="citation_author" content="Movshon, J Anthony"/>
    <meta name="citation_author_institution" content="Center for Neural Science, New York University, New York, USA"/>
    <meta name="citation_author_institution" content="Department of Psychology, New York University, New York, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="A functional and perceptual signature of the second visual area in primates"/>
    <meta name="twitter:description" content="Nature Neuroscience - The authors examined neuronal responses in V1 and V2 to synthetic texture stimuli that replicate higher-order statistical dependencies found in natural images. V2, but not V1,..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig1_HTML.jpg"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/nn.3402"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="A functional and perceptual signature of the second visual area in primates - Nature Neuroscience"/>
    <meta property="og:description" content="The authors examined neuronal responses in V1 and V2 to synthetic texture stimuli that replicate higher-order statistical dependencies found in natural images. V2, but not V1, responded differentially to these textures, in both macaque (single neurons) and human (fMRI). Human detection of naturalistic structure in the same images was predicted by V2 responses, suggesting a role for V2 in representing natural image structure."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig1_HTML.jpg"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=nn.3402;doi=10.1038/nn.3402;subjmeta=116,2395,2613,2614,378,631;kwrd=Extrastriate+cortex,Neural+encoding">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=418264477&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.3402%26doi%3D10.1038/nn.3402%26subjmeta%3D116,2395,2613,2614,378,631%26kwrd%3DExtrastriate+cortex,Neural+encoding">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=418264477&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.3402%26doi%3D10.1038/nn.3402%26subjmeta%3D116,2395,2613,2614,378,631%26kwrd%3DExtrastriate+cortex,Neural+encoding"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/nn.3402'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        A functional and perceptual signature of the second visual area in primates
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3402.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2013-05-19">19 May 2013</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">A functional and perceptual signature of the second visual area in primates</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jeremy-Freeman-Aff1-Aff7" data-author-popup="auth-Jeremy-Freeman-Aff1-Aff7" data-author-search="Freeman, Jeremy" data-corresp-id="c1">Jeremy Freeman<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a></sup><sup class="u-js-hide"><a href="#na1">na1</a></sup><sup class="u-js-hide"><a href="#nAff7">nAff7</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Corey_M-Ziemba-Aff1" data-author-popup="auth-Corey_M-Ziemba-Aff1" data-author-search="Ziemba, Corey M">Corey M Ziemba</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup><sup class="u-js-hide"><a href="#na1">na1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-David_J-Heeger-Aff1-Aff2" data-author-popup="auth-David_J-Heeger-Aff1-Aff2" data-author-search="Heeger, David J">David J Heeger</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Eero_P-Simoncelli-Aff1-Aff2-Aff3-Aff4" data-author-popup="auth-Eero_P-Simoncelli-Aff1-Aff2-Aff3-Aff4" data-author-search="Simoncelli, Eero P">Eero P Simoncelli</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a>,<a href="#Aff4">4</a></sup><sup class="u-js-hide"><a href="#na2">na2</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 5 authors for this article" title="Show all 5 authors for this article"></li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-J_Anthony-Movshon-Aff1-Aff2" data-author-popup="auth-J_Anthony-Movshon-Aff1-Aff2" data-author-search="Movshon, J Anthony">J Anthony Movshon</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup><sup class="u-js-hide"><a href="#na2">na2</a></sup></li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>16</b>,<span class="u-visually-hidden">pages </span>974981 (<span data-test="article-publication-year">2013</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">14k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">189 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">21 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/nn.3402/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/extrastriate-cortex" data-track="click" data-track-action="view subject" data-track-label="link">Extrastriate cortex</a></li><li class="c-article-subject-list__subject"><a href="/subjects/neural-encoding" data-track="click" data-track-action="view subject" data-track-label="link">Neural encoding</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs2" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs2">Abstract</h2><div class="c-article-section__content" id="Abs2-content"><p>There is no generally accepted account of the function of the second visual cortical area (V2), partly because no simple response properties robustly distinguish V2 neurons from those in primary visual cortex (V1). We constructed synthetic stimuli replicating the higher-order statistical dependencies found in natural texture images and used them to stimulate macaque V1 and V2 neurons. Most V2 cells responded more vigorously to these textures than to control stimuli lacking naturalistic structure; V1 cells did not. Functional magnetic resonance imaging (fMRI) measurements in humans revealed differences between V1 and V2 that paralleled the neuronal measurements. The ability of human observers to detect naturalistic structure in different types of texture was well predicted by the strength of neuronal and fMRI responses in V2 but not in V1. Together, these results reveal a particular functional role for V2 in the representation of natural image structure.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3402.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3402.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-024-45919-3/MediaObjects/41467_2024_45919_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-024-45919-3?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41467-024-45919-3">Efficient coding of natural images in the mouse visual cortex
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">19 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Federico Bolaos, Javier G. Orlandi,  Andrea Benucci</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-022-31041-9/MediaObjects/41467_2022_31041_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-022-31041-9?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41467-022-31041-9">Linking individual differences in human primary visual cortex to contrast sensitivity around the visual field
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">13 June 2022</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Marc M. Himmelberg, Jonathan Winawer &amp; Marisa Carrasco</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41593-019-0550-9/MediaObjects/41593_2019_550_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41593-019-0550-9?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41593-019-0550-9">A large-scale standardized physiological survey reveals functional organization of the mouse visual cortex
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">16 December 2019</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Saskia E. J. de Vries, Jerome A. Lecoq,  Christof Koch</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711582778,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>The perception of complex visual patterns emerges from neuronal activity in a cascade of areas in the primate cerebral cortex. Neurons in the primary visual cortex (V1) represent information about basic image features such as local orientation and spatial scale. Downstream areas contain neurons sensitive to more complex properties, especially those found in behaviorally relevant, natural images. But sensitivity to these naturalistic structures requires transformations of basic visual signals, which have been difficult to characterize in computational or physiological terms.</p><p>The function of V2 has been particularly enigmatic. V2 is the largest extrastriate visual cortical area in primates, and its responses depend on feedforward input from V1 (refs. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Schiller, P.H. &amp; Malpeli, J.G. The effect of striate cortex cooling on area 18 cells in the monkey. Brain Res. 126, 366369 (1977)." href="/articles/nn.3402#ref-CR1" id="ref-link-section-d30947402e428">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Sincich, L.C. &amp; Horton, J.C. The circuitry of V1 and V2: integration of color, form, and motion. Annu. Rev. Neurosci. 28, 303326 (2005)." href="/articles/nn.3402#ref-CR2" id="ref-link-section-d30947402e431">2</a>). Neurons in V2 presumably combine and elaborate signals from V1 to encode image features that V1 does not, but the responses of V2 neurons to most artificial stimuli, including gratings, angles, curves, anomalous contours and second-order patterns, are largely similar to the responses of neurons in V1 (refs. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Peterhans, E. &amp; Heydt, R.V.D. Mechanisms of contour perception in monkey visual cortex. II. Contours bridging gaps. J. Neurosci. 9, 17491763 (1989)." href="/articles/nn.3402#ref-CR3" id="ref-link-section-d30947402e434">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Hegd, J. &amp; Essen, D.C.V. Selectivity for complex shapes in primate visual area V2. J. Neurosci. 20, RC61RC66 (2000)." href="/articles/nn.3402#ref-CR4" id="ref-link-section-d30947402e437">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Hegd, J. &amp; Essen, D.C.V. A comparative study of shape representation in macaque visual areas v2 and v4. Cereb. Cortex 17, 11001116 (2007)." href="/articles/nn.3402#ref-CR5" id="ref-link-section-d30947402e440">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Lee, T.S. &amp; Nguyen, M. Dynamics of subjective contour formation in the early visual cortex. Proc. Natl. Acad. Sci. USA 98, 19071911 (2001)." href="/articles/nn.3402#ref-CR6" id="ref-link-section-d30947402e444">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Mahon, L.E. &amp; Valois, R.L.D. Cartesian and non-Cartesian responses in LGN, V1, and V2 cells. Vis. Neurosci. 18, 973981 (2001)." href="/articles/nn.3402#ref-CR7" id="ref-link-section-d30947402e447">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Ito, M. &amp; Komatsu, H. Representation of angles embedded within contour stimuli in area V2 of macaque monkeys. J. Neurosci. 24, 33133324 (2004)." href="/articles/nn.3402#ref-CR8" id="ref-link-section-d30947402e450">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Anzai, A., Peng, X. &amp; Van Essen, D.C. Neurons in monkey visual area V2 encode combinations of orientations. Nat. Neurosci. 10, 13131321 (2007)." href="/articles/nn.3402#ref-CR9" id="ref-link-section-d30947402e453">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="El-Shamayleh, Y. &amp; Movshon, J.A. Neuronal responses to texture-defined form in macaque visual area v2. J. Neurosci. 31, 85438555 (2011)." href="/articles/nn.3402#ref-CR10" id="ref-link-section-d30947402e456">10</a>). Reliable responses to border ownership and relative binocular disparity are more prevalent in V2 than in V1 (refs. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Zhou, H., Friedman, H.S. &amp; Heydt, R.V.D. Coding of border ownership in monkey visual cortex. J. Neurosci. 20, 65946611 (2000)." href="/articles/nn.3402#ref-CR11" id="ref-link-section-d30947402e459">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Thomas, O.M., Cumming, B.G. &amp; Parker, A.J. A specialization for relative disparity in V2. Nat. Neurosci. 5, 472478 (2002)." href="/articles/nn.3402#ref-CR12" id="ref-link-section-d30947402e463">12</a>), and V2 neurons exhibit stronger tuned suppression<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Willmore, B.D., Prenger, R.J. &amp; Gallant, J.L. Neural representation of natural images in visual area V2. J. Neurosci. 30, 21022114 (2010)." href="/articles/nn.3402#ref-CR13" id="ref-link-section-d30947402e467">13</a></sup>, but neither of these properties reliably and robustly distinguish V1 and V2 neurons.</p><p>We wondered whether the responses of V2 cells might encode aspects of natural image structure. A ubiquitous property of natural images is that they contain orderly structures that create strong statistical dependencies across the outputs of filterssimilar to the responses of V1 cellstuned to different positions, orientations and spatial scales<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Simoncelli, E.P. Statistical models for images: compression, restoration and synthesis. 31st Asilomar Conference on Signals, Systems &amp; Computers 1, 673678 (IEEE, 1997)." href="/articles/nn.3402#ref-CR14" id="ref-link-section-d30947402e474">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Schwartz, O. &amp; Simoncelli, E.P. Natural signal statistics and sensory gain control. Nat. Neurosci. 4, 819825 (2001)." href="/articles/nn.3402#ref-CR15" id="ref-link-section-d30947402e477">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Karklin, Y. &amp; Lewicki, M.S. Emergence of complex cell properties by learning to generalize in natural scenes. Nature 457, 8386 (2009)." href="/articles/nn.3402#ref-CR16" id="ref-link-section-d30947402e480">16</a></sup>. Dependencies across scale, for example, occur in the vicinity of abrupt changes in luminance, and dependencies across orientation and position arise from spatially extended contours<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Sigman, M., Cecchi, G.A., Gilbert, C.D. &amp; Magnasco, M.O. On a common circle: natural scenes and Gestalt rules. Proc. Natl. Acad. Sci. USA 98, 19351940 (2001)." href="/articles/nn.3402#ref-CR17" id="ref-link-section-d30947402e484">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Geisler, W.S., Perry, J.S., Super, B.J. &amp; Gallogly, D.P. Edge co-occurrence in natural images predicts contour grouping performance. Vision Res. 41, 711724 (2001)." href="/articles/nn.3402#ref-CR18" id="ref-link-section-d30947402e487">18</a></sup>. The character and extent of these dependencies varies for different classes of images. Many artificial stimuli lack them; in photographs of scenes and objects, they are present but sparse, nonuniform and difficult to control. But a subclass of natural images, visual textures, contain these dependencies in a form that can be captured parametrically<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Portilla, J. &amp; Simoncelli, E.P. A parametric texture model based on joint statistics of complex wavelet coefficients. Int. J. Comput. Vis. 40, 4970 (2000)." href="/articles/nn.3402#ref-CR19" id="ref-link-section-d30947402e491">19</a></sup>, and previous psychophysical investigations suggest that V2 may be the locus for representing them<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Freeman, J. &amp; Simoncelli, E.P. Metamers of the ventral stream. Nat. Neurosci. 14, 11951201 (2011)." href="/articles/nn.3402#ref-CR20" id="ref-link-section-d30947402e495">20</a></sup>.</p><p>We discovered a distinctive property of V2 cells by measuring their responses to controlled naturalistic texture stimuli. We first captured the statistical dependencies in natural texture photographs by computing correlations among the outputs of V1-like filters tuned to different positions, orientations and spatial scales. We then generated families of homogenous textures containing the same statistical dependencies. There was a unique response to these texture stimuli in V2 but not V1, in both macaque and human, that reliably predicted perceptual sensitivity to the same stimuli. A large-scale 'crowd-sourced' psychophysics experiment revealed the statistical dependencies most relevant for perception and, by extension, selective responses in V2. Together, these findings situate V2 along a cascade of computations that lead to the representation of naturally occurring patterns and objects.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Generating naturalistic texture stimuli</h3><p>For each of several original photographs of visual texture, we transformed samples of Gaussian noise to synthesize new images with the statistical properties of the original<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Portilla, J. &amp; Simoncelli, E.P. A parametric texture model based on joint statistics of complex wavelet coefficients. Int. J. Comput. Vis. 40, 4970 (2000)." href="/articles/nn.3402#ref-CR19" id="ref-link-section-d30947402e514">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Heeger, D.J. &amp; Bergen, J.R. Pyramid-based texture analysis/synthesis. Proceedings of SIGGRAPH 229238 (ACM, 1995)." href="/articles/nn.3402#ref-CR21" id="ref-link-section-d30947402e517">21</a></sup> (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig1">Fig. 1</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3402#MOESM3">Supplementary Fig. 1</a>). For each original texture, we generated two sets of stimuli using different statistics: spectrally matched noise images and naturalistic texture images. Spectrally matched noise images were synthesized using phase randomization; that is, by computing the Fourier transform, randomizing the phase values and then inverting the Fourier transform. This is approximately equivalent to measuring and matching the spatially averaged responses of linear and energy filters (akin to V1 simple and complex cells, respectively) selective for different orientations, positions and spatial scales. The resulting synthetic images had the same overall orientation and spatial-frequency content as the original (that is, the same spectral properties) but lacked its higher-order statistical dependencies (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig1">Fig. 1a</a>). Naturalistic texture images were generated by also matching correlations between filter responses (and their energies) across orientations, positions and spatial scales (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig1">Fig. 1b</a>). We used an iterative procedure (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig1">Fig. 1c</a>) to match the spatially averaged filter responses, the correlations between filter responses, and the mean, variance, skewness and kurtosis of the pixel luminance distribution ('marginal statistics'). Synthetic images matched for these properties contain many complex naturalistic structures seen in the original photograph<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Portilla, J. &amp; Simoncelli, E.P. A parametric texture model based on joint statistics of complex wavelet coefficients. Int. J. Comput. Vis. 40, 4970 (2000)." href="/articles/nn.3402#ref-CR19" id="ref-link-section-d30947402e537">19</a></sup>, readily recognizable by human observers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Balas, B. Attentive texture similarity as a categorization task: comparing texture synthesis models. Pattern Recognit. 41, 972982 (2008)." href="/articles/nn.3402#ref-CR22" id="ref-link-section-d30947402e541">22</a></sup>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Analysis and synthesis of naturalistic textures."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1: Analysis and synthesis of naturalistic textures.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3402/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig1_HTML.jpg?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig1_HTML.jpg" alt="figure 1" loading="lazy" width="685" height="712"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>(<b>a</b>) Original texture photographs. (<b>b</b>) Spectrally matched noise images. The original texture is analyzed with linear filters and energy filters (akin to V1 simple and complex cells, respectively) tuned to different orientations, spatial frequencies and spatial positions. Noise images contain the same spatially averaged orientation and frequency structure as the original but lack many of the more complex features. (<b>c</b>) Naturalistic texture images. Correlations are computed by taking products of linear and energy filter responses across different orientations, spatial frequencies and positions. Images are synthesized to match both the spatially averaged filter responses and the spatially averaged correlations between filter responses. The resulting texture images contain many more of the naturalistic features of the original. More examples in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3402#MOESM3">Supplementary Figure 1</a>. (<b>d</b>) Synthesis of naturalistic textures begins with Gaussian white noise, and the noise is iteratively adjusted using gradient descent until analysis of the synthetic image matches analysis of the original (see ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Portilla, J. &amp; Simoncelli, E.P. A parametric texture model based on joint statistics of complex wavelet coefficients. Int. J. Comput. Vis. 40, 4970 (2000)." href="/articles/nn.3402#ref-CR19" id="ref-link-section-d30947402e572">19</a>). Initializing with different samples of Gaussian noise yields distinct but statistically similar images.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3402/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We synthesized images based on 15 original texture photographs, yielding 15 different 'texture families'; for each original, we made ensembles of self-similar naturalistic texture samples, each different in detail but all having identical statistical dependencies and containing similar visual properties (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3402#MOESM3">Supplementary Fig. 1</a>). Since each of these 15 texture families was based on a different original photograph, they varied in their appearance and in the form and extent of their higher-order statistical dependencies.</p><h3 class="c-article__sub-heading" id="Sec4">Differentiating V2 from V1 in macaque</h3><p>We recorded in 13 anesthetized macaque monkeys the responses of 102 V1 and 103 V2 neurons to a sequence of texture stimuli, presented in suitably vignetted 4 patches centered on each neuron's receptive field. The sequence, which was identical for all cells, included 20 repetitions for each of 15 samples of naturalistic and 15 samples of noise stimuli from 15 different texture families (9,000 stimuli in total). The textures were each presented for 100 ms and were separated by 100 ms of a blank gray screen, so the entire sequence lasted 30 min.</p><p>V1 neurons responded similarly to both stimulus types, whereas V2 neurons often responded more vigorously to naturalistic textures than to spectrally matched noise. This distinction between V2 and V1 was evident when examining individual responses as a function of time from stimulus onset (averaged over all samples of all texture families) (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2a</a>) and when the responses were averaged over the cell populations (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2b</a>). We use the term 'modulation' to capture the differential responses to textures and noise, and index its magnitude by taking the difference of responses divided by the sum (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2c</a>). The average modulation index of neurons in V1 was near zero for most of the response time course, except for a modest late positive modulation (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2c</a>). Neurons in V2 showed a substantial modulation that was evident soon after response onset and persisted throughout the duration of the response (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2c</a>). The late modulation in V1 might reflect feedback from V2 or other higher areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Angelucci, A. et al. Circuits for local and global signal integration in primary visual cortex. J. Neurosci. 22, 86338646 (2002)." href="/articles/nn.3402#ref-CR23" id="ref-link-section-d30947402e617">23</a></sup>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Neuronal responses to naturalistic textures differentiate V2 from V1 in macaques."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2: Neuronal responses to naturalistic textures differentiate V2 from V1 in macaques.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3402/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="685" height="493"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>(<b>a</b>) Time course of firing rate for three single units in V1 (green) and V2 (blue) to images of naturalistic texture (dark) and spectrally matched noise (light). Thickness of lines indicates s.e.m. across texture families. Black bar indicates the presentation of the stimulus; gray bar indicates the presentation of the subsequent stimulus. (<b>b</b>) Time course of firing rate averaged across neurons in V1 and V2. Each neuron's firing rate was normalized by its maximum before averaging. Thickness of lines indicates s.e.m. across neurons. (<b>c</b>) Modulation index, computed as the difference between the response to naturalistic and the response to noise, divided by their sum. Modulation was computed separately for each neuron and texture family, then averaged across all neurons and families. Thickness of blue and green lines indicates s.e.m. across neurons. Thickness of gray shaded region indicates the 2.5th and 97.5th percentiles of the null distribution of modulation expected at each time point due to chance. (<b>d</b>) Firing rates for three single units in V1 (green) and V2 (blue) to naturalistic (dark dots) and noise (light dots), separately for the 15 texture families. Families are sorted according to the ranking in <b>e</b>. Gray bars connecting points are only for visualization of the differential response. Modulation indices (averaged across texture families) are reported in the upper right of each panel. Error bars indicate s.e.m. across the 15 samples of each texture family. (<b>e</b>) Diversity in modulation across texture families, averaged across all neurons. Error bars indicate s.e.m. across neurons. Gray bar indicates 2.5th and 97.5th percentiles of the null distribution of modulation expected due to chance. (<b>f</b>) Distributions of modulation indices across single neurons in V1 and V2. For each neuron, the modulation index for each texture family was computed on firing rates averaged in a 100-ms window following response onset, and modulation was then averaged across families.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3402/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>V2 responses were substantially modulated by naturalistic structure on average, but the modulation was typically more pronounced for some texture families than for others. We examined responses as a function of texture family, averaged over all samples. There was a consistent trend across the V2 population for some texture families to evoke stronger modulation than others, although the most effective families varied from cell to cell (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2d,e</a>). By contrast, all families yielded negligible modulation of V1 responses (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2d,e</a>). In V2, the modulation strength across texture families was not significantly correlated with the response magnitude (<i>r</i> = 0.42, <i>P</i> = 0.12, correlation computed after averaging across cells). An analysis of the distribution and ranking of modulation across individual neurons ruled out the possibility that modulation in V1 was present but concealed by the process of taking means (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3402#MOESM3">Supplementary Fig. 2</a>).</p><p>Some neurons were more sensitive overall to naturalistic structure than others. We computed a modulation index for each neuron, averaged over the response duration and over all samples of all texture families (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2f</a>). Significant positive modulation was observed in 15% of V1 neurons and 63% of V2 neurons (<i>P</i> &lt; 0.05, randomization test for each neuron). The difference in modulation between V1 and V2 was significant (<i>P</i> &lt; 0.0001, <i>t</i>-test on signed modulation; <i>P</i> &lt; 0.0001, <i>t</i>-test on modulation magnitude ignoring sign). Results were similar when examining firing rates instead of modulation index (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3402#MOESM3">Supplementary Fig. 3</a>).</p><p>The receptive fields of V2 neurons are larger than those of V1, but this distinction did not explain the observed differences in sensitivity to naturalistic structure (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig3">Fig. 3</a>). The stimuli presented to V1 and V2 cells were of the same diameter, roughly twice that of a typical V2 receptive field and four times that of a typical V1 receptive field. There was no evidence of a correlation between receptive field size and modulation in either visual area (V1, <i>r</i> = 0.13, <i>P</i> = 0.23; V2, <i>r</i> = 0.13, <i>P</i> = 0.26, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig3">Fig. 3a,b</a>). When we restricted our analysis to subsets of neurons matched for average receptive field size, the difference in modulation index between areas was reduced by only 9% and remained significant (<i>P</i> &lt; 0.0001, randomization test).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Receptive field size does not explain differential responses to naturalistic texture stimuli in V2."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3: Receptive field size does not explain differential responses to naturalistic texture stimuli in V2.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3402/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig3_HTML.jpg?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig3_HTML.jpg" alt="figure 3" loading="lazy" width="685" height="660"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>(<b>a</b>,<b>b</b>) Modulation index (difference in response to naturalistic and noise stimuli, divided by the sum) measured using stimuli presented in a 4 aperture (ordinate) versus classical receptive field size (abscissa). Each data point represents a neuron. There was no evidence for a relationship between modulation index and classical receptive field size in either V1 (green) or V2 (blue). (<b>c</b>,<b>d</b>) Comparison of modulation indices measured using stimuli presented in an aperture matched in size to the classical receptive field (ordinate) versus indices measured using stimuli presented within a 4 aperture (abscissa). Each data point represents a neuron. Diagonal dashed line is the line of equality. Modulation in V1 was near 0 for both stimulus sizes. Modulation in V2 was positive for both stimulus sizes, but there was less modulation in V2 for the smaller size.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3402/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We also made measurements on a subset of cells in which the stimuli were confined to each neuron's classical receptive field. In V1, the modulation was near 0 for both classical receptive fieldmatched and large stimuli, though there was a small but significant reduction in modulation for the smaller stimuli (<i>P</i> &lt; 0.05, <i>t</i>-test, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig3">Fig. 3c</a>). In V2, there was a robust but incomplete reduction in modulation for the smaller stimuli (<i>P</i> &lt; 0.0001, <i>t</i>-test, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig3">Fig. 3d</a>), suggesting that the modulation in V2 depended partly, but not entirely, on interactions between receptive field center and surround. We found no evidence for a relationship in V2 between the modulation and commonly characterized properties of early visual neurons, including surround suppression, orientation tuning bandwidth, preferred spatial frequency, spatial frequency tuning bandwidth or parameters of the contrast sensitivity function (<i>c</i><sub>50</sub> and exponent) (all correlations <i>P</i> &gt; 0.05). We therefore believe that our measurements reveal a hitherto unrecognized dimension of visual processing in macaque V2.</p><h3 class="c-article__sub-heading" id="Sec5">Differentiating V2 from V1 in human</h3><p>Given the reliable effect of higher-order image statistics on the responses of V2 neurons, we wondered if similar effects could be observed in humans using fMRI, which can capture large-scale differential responses across visual areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Wandell, B.A., Dumoulin, S.O. &amp; Brewer, A.A. Visual field maps in human cortex. Neuron 56, 366383 (2007)." href="/articles/nn.3402#ref-CR24" id="ref-link-section-d30947402e801">24</a></sup>. We presented alternating blocks of naturalistic and noise stimuli, one texture family at a time, in the near-peripheral visual field while measuring blood-oxygenation level dependent (BOLD) fMRI responses in visual cortex. Subjects performed a demanding task at the center of gaze to divert their attention from the peripheral stimulus. Responses were visualized on a flattened representation of the occipital lobe, and boundaries between V1 and V2 were derived from independent retinotopic mapping<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Wandell, B.A., Dumoulin, S.O. &amp; Brewer, A.A. Visual field maps in human cortex. Neuron 56, 366383 (2007)." href="/articles/nn.3402#ref-CR24" id="ref-link-section-d30947402e805">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Larsson, J. &amp; Heeger, D.J. Two retinotopic visual areas in human lateral occipital cortex. J. Neurosci. 26, 1312813142 (2006)." href="/articles/nn.3402#ref-CR25" id="ref-link-section-d30947402e808">25</a></sup>.</p><p>In all three subjects, there were strong differential fMRI responses to naturalistic texture throughout V2, with weaker ones in V1 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4a</a>). We captured differential fMRI responses evoked by naturalistic texture and noise stimuli with a modulation index analogous to that used for single-unit physiology (see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.3402#Sec9">Methods</a>). Differences in modulation between V2 and V1 were significant in each subject (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4b</a>; <i>P</i> &lt; 0.0001, paired <i>t</i>-test comparing responses in V1 and V2 across the 15 texture families). The much weaker modulation in V1 was nevertheless significantly greater than 0 in two of three subjects (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4b</a>; <i>P</i> &lt; 0.05). Modulation was also evident in V3 and, to some extent, in V4, although it was weaker in higher object-selective areas such as the lateral occipital complex. The modulation in V3 and V4 might be inherited from V2. These results complement the single-cell findings by showing that the same response differences were evident over all of V2 and were sufficiently robust to manifest at the coarse spatial scale of fMRI.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="fMRI responses to naturalistic textures differentiate V2 from V1 in humans."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4: fMRI responses to naturalistic textures differentiate V2 from V1 in humans.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3402/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig4_HTML.jpg?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig4_HTML.jpg" alt="figure 4" loading="lazy" width="685" height="481"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>(<b>a</b>) Responses in subjects 13 (S1S3) to alternating blocks of naturalistic texture images and spectrally matched noise shown on a flattened representation of the occipital pole. Color indicates coherence, which captures the extent to which the fMRI responses to naturalistic and noise stimuli differ, computed voxel by voxel after averaging responses to all texture families. White lines indicate boundaries between visual areas, identified in an independent retinotopic mapping experiment. (<b>b</b>) A measure of fMRI modulation (see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.3402#Sec9">Methods</a>) averaged across voxels and texture families in V1 and V2 for the three subjects. Error bars indicate s.e.m. across texture families. (<b>c</b>) Responses from a subject to two individual texture families, only one of which evoked robust differential responses in V2. Same format as <b>a</b>. (<b>d</b>) Correlation between fMRI and single-unit modulation for V1 (green) and V2 (blue). Each data point represents a different texture family.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3402/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>As with the single-cell responses, some texture families elicited more robust fMRI modulation in V2 than others (examples in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4c</a>). We compared, across texture families, the fMRI and single-unit modulation indices (averaged across neurons). fMRI and electrophysiological measures were significantly correlated in V2 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4d</a>; <i>r</i> = 0.55, <i>P</i> &lt; 0.05), but this was not evident in V1 (<i>r</i> = 0.30, <i>P</i> = 0.28). We also correlated the modulation indices from each individual neuron with the fMRI response modulation. Correlations were significantly higher in V2 than in V1 (<i>P</i> &lt; 0.005, <i>t</i>-test on <i>Z</i>-transformed correlations). The presence and diversity of the differential responses to naturalistic textures in V2 were thus similar when measured in macaque neurons and human fMRI.</p><h3 class="c-article__sub-heading" id="Sec6">Linking V2 physiology to perception</h3><p>If this distinctive feature of V2 responses has a perceptual correlate, then texture families that evoke larger differential responses (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Figs. 2</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">4</a>) should be those for which the naturalistic textures are more perceptually distinct from spectrally matched noise. To test this hypothesis, we built textures with varying degrees of 'naturalness' (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Fig. 5a</a>) by titrating the inclusion of higher-order correlations in the synthesis process. We measured perceptual sensitivity to naturalness for each texture family using a three-alternative forced choice discrimination task (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Fig. 5b,c</a>) suitable for studying stochastic stimuli such as textures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Hillis, J.M., Ernst, M.O., Banks, M.S. &amp; Landy, M.S. Combining sensory information: mandatory fusion within, but not between, senses. Science 298, 16271630 (2002)." href="/articles/nn.3402#ref-CR26" id="ref-link-section-d30947402e927">26</a></sup>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Neuronal responses to naturalistic textures in V2 predict perceptual sensitivity."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5: Neuronal responses to naturalistic textures in V2 predict perceptual sensitivity.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3402/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig5_HTML.jpg?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig5_HTML.jpg" alt="figure 5" loading="lazy" width="685" height="961"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>(<b>a</b>) Stimuli were generated along an axis of 'naturalness' by gradually introducing higher-order correlations (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig1">Fig. 1b</a>). (<b>b</b>) Observers performed a three-alternative, forced-choice 'oddity' task in which they viewed three images, two naturalistic and one noise (or vice versa), and indicated which looked different from the other two. All three images were synthesized independently (that is, starting with statistically independent samples of Gaussian white noise). (<b>c</b>) Psychometric function: performance as a function of naturalness. Solid curves, best-fit cumulative Weibull function. Chance performance is 1/3. The two panels show two different texture families (same as in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4c</a>) with different thresholds (defined as the naturalness required to obtain <span class="stix"></span>75% correct). Error bars indicate s.e.m. (<b>d</b>) Correlation between psychophysical sensitivity (reciprocal of the threshold) and single-unit modulation in V1 (green) and V2 (blue). Each data point represents a texture family. (<b>e</b>) Correlation between psychophysical sensitivity and fMRI modulation. Same format as <b>d</b>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3402/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Across 15 texture families, perceptual sensitivity correlated significantly with electrophysiological response modulations averaged across neurons in V2 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Fig. 5d</a>; <i>r</i> = 0.62, <i>P</i> &lt; 0.05) but not in V1 (<i>r</i> = 0.21, <i>P</i> = 0.45), and the correlation was significantly larger for V2 than V1 (<i>P</i> &lt; 0.0001, <i>t</i>-test on <i>Z</i>-transformed correlations). We also found that perceptual sensitivity was significantly correlated with the fMRI modulation in V2 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Fig. 5e</a>; <i>r</i> = 0.70, <i>P</i> &lt; 0.005) but not in V1 (<i>r</i> = 0.40; <i>P</i> = 0.13) and that this correlation was again significantly larger for V2 than V1 (<i>P</i> &lt; 0.01, paired <i>t</i>-test on <i>Z</i>-transformed correlations). These relationships suggest a function for V2 in the perception of these naturalistic stimuli.</p><h3 class="c-article__sub-heading" id="Sec7">Predicting diversity in neuronal and perceptual sensitivity</h3><p>The texture families we used varied in the form and extent of their statistical dependencies. We wondered which of the many possible dependencies were most important for perception and, by extension, for evoking responses in V2. Identifying the relevant subset requires many stimuli, and making biological measurementsneuronal or fMRIfor such an ensemble would be unfeasible. We therefore measured perceptual sensitivity for nearly 500 texture families using Amazon.com's Mechanical Turk service (<a href="http://www.mturk.com/">http://www.mturk.com/</a>) to crowd-source our measurements<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Paolacci, G., Chandler, J. &amp; Ipeirotis, P. Running experiments on Amazon Mechanical Turk. Judgm. Decis. Mak. 5, 411419 (2010)." href="/articles/nn.3402#ref-CR27" id="ref-link-section-d30947402e1046">27</a></sup> and expand their range 30-fold. This approach yielded a total of 300 h of behavioral data from thousands of human observers (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">Fig. 6</a>; see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.3402#Sec9">Methods</a>). We developed analysis procedures to combine data from this large number of observers and to evaluate the reliability of the results.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Crowd-sourced psychophysical estimates of sensitivity for hundreds of texture families."><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 6: Crowd-sourced psychophysical estimates of sensitivity for hundreds of texture families.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3402/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig6_HTML.jpg?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig6_HTML.jpg" alt="figure 6" loading="lazy" width="685" height="765"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>(<b>a</b>) Example psychometric functions for two texture families (same as <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Figs. 4c</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">5c</a>), each based on observers recruited from Amazon.com's Mechanical Turk performing a three-alternative, forced-choice task in a web browser. Each colored line corresponds to one observer. The black line indicates the best-fitting psychometric function, estimated using a mixture model that reweighted observers based on their reliability (see <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3402#MOESM3">Supplementary Modeling</a>); thickness of the colored lines indicates the weight assigned to each observer. Chance performance is 1/3. (<b>b</b>) Perceptual sensitivity (reciprocal of the threshold) was significantly correlated between measurements in the laboratory (abscissa) and in the crowd (ordinate). Dashed line is the line of equality. (<b>c</b>) The distribution of perceptual sensitivities across 494 texture families was used to pick 20 families spanning the range of sensitivities, emphasizing the extremes (light gray regions). (<b>d</b>) Correlations between single-unit modulation and sensitivity (measured in the crowd) for the chosen families, in V1 (green) and V2 (blue). Only 17 of the 20 families were included owing to experimental time constraints. (<b>e</b>) Correlations between fMRI modulation and sensitivity. All 20 families were included. Same format as <b>d</b>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3402/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We related our crowd-sourced measurements to our previous results in two ways. First, we confirmed for the original 15 texture families (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Fig. 5</a>) that perceptual sensitivity measured in the crowd was reliably correlated with, albeit lower than, sensitivity measured in the laboratory (<i>r</i> = 0.92, <i>P</i> &lt; 0.0001, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">Fig. 6b</a>). Second, we used the 494 new texture families to link the crowd-sourced sensitivity estimates back to physiological responses. We selected 20 texture families spanning a range of crowd-estimated sensitivities, emphasizing the extremes (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">Fig. 6c</a>). We used images from these families as stimuli in further single-unit and fMRI experiments. Both the single-unit modulation in V2 (<i>r</i> = 0.74, <i>P</i> &lt; 0.001, 16 cells) and fMRI modulation in V2 (<i>r</i> = 0.77, <i>P</i> &lt; 0.0001, 2 subjects) were significantly correlated with crowd-estimated sensitivity (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">Fig. 6d,e</a>), confirming with new stimuli the relationship found in our earlier experiments (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Fig. 5</a>). In V1, single-unit modulation showed no evidence for a correlation with sensitivity (<i>r</i> = 0.25, <i>P</i> = 0.33, 11 cells). fMRI modulation in V1 to these new stimuli revealed a significant correlation (<i>r</i> = 0.49, <i>P</i> &lt; 0.05). This was weaker than the correlation found for V2 and similar to our results using the original 15 texture families (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Fig. 5e</a>).</p><p>The crowd-sourced psychophysical data for the complete ensemble of texture families allowed us to identify which statistical dependencies of the images explained diversity in perceptual sensitivity to naturalistic structure. Recall that our textures were synthesized to match correlations among V1-like responsesboth linear filter responses and energiesat different orientations, positions and scales (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig7">Fig. 7a,b</a>). Through a combination of principal components analysis and multiple linear regression (see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.3402#Sec9">Methods</a>), we used these correlations, along with spectral and marginal statistics, to predict more than half of the variance in perceptual sensitivity (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig7">Fig. 7c</a>, <i>R</i><sup>2</sup> = 66%). To ensure that results were not a result of overfitting, we confirmed that accuracy was still high (<i>R</i><sup>2</sup> = 60%) with tenfold cross-validation. To identify the relative importance of different synthesis parameters, we decomposed the total <i>R</i><sup>2</sup> using the averaging-over-orderings technique (see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.3402#Sec9">Methods</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Grmping, U. Estimators of relative importance in linear regression based on variance decomposition. Am. Stat. 61, 139147 (2007)." href="/articles/nn.3402#ref-CR28" id="ref-link-section-d30947402e1185">28</a></sup>. The cross-scale correlations among the energy filter responses accounted for the largest share; second and third most important were the cross-position and cross-orientation energy-filter correlations (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig7">Fig. 7d</a>). Correlations among linear filter responses were less important. Spectral properties had a small amount of predictive power, but this likely reflected how spectra control visibility; for example, insensitivity to high spatial frequencies. The contribution of marginal statistics (skewness and kurtosis) was negligible, indicating that perceptual sensitivity is driven by the higher-order correlations rather than basic image properties. Together, these results link perceptual sensitivityand, we infer, neuronal sensitivity in V2to the particular kinds of higher-order statistical dependencies found in our naturalistic textures.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Using higher-order correlations to predict perceptual sensitivity."><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 7: Using higher-order correlations to predict perceptual sensitivity.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.3402/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig7_HTML.jpg?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Fig7_HTML.jpg" alt="figure 7" loading="lazy" width="685" height="592"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>(<b>a</b>) Cross-scale, cross-position and cross-orientation correlations are computed by taking products of localized V1-like filter responses. Each circle represents an image location. Filters at each location are tuned to orientation and frequency, and compute either linear or energy responses (see <b>b</b>). (<b>b</b>) Linear filters are sensitive to phase, akin to V1 simple cells; energy filters compute the square root of the sum of squared responses of two phase-shifted filters (in quadrature pair) and are thus insensitive to phase, akin to V1 complex cells<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Adelson, E.H. &amp; Bergen, J.R. Spatiotemporal energy models for the perception of motion. J. Opt. Soc. Am. A 2, 284299 (1985)." href="/articles/nn.3402#ref-CR42" id="ref-link-section-d30947402e1214">42</a></sup>. For both filter types, products (as in <b>a</b>) are averaged across spatial locations to yield correlations. (<b>c</b>) We used multiple linear regression to predict perceptual sensitivity to naturalistic textures based on higher-order correlations and other image statistics used in texture synthesis. Each data point corresponds to a texture family; black dots indicate all texture families used in physiological experiments (from <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Figs. 2e</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">5d,e</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">6d,e</a>). Black dashed line is the line of equality. (<b>d</b>) Wedges indicate the fractional <i>R</i><sup>2</sup> assigned to each group of texture synthesis parameters from the regression analysis. See refs. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Portilla, J. &amp; Simoncelli, E.P. A parametric texture model based on joint statistics of complex wavelet coefficients. Int. J. Comput. Vis. 40, 4970 (2000)." href="/articles/nn.3402#ref-CR19" id="ref-link-section-d30947402e1241">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Balas, B. Attentive texture similarity as a categorization task: comparing texture synthesis models. Pattern Recognit. 41, 972982 (2008)." href="/articles/nn.3402#ref-CR22" id="ref-link-section-d30947402e1244">22</a> for example images showing the role of some of these parameters in texture synthesis.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.3402/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Discussion</h2><div class="c-article-section__content" id="Sec8-content"><p>We have found that naturalistic texture stimuli modulate the responses of neurons in area V2, while having only a minimal effect on neurons in area V1. These modulations were similar and substantial in both anesthetized macaques and awake humans. The diversity of modulation across different texture families predicted the perceptual salience of their naturalistic structure. We capitalized on this diversity to reveal the importance to V2 activity of correlations across scale and, to a lesser extent, across position and orientation. The combination of human and monkey physiology with psychophysics provided mutually reinforcing evidence that V2 has a direct functional role in representing naturalistic structures.</p><p>Previous studies have identified specialized response properties in subpopulations of V2 neurons<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Ito, M. &amp; Komatsu, H. Representation of angles embedded within contour stimuli in area V2 of macaque monkeys. J. Neurosci. 24, 33133324 (2004)." href="/articles/nn.3402#ref-CR8" id="ref-link-section-d30947402e1268">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Anzai, A., Peng, X. &amp; Van Essen, D.C. Neurons in monkey visual area V2 encode combinations of orientations. Nat. Neurosci. 10, 13131321 (2007)." href="/articles/nn.3402#ref-CR9" id="ref-link-section-d30947402e1271">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Willmore, B.D., Prenger, R.J. &amp; Gallant, J.L. Neural representation of natural images in visual area V2. J. Neurosci. 30, 21022114 (2010)." href="/articles/nn.3402#ref-CR13" id="ref-link-section-d30947402e1274">13</a></sup>, but the differences between V2 and V1 were usually small<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Peterhans, E. &amp; Heydt, R.V.D. Mechanisms of contour perception in monkey visual cortex. II. Contours bridging gaps. J. Neurosci. 9, 17491763 (1989)." href="/articles/nn.3402#ref-CR3" id="ref-link-section-d30947402e1278">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Hegd, J. &amp; Essen, D.C.V. A comparative study of shape representation in macaque visual areas v2 and v4. Cereb. Cortex 17, 11001116 (2007)." href="/articles/nn.3402#ref-CR5" id="ref-link-section-d30947402e1281">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Lee, T.S. &amp; Nguyen, M. Dynamics of subjective contour formation in the early visual cortex. Proc. Natl. Acad. Sci. USA 98, 19071911 (2001)." href="/articles/nn.3402#ref-CR6" id="ref-link-section-d30947402e1284">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Mahon, L.E. &amp; Valois, R.L.D. Cartesian and non-Cartesian responses in LGN, V1, and V2 cells. Vis. Neurosci. 18, 973981 (2001)." href="/articles/nn.3402#ref-CR7" id="ref-link-section-d30947402e1287">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="El-Shamayleh, Y. &amp; Movshon, J.A. Neuronal responses to texture-defined form in macaque visual area v2. J. Neurosci. 31, 85438555 (2011)." href="/articles/nn.3402#ref-CR10" id="ref-link-section-d30947402e1290">10</a></sup>. Some of these may reflect special cases of the properties identified here; for example, tuning for angles could arise from sensitivity to cross-orientation correlations. The attribute that has most robustly distinguished V2 from V1 is 'border ownership'<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Zhou, H., Friedman, H.S. &amp; Heydt, R.V.D. Coding of border ownership in monkey visual cortex. J. Neurosci. 20, 65946611 (2000)." href="/articles/nn.3402#ref-CR11" id="ref-link-section-d30947402e1294">11</a></sup>, which may also depend on the receptive field surround in V2 (refs. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Geisler, W.S., Perry, J.S., Super, B.J. &amp; Gallogly, D.P. Edge co-occurrence in natural images predicts contour grouping performance. Vision Res. 41, 711724 (2001)." href="/articles/nn.3402#ref-CR18" id="ref-link-section-d30947402e1297">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Craft, E., Schtze, H., Niebur, E. &amp; von der Heydt, R. A neural model of figure-ground organization. J. Neurophysiol. 97, 43104326 (2007)." href="/articles/nn.3402#ref-CR29" id="ref-link-section-d30947402e1300">29</a>). Border ownership signaling, however, may rely on attentional feedback<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Qiu, F.T., Sugihara, T. &amp; Heydt, R.V.D. Figure-ground mechanisms provide structure for selective attention. Nat. Neurosci. 10, 14921499 (2007)." href="/articles/nn.3402#ref-CR30" id="ref-link-section-d30947402e1305">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Fang, F., Boyaci, H. &amp; Kersten, D. Border ownership selectivity in human early visual cortex and its modulation by attention. J. Neurosci. 29, 460465 (2009)." href="/articles/nn.3402#ref-CR31" id="ref-link-section-d30947402e1308">31</a></sup>, whereas the response pattern we have discovered probably does not, as it is evident in both awake humans with diverted attention and anesthetized macaques.</p><p>Our fMRI measurements robustly differentiated human V2 from V1. However, unlike in our single-unit recordings, there was a weak but significant correlation between fMRI measurements in V1 and perceptual sensitivity (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Figs. 5e</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">6e</a>). These V1 signals may reflect the influence of modulatory feedback<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Angelucci, A. et al. Circuits for local and global signal integration in primary visual cortex. J. Neurosci. 22, 86338646 (2002)." href="/articles/nn.3402#ref-CR23" id="ref-link-section-d30947402e1321">23</a></sup>. Such an influence was hinted at by the late component of modulation in the V1 single-unit response time course (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2c</a>) and could be more readily evident with fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Ress, D., Backus, B.T. &amp; Heeger, D.J. Activity in primary visual cortex predicts performance in a visual detection task. Nat. Neurosci. 3, 940945 (2000)." href="/articles/nn.3402#ref-CR32" id="ref-link-section-d30947402e1328">32</a></sup>. Establishing a more direct relationship would require further study of the late V1 single-unit response, by recording from more neurons and thus more reliably measuring the weak signal or by means of techniques capable of isolating feedback signals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Ferster, D., Chung, S. &amp; Wheat, H. Orientation selectivity of thalamic input to simple cells of cat visual cortex. Nature 380, 249252 (1996)." href="/articles/nn.3402#ref-CR33" id="ref-link-section-d30947402e1333">33</a></sup>.</p><p>We compared responses to naturalistic texture stimuli with responses to spectrally matched noise images, similar to the globally phase-randomized images that have been used previously in fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Malach, R. et al. Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex. Proc. Natl. Acad. Sci. USA 92, 81358139 (1995)." href="/articles/nn.3402#ref-CR34" id="ref-link-section-d30947402e1340">34</a></sup>, psychophysics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Thomson, M.G., Foster, D.H. &amp; Summers, R.J. Human sensitivity to phase perturbations in natural images: a statistical framework. Perception 29, 10571069 (2000)." href="/articles/nn.3402#ref-CR35" id="ref-link-section-d30947402e1344">35</a></sup> and physiology<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Felsen, G., Touryan, J., Han, F. &amp; Dan, Y. Cortical sensitivity to visual features in natural scenes. PLoS Biol. 3, e342 (2005)." href="/articles/nn.3402#ref-CR36" id="ref-link-section-d30947402e1348">36</a></sup> experiments. Presentation of intact and phase-randomized objects, for example, reveals differential fMRI responses throughout the human lateral occipital cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Malach, R. et al. Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex. Proc. Natl. Acad. Sci. USA 92, 81358139 (1995)." href="/articles/nn.3402#ref-CR34" id="ref-link-section-d30947402e1352">34</a></sup>. But none of these studies reported differences between V1 and V2. This may be due to the use of uncontrolled images of natural objects or scenes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Felsen, G. &amp; Dan, Y. A natural approach to studying vision. Nat. Neurosci. 8, 16431646 (2005)." href="/articles/nn.3402#ref-CR37" id="ref-link-section-d30947402e1356">37</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Rust, N.C. &amp; Movshon, J.A. In praise of artifice. Nat. Neurosci. 8, 16471650 (2005)." href="/articles/nn.3402#ref-CR38" id="ref-link-section-d30947402e1359">38</a></sup>, which obscures the influence of the higher-order statistical dependencies on which we have focused and instead emphasizes responses in downstream object-selective areas. A previous study of V1 and V2 used natural photographs as stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Willmore, B.D., Prenger, R.J. &amp; Gallant, J.L. Neural representation of natural images in visual area V2. J. Neurosci. 30, 21022114 (2010)." href="/articles/nn.3402#ref-CR13" id="ref-link-section-d30947402e1364">13</a></sup>, but this study had different goals and did not relate neuronal responses to the particular statistical dependencies considered here. The spatial homogeneity of our stimuli, coupled with a synthesis method that enforced a particular set of higher-order statistical dependencies, facilitated robust and specific links between neuronal responses in V2, image statistics and perception. Our ability to generate multiple images from each texture family also facilitated comparisons between neurophysiology (averaging across neurons with different receptive field locations) and human fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heeger, D.J., Boynton, G.M., Demb, J.B., Seidemann, E. &amp; Newsome, W.T. Motion opponency in visual cortex. J. Neurosci. 19, 71627174 (1999)." href="/articles/nn.3402#ref-CR39" id="ref-link-section-d30947402e1368">39</a></sup>. Synthetic naturalistic stimuli like ours thus offer a balance between natural and artificial that may prove useful in physiological characterization in other sensory domains<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="McDermott, J.H. &amp; Simoncelli, E.P. Sound texture perception via statistics of the auditory periphery: evidence from sound synthesis. Neuron 71, 926940 (2011)." href="/articles/nn.3402#ref-CR40" id="ref-link-section-d30947402e1372">40</a></sup>.</p><p>We used a large-scale, crowd-sourced psychophysical experiment to show that particular subsets of higher-order statistical dependencies predicted diversity in perceptual sensitivityand, by extension, neuronal responses in V2. Correlations among energy filter responses (akin to V1 complex cells) were more important than among linear filter responses (akin to V1 simple cells), which is notable given that V2 neurons receive input from both simple and complex cells (Y. El-Shamayleh, R.F. Kumbhani, N.T. Dhruv &amp; J.A. Movshon, <i>Soc. Neurosci. Abstr.</i> 404.3, 2009). The particular computation implied by the responses to our stimuli may depend primarily on complex cell input. This hypothesis could be further explored by combining our stimulus protocol with measures of V1-to-V2 connectivity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Glickfeld, L.L., Andermann, M.L., Bonin, V. &amp; Reid, R.C. Cortico-cortical projections in mouse visual cortex are functionally target specific. Nat. Neurosci. 16, 219226 (2013)." href="/articles/nn.3402#ref-CR41" id="ref-link-section-d30947402e1383">41</a></sup>. Our analysis of crowd-sourced data also revealed the importance of dependencies across scale, followed by dependencies across position and orientation. Most studies of V2 thus far have emphasized interactions across orientation; for example, by measuring responses to curvature or angles<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Hegd, J. &amp; Essen, D.C.V. Selectivity for complex shapes in primate visual area V2. J. Neurosci. 20, RC61RC66 (2000)." href="/articles/nn.3402#ref-CR4" id="ref-link-section-d30947402e1387">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Hegd, J. &amp; Essen, D.C.V. A comparative study of shape representation in macaque visual areas v2 and v4. Cereb. Cortex 17, 11001116 (2007)." href="/articles/nn.3402#ref-CR5" id="ref-link-section-d30947402e1390">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Ito, M. &amp; Komatsu, H. Representation of angles embedded within contour stimuli in area V2 of macaque monkeys. J. Neurosci. 24, 33133324 (2004)." href="/articles/nn.3402#ref-CR8" id="ref-link-section-d30947402e1393">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Anzai, A., Peng, X. &amp; Van Essen, D.C. Neurons in monkey visual area V2 encode combinations of orientations. Nat. Neurosci. 10, 13131321 (2007)." href="/articles/nn.3402#ref-CR9" id="ref-link-section-d30947402e1396">9</a></sup>. These visual elements are salient in man-made environments but may play an outsized role in our intuitions about how the visual system begins the process of parsing natural scenes. Instead, we infer that V2 neurons might be particularly sensitive to dependencies across scale, which are equally fundamental to natural image structure.</p><p>The statistical dependencies in our texture stimuli are readily computable from the responses of V1 neurons. Given our results, it is tempting to hypothesize that V2 neurons directly encode correlations of their V1 afferents. However, a variety of nonlinear computations, similar in function but differing in detail, can effectively capture the same information and could enable the sensitivity to naturalistic stimuli that we found in V2. For example, selectivity for different kinds of correlations could be achieved by combining squared and spatially pooled linear combinations of appropriate V1 inputs, analogously to the way 'motion energy' computations can express the correlations of the Reichardt model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Adelson, E.H. &amp; Bergen, J.R. Spatiotemporal energy models for the perception of motion. J. Opt. Soc. Am. A 2, 284299 (1985)." href="/articles/nn.3402#ref-CR42" id="ref-link-section-d30947402e1403">42</a></sup>. Such 'complex cells' in V2 would give enhanced responses to stimuli containing higher-order correlations, unlike V2 'simple cells', which would linearly combine the responses of orientation-tuned filters (refs. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Anzai, A., Peng, X. &amp; Van Essen, D.C. Neurons in monkey visual area V2 encode combinations of orientations. Nat. Neurosci. 10, 13131321 (2007)." href="/articles/nn.3402#ref-CR9" id="ref-link-section-d30947402e1406">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Willmore, B.D., Prenger, R.J. &amp; Gallant, J.L. Neural representation of natural images in visual area V2. J. Neurosci. 30, 21022114 (2010)." href="/articles/nn.3402#ref-CR13" id="ref-link-section-d30947402e1409">13</a> and B. Vintch, J.A. Movshon and E.P. Simoncelli, E.P. <i>Soc. Neurosci. Abstr.</i> 580.4, 2010). In this framework, the larger receptive field sizes of V2 cells would allow them to compute correlations of V1 inputs across distinct spatial positions, as well as across different orientations and scales; our analyses revealed importance for all three factors (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig7">Fig. 7d</a>). Individual V2 complex cells could be sensitive only to particular subsets of higher-order correlations, explaining both why some texture families were more effective on average (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2e</a>) and why there was a diversity of selectivity across individual neurons (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2d</a>). The idea of a V2 complex cell is conceptually satisfying because it suggests that nonlinear computations of identical form reappear at multiple stages of the cortical hierarchy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Heeger, D.J., Simoncelli, E.P. &amp; Movshon, J.A. Computational models of cortical visual processing. Proc. Natl. Acad. Sci. USA 93, 623627 (1996)." href="/articles/nn.3402#ref-CR43" id="ref-link-section-d30947402e1426">43</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Carandini, M. &amp; Heeger, D.J. Normalization as a canonical neural computation. Nat. Rev. Neurosci. 13, 5162 (2012)." href="/articles/nn.3402#ref-CR44" id="ref-link-section-d30947402e1429">44</a></sup>, and it could be further explored in V2 by measuring responses to naturalistic or artificial stimuli containing specific higher-order correlations and predicting their responses with hierarchical models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Rust, N.C., Mante, V., Simoncelli, E.P. &amp; Movshon, J.A. How MT cells analyze the motion of visual patterns. Nat. Neurosci. 9, 14211431 (2006)." href="/articles/nn.3402#ref-CR45" id="ref-link-section-d30947402e1433">45</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Vintch, B., Zaharia, A.Z., Movshon, J.A. &amp; Simoncelli, E.P. Efficient and direct estimation of a neural subunit model for sensory coding. in Advances in Neural Information Processing Systems vol. 25 (eds. Bartlett, P., Pereira, F.C.N., Burges, C.J.C., Bottou, L. &amp; Weinberger, K.Q.), 31133121 (2012)." href="/articles/nn.3402#ref-CR46" id="ref-link-section-d30947402e1436">46</a></sup>.</p><p>The transformation of visual information as it ascends the cortical hierarchy enables the perception of scenes and objects. A common view is that early computations encode the primitive elements of which scenes are made and that subsequent stages of processing assemble these elements into larger and more complex combinations, capturing the structural relationships that determine the visual world. This constructionist view has stumbled on the problem of V2, whose neurons have stubbornly refused to reveal the form of their preferred elementary feature combinations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Peterhans, E. &amp; Heydt, R.V.D. Mechanisms of contour perception in monkey visual cortex. II. Contours bridging gaps. J. Neurosci. 9, 17491763 (1989)." href="/articles/nn.3402#ref-CR3" id="ref-link-section-d30947402e1443">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Hegd, J. &amp; Essen, D.C.V. Selectivity for complex shapes in primate visual area V2. J. Neurosci. 20, RC61RC66 (2000)." href="/articles/nn.3402#ref-CR4" id="ref-link-section-d30947402e1446">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Hegd, J. &amp; Essen, D.C.V. A comparative study of shape representation in macaque visual areas v2 and v4. Cereb. Cortex 17, 11001116 (2007)." href="/articles/nn.3402#ref-CR5" id="ref-link-section-d30947402e1449">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Lee, T.S. &amp; Nguyen, M. Dynamics of subjective contour formation in the early visual cortex. Proc. Natl. Acad. Sci. USA 98, 19071911 (2001)." href="/articles/nn.3402#ref-CR6" id="ref-link-section-d30947402e1452">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Mahon, L.E. &amp; Valois, R.L.D. Cartesian and non-Cartesian responses in LGN, V1, and V2 cells. Vis. Neurosci. 18, 973981 (2001)." href="/articles/nn.3402#ref-CR7" id="ref-link-section-d30947402e1455">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Ito, M. &amp; Komatsu, H. Representation of angles embedded within contour stimuli in area V2 of macaque monkeys. J. Neurosci. 24, 33133324 (2004)." href="/articles/nn.3402#ref-CR8" id="ref-link-section-d30947402e1458">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Anzai, A., Peng, X. &amp; Van Essen, D.C. Neurons in monkey visual area V2 encode combinations of orientations. Nat. Neurosci. 10, 13131321 (2007)." href="/articles/nn.3402#ref-CR9" id="ref-link-section-d30947402e1462">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="El-Shamayleh, Y. &amp; Movshon, J.A. Neuronal responses to texture-defined form in macaque visual area v2. J. Neurosci. 31, 85438555 (2011)." href="/articles/nn.3402#ref-CR10" id="ref-link-section-d30947402e1465">10</a></sup>. We have found it useful to attack this problem with well-controlled texture stimuli that emphasize the statistical regularities of natural images, as well as with stimuli containing more conventional visual features. Our findings suggest that two fundamental constituents of visual scenesthe specific feature combinations that comprise objects and the statistics that define textures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Adelson, E.H. On seeing stuff: the perception of materials by humans and machines. Proc. SPIE 4299, 1 (2001)." href="/articles/nn.3402#ref-CR47" id="ref-link-section-d30947402e1469">47</a></sup>may both be represented in V2.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Methods</h2><div class="c-article-section__content" id="Sec9-content"><h3 class="c-article__sub-heading" id="Sec10">Model and synthesis of stimuli.</h3><h3 class="c-article__sub-heading" id="Sec11">Model.</h3><p>Here we describe aspects of the model and stimulus generation common to all experiments. Further details of stimulus presentation for each experimental method are presented separately below. Stimuli in all experiments were generated using the texture analysissynthesis procedure described in ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Portilla, J. &amp; Simoncelli, E.P. A parametric texture model based on joint statistics of complex wavelet coefficients. Int. J. Comput. Vis. 40, 4970 (2000)." href="/articles/nn.3402#ref-CR19" id="ref-link-section-d30947402e1489">19</a> (code and examples available at <a href="http://www.cns.nyu.edu/~lcv/texture/">http://www.cns.nyu.edu/~lcv/texture/</a>). We began with an ensemble of diverse natural homogenous black and white photographs of visual textures, drawn from both commercial and personal databases. Each original texture photograph served as the basis for a texture family. Most of our experiments used 15 texture families, selected to vary in the extent to which each texture differed from an image of spectrally matched noise. The crowd-sourced psychophysical experiments (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">Figs. 6</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig7">7</a>) used an additional 479 texture families, selected only to avoid duplicates and images with entirely blank regions (for example, sky). For each texture family, we computed the model parameters on the original photograph, by processing the image with a multi-scale, multi-oriented bank of filters with four orientations and four spatial scales. For each filter, we computed the real, linear output and the energy (square root of sum of squared quadrature pair outputs). We then computed pairwise products across filter responses at different positions (within each orientation and scale), across different orientations and across different scales. All of these pairwise products were averaged across the spatial extent of the image, yielding correlations. We also computed spectral statistics (average energy within each band of the pyramid) and marginal pixel statistics (skew and kurtosis).</p><h3 class="c-article__sub-heading" id="Sec12">Synthesis.</h3><p>After computing the model responses on an original image, we synthesized 15 new samples by initializing 15 different images of Gaussian white noise and adjusting each using gradient descent (specifically, gradient projection) until it matched the model parameters computed on the original image. Because the dimensionality of the image was larger than the number of parameters, this process yielded multiple random high-entropy samples that were statistically identical in terms of the model parameters. Convergence of all parameter groups was monitored and ensured, and the number of synthesis iterations used (50) was far more than typically required. For each texture family, we also generated spectrally matched noise images by randomizing the phase but matching the complete two-dimensional power spectra. This procedure yielded nearly identical results to iteratively matching the power averaged within each band of the multi-scale, multi-oriented filter bank but was preferred for speed of computation. We performed noise synthesis separately on each naturalistic texture sample to generate 15 samples. For psychophysical experiments, we generated stimuli that spanned a naturalness axis between naturalistic and noise. For each texture family, we computed the model parameter vector <b>p</b><sub>nat</sub> on the original natural photograph and parameters <b>p</b><sub>noise</sub> on a spectrally matched noise image and then linearly interpolated the model parameters between the two endpoints, <img src="//media.springernature.com/lw176/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_IEq1_HTML.gif" style="width:176px;max-width:none;" alt="">. For each interpolated parameter vector, we used the same synthesis procedure to generate 15 samples. Pilot experiments suggested that the distribution of thresholds across texture families was approximately normally distributed in the log domain, so we sampled the naturalness axis with 10 values of <i></i> equally spaced on a logarithmic scale. For laboratory psychophysics, we used a range of 0.040.8; for crowd-sourced psychophysics, we used a range of 0.11.0 (see below).</p><h3 class="c-article__sub-heading" id="Sec13">Physiology.</h3><h3 class="c-article__sub-heading" id="Sec14">Recording.</h3><p>We recorded from 13 anesthetized, paralyzed, adult macaque monkeys (2 <i>Macaca nemestrina</i> and 11 <i>M. cynomolgus</i>). Our standard methods for surgical preparation have been documented previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Cavanaugh, J.R., Bair, W. &amp; Movshon, J.A. Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons. J. Neurophysiol. 88, 25302546 (2002)." href="/articles/nn.3402#ref-CR48" id="ref-link-section-d30947402e1553">48</a></sup>. We maintained anesthesia with infusion of sufentanil citrate (630 g kg<sup>1</sup> h<sup>1</sup>) and paralysis with infusion of vecuronium bromide (Norcuron; 0.1 mg kg<sup>1</sup> h<sup>1</sup>) in isotonic dextrose-Normosol solution. We monitored vital signs (heart rate, lung pressure, EEG, body temperature, urine volume and specific gravity, and end-tidal pCO<sub>2</sub>) and maintained them within physiological ranges. The eyes were protected with gas-permeable contact lenses and refracted with supplementary lenses chosen through direct ophthalmoscopy. At the conclusion of data collection, the animal was killed with an overdose of sodium pentobarbital. All experimental procedures were conducted in compliance with US National Institutes of Health Guide for the Care and Use of Laboratory Animals and with the approval of the New York University Animal Welfare Committee. We made a craniotomy and durotomy centered approximately 24 mm posterior to the lunate sulcus and 1016 mm lateral and individually advanced several quartz-platinum-tungsten microelectrodes (Thomas Recording) into the brain at an angle 20 from vertical. We distinguished V2 from V1 on the basis of depth from the cortical surface and changes in the receptive field location of recorded units. In an effort to obtain an unbiased sample of single units, we made extracellular recordings in V1 and V2 from every single unit with a spike waveform that rose sufficiently above noise to be isolated, and we fully characterized every unit that demonstrated a measurable visually evoked response to gratings or naturalistic texture. Data are reported from every unit for which we completed characterization (see below). The receptive fields of most units were between 2 and 5 eccentricity, but our estimates of eccentricity were not sufficiently precise to include in analyses.</p><h3 class="c-article__sub-heading" id="Sec15">Visual stimulation.</h3><p>We presented visual stimuli on a gamma-corrected CRT monitor (Eizo T966; mean luminance, 33 cd/m<sup>2</sup>) at a resolution of 1,280  960 with a refresh rate of 120 Hz. Stimuli were presented using Expo software on an Apple Macintosh computer. For each isolated unit, we first determined its ocular dominance and occluded the non-preferred eye. We used drifting sinusoidal gratings to characterize the basic receptive field properties of each unit, including tuning for orientation and direction, spatial and temporal frequency, size and contrast. We then presented the texture stimuli. We used a set of 15 texture families and generated 15 samples for each texture family for a total of 225 images. We also presented 15 spectrally matched noise samples of the 15 families. The 450 unique images making up our stimulus ensemble were presented in pseudorandom order for 100 ms each, separated by 100 ms of mean luminance. Each image was presented 20 times. Images were presented to every unit at the same scale and at a size of 4 in a raised cosine aperture. We chose a 4 aperture to be larger than all the receptive fields at the eccentricities from which we typically record. Nearly all recorded units had receptive fields smaller than 4, and the majority were less than 2. For a subset of V1 and V2 neurons, we also presented stimuli in a smaller aperture matched to the receptive field size of that unit. The aperture diameter was set to be the grating summation field as measured with full contrast drifting gratings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Cavanaugh, J.R., Bair, W. &amp; Movshon, J.A. Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons. J. Neurophysiol. 88, 25302546 (2002)." href="/articles/nn.3402#ref-CR48" id="ref-link-section-d30947402e1578">48</a></sup>. We ran the full texture stimulus ensemble in this aperture, although typically with only 510 repeats per image.</p><h3 class="c-article__sub-heading" id="Sec16">Analysis.</h3><p>The full stimulus ensemble consisted of 450 images presented 20 times each. All analyses were performed after averaging spiking responses across those 20 repeats and also averaging responses across the 15 samples. Depending on the analysis, responses were further averaged across texture family, neurons and/or a temporal window. Response time courses were computed by counting spikes in a sliding, nonoverlapping 10-ms window. Time courses were always averaged across texture families (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2a,b</a>). For the population average plot (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2b</a>), time courses for each neuron were first normalized by dividing by each neuron's maximum response across all texture families and time points but after averaging responses evoked by the 20 repeats of each of the 15 images in the same texture family. A modulation index was computed as the difference in firing rate between naturalistic and noise divided by the sum. The index was computed separately for each texture family. For time course plots (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2c</a>), modulation was computed in 10-ms windows. In all other cases, firing rates were first averaged within a 100-ms window following response onset, and the modulation index was computed on those rates. Response onset was determined by inspection as the time point eliciting a response above baseline; results were nearly identical when using a quantitative criterion based on the s.d. of the response. Finally, modulation indices were also averaged across neurons (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2e</a>) or across texture families (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2f</a>).</p><p>Basic receptive field properties for each neuronfor example, receptive field size, surround suppressionwere determined offline by using maximum likelihood estimation to fit an appropriate parametric form to each tuning function. These fits were only obtainable for a subset of neurons (81% in V1, 74% in V2) owing to incomplete characterization arising from time constraints during the experiment.</p><h3 class="c-article__sub-heading" id="Sec17">fMRI.</h3><h3 class="c-article__sub-heading" id="Sec18">Subjects.</h3><p>Data were acquired from three healthy subjects with normal or corrected-to-normal vision (all male; age range, 2630 years). Two subjects were authors. Experiments were conducted with the written consent of each subject and in accordance with the safety guidelines for fMRI research, as approved by the University Committee on Activities Involving Human Subjects at New York University. Each subject participated in at least three scanning sessions: one session to obtain a set of high-resolution anatomical volumes, one session for standard retinotopic mapping (single wedge angular position and expanding ring eccentricity) and one session to measure differential responses to naturalistic and spectrally matched noise stimuli. Two subjects participated in an extra scanning session using texture families derived from the crowd-sourced psychophysical experiment (described below).</p><h3 class="c-article__sub-heading" id="Sec19">Stimuli.</h3><p>Stimuli were presented using <span class="u-small-caps">MATLAB</span> (MathWorks) and MGL (available at <a href="http://justingardner.net/mgl/">http://justingardner.net/mgl/</a>) on an Apple Macintosh computer. Stimuli were displayed via an LCD projector (Eiki LC-XG250) onto a back-projection screen in the bore of the magnet. Subjects lay supine and viewed the stimuli through an angled mirror. All images were presented in a suitably vignetted annular region (inner radius, 2; outer radius, 8). We used textures that approximately matched in scale the presentation conditions in the electrophysiological and psychophysical experiments.</p><h3 class="c-article__sub-heading" id="Sec20">Protocol.</h3><p>Blocks of naturalistic and spectrally matched noise stimuli were presented in alternation. In each 9-s block, a random sequence of images from one texture family were presented at 5 Hz. Each run consisted of 20 blocks: 10 naturalistic, 10 noise. Different texture families were presented in separate runs, and multiple runs were performed in each session. Subjects performed two runs for each texture family. In each session, a separate localizer run was used to define retinotopic subregions corresponding to the stimulus region. In each 9-s block of the localizer run, a random sequence of both naturalistic and noise stimuli were presented within the stimulus annulus or the region complementary to the annulus. Each run consisted of 40 blocks: 20 annulus, 20 anti-annulus.</p><h3 class="c-article__sub-heading" id="Sec21">Task.</h3><p>Observers performed a demanding two-back detection task continuously throughout each run to maintain a consistent behavioral state, encourage fixation and divert attention from the peripheral stimulus. Without attentional control, we have reported large and variable attentional signals in visual cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Ress, D., Backus, B.T. &amp; Heeger, D.J. Activity in primary visual cortex predicts performance in a visual detection task. Nat. Neurosci. 3, 940945 (2000)." href="/articles/nn.3402#ref-CR32" id="ref-link-section-d30947402e1656">32</a></sup>. Digits (0 to 9) were displayed continuously at fixation, changing every 400 ms. The observer used a button press to indicate whether the current digit matched the digit from two steps before.</p><h3 class="c-article__sub-heading" id="Sec22">Preprocessing.</h3><p>All preprocessing and analyses were implemented in <span class="u-small-caps">MATLAB</span> using mrTools (<a href="http://www.cns.nyu.edu/heegerlab/?page=software">http://www.cns.nyu.edu/heegerlab/?page=software</a>). The anatomical volume acquired in each scanning session was aligned to the high-resolution anatomical volume of the same subject's brain, using a robust image registration algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Nestares, O. &amp; Heeger, D.J. Robust multiresolution alignment of MRI brain volumes. Magn. Reson. Med. 43, 705715 (2000)." href="/articles/nn.3402#ref-CR49" id="ref-link-section-d30947402e1678">49</a></sup>. Data from the first half cycle (eight frames) of each functional run were discarded to minimize the effect of transient magnetic saturation and allow the hemodynamic response to reach steady state. Head movement within and across scans was compensated for using standard procedures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Nestares, O. &amp; Heeger, D.J. Robust multiresolution alignment of MRI brain volumes. Magn. Reson. Med. 43, 705715 (2000)." href="/articles/nn.3402#ref-CR49" id="ref-link-section-d30947402e1682">49</a></sup>. The time series from each voxel was high-pass filtered (cutoff, 0.01 Hz) to remove low-frequency noise and drift<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Smith, A.M. et al. Investigation of low frequency drift in fMRI signal. Neuroimage 9, 526533 (1999)." href="/articles/nn.3402#ref-CR50" id="ref-link-section-d30947402e1686">50</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec23">Analysis.</h3><p>We performed two complementary analyses of fMRI responses to alternating blocks of naturalistic texture and noise stimuli, one to visualize responses and a second to quantify them for statistical analyses (and for comparisons to psychophysics and physiology). First, for each voxel, response time courses were averaged across texture families and fit with a sinusoid with period matched to the block alternation (9 s). The coherence between the best-fitting sinusoid and the average time series was used to assess the statistical reliability of differences in cortical activity evoked by naturalistic and noise stimuli, visualized on flattened maps of the occipital lobe (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4a,c</a>).</p><p>To quantify responses, we computed an fMRI modulation index, analogous to the index used for single unit measurements. We computed the index as the ratio of two response amplitudes: the amplitude of differential responses to naturalistic versus noise (texture minus noise) and the amplitude of differential responses to naturalistic and noise together versus a blank screen (texture plus noise). To obtain the numerator (texture minus noise), for each texture family, we averaged the time course of each voxel across repeated runs and then projected it onto a unit-norm sinusoid having period matched to the stimulus alternation and phase given by the responses to the localizer scan (see above). The reference phase provided an estimate of the hemodynamic delay and was computed separately for each visual area. The amplitude of projection isolated the component of the response time course that responded positively and differentially to the naturalistic texture stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heeger, D.J., Boynton, G.M., Demb, J.B., Seidemann, E. &amp; Newsome, W.T. Motion opponency in visual cortex. J. Neurosci. 19, 71627174 (1999)." href="/articles/nn.3402#ref-CR39" id="ref-link-section-d30947402e1704">39</a></sup>. To obtain the denominator (texture plus noise), we projected the response time courses from the localizer scan onto a unit-norm sinusoid with the same reference phase. The amplitude of this projection captured the combined response to texture and noise images together because the localizer scan presented both (randomly interleaved) alternating with a blank screen. Both response amplitudes (texture minus noise and texture plus noise) were averaged across voxels, and their ratio yielded a modulation index for each visual area. fMRI modulation indices were then either averaged across texture families (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Fig. 4b</a>) or analyzed separately (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">Figs. 4d</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">5e</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">6e</a>). Results were qualitatively similar (and supported the same conclusions) when this fMRI modulation index was replaced by either coherence or the texture-minus-noise response amplitudes (without division by texture-plus-noise response amplitudes).</p><h3 class="c-article__sub-heading" id="Sec24">MRI acquisition.</h3><p>MRI data were acquired on a Siemens 3T Allegra head-only scanner using a head coil (NM-011; Nova Medical) for transmitting and an eight-channel phased array surface coil (NMSC-071; Nova Medical) for receiving. Functional scans were acquired with gradient recalled echo-planar imaging to measure blood oxygen leveldependent changes in image intensity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Ogawa, S., Lee, T.M., Kay, A.R. &amp; Tank, D.W. Brain magnetic resonance imaging with contrast dependent on blood oxygenation. Proc. Natl. Acad. Sci. USA 87, 98689872 (1990)." href="/articles/nn.3402#ref-CR51" id="ref-link-section-d30947402e1728">51</a></sup>. Functional imaging was conducted with 24 slices oriented perpendicular to the calcarine sulcus and positioned with the most posterior slice at the occipital pole (1,500 ms repetition time; 30 ms echo time; 72 flip angle; 2  2  2 mm voxel size; 104  80 voxel grid). A T1-weighted magnetization-prepared rapid gradient echo anatomical volume (MPRAGE) was acquired in each scanning session with the same slice prescriptions as the functional images (1,530 ms repetition time; 3.8 ms echo time; 8 flip angle; 1  1  2.5 mm voxel size; 256  160 voxel grid). A high-resolution anatomical volume, acquired in a separate session, was the average of three MPRAGE scans that were aligned and averaged (2,500 ms repetition time; 3.93 ms echo time; 8 flip angle; 1  1  1 mm voxel size; 256  256 voxel grid). This high-resolution anatomical scan was used both for registration across scanning sessions and for gray matter segmentation and cortical flattening.</p><h3 class="c-article__sub-heading" id="Sec25">Defining retinotopic regions of interest.</h3><p>Each subject participated in a standard retinotopic mapping experiment, described in detail previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Larsson, J. &amp; Heeger, D.J. Two retinotopic visual areas in human lateral occipital cortex. J. Neurosci. 26, 1312813142 (2006)." href="/articles/nn.3402#ref-CR25" id="ref-link-section-d30947402e1740">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Gardner, J.L., Merriam, E.P., Movshon, J.A. &amp; Heeger, D.J. Maps of visual space in human occipital cortex are retinotopic, not spatiotopic. J. Neurosci. 28, 39883999 (2008)." href="/articles/nn.3402#ref-CR52" id="ref-link-section-d30947402e1743">52</a></sup>. The data were analyzed following standard procedures to identify meridian representations corresponding to the borders between retinotopically organized visual areas V1, V2, V3 and V4. There is some controversy over the exact definition of human V4 and the area just anterior to it; we adopted the conventions proposed in ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Wandell, B.A., Dumoulin, S.O. &amp; Brewer, A.A. Visual field maps in human cortex. Neuron 56, 366383 (2007)." href="/articles/nn.3402#ref-CR24" id="ref-link-section-d30947402e1746">24</a>. We used data from an independent localizer scan (see above) to further restrict each visual area to only those voxels responding to the stimulus annulus with coherence of at least 0.25. Qualitatively similar results were obtained using higher or lower thresholds.</p><h3 class="c-article__sub-heading" id="Sec26">Psychophysics (laboratory).</h3><h3 class="c-article__sub-heading" id="Sec27">Observers.</h3><p>Three observers with normal or corrected-to-normal vision participated in the experiments (all male; age range, 2630 years). Protocols for selection of observers and experimental procedures were approved by the Human Subjects Committee of New York University. Two observers were authors. The other was naive to the purpose of the experiment.</p><h3 class="c-article__sub-heading" id="Sec28">Stimuli.</h3><p>Stimuli were presented on a 41  30 cm flat screen CRT monitor at a distance of 46 cm. Texture images were presented in vignetted 4 circular patches at three locations equidistant from fixation, each 4 eccentricity (one above fixation, one to the lower left and one to the lower right). A 0.25 degree fixation square was shown throughout the experiment.</p><h3 class="c-article__sub-heading" id="Sec29">Task.</h3><p>Every trial of the three-alternative, forced-choice (3AFC) 'oddity' task presented three different images in the three patches: two images were spectrally matched noise and one was naturalistic, or one was noise and two were naturalistic. The naturalness of the naturalistic texture(s) varied across trials, chosen from ten values between 0.04 and 0.8, equally spaced on a log scale. If two naturalistic textures were presented on a trial, they had the same level of naturalness. Image patches were presented for 600 ms, after which observers had 1 s to indicate with a keypress which of the three was the odd one out. There was no feedback during the experiment. Before the experiment, each observer performed a small number of practice trials (<span class="stix"></span>10) with feedback to become familiar with the task. Different texture families were run in separate blocks. Each observer performed 480 trials in each block; the order of conditions and location of the target were appropriately randomized and counterbalanced. Blocks were performed in random order for each subject. Data were collected from 15 texture families.</p><h3 class="c-article__sub-heading" id="Sec30">Analysis.</h3><p>For each texture family, we fit the parameters of a Weibull function that maximized the likelihood of the psychometric data. The function was parameterized with a threshold, slope and lapse rate<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Wichmann, F.A. &amp; Hill, N.J. The psychometric function: I. Fitting, sampling, and goodness of fit. Percept. Psychophys. 63, 12931313 (2001)." href="/articles/nn.3402#ref-CR53" id="ref-link-section-d30947402e1788">53</a></sup>. Estimated lapse rates were typically very small (mean 0.01, maximum 0.06). Threshold was converted to its reciprocal (sensitivity) for all subsequent analyses, and statisticsfor example, correlationswere computed in the log domain (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Figs. 5</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">6</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig7">7</a>).</p><h3 class="c-article__sub-heading" id="Sec31">Psychophysics (crowd-sourced).</h3><h3 class="c-article__sub-heading" id="Sec32">Observers.</h3><p>Several hundred observers ('Turkers') were recruited for experiments through Amazon.com's Mechanical Turk website (<a href="http://www.mturk.com/">http://www.mturk.com/</a>). Each was paid $0.40 for approximately 5 min of their time. Payment was made so long as Turkers completed the task, regardless of performance. Demographic data were not collected, but demographic studies of the Mechanical Turk<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Paolacci, G., Chandler, J. &amp; Ipeirotis, P. Running experiments on Amazon Mechanical Turk. Judgm. Decis. Mak. 5, 411419 (2010)." href="/articles/nn.3402#ref-CR27" id="ref-link-section-d30947402e1822">27</a></sup> suggest that our sample reflected gender and age diversity. Participation was restricted to those Turkers achieving 95% approval rating on other Mechanical Turk tasks. Protocols for selection of Turkers and experimental procedures were approved by the human subjects committee of New York University. All Turkers signed an electronic consent form at the beginning of the experiment. We ensured that ten unique Turkers completed the task for each texture family, but we did not prevent the same Turkers from completing the task for multiple texture families.</p><h3 class="c-article__sub-heading" id="Sec33">Stimuli.</h3><p>We developed a version of our 3AFC task for display in a web browser (see example at <a href="http://www.jeremyfreeman.net/public/turk/code/?csv=tex-018-files.csv">http://www.jeremyfreeman.net/public/turk/code/?csv=tex-018-files.csv</a>), using Javascript and HTML. Each trial began with 700-ms blank period, followed by a 600-ms stimulus presentation and a second 700-ms blank period. As in the laboratory version of the experiment, images were presented in three patches equidistant from fixation. A small red fixation dot was shown throughout the experiment. After the second blank, three arrows were presented near fixation pointing toward the three possible target locations. Turkers were instructed that One image will look different from the other two  your task is to identify it by clicking the black arrow that points to it. There was no other explanation of the nature of the stimuli nor the conditions. We were unable to verify or control viewing distance, size, eccentricity or presentation time. However, data obtained from the crowd and from the lab were comparable (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">Fig. 6b</a>), suggesting that such variations were unimportant, at least with respect to this stimulus and task.</p><h3 class="c-article__sub-heading" id="Sec34">Task.</h3><p>Trial types for the 3AFC task were similar to those in the laboratory experiment, except that naturalness was varied across ten points equally spaced on a logarithmic scale between 0.1 and 1.0, instead of 0.04 to 0.8. This range was chosen because pilot experiments suggested moderately higher thresholds than in the laboratory data. Each Turker performed 60 trials, and different texture families were run separately. There was no feedback during the experiment, but Turkers performed 6 trials at the beginning with 1.0 naturalness and were told that these initial trials would be easier than the others. Data were collected from 494 texture families.</p><h3 class="c-article__sub-heading" id="Sec35">Analysis.</h3><p>Each Turker and texture family yielded a psychometric function, based on six trials for each of ten levels of naturalness. Typically, for each texture family, a small number of Turkers performed at or near chance at all naturalness levels, suggesting that they may not have been performing the task appropriately. If data from all Turkers were averaged, the influence of these Turkers would have yielded fitted psychometric functions with unreasonably high lapse rates<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Wichmann, F.A. &amp; Hill, N.J. The psychometric function: I. Fitting, sampling, and goodness of fit. Percept. Psychophys. 63, 12931313 (2001)." href="/articles/nn.3402#ref-CR53" id="ref-link-section-d30947402e1860">53</a></sup>. As an alternative, we described the data using a mixture model, with one common psychometric function and an individual lapse rate for each Turker, based on an approach developed in a related problem setting<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Dawid, A. &amp; Skene, A. Maximum likelihood estimation of observer error-rates using the EM algorithm. J. R. Stat. Soc. Ser. C Appl. Stat. 28, 2028 (1979)." href="/articles/nn.3402#ref-CR54" id="ref-link-section-d30947402e1864">54</a></sup>. The analysis inferred the quality of individual Turkers and appropriately weighted their contribution to estimates of threshold (see <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.3402#MOESM3">Supplementary Modeling</a> for details of fitting). Although we consider this approach appropriate for these data, simple averaging of Turker responses yielded qualitatively similar results.</p><h3 class="c-article__sub-heading" id="Sec36">Validation of perceptual-neuronal relationship.</h3><p>We used the crowd-sourced sensitivities to validate the relationship between perceptual sensitivity and neuronal response as measured both with fMRI and in single units. From the distribution of 494 sensitivities, we selected 20 texture families that sampled the range of sensitivity, emphasizing the extremes (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">Fig. 6c</a>) and not including the 15 used previously. In two human subjects, we performed another fMRI experiment measuring responses to these 20 texture families. In one monkey, we recorded responses from 16 single units in V2 and 11 single units in V1 to 17 of the texture families (3 of the families were excluded owing to experimental time constraints). Experimental procedures and analyses for both fMRI and single-unit experiments were otherwise identical to those described above.</p><h3 class="c-article__sub-heading" id="Sec37">Predicting perceptual sensitivity from texture statistics.</h3><p>All naturalistic textures were generated by matching an image for a particular set of higher-order image statistical parameters derived from an original texture photograph. We used a combination of principal components analysis and multiple linear regression to relate diversity in these parameters to diversity in perceptual sensitivityand, by extension, neuronal response in V2. We began by computing all parameters for each texture family. The parameters were appropriately transformed so that all varied linearly in image contrast; for example, by taking the signed square root of correlations. Parameters were then <i>Z</i>-scored so that, for each parameter, the mean of its value across the images was 0 and the s.d. was 1. We then grouped the parameters as follows: (i) marginal statistics (skew and kurtosis), (ii) spectral statistics (average energy in each sub-band), (iii) correlations of linear filter responses at neighboring locations, (iv) correlations of linear filter responses at neighboring scales, (v) correlations of energy filter responses at neighboring orientations, (vi) correlations of energy filter responses at neighboring locations and (vii) correlations of energy filter responses at neighboring scales. For each group of parameters <i>g</i>, we constructed the 494  <i>p</i><sub><i>g</i></sub> matrix <i>P</i><sub><i>g</i></sub> containing the <i>p</i><sub><i>g</i></sub> parameters in that group for the 494 texture families. We then reduced the dimensionality of each group of parameters separately using principal components analysis, projecting each parameter matrix into the spaced spanned by the first <i>k</i> components, yielding a 494  <i>k</i><sub><i>g</i></sub> matrix <img src="//media.springernature.com/lw15/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_IEq2_HTML.gif" style="width:15px;max-width:none;" alt="">. We used the <i>k</i> components required to capture 70% of the variance in each parameter group (typically between 2 and 5, at most 10), for a total of 31 components across all groups. Overall predictive performance was similar when using only 1 component per parameter group, but that would have made it inappropriate to compare the predictive power of the different parameter groups (see below).</p><p>Having reduced the dimensionality of each parameter group, we obtained a combined predictor matrix <i>X</i>, with 494 rows and 31 columns, and used multiple linear regression to predict sensitivity to the parameters. We added a column of ones to the matrix (to account for a constant offset) and solved for the weights <img src="//media.springernature.com/lw8/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_IEq3_HTML.gif" style="width:8px;max-width:none;" alt=""> that minimized the squared error</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><img src="//media.springernature.com/lw440/springer-static/image/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_Article_BFnn3402_Equ1_HTML.gif" class="u-display-block" alt=""></div></div><p>where <b>y</b> is a vector of log sensitivities for each of the texture families (as mentioned above, we worked in the log domain because log sensitivities were approximately normally distributed). We removed from analysis any families for which thresholds were estimated as greater than 1.0 or less than 0.0 naturalness (only 4% of families), to avoid the influence of outliers arising from unstable threshold estimates.</p><p><i>R</i><sup>2</sup> for the linear model was used to assess prediction accuracy. <i>R</i><sup>2</sup> was computed for the full data set, as well as using tenfold cross-validation. In tenfold cross-validation, the model was fit to 9/10 of the data and <i>R</i><sup>2</sup> was evaluated on the remaining 1/10, and then <i>R</i><sup>2</sup> was averaged over different splits.</p><p>Three complementary procedures were used to assess the relative importance of the different parameter groups in predicting sensitivity. When parameter groups are correlated, as ours were, there is no objective decomposition of <i>R</i><sup>2</sup>, but for our primary analysis we used a well-established procedure known as averaging over orderings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Grmping, U. Estimators of relative importance in linear regression based on variance decomposition. Am. Stat. 61, 139147 (2007)." href="/articles/nn.3402#ref-CR28" id="ref-link-section-d30947402e1988">28</a></sup>. For each parameter group, a difference in <i>R</i><sup>2</sup> is computed for two models, only one of which contains the group. This differential <i>R</i><sup>2</sup> depends on the order in which the different parameter groups are added to the model, as well as the size of the model when the group is added, so its value is averaged over all possible order permutations and model sizes. The resulting estimates of <i>R</i><sup>2</sup> for each parameter group exactly partition the full model's <i>R</i><sup>2</sup> (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig7">Fig. 7</a>).</p><p>As a complementary analysis, we assessed the marginal predictive accuracy of each parameter group by computing <i>R</i><sup>2</sup> when including each parameter group on its own. We also assessed the conditional predictive accuracy of each parameter group by computing the difference in <i>R</i><sup>2</sup> for two models containing all parameter groups, with or without the group of interest. Both these analyses yielded qualitatively similar results to the averaging-over-orderings procedure, in particular emphasizing the importance of cross-scale dependencies of energy filter responses.</p><h3 class="c-article__sub-heading" id="Sec38">Statistical testing.</h3><p>Except where noted, all statistical tests for differences of fMRI and single-unit responses between V1 and V2 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Figs. 2</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig4">4</a>) or differences in single-unit responses across size conditions (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig3">Fig. 3</a>) used two-tailed, unpaired <i>t</i>-tests. Relationships among single-unit, fMRI and psychophysical data (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig5">Figs. 5</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig6">6</a>) and between single-unit modulation and basic response properties were tested for significance of correlation using a <i>t</i>-statistic. Sample sizes for statistical tests were greater than 50, except for sample sizes of 15 when analyzing the 15 texture families. There was no evidence of significant deviations from normality for data subjected to statistical tests that assume normality. As noted above, psychophysical sensitivity was expressed on a logarithmic scale because sensitivities were approximately normally distributed in the log domain. Analyses of the significance of modulation for each individual neuron (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.3402#Fig2">Fig. 2f</a>) was computed using a randomization test: the neuron's firing rate to each image was randomly assigned to either naturalistic or noise and the modulation index computed. This procedure was repeated 10,000 times, and we computed the fraction of the resulting null distribution that exceeded the measured modulation for that neuron.</p></div></div></section>
                </div>
            

            <div>
                <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1"><p class="c-article-references__text" id="ref-CR1">Schiller, P.H. &amp; Malpeli, J.G. The effect of striate cortex cooling on area 18 cells in the monkey. <i>Brain Res.</i> <b>126</b>, 366369 (1977).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0006-8993(77)90734-X" data-track-action="article reference" href="https://doi.org/10.1016%2F0006-8993%2877%2990734-X" aria-label="Article reference 1" data-doi="10.1016/0006-8993(77)90734-X">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaE2s7otlSnug%3D%3D" aria-label="CAS reference 1">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=405082" aria-label="PubMed reference 1">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20striate%20cortex%20cooling%20on%20area%2018%20cells%20in%20the%20monkey&amp;journal=Brain%20Res.&amp;doi=10.1016%2F0006-8993%2877%2990734-X&amp;volume=126&amp;pages=366-369&amp;publication_year=1977&amp;author=Schiller%2CPH&amp;author=Malpeli%2CJG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2"><p class="c-article-references__text" id="ref-CR2">Sincich, L.C. &amp; Horton, J.C. The circuitry of V1 and V2: integration of color, form, and motion. <i>Annu. Rev. Neurosci.</i> <b>28</b>, 303326 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.neuro.28.061604.135731" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.neuro.28.061604.135731" aria-label="Article reference 2" data-doi="10.1146/annurev.neuro.28.061604.135731">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXosVegtLY%3D" aria-label="CAS reference 2">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16022598" aria-label="PubMed reference 2">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20circuitry%20of%20V1%20and%20V2%3A%20integration%20of%20color%2C%20form%2C%20and%20motion&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.neuro.28.061604.135731&amp;volume=28&amp;pages=303-326&amp;publication_year=2005&amp;author=Sincich%2CLC&amp;author=Horton%2CJC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3"><p class="c-article-references__text" id="ref-CR3">Peterhans, E. &amp; Heydt, R.V.D. Mechanisms of contour perception in monkey visual cortex. II. Contours bridging gaps. <i>J. Neurosci.</i> <b>9</b>, 17491763 (1989).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.09-05-01749.1989" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.09-05-01749.1989" aria-label="Article reference 3" data-doi="10.1523/JNEUROSCI.09-05-01749.1989">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL1M3lslKhsA%3D%3D" aria-label="CAS reference 3">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=2723748" aria-label="PubMed reference 3">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6569836" aria-label="PubMed Central reference 3">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Mechanisms%20of%20contour%20perception%20in%20monkey%20visual%20cortex.%20II.%20Contours%20bridging%20gaps&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.09-05-01749.1989&amp;volume=9&amp;pages=1749-1763&amp;publication_year=1989&amp;author=Peterhans%2CE&amp;author=Heydt%2CRVD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4"><p class="c-article-references__text" id="ref-CR4">Hegd, J. &amp; Essen, D.C.V. Selectivity for complex shapes in primate visual area V2. <i>J. Neurosci.</i> <b>20</b>, RC61RC66 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.20-05-j0001.2000" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.20-05-j0001.2000" aria-label="Article reference 4" data-doi="10.1523/JNEUROSCI.20-05-j0001.2000">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10684908" aria-label="PubMed reference 4">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6772904" aria-label="PubMed Central reference 4">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Selectivity%20for%20complex%20shapes%20in%20primate%20visual%20area%20V2&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.20-05-j0001.2000&amp;volume=20&amp;pages=RC61-RC66&amp;publication_year=2000&amp;author=Hegd%C3%A9%2CJ&amp;author=Essen%2CDCV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5"><p class="c-article-references__text" id="ref-CR5">Hegd, J. &amp; Essen, D.C.V. A comparative study of shape representation in macaque visual areas v2 and v4. <i>Cereb. Cortex</i> <b>17</b>, 11001116 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhl020" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhl020" aria-label="Article reference 5" data-doi="10.1093/cercor/bhl020">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16785255" aria-label="PubMed reference 5">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20comparative%20study%20of%20shape%20representation%20in%20macaque%20visual%20areas%20v2%20and%20v4&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhl020&amp;volume=17&amp;pages=1100-1116&amp;publication_year=2007&amp;author=Hegd%C3%A9%2CJ&amp;author=Essen%2CDCV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6"><p class="c-article-references__text" id="ref-CR6">Lee, T.S. &amp; Nguyen, M. Dynamics of subjective contour formation in the early visual cortex. <i>Proc. Natl. Acad. Sci. USA</i> <b>98</b>, 19071911 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.98.4.1907" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.98.4.1907" aria-label="Article reference 6" data-doi="10.1073/pnas.98.4.1907">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXhsVWisbo%3D" aria-label="CAS reference 6">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11172049" aria-label="PubMed reference 6">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC29355" aria-label="PubMed Central reference 6">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamics%20of%20subjective%20contour%20formation%20in%20the%20early%20visual%20cortex&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.98.4.1907&amp;volume=98&amp;pages=1907-1911&amp;publication_year=2001&amp;author=Lee%2CTS&amp;author=Nguyen%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7"><p class="c-article-references__text" id="ref-CR7">Mahon, L.E. &amp; Valois, R.L.D. Cartesian and non-Cartesian responses in LGN, V1, and V2 cells. <i>Vis. Neurosci.</i> <b>18</b>, 973981 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/S0952523801186141" data-track-action="article reference" href="https://doi.org/10.1017%2FS0952523801186141" aria-label="Article reference 7" data-doi="10.1017/S0952523801186141">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD383nvFCiuw%3D%3D" aria-label="CAS reference 7">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12020088" aria-label="PubMed reference 7">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Cartesian%20and%20non-Cartesian%20responses%20in%20LGN%2C%20V1%2C%20and%20V2%20cells&amp;journal=Vis.%20Neurosci.&amp;doi=10.1017%2FS0952523801186141&amp;volume=18&amp;pages=973-981&amp;publication_year=2001&amp;author=Mahon%2CLE&amp;author=Valois%2CRLD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8"><p class="c-article-references__text" id="ref-CR8">Ito, M. &amp; Komatsu, H. Representation of angles embedded within contour stimuli in area V2 of macaque monkeys. <i>J. Neurosci.</i> <b>24</b>, 33133324 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.4364-03.2004" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.4364-03.2004" aria-label="Article reference 8" data-doi="10.1523/JNEUROSCI.4364-03.2004">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2cXjt1yhs7Y%3D" aria-label="CAS reference 8">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15056711" aria-label="PubMed reference 8">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6730022" aria-label="PubMed Central reference 8">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Representation%20of%20angles%20embedded%20within%20contour%20stimuli%20in%20area%20V2%20of%20macaque%20monkeys&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.4364-03.2004&amp;volume=24&amp;pages=3313-3324&amp;publication_year=2004&amp;author=Ito%2CM&amp;author=Komatsu%2CH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9"><p class="c-article-references__text" id="ref-CR9">Anzai, A., Peng, X. &amp; Van Essen, D.C. Neurons in monkey visual area V2 encode combinations of orientations. <i>Nat. Neurosci.</i> <b>10</b>, 13131321 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1975" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1975" aria-label="Article reference 9" data-doi="10.1038/nn1975">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXhtVOrsLrE" aria-label="CAS reference 9">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17873872" aria-label="PubMed reference 9">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Neurons%20in%20monkey%20visual%20area%20V2%20encode%20combinations%20of%20orientations&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1975&amp;volume=10&amp;pages=1313-1321&amp;publication_year=2007&amp;author=Anzai%2CA&amp;author=Peng%2CX&amp;author=Van%20Essen%2CDC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10"><p class="c-article-references__text" id="ref-CR10">El-Shamayleh, Y. &amp; Movshon, J.A. Neuronal responses to texture-defined form in macaque visual area v2. <i>J. Neurosci.</i> <b>31</b>, 85438555 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.5974-10.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.5974-10.2011" aria-label="Article reference 10" data-doi="10.1523/JNEUROSCI.5974-10.2011">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXnsl2mu7w%3D" aria-label="CAS reference 10">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21653858" aria-label="PubMed reference 10">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3142611" aria-label="PubMed Central reference 10">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuronal%20responses%20to%20texture-defined%20form%20in%20macaque%20visual%20area%20v2&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.5974-10.2011&amp;volume=31&amp;pages=8543-8555&amp;publication_year=2011&amp;author=El-Shamayleh%2CY&amp;author=Movshon%2CJA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11"><p class="c-article-references__text" id="ref-CR11">Zhou, H., Friedman, H.S. &amp; Heydt, R.V.D. Coding of border ownership in monkey visual cortex. <i>J. Neurosci.</i> <b>20</b>, 65946611 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.20-17-06594.2000" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.20-17-06594.2000" aria-label="Article reference 11" data-doi="10.1523/JNEUROSCI.20-17-06594.2000">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3cXmsVygsrY%3D" aria-label="CAS reference 11">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10964965" aria-label="PubMed reference 11">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4784717" aria-label="PubMed Central reference 11">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Coding%20of%20border%20ownership%20in%20monkey%20visual%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.20-17-06594.2000&amp;volume=20&amp;pages=6594-6611&amp;publication_year=2000&amp;author=Zhou%2CH&amp;author=Friedman%2CHS&amp;author=Heydt%2CRVD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12"><p class="c-article-references__text" id="ref-CR12">Thomas, O.M., Cumming, B.G. &amp; Parker, A.J. A specialization for relative disparity in V2. <i>Nat. Neurosci.</i> <b>5</b>, 472478 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn837" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn837" aria-label="Article reference 12" data-doi="10.1038/nn837">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38XjtFykuro%3D" aria-label="CAS reference 12">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11967544" aria-label="PubMed reference 12">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20specialization%20for%20relative%20disparity%20in%20V2&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn837&amp;volume=5&amp;pages=472-478&amp;publication_year=2002&amp;author=Thomas%2COM&amp;author=Cumming%2CBG&amp;author=Parker%2CAJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13"><p class="c-article-references__text" id="ref-CR13">Willmore, B.D., Prenger, R.J. &amp; Gallant, J.L. Neural representation of natural images in visual area V2. <i>J. Neurosci.</i> <b>30</b>, 21022114 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.4099-09.2010" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.4099-09.2010" aria-label="Article reference 13" data-doi="10.1523/JNEUROSCI.4099-09.2010">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXkt12ltL0%3D" aria-label="CAS reference 13">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20147538" aria-label="PubMed reference 13">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2994536" aria-label="PubMed Central reference 13">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20representation%20of%20natural%20images%20in%20visual%20area%20V2&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.4099-09.2010&amp;volume=30&amp;pages=2102-2114&amp;publication_year=2010&amp;author=Willmore%2CBD&amp;author=Prenger%2CRJ&amp;author=Gallant%2CJL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14"><p class="c-article-references__text" id="ref-CR14">Simoncelli, E.P. Statistical models for images: compression, restoration and synthesis. 31st Asilomar Conference on Signals, Systems &amp; Computers 1, 673678 (IEEE, 1997).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15"><p class="c-article-references__text" id="ref-CR15">Schwartz, O. &amp; Simoncelli, E.P. Natural signal statistics and sensory gain control. <i>Nat. Neurosci.</i> <b>4</b>, 819825 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/90526" data-track-action="article reference" href="https://doi.org/10.1038%2F90526" aria-label="Article reference 15" data-doi="10.1038/90526">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXlslSjsLg%3D" aria-label="CAS reference 15">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11477428" aria-label="PubMed reference 15">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Natural%20signal%20statistics%20and%20sensory%20gain%20control&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F90526&amp;volume=4&amp;pages=819-825&amp;publication_year=2001&amp;author=Schwartz%2CO&amp;author=Simoncelli%2CEP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16"><p class="c-article-references__text" id="ref-CR16">Karklin, Y. &amp; Lewicki, M.S. Emergence of complex cell properties by learning to generalize in natural scenes. <i>Nature</i> <b>457</b>, 8386 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature07481" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature07481" aria-label="Article reference 16" data-doi="10.1038/nature07481">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhtVGhtQ%3D%3D" aria-label="CAS reference 16">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19020501" aria-label="PubMed reference 16">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Emergence%20of%20complex%20cell%20properties%20by%20learning%20to%20generalize%20in%20natural%20scenes&amp;journal=Nature&amp;doi=10.1038%2Fnature07481&amp;volume=457&amp;pages=83-86&amp;publication_year=2009&amp;author=Karklin%2CY&amp;author=Lewicki%2CMS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17"><p class="c-article-references__text" id="ref-CR17">Sigman, M., Cecchi, G.A., Gilbert, C.D. &amp; Magnasco, M.O. On a common circle: natural scenes and Gestalt rules. <i>Proc. Natl. Acad. Sci. USA</i> <b>98</b>, 19351940 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.98.4.1935" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.98.4.1935" aria-label="Article reference 17" data-doi="10.1073/pnas.98.4.1935">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXhsVWisbc%3D" aria-label="CAS reference 17">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11172054" aria-label="PubMed reference 17">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC29360" aria-label="PubMed Central reference 17">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20a%20common%20circle%3A%20natural%20scenes%20and%20Gestalt%20rules&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.98.4.1935&amp;volume=98&amp;pages=1935-1940&amp;publication_year=2001&amp;author=Sigman%2CM&amp;author=Cecchi%2CGA&amp;author=Gilbert%2CCD&amp;author=Magnasco%2CMO">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18"><p class="c-article-references__text" id="ref-CR18">Geisler, W.S., Perry, J.S., Super, B.J. &amp; Gallogly, D.P. Edge co-occurrence in natural images predicts contour grouping performance. <i>Vision Res.</i> <b>41</b>, 711724 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0042-6989(00)00277-7" data-track-action="article reference" href="https://doi.org/10.1016%2FS0042-6989%2800%2900277-7" aria-label="Article reference 18" data-doi="10.1016/S0042-6989(00)00277-7">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3MzisVSgsQ%3D%3D" aria-label="CAS reference 18">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11248261" aria-label="PubMed reference 18">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Edge%20co-occurrence%20in%20natural%20images%20predicts%20contour%20grouping%20performance&amp;journal=Vision%20Res.&amp;doi=10.1016%2FS0042-6989%2800%2900277-7&amp;volume=41&amp;pages=711-724&amp;publication_year=2001&amp;author=Geisler%2CWS&amp;author=Perry%2CJS&amp;author=Super%2CBJ&amp;author=Gallogly%2CDP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19"><p class="c-article-references__text" id="ref-CR19">Portilla, J. &amp; Simoncelli, E.P. A parametric texture model based on joint statistics of complex wavelet coefficients. <i>Int. J. Comput. Vis.</i> <b>40</b>, 4970 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1023/A:1026553619983" data-track-action="article reference" href="https://doi.org/10.1023%2FA%3A1026553619983" aria-label="Article reference 19" data-doi="10.1023/A:1026553619983">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20parametric%20texture%20model%20based%20on%20joint%20statistics%20of%20complex%20wavelet%20coefficients&amp;journal=Int.%20J.%20Comput.%20Vis.&amp;doi=10.1023%2FA%3A1026553619983&amp;volume=40&amp;pages=49-70&amp;publication_year=2000&amp;author=Portilla%2CJ&amp;author=Simoncelli%2CEP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20"><p class="c-article-references__text" id="ref-CR20">Freeman, J. &amp; Simoncelli, E.P. Metamers of the ventral stream. <i>Nat. Neurosci.</i> <b>14</b>, 11951201 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.2889" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.2889" aria-label="Article reference 20" data-doi="10.1038/nn.2889">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhtVWmtbnE" aria-label="CAS reference 20">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21841776" aria-label="PubMed reference 20">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3164938" aria-label="PubMed Central reference 20">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Metamers%20of%20the%20ventral%20stream&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.2889&amp;volume=14&amp;pages=1195-1201&amp;publication_year=2011&amp;author=Freeman%2CJ&amp;author=Simoncelli%2CEP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21"><p class="c-article-references__text" id="ref-CR21">Heeger, D.J. &amp; Bergen, J.R. Pyramid-based texture analysis/synthesis. Proceedings of SIGGRAPH 229238 (ACM, 1995).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22"><p class="c-article-references__text" id="ref-CR22">Balas, B. Attentive texture similarity as a categorization task: comparing texture synthesis models. <i>Pattern Recognit.</i> <b>41</b>, 972982 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.patcog.2007.08.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.patcog.2007.08.007" aria-label="Article reference 22" data-doi="10.1016/j.patcog.2007.08.007">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20890384" aria-label="PubMed reference 22">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2947373" aria-label="PubMed Central reference 22">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Attentive%20texture%20similarity%20as%20a%20categorization%20task%3A%20comparing%20texture%20synthesis%20models&amp;journal=Pattern%20Recognit.&amp;doi=10.1016%2Fj.patcog.2007.08.007&amp;volume=41&amp;pages=972-982&amp;publication_year=2008&amp;author=Balas%2CB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23"><p class="c-article-references__text" id="ref-CR23">Angelucci, A. et al. Circuits for local and global signal integration in primary visual cortex. <i>J. Neurosci.</i> <b>22</b>, 86338646 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.22-19-08633.2002" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.22-19-08633.2002" aria-label="Article reference 23" data-doi="10.1523/JNEUROSCI.22-19-08633.2002">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38Xns1Cis70%3D" aria-label="CAS reference 23">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12351737" aria-label="PubMed reference 23">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6757772" aria-label="PubMed Central reference 23">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Circuits%20for%20local%20and%20global%20signal%20integration%20in%20primary%20visual%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.22-19-08633.2002&amp;volume=22&amp;pages=8633-8646&amp;publication_year=2002&amp;author=Angelucci%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24"><p class="c-article-references__text" id="ref-CR24">Wandell, B.A., Dumoulin, S.O. &amp; Brewer, A.A. Visual field maps in human cortex. <i>Neuron</i> <b>56</b>, 366383 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2007.10.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2007.10.012" aria-label="Article reference 24" data-doi="10.1016/j.neuron.2007.10.012">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXht12jsrvP" aria-label="CAS reference 24">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17964252" aria-label="PubMed reference 24">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20field%20maps%20in%20human%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2007.10.012&amp;volume=56&amp;pages=366-383&amp;publication_year=2007&amp;author=Wandell%2CBA&amp;author=Dumoulin%2CSO&amp;author=Brewer%2CAA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25"><p class="c-article-references__text" id="ref-CR25">Larsson, J. &amp; Heeger, D.J. Two retinotopic visual areas in human lateral occipital cortex. <i>J. Neurosci.</i> <b>26</b>, 1312813142 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1657-06.2006" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1657-06.2006" aria-label="Article reference 25" data-doi="10.1523/JNEUROSCI.1657-06.2006">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXjsFantQ%3D%3D" aria-label="CAS reference 25">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17182764" aria-label="PubMed reference 25">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1904390" aria-label="PubMed Central reference 25">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Two%20retinotopic%20visual%20areas%20in%20human%20lateral%20occipital%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1657-06.2006&amp;volume=26&amp;pages=13128-13142&amp;publication_year=2006&amp;author=Larsson%2CJ&amp;author=Heeger%2CDJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26"><p class="c-article-references__text" id="ref-CR26">Hillis, J.M., Ernst, M.O., Banks, M.S. &amp; Landy, M.S. Combining sensory information: mandatory fusion within, but not between, senses. <i>Science</i> <b>298</b>, 16271630 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1075396" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1075396" aria-label="Article reference 26" data-doi="10.1126/science.1075396">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38Xosl2kurg%3D" aria-label="CAS reference 26">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12446912" aria-label="PubMed reference 26">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Combining%20sensory%20information%3A%20mandatory%20fusion%20within%2C%20but%20not%20between%2C%20senses&amp;journal=Science&amp;doi=10.1126%2Fscience.1075396&amp;volume=298&amp;pages=1627-1630&amp;publication_year=2002&amp;author=Hillis%2CJM&amp;author=Ernst%2CMO&amp;author=Banks%2CMS&amp;author=Landy%2CMS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27"><p class="c-article-references__text" id="ref-CR27">Paolacci, G., Chandler, J. &amp; Ipeirotis, P. Running experiments on Amazon Mechanical Turk. <i>Judgm. Decis. Mak.</i> <b>5</b>, 411419 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Running%20experiments%20on%20Amazon%20Mechanical%20Turk&amp;journal=Judgm.%20Decis.%20Mak.&amp;volume=5&amp;pages=411-419&amp;publication_year=2010&amp;author=Paolacci%2CG&amp;author=Chandler%2CJ&amp;author=Ipeirotis%2CP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28"><p class="c-article-references__text" id="ref-CR28">Grmping, U. Estimators of relative importance in linear regression based on variance decomposition. <i>Am. Stat.</i> <b>61</b>, 139147 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1198/000313007X188252" data-track-action="article reference" href="https://doi.org/10.1198%2F000313007X188252" aria-label="Article reference 28" data-doi="10.1198/000313007X188252">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Estimators%20of%20relative%20importance%20in%20linear%20regression%20based%20on%20variance%20decomposition&amp;journal=Am.%20Stat.&amp;doi=10.1198%2F000313007X188252&amp;volume=61&amp;pages=139-147&amp;publication_year=2007&amp;author=Gr%C3%B6mping%2CU">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29"><p class="c-article-references__text" id="ref-CR29">Craft, E., Schtze, H., Niebur, E. &amp; von der Heydt, R. A neural model of figure-ground organization. <i>J. Neurophysiol.</i> <b>97</b>, 43104326 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00203.2007" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00203.2007" aria-label="Article reference 29" data-doi="10.1152/jn.00203.2007">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17442769" aria-label="PubMed reference 29">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20neural%20model%20of%20figure-ground%20organization&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00203.2007&amp;volume=97&amp;pages=4310-4326&amp;publication_year=2007&amp;author=Craft%2CE&amp;author=Sch%C3%BCtze%2CH&amp;author=Niebur%2CE&amp;author=von%20der%20Heydt%2CR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30"><p class="c-article-references__text" id="ref-CR30">Qiu, F.T., Sugihara, T. &amp; Heydt, R.V.D. Figure-ground mechanisms provide structure for selective attention. <i>Nat. Neurosci.</i> <b>10</b>, 14921499 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1989" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1989" aria-label="Article reference 30" data-doi="10.1038/nn1989">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXht1ajtr7N" aria-label="CAS reference 30">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17922006" aria-label="PubMed reference 30">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2666969" aria-label="PubMed Central reference 30">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Figure-ground%20mechanisms%20provide%20structure%20for%20selective%20attention&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1989&amp;volume=10&amp;pages=1492-1499&amp;publication_year=2007&amp;author=Qiu%2CFT&amp;author=Sugihara%2CT&amp;author=Heydt%2CRVD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31"><p class="c-article-references__text" id="ref-CR31">Fang, F., Boyaci, H. &amp; Kersten, D. Border ownership selectivity in human early visual cortex and its modulation by attention. <i>J. Neurosci.</i> <b>29</b>, 460465 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.4628-08.2009" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.4628-08.2009" aria-label="Article reference 31" data-doi="10.1523/JNEUROSCI.4628-08.2009">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhtVKru7w%3D" aria-label="CAS reference 31">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19144846" aria-label="PubMed reference 31">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2768354" aria-label="PubMed Central reference 31">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Border%20ownership%20selectivity%20in%20human%20early%20visual%20cortex%20and%20its%20modulation%20by%20attention&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.4628-08.2009&amp;volume=29&amp;pages=460-465&amp;publication_year=2009&amp;author=Fang%2CF&amp;author=Boyaci%2CH&amp;author=Kersten%2CD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32"><p class="c-article-references__text" id="ref-CR32">Ress, D., Backus, B.T. &amp; Heeger, D.J. Activity in primary visual cortex predicts performance in a visual detection task. <i>Nat. Neurosci.</i> <b>3</b>, 940945 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/78856" data-track-action="article reference" href="https://doi.org/10.1038%2F78856" aria-label="Article reference 32" data-doi="10.1038/78856">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3cXmtlGhtrY%3D" aria-label="CAS reference 32">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10966626" aria-label="PubMed reference 32">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Activity%20in%20primary%20visual%20cortex%20predicts%20performance%20in%20a%20visual%20detection%20task&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F78856&amp;volume=3&amp;pages=940-945&amp;publication_year=2000&amp;author=Ress%2CD&amp;author=Backus%2CBT&amp;author=Heeger%2CDJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33"><p class="c-article-references__text" id="ref-CR33">Ferster, D., Chung, S. &amp; Wheat, H. Orientation selectivity of thalamic input to simple cells of cat visual cortex. <i>Nature</i> <b>380</b>, 249252 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/380249a0" data-track-action="article reference" href="https://doi.org/10.1038%2F380249a0" aria-label="Article reference 33" data-doi="10.1038/380249a0">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK28XhvVahsL4%3D" aria-label="CAS reference 33">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8637573" aria-label="PubMed reference 33">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Orientation%20selectivity%20of%20thalamic%20input%20to%20simple%20cells%20of%20cat%20visual%20cortex&amp;journal=Nature&amp;doi=10.1038%2F380249a0&amp;volume=380&amp;pages=249-252&amp;publication_year=1996&amp;author=Ferster%2CD&amp;author=Chung%2CS&amp;author=Wheat%2CH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34"><p class="c-article-references__text" id="ref-CR34">Malach, R. et al. Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex. <i>Proc. Natl. Acad. Sci. USA</i> <b>92</b>, 81358139 (1995).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.92.18.8135" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.92.18.8135" aria-label="Article reference 34" data-doi="10.1073/pnas.92.18.8135">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK2MXnvVymsbw%3D" aria-label="CAS reference 34">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7667258" aria-label="PubMed reference 34">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC41110" aria-label="PubMed Central reference 34">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Object-related%20activity%20revealed%20by%20functional%20magnetic%20resonance%20imaging%20in%20human%20occipital%20cortex&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.92.18.8135&amp;volume=92&amp;pages=8135-8139&amp;publication_year=1995&amp;author=Malach%2CR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35"><p class="c-article-references__text" id="ref-CR35">Thomson, M.G., Foster, D.H. &amp; Summers, R.J. Human sensitivity to phase perturbations in natural images: a statistical framework. <i>Perception</i> <b>29</b>, 10571069 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1068/p2867" data-track-action="article reference" href="https://doi.org/10.1068%2Fp2867" aria-label="Article reference 35" data-doi="10.1068/p2867">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3M7gsFCnsQ%3D%3D" aria-label="CAS reference 35">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11144819" aria-label="PubMed reference 35">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20sensitivity%20to%20phase%20perturbations%20in%20natural%20images%3A%20a%20statistical%20framework&amp;journal=Perception&amp;doi=10.1068%2Fp2867&amp;volume=29&amp;pages=1057-1069&amp;publication_year=2000&amp;author=Thomson%2CMG&amp;author=Foster%2CDH&amp;author=Summers%2CRJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36"><p class="c-article-references__text" id="ref-CR36">Felsen, G., Touryan, J., Han, F. &amp; Dan, Y. Cortical sensitivity to visual features in natural scenes. <i>PLoS Biol.</i> <b>3</b>, e342 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pbio.0030342" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pbio.0030342" aria-label="Article reference 36" data-doi="10.1371/journal.pbio.0030342">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXhtFeitrvI" aria-label="CAS reference 36">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16171408" aria-label="PubMed reference 36">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1233414" aria-label="PubMed Central reference 36">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20sensitivity%20to%20visual%20features%20in%20natural%20scenes&amp;journal=PLoS%20Biol.&amp;doi=10.1371%2Fjournal.pbio.0030342&amp;volume=3&amp;publication_year=2005&amp;author=Felsen%2CG&amp;author=Touryan%2CJ&amp;author=Han%2CF&amp;author=Dan%2CY">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37"><p class="c-article-references__text" id="ref-CR37">Felsen, G. &amp; Dan, Y. A natural approach to studying vision. <i>Nat. Neurosci.</i> <b>8</b>, 16431646 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1608" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1608" aria-label="Article reference 37" data-doi="10.1038/nn1608">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXht1Gis7%2FK" aria-label="CAS reference 37">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16306891" aria-label="PubMed reference 37">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20natural%20approach%20to%20studying%20vision&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1608&amp;volume=8&amp;pages=1643-1646&amp;publication_year=2005&amp;author=Felsen%2CG&amp;author=Dan%2CY">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38"><p class="c-article-references__text" id="ref-CR38">Rust, N.C. &amp; Movshon, J.A. In praise of artifice. <i>Nat. Neurosci.</i> <b>8</b>, 16471650 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1606" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1606" aria-label="Article reference 38" data-doi="10.1038/nn1606">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXht1Gis7%2FI" aria-label="CAS reference 38">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16306892" aria-label="PubMed reference 38">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=In%20praise%20of%20artifice&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1606&amp;volume=8&amp;pages=1647-1650&amp;publication_year=2005&amp;author=Rust%2CNC&amp;author=Movshon%2CJA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39"><p class="c-article-references__text" id="ref-CR39">Heeger, D.J., Boynton, G.M., Demb, J.B., Seidemann, E. &amp; Newsome, W.T. Motion opponency in visual cortex. <i>J. Neurosci.</i> <b>19</b>, 71627174 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.19-16-07162.1999" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.19-16-07162.1999" aria-label="Article reference 39" data-doi="10.1523/JNEUROSCI.19-16-07162.1999">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXlt1Cht70%3D" aria-label="CAS reference 39">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10436069" aria-label="PubMed reference 39">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6782843" aria-label="PubMed Central reference 39">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Motion%20opponency%20in%20visual%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.19-16-07162.1999&amp;volume=19&amp;pages=7162-7174&amp;publication_year=1999&amp;author=Heeger%2CDJ&amp;author=Boynton%2CGM&amp;author=Demb%2CJB&amp;author=Seidemann%2CE&amp;author=Newsome%2CWT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40"><p class="c-article-references__text" id="ref-CR40">McDermott, J.H. &amp; Simoncelli, E.P. Sound texture perception via statistics of the auditory periphery: evidence from sound synthesis. <i>Neuron</i> <b>71</b>, 926940 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2011.06.032" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2011.06.032" aria-label="Article reference 40" data-doi="10.1016/j.neuron.2011.06.032">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhtFKjtLnO" aria-label="CAS reference 40">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21903084" aria-label="PubMed reference 40">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4143345" aria-label="PubMed Central reference 40">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Sound%20texture%20perception%20via%20statistics%20of%20the%20auditory%20periphery%3A%20evidence%20from%20sound%20synthesis&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2011.06.032&amp;volume=71&amp;pages=926-940&amp;publication_year=2011&amp;author=McDermott%2CJH&amp;author=Simoncelli%2CEP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41"><p class="c-article-references__text" id="ref-CR41">Glickfeld, L.L., Andermann, M.L., Bonin, V. &amp; Reid, R.C. Cortico-cortical projections in mouse visual cortex are functionally target specific. <i>Nat. Neurosci.</i> <b>16</b>, 219226 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3300" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3300" aria-label="Article reference 41" data-doi="10.1038/nn.3300">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXjsleisg%3D%3D" aria-label="CAS reference 41">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23292681" aria-label="PubMed reference 41">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortico-cortical%20projections%20in%20mouse%20visual%20cortex%20are%20functionally%20target%20specific&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3300&amp;volume=16&amp;pages=219-226&amp;publication_year=2013&amp;author=Glickfeld%2CLL&amp;author=Andermann%2CML&amp;author=Bonin%2CV&amp;author=Reid%2CRC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42"><p class="c-article-references__text" id="ref-CR42">Adelson, E.H. &amp; Bergen, J.R. Spatiotemporal energy models for the perception of motion. <i>J. Opt. Soc. Am. A</i> <b>2</b>, 284299 (1985).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1364/JOSAA.2.000284" data-track-action="article reference" href="https://doi.org/10.1364%2FJOSAA.2.000284" aria-label="Article reference 42" data-doi="10.1364/JOSAA.2.000284">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL2M7jsVShtQ%3D%3D" aria-label="CAS reference 42">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3973762" aria-label="PubMed reference 42">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatiotemporal%20energy%20models%20for%20the%20perception%20of%20motion&amp;journal=J.%20Opt.%20Soc.%20Am.%20A&amp;doi=10.1364%2FJOSAA.2.000284&amp;volume=2&amp;pages=284-299&amp;publication_year=1985&amp;author=Adelson%2CEH&amp;author=Bergen%2CJR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43"><p class="c-article-references__text" id="ref-CR43">Heeger, D.J., Simoncelli, E.P. &amp; Movshon, J.A. Computational models of cortical visual processing. <i>Proc. Natl. Acad. Sci. USA</i> <b>93</b>, 623627 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.93.2.623" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.93.2.623" aria-label="Article reference 43" data-doi="10.1073/pnas.93.2.623">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK28XnslOntQ%3D%3D" aria-label="CAS reference 43">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8570605" aria-label="PubMed reference 43">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC40101" aria-label="PubMed Central reference 43">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Computational%20models%20of%20cortical%20visual%20processing&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.93.2.623&amp;volume=93&amp;pages=623-627&amp;publication_year=1996&amp;author=Heeger%2CDJ&amp;author=Simoncelli%2CEP&amp;author=Movshon%2CJA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44"><p class="c-article-references__text" id="ref-CR44">Carandini, M. &amp; Heeger, D.J. Normalization as a canonical neural computation. <i>Nat. Rev. Neurosci.</i> <b>13</b>, 5162 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn3136" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn3136" aria-label="Article reference 44" data-doi="10.1038/nrn3136">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhsFWqtLrL" aria-label="CAS reference 44">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Normalization%20as%20a%20canonical%20neural%20computation&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn3136&amp;volume=13&amp;pages=51-62&amp;publication_year=2012&amp;author=Carandini%2CM&amp;author=Heeger%2CDJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45"><p class="c-article-references__text" id="ref-CR45">Rust, N.C., Mante, V., Simoncelli, E.P. &amp; Movshon, J.A. How MT cells analyze the motion of visual patterns. <i>Nat. Neurosci.</i> <b>9</b>, 14211431 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1786" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1786" aria-label="Article reference 45" data-doi="10.1038/nn1786">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD28XhtFaksrbJ" aria-label="CAS reference 45">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17041595" aria-label="PubMed reference 45">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20MT%20cells%20analyze%20the%20motion%20of%20visual%20patterns&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1786&amp;volume=9&amp;pages=1421-1431&amp;publication_year=2006&amp;author=Rust%2CNC&amp;author=Mante%2CV&amp;author=Simoncelli%2CEP&amp;author=Movshon%2CJA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46"><p class="c-article-references__text" id="ref-CR46">Vintch, B., Zaharia, A.Z., Movshon, J.A. &amp; Simoncelli, E.P. Efficient and direct estimation of a neural subunit model for sensory coding. <i>in Advances in Neural Information Processing Systems vol. 25 (eds. Bartlett, P., Pereira, F.C.N., Burges, C.J.C., Bottou, L. &amp; Weinberger, K.Q.)</i>, 31133121 (2012).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47"><p class="c-article-references__text" id="ref-CR47">Adelson, E.H. On seeing stuff: the perception of materials by humans and machines. <i>Proc. SPIE</i> <b>4299</b>, 1 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1117/12.429489" data-track-action="article reference" href="https://doi.org/10.1117%2F12.429489" aria-label="Article reference 47" data-doi="10.1117/12.429489">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20seeing%20stuff%3A%20the%20perception%20of%20materials%20by%20humans%20and%20machines&amp;journal=Proc.%20SPIE&amp;doi=10.1117%2F12.429489&amp;volume=4299&amp;publication_year=2001&amp;author=Adelson%2CEH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48"><p class="c-article-references__text" id="ref-CR48">Cavanaugh, J.R., Bair, W. &amp; Movshon, J.A. Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons. <i>J. Neurophysiol.</i> <b>88</b>, 25302546 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00692.2001" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00692.2001" aria-label="Article reference 48" data-doi="10.1152/jn.00692.2001">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12424292" aria-label="PubMed reference 48">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Nature%20and%20interaction%20of%20signals%20from%20the%20receptive%20field%20center%20and%20surround%20in%20macaque%20V1%20neurons&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00692.2001&amp;volume=88&amp;pages=2530-2546&amp;publication_year=2002&amp;author=Cavanaugh%2CJR&amp;author=Bair%2CW&amp;author=Movshon%2CJA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49"><p class="c-article-references__text" id="ref-CR49">Nestares, O. &amp; Heeger, D.J. Robust multiresolution alignment of MRI brain volumes. <i>Magn. Reson. Med.</i> <b>43</b>, 705715 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/(SICI)1522-2594(200005)43:5<705::AID-MRM13&gt;3.0.CO;2-R" data-track-action="article reference" href="https://doi.org/10.1002%2F%28SICI%291522-2594%28200005%2943%3A5%3C705%3A%3AAID-MRM13%3E3.0.CO%3B2-R" aria-label="Article reference 49" data-doi="10.1002/(SICI)1522-2594(200005)43:5<705::AID-MRM13&gt;3.0.CO;2-R">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3c3mtFOrtA%3D%3D" aria-label="CAS reference 49">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10800036" aria-label="PubMed reference 49">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20multiresolution%20alignment%20of%20MRI%20brain%20volumes&amp;journal=Magn.%20Reson.%20Med.&amp;doi=10.1002%2F%28SICI%291522-2594%28200005%2943%3A5%3C705%3A%3AAID-MRM13%3E3.0.CO%3B2-R&amp;volume=43&amp;pages=705-715&amp;publication_year=2000&amp;author=Nestares%2CO&amp;author=Heeger%2CDJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50"><p class="c-article-references__text" id="ref-CR50">Smith, A.M. et al. Investigation of low frequency drift in fMRI signal. <i>Neuroimage</i> <b>9</b>, 526533 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1006/nimg.1999.0435" data-track-action="article reference" href="https://doi.org/10.1006%2Fnimg.1999.0435" aria-label="Article reference 50" data-doi="10.1006/nimg.1999.0435">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M3mtlakuw%3D%3D" aria-label="CAS reference 50">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10329292" aria-label="PubMed reference 50">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Investigation%20of%20low%20frequency%20drift%20in%20fMRI%20signal&amp;journal=Neuroimage&amp;doi=10.1006%2Fnimg.1999.0435&amp;volume=9&amp;pages=526-533&amp;publication_year=1999&amp;author=Smith%2CAM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51"><p class="c-article-references__text" id="ref-CR51">Ogawa, S., Lee, T.M., Kay, A.R. &amp; Tank, D.W. Brain magnetic resonance imaging with contrast dependent on blood oxygenation. <i>Proc. Natl. Acad. Sci. USA</i> <b>87</b>, 98689872 (1990).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.87.24.9868" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.87.24.9868" aria-label="Article reference 51" data-doi="10.1073/pnas.87.24.9868">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK3MXnsl2htw%3D%3D" aria-label="CAS reference 51">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=2124706" aria-label="PubMed reference 51">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC55275" aria-label="PubMed Central reference 51">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Brain%20magnetic%20resonance%20imaging%20with%20contrast%20dependent%20on%20blood%20oxygenation&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.87.24.9868&amp;volume=87&amp;pages=9868-9872&amp;publication_year=1990&amp;author=Ogawa%2CS&amp;author=Lee%2CTM&amp;author=Kay%2CAR&amp;author=Tank%2CDW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52"><p class="c-article-references__text" id="ref-CR52">Gardner, J.L., Merriam, E.P., Movshon, J.A. &amp; Heeger, D.J. Maps of visual space in human occipital cortex are retinotopic, not spatiotopic. <i>J. Neurosci.</i> <b>28</b>, 39883999 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.5476-07.2008" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.5476-07.2008" aria-label="Article reference 52" data-doi="10.1523/JNEUROSCI.5476-07.2008">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXkvV2htr0%3D" aria-label="CAS reference 52">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18400898" aria-label="PubMed reference 52">PubMed</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2515359" aria-label="PubMed Central reference 52">PubMed Central</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Maps%20of%20visual%20space%20in%20human%20occipital%20cortex%20are%20retinotopic%2C%20not%20spatiotopic&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.5476-07.2008&amp;volume=28&amp;pages=3988-3999&amp;publication_year=2008&amp;author=Gardner%2CJL&amp;author=Merriam%2CEP&amp;author=Movshon%2CJA&amp;author=Heeger%2CDJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53"><p class="c-article-references__text" id="ref-CR53">Wichmann, F.A. &amp; Hill, N.J. The psychometric function: I. Fitting, sampling, and goodness of fit. <i>Percept. Psychophys.</i> <b>63</b>, 12931313 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/BF03194544" data-track-action="article reference" href="https://doi.org/10.3758%2FBF03194544" aria-label="Article reference 53" data-doi="10.3758/BF03194544">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD38%2FnsVWquw%3D%3D" aria-label="CAS reference 53">CAS</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11800458" aria-label="PubMed reference 53">PubMed</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20psychometric%20function%3A%20I.%20Fitting%2C%20sampling%2C%20and%20goodness%20of%20fit&amp;journal=Percept.%20Psychophys.&amp;doi=10.3758%2FBF03194544&amp;volume=63&amp;pages=1293-1313&amp;publication_year=2001&amp;author=Wichmann%2CFA&amp;author=Hill%2CNJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54"><p class="c-article-references__text" id="ref-CR54">Dawid, A. &amp; Skene, A. Maximum likelihood estimation of observer error-rates using the EM algorithm. <i>J. R. Stat. Soc. Ser. C Appl. Stat.</i> <b>28</b>, 2028 (1979).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=Maximum%20likelihood%20estimation%20of%20observer%20error-rates%20using%20the%20EM%20algorithm&amp;journal=J.%20R.%20Stat.%20Soc.%20Ser.%20C%20Appl.%20Stat.&amp;volume=28&amp;pages=20-28&amp;publication_year=1979&amp;author=Dawid%2CA&amp;author=Skene%2CA">
                    Google Scholar</a>
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.3402?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We are grateful to G. Boynton for discussions, to M. Landy for comments on the manuscript, to M. Brotzmang for help programming the Mechanical Turk experiments and to members of the Movshon laboratory for help with physiological experiments. This work was supported by US National Institutes of Health grant EY04440, the Howard Hughes Medical Institute, the New York University Center for Brain Imaging and US National Science Foundation Graduate Research Fellowships to J.F. and C.M.Z.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><span class="c-article-author-information__subtitle u-visually-hidden" id="author-notes">Author notes</span><ol class="c-article-author-information__list"><li class="c-article-author-information__item" id="nAff7"><p class="c-article-author-information__authors-list">Jeremy Freeman</p><p class="js-present-address">Present address: Present address: Janelia Farm Research Campus, Howard Hughes Medical Institute, Ashburn, Virginia, USA., </p></li><li class="c-article-author-information__item" id="na1"><p>Jeremy Freeman and Corey M Ziemba: These authors contributed equally to this work</p></li><li class="c-article-author-information__item" id="na2"><p>Eero P Simoncelli and J Anthony Movshon: These authors jointly directed this work</p></li></ol><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Center for Neural Science, New York University, New York, New York, USA</p><p class="c-article-author-affiliation__authors-list">Jeremy Freeman,Corey M Ziemba,David J Heeger,Eero P Simoncelli&amp;J Anthony Movshon</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Psychology, New York University, New York, New York, USA</p><p class="c-article-author-affiliation__authors-list">David J Heeger,Eero P Simoncelli&amp;J Anthony Movshon</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Howard Hughes Medical Institute, New York University, New York, New York, USA</p><p class="c-article-author-affiliation__authors-list">Eero P Simoncelli</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Courant Institute of Mathematical Sciences, New York University, New York, New York, USA</p><p class="c-article-author-affiliation__authors-list">Eero P Simoncelli</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Jeremy-Freeman-Aff1-Aff7"><span class="c-article-authors-search__title u-h3 js-search-name">Jeremy Freeman</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Jeremy%20Freeman" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jeremy%20Freeman" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jeremy%20Freeman%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Corey_M-Ziemba-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Corey M Ziemba</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Corey%20M%20Ziemba" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Corey%20M%20Ziemba" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Corey%20M%20Ziemba%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-David_J-Heeger-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">David J Heeger</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=David%20J%20Heeger" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=David%20J%20Heeger" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22David%20J%20Heeger%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Eero_P-Simoncelli-Aff1-Aff2-Aff3-Aff4"><span class="c-article-authors-search__title u-h3 js-search-name">Eero P Simoncelli</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Eero%20P%20Simoncelli" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Eero%20P%20Simoncelli" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Eero%20P%20Simoncelli%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-J_Anthony-Movshon-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">J Anthony Movshon</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=J%20Anthony%20Movshon" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=J%20Anthony%20Movshon" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22J%20Anthony%20Movshon%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>J.F. and C.M.Z. performed the experiments and analysis. All authors designed the experiments, interpreted the results and wrote the paper.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:freemanj11@janelia.hhmi.org">Jeremy Freeman</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading">Competing interests</h3>
                <p>The authors declare no competing financial interests.</p>
              
            </div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec39-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec39">Supplementary information</h2><div class="c-article-section__content" id="Sec39-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM3"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary text and figures" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.3402/MediaObjects/41593_2013_BFnn3402_MOESM3_ESM.pdf" data-supp-info-image="">Supplementary Text and Figures</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Supplementary Figures 13 and Supplementary Modeling (PDF 4220 kb)</p></div></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20functional%20and%20perceptual%20signature%20of%20the%20second%20visual%20area%20in%20primates&amp;author=Jeremy%20Freeman%20et%20al&amp;contentID=10.1038%2Fnn.3402&amp;copyright=Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2013-05-19&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Freeman, J., Ziemba, C., Heeger, D. <i>et al.</i> A functional and perceptual signature of the second visual area in primates.
                    <i>Nat Neurosci</i> <b>16</b>, 974981 (2013). https://doi.org/10.1038/nn.3402</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.3402?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2013-02-14">14 February 2013</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2013-04-17">17 April 2013</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2013-05-19">19 May 2013</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2013-07">July 2013</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/nn.3402</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Model metamers reveal divergent invariances between biological and artificial neural networks" href="https://doi.org/10.1038/s41593-023-01442-0">
                                        Model metamers reveal divergent invariances between biological and artificial neural networks
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Jenelle Feather</li><li>Guillaume Leclerc</li><li>Josh H. McDermott</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Neuroscience</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Neural Correlates and Perceived Attractiveness of Male and Female Shoulder-to-Hip Ratio in Men and Women: An EEG Study" href="https://doi.org/10.1007/s10508-023-02610-w">
                                        Neural Correlates and Perceived Attractiveness of Male and Female Shoulder-to-Hip Ratio in Men and Women: An EEG Study
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Farid Pazhoohi</li><li>Joana Arantes</li><li>Diego Pinal</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Archives of Sexual Behavior</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Application of feature extraction using nonlinear dynamic system in face recognition" href="https://doi.org/10.1007/s12530-022-09468-8">
                                        Application of feature extraction using nonlinear dynamic system in face recognition
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Lianglei Sun</li><li>Hongchen Lin</li><li>Yi Zhang</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Evolving Systems</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Numerosity tuning in human association cortices and local image contrast representations in early visual cortex" href="https://doi.org/10.1038/s41467-022-29030-z">
                                        Numerosity tuning in human association cortices and local image contrast representations in early visual cortex
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Jacob M. Paul</li><li>Martijn van Ackooij</li><li>Ben M. Harvey</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Communications</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Estimating null and potent modes of feedforward communication in a computational model of cortical activity" href="https://doi.org/10.1038/s41598-021-04684-9">
                                        Estimating null and potent modes of feedforward communication in a computational model of cortical activity
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Jean-Philippe Thivierge</li><li>Artem Pilzak</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2022)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3402.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.3402.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    
        <div class="c-article-associated-content__container">
            <section>
                <h2 class="c-article-associated-content__title u-mb-24">Associated content</h2>
                
                    
                        <div class="c-article-associated-content__collection collection u-mb-24">
                            <section>
                                <p class="c-article-associated-content__collection-label u-sans-serif u-text-bold u-mb-8">Collection</p>
                                <h3 class="c-article-associated-content__collection-title u-h3 u-mb-8">
                                    <a href="https://www.nature.com/collections/tmdlscdqmc"
                                       class="u-link-inherit"
                                       data-track="click"
                                       data-track-action="view collection"
                                       data-track-category="associated content"
                                       data-track-label="collection"
                                       data-test="collection-link">Computational Biology</a>
                                </h3>
                            </section>
                        </div>
                    
                    
                
            </section>
        </div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer[0] = window.dataLayer[0] || {};
            window.dataLayer[0].content = window.dataLayer[0].content || {};
            window.dataLayer[0].content.associatedContentTypes = "collection";
        </script>
    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=nn.3402;doi=10.1038/nn.3402;subjmeta=116,2395,2613,2614,378,631;kwrd=Extrastriate+cortex,Neural+encoding">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=610586617&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.3402%26doi%3D10.1038/nn.3402%26subjmeta%3D116,2395,2613,2614,378,631%26kwrd%3DExtrastriate+cortex,Neural+encoding">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=610586617&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.3402%26doi%3D10.1038/nn.3402%26subjmeta%3D116,2395,2613,2614,378,631%26kwrd%3DExtrastriate+cortex,Neural+encoding"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter  what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/nn.3402&amp;format=js&amp;last_modified=2013-07-01" async></script>
<img src="/349yqh9c/article/nn.3402" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>