<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>A fast pathway for fear in human amygdala | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"amygdala;anxiety;psychology","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/nn.4324"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Constantino Méndez-Bértolo","Stephan Moratti","Rafael Toledano","Fernando Lopez-Sosa","Roberto Martínez-Alvarez","Yee H Mah","Patrik Vuilleumier","Antonio Gil-Nagel","Bryan A Strange"],"publishedAt":1470009600,"publishedAtString":"2016-08-01","title":"A fast pathway for fear in human amygdala","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"19","issue":"8"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"A fast pathway for fear in human amygdala","description":"Human intracranial amygdala recordings reveal fast-latency responses to broad and low, but not high, spatial frequency components of fearful, but not happy or neutral, faces, which are not observed with unpleasant scenes. Amygdala fearful face responses are faster than in fusiform cortex, supporting a phylogenetically old, subcortical pathway to human amygdala. A fast, subcortical pathway to the amygdala is thought to have evolved to enable rapid detection of threat. This pathway's existence is fundamental for understanding nonconscious emotional responses, but has been challenged as a result of a lack of evidence for short-latency fear-related responses in primate amygdala, including humans. We recorded human intracranial electrophysiological data and found fast amygdala responses, beginning 74-ms post-stimulus onset, to fearful, but not neutral or happy, facial expressions. These responses had considerably shorter latency than fear responses that we observed in visual cortex. Notably, fast amygdala responses were limited to low spatial frequency components of fearful faces, as predicted by magnocellular inputs to amygdala. Furthermore, fast amygdala responses were not evoked by photographs of arousing scenes, which is indicative of selective early reactivity to socially relevant visual information conveyed by fearful faces. These data therefore support the existence of a phylogenetically old subcortical pathway providing fast, but coarse, threat-related signals to human amygdala.","datePublished":"2016-08-01T00:00:00Z","dateModified":"2016-08-01T00:00:00Z","pageStart":"1041","pageEnd":"1049","sameAs":"https://doi.org/10.1038/nn.4324","keywords":["Amygdala","Anxiety","Psychology","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig1_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig2_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig3_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig4_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig5_HTML.jpg"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"19","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Constantino Méndez-Bértolo","affiliation":[{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid","address":{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"},{"name":"CEI Campus Moncloa, UCM-UPM","address":{"name":"CEI Campus Moncloa, UCM-UPM, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Stephan Moratti","url":"http://orcid.org/0000-0003-0824-8759","affiliation":[{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid","address":{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"},{"name":"Complutense University of Madrid","address":{"name":"Department of Basic Psychology I, Complutense University of Madrid, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"},{"name":"Laboratory for Cognitive and Computational Neuroscience, Centre for Biomedical Technology, Technical University of Madrid","address":{"name":"Laboratory for Cognitive and Computational Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Rafael Toledano","affiliation":[{"name":"Epilepsy Unit, Hospital Ruber Internacional","address":{"name":"Department of Neurology, Epilepsy Unit, Hospital Ruber Internacional, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Fernando Lopez-Sosa","affiliation":[{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid","address":{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Roberto Martínez-Alvarez","affiliation":[{"name":"Hospital Ruber Internacional","address":{"name":"Department of Neurosurgery, Hospital Ruber Internacional, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Yee H Mah","affiliation":[{"name":"Neuroscience Research Centre, Cardiovascular and Cell Sciences Institute, St. George's, University of London","address":{"name":"Neuroscience Research Centre, Cardiovascular and Cell Sciences Institute, St. George's, University of London, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Patrik Vuilleumier","affiliation":[{"name":"Laboratory for Neurology and Imaging of Cognition, University Hospital and Medical School, University of Geneva","address":{"name":"Department of Neuroscience and Neurology, Laboratory for Neurology and Imaging of Cognition, University Hospital and Medical School, University of Geneva, Geneva, Switzerland","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Antonio Gil-Nagel","affiliation":[{"name":"Epilepsy Unit, Hospital Ruber Internacional","address":{"name":"Department of Neurology, Epilepsy Unit, Hospital Ruber Internacional, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Bryan A Strange","url":"http://orcid.org/0000-0001-6476-4091","affiliation":[{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid","address":{"name":"Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"},{"name":"Reina Sofia Centre for Alzheimer's Research","address":{"name":"Department of Neuroimaging, Reina Sofia Centre for Alzheimer's Research, Madrid, Spain","@type":"PostalAddress"},"@type":"Organization"}],"email":"bryan.strange@upm.es","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/nn.4324">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="A fast pathway for fear in human amygdala"/>
    <meta name="dc.source" content="Nature Neuroscience 2016 19:8"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2016-08-01"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2016 Springer Nature Limited"/>
    <meta name="dc.rights" content="2016 Springer Nature Limited"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Human intracranial amygdala recordings reveal fast-latency responses to broad and low, but not high, spatial frequency components of fearful, but not happy or neutral, faces, which are not observed with unpleasant scenes. Amygdala fearful face responses are faster than in fusiform cortex, supporting a phylogenetically old, subcortical pathway to human amygdala. A fast, subcortical pathway to the amygdala is thought to have evolved to enable rapid detection of threat. This pathway&#39;s existence is fundamental for understanding nonconscious emotional responses, but has been challenged as a result of a lack of evidence for short-latency fear-related responses in primate amygdala, including humans. We recorded human intracranial electrophysiological data and found fast amygdala responses, beginning 74-ms post-stimulus onset, to fearful, but not neutral or happy, facial expressions. These responses had considerably shorter latency than fear responses that we observed in visual cortex. Notably, fast amygdala responses were limited to low spatial frequency components of fearful faces, as predicted by magnocellular inputs to amygdala. Furthermore, fast amygdala responses were not evoked by photographs of arousing scenes, which is indicative of selective early reactivity to socially relevant visual information conveyed by fearful faces. These data therefore support the existence of a phylogenetically old subcortical pathway providing fast, but coarse, threat-related signals to human amygdala."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2016-08-01"/>
    <meta name="prism.volume" content="19"/>
    <meta name="prism.number" content="8"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="1041"/>
    <meta name="prism.endingPage" content="1049"/>
    <meta name="prism.copyright" content="2016 Springer Nature Limited"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/nn.4324"/>
    <meta name="prism.doi" content="doi:10.1038/nn.4324"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/nn.4324.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/nn.4324"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="A fast pathway for fear in human amygdala"/>
    <meta name="citation_volume" content="19"/>
    <meta name="citation_issue" content="8"/>
    <meta name="citation_publication_date" content="2016/08"/>
    <meta name="citation_online_date" content="2016/08/01"/>
    <meta name="citation_firstpage" content="1041"/>
    <meta name="citation_lastpage" content="1049"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/nn.4324"/>
    <meta name="DOI" content="10.1038/nn.4324"/>
    <meta name="size" content="232288"/>
    <meta name="citation_doi" content="10.1038/nn.4324"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/nn.4324&amp;api_key="/>
    <meta name="description" content="Human intracranial amygdala recordings reveal fast-latency responses to broad and low, but not high, spatial frequency components of fearful, but not happy or neutral, faces, which are not observed with unpleasant scenes. Amygdala fearful face responses are faster than in fusiform cortex, supporting a phylogenetically old, subcortical pathway to human amygdala. A fast, subcortical pathway to the amygdala is thought to have evolved to enable rapid detection of threat. This pathway&#39;s existence is fundamental for understanding nonconscious emotional responses, but has been challenged as a result of a lack of evidence for short-latency fear-related responses in primate amygdala, including humans. We recorded human intracranial electrophysiological data and found fast amygdala responses, beginning 74-ms post-stimulus onset, to fearful, but not neutral or happy, facial expressions. These responses had considerably shorter latency than fear responses that we observed in visual cortex. Notably, fast amygdala responses were limited to low spatial frequency components of fearful faces, as predicted by magnocellular inputs to amygdala. Furthermore, fast amygdala responses were not evoked by photographs of arousing scenes, which is indicative of selective early reactivity to socially relevant visual information conveyed by fearful faces. These data therefore support the existence of a phylogenetically old subcortical pathway providing fast, but coarse, threat-related signals to human amygdala."/>
    <meta name="dc.creator" content="M&#233;ndez-B&#233;rtolo, Constantino"/>
    <meta name="dc.creator" content="Moratti, Stephan"/>
    <meta name="dc.creator" content="Toledano, Rafael"/>
    <meta name="dc.creator" content="Lopez-Sosa, Fernando"/>
    <meta name="dc.creator" content="Mart&#237;nez-Alvarez, Roberto"/>
    <meta name="dc.creator" content="Mah, Yee H"/>
    <meta name="dc.creator" content="Vuilleumier, Patrik"/>
    <meta name="dc.creator" content="Gil-Nagel, Antonio"/>
    <meta name="dc.creator" content="Strange, Bryan A"/>
    <meta name="dc.subject" content="Amygdala"/>
    <meta name="dc.subject" content="Anxiety"/>
    <meta name="dc.subject" content="Psychology"/>
    <meta name="citation_reference" content="LeDoux, J.E. The Emotional Brain (Simon &amp; Schuster, New York, 1996)."/>
    <meta name="citation_reference" content="citation_journal_title=Front. Neuroanat.; citation_title=Pulvinar projections to the striatum and amygdala in the tree shrew; citation_author=JD Day-Brown, H Wei, RD Chomsung, HM Petry, ME Bickford; citation_volume=4; citation_publication_date=2010; citation_pages=143; citation_doi=10.3389/fnana.2010.00143; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Neural bases of the non-conscious perception of emotional signals; citation_author=M Tamietto, B de Gelder; citation_volume=11; citation_publication_date=2010; citation_pages=697-709; citation_doi=10.1038/nrn2889; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Subcortical face processing; citation_author=MH Johnson; citation_volume=6; citation_publication_date=2005; citation_pages=766-774; citation_doi=10.1038/nrn1766; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Biol.; citation_title=Functional evidence for a dual route to amygdala; citation_author=MI Garrido, GR Barnes, M Sahani, RJ Dolan; citation_volume=22; citation_publication_date=2012; citation_pages=129-134; citation_doi=10.1016/j.cub.2011.11.056; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Conscious and unconscious emotional learning in the human amygdala; citation_author=JS Morris, A Ohman, RJ Dolan; citation_volume=393; citation_publication_date=1998; citation_pages=467-470; citation_doi=10.1038/30976; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Masked presentations of emotional facial expressions modulate amygdala activity without explicit knowledge; citation_author=PJ Whalen; citation_volume=18; citation_publication_date=1998; citation_pages=411-418; citation_doi=10.1523/JNEUROSCI.18-01-00411.1998; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Discriminating emotional faces without primary visual cortices involves the right amygdala; citation_author=AJ Pegna, A Khateb, F Lazeyras, ML Seghier; citation_volume=8; citation_publication_date=2004; citation_pages=24-25; citation_doi=10.1038/nn1364; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Brain; citation_title=Differential extrageniculostriate and amygdala responses to presentation of emotional faces in a cortically blind field; citation_author=JS Morris, B DeGelder, L Weiskrantz, RJ Dolan; citation_volume=124; citation_publication_date=2001; citation_pages=1241-1252; citation_doi=10.1093/brain/124.6.1241; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Biol.; citation_title=Subcortical connections to human amygdala and changes following destruction of the visual cortex; citation_author=M Tamietto, P Pullens, B de Gelder, L Weiskrantz, R Goebel; citation_volume=22; citation_publication_date=2012; citation_pages=1449-1455; citation_doi=10.1016/j.cub.2012.06.006; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Electrophysiological responses in the human amygdala discriminate emotion categories of complex visual stimuli; citation_author=H Oya, H Kawasaki, MA Howard, R Adolphs; citation_volume=22; citation_publication_date=2002; citation_pages=9502-9512; citation_doi=10.1523/JNEUROSCI.22-21-09502.2002; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human; citation_author=P Krolak-Salmon, MA Henaff, A Vighetto, O Bertrand, F Mauguiere; citation_volume=42; citation_publication_date=2004; citation_pages=665-676; citation_doi=10.1016/S0896-6273(04)00264-8; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=A direct intracranial record of emotions evoked by subliminal words; citation_author=L Naccache; citation_volume=102; citation_publication_date=2005; citation_pages=7713-7717; citation_doi=10.1073/pnas.0500542102; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Neural correlates of affective picture processing&#8212;a depth ERP study; citation_author=M Brazdil; citation_volume=47; citation_publication_date=2009; citation_pages=376-383; citation_doi=10.1016/j.neuroimage.2009.03.081; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Emotion processing and the amygdala: from a &#39;low road&#39; to &#39;many roads&#39; of evaluating biological significance; citation_author=L Pessoa, R Adolphs; citation_volume=11; citation_publication_date=2010; citation_pages=773-783; citation_doi=10.1038/nrn2920; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=How brains beware: neural mechanisms of emotional attention; citation_author=P Vuilleumier; citation_volume=9; citation_publication_date=2005; citation_pages=585; citation_doi=10.1016/j.tics.2005.10.011; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Composition of geniculostriate input to superior colliculus of the rhesus monkey; citation_author=PH Schiller, JG Malpeli, SJ Schein; citation_volume=42; citation_publication_date=1979; citation_pages=1124-1133; citation_doi=10.1152/jn.1979.42.4.1124; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=Prog. Brain Res.; citation_title=Retinal and cortical inputs to cat superior colliculus: composition, convergence and laminar specificity; citation_author=DM Berson; citation_volume=75; citation_publication_date=1988; citation_pages=17-26; citation_doi=10.1016/S0079-6123(08)60462-8; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Distinct spatial frequency sensitivities for processing faces and emotional expressions; citation_author=P Vuilleumier, JL Armony, J Driver, RJ Dolan; citation_volume=6; citation_publication_date=2003; citation_pages=624-631; citation_doi=10.1038/nn1057; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=An electrophysiological study on the interaction between emotional content and spatial frequency of visual stimuli; citation_author=L Carreti&#233;, JA Hinojosa, S L&#243;pez-Mart&#237;n, M Tapia; citation_volume=45; citation_publication_date=2007; citation_pages=1187-1195; citation_doi=10.1016/j.neuropsychologia.2006.10.013; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Reference frames for spatial frequency in face representation differ in the temporal visual cortex and amygdala; citation_author=M Inagaki, I Fujita; citation_volume=31; citation_publication_date=2011; citation_pages=10371-10379; citation_doi=10.1523/JNEUROSCI.1114-11.2011; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=Behav. Ther.; citation_title=Phobias and preparedness; citation_author=MEP Seligman; citation_volume=2; citation_publication_date=1971; citation_pages=307-320; citation_doi=10.1016/S0005-7894(71)80064-3; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci. Methods; citation_title=Nonparametric statistical testing of EEG and MEG data; citation_author=E Maris, R Oostenveld; citation_volume=164; citation_publication_date=2007; citation_pages=177-190; citation_doi=10.1016/j.jneumeth.2007.03.024; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Brain Res.; citation_title=Cortical and subcortical afferents to the amygdala of the rhesus monkey (Macaca mulatta); citation_author=J Aggleton, M Burton, R Passingham; citation_volume=190; citation_publication_date=1980; citation_pages=347-368; citation_doi=10.1016/0006-8993(80)90279-6; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=J. Comp. Neurol.; citation_title=Topographic organization of cortical inputs to the lateral nucleus of the macaque monkey amygdala: a retrograde tracing study; citation_author=L Stefanacci, DG Amaral; citation_volume=421; citation_publication_date=2000; citation_pages=52-79; citation_doi=10.1002/(SICI)1096-9861(20000522)421:1&lt;52::AID-CNE4&gt;3.0.CO;2-O; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Exp. Brain Res.; citation_title=Retrograde transport of D-[3H]-aspartate injected into the monkey amygdaloid complex; citation_author=DG Amaral, R Insausti; citation_volume=88; citation_publication_date=1992; citation_pages=375-388; citation_doi=10.1007/BF02259113; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=The fusiform face area: a module in human extrastriate cortex specialized for face perception; citation_author=N Kanwisher, J McDermott, MM Chun; citation_volume=17; citation_publication_date=1997; citation_pages=4302-4311; citation_doi=10.1523/JNEUROSCI.17-11-04302.1997; citation_id=CR27"/>
    <meta name="citation_reference" content="Eimer, M. The face-sensitive N170 component of the event-related brain potential. in The Oxford Handbook of Face Perception (eds. Calder, A., Rhodes, G., Johnson M. &amp; Haxby, J.) 329&#8211;344 (Oxford University Press, 2011)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Distributed and interactive brain mechanisms during emotion face perception: evidence from functional neuroimaging; citation_author=P Vuilleumier, G Pourtois; citation_volume=45; citation_publication_date=2007; citation_pages=174-194; citation_doi=10.1016/j.neuropsychologia.2006.06.003; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Segregation of form, color, movement, and depth: anatomy, physiology and perception; citation_author=M Livingstone, D Hubel; citation_volume=240; citation_publication_date=1988; citation_pages=740-749; citation_doi=10.1126/science.3283936; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Neurosci.; citation_title=How parallel are the primate visual pathways?; citation_author=WH Merigan, JHR Maunsell; citation_volume=16; citation_publication_date=1993; citation_pages=369-402; citation_doi=10.1146/annurev.ne.16.030193.002101; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Neurons in the human amygdala selective for perceived emotion; citation_author=S Wang; citation_volume=111; citation_publication_date=2014; citation_pages=E3110-E3119; citation_doi=10.1073/pnas.1318376111; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Eur. J. Neurosci.; citation_title=Neuronal responses to face-like stimuli in the monkey pulvinar; citation_author=MN Nguyen; citation_volume=37; citation_publication_date=2013; citation_pages=35-51; citation_doi=10.1111/ejn.12020; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Neural responses to facial expression and face identity in the monkey amygdala; citation_author=KM Gothard, FP Battaglia, CA Erickson, KM Spitler, DG Amaral; citation_volume=97; citation_publication_date=2007; citation_pages=1671-1683; citation_doi=10.1152/jn.00714.2006; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Rapid amygdala gamma oscillations in response to fearful facial expressions; citation_author=W Sato; citation_volume=49; citation_publication_date=2011; citation_pages=612-617; citation_doi=10.1016/j.neuropsychologia.2010.12.025; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=Cogn. Affect. Behav. Neurosci.; citation_title=Temporal precedence of emotion over attention modulations in the lateral amygdala: Intracranial ERP evidence from a patient with temporal lobe epilepsy; citation_author=G Pourtois, L Spinelli, M Seeck, P Vuilleumier; citation_volume=10; citation_publication_date=2010; citation_pages=83-93; citation_doi=10.3758/CABN.10.1.83; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Repeated stimuli elicit diminished high-gamma electrocorticographic responses; citation_author=A Rodriguez Merzagora; citation_volume=85; citation_publication_date=2014; citation_pages=844-852; citation_doi=10.1016/j.neuroimage.2013.07.006; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Motiv. Emotion; citation_title=Behold the wrath: Psychophysiological responses to facial stimuli; citation_author=U Dimberg, A &#214;hman; citation_volume=20; citation_publication_date=1996; citation_pages=149-182; citation_doi=10.1007/BF02253869; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Neural correlates of the automatic processing of threat facial signals; citation_author=AK Anderson, K Christoff, D Panitz, E De Rosa, JDE Gabrieli; citation_volume=23; citation_publication_date=2003; citation_pages=5627-5633; citation_doi=10.1523/JNEUROSCI.23-13-05627.2003; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Dir. Psychol. Sci.; citation_title=Automaticity and the amygdala: nonconscious responses to emotional faces; citation_author=A &#214;hman; citation_volume=11; citation_publication_date=2002; citation_pages=62-66; citation_doi=10.1111/1467-8721.00169; citation_id=CR40"/>
    <meta name="citation_reference" content="Kling, A.S. &amp; Brothers, L.A. The amygdala and social behavior. in The Amygdala: Neurobiological Aspects of Emotion, Memory, and Mental Dysfunction (ed. Aggleton, J.P.) 353&#8211;377 (Wiley-Liss, 1992)."/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Rev.; citation_title=Fears, phobias and preparedness: toward an evolved module of fear and fear learning; citation_author=A Ohman, S Mineka; citation_volume=108; citation_publication_date=2001; citation_pages=483-522; citation_doi=10.1037/0033-295X.108.3.483; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Neural processing of emotional faces requires attention; citation_author=L Pessoa, M McKenna, E Gutierrez, L Ungerleider; citation_volume=99; citation_publication_date=2002; citation_pages=11458-11463; citation_doi=10.1073/pnas.172403899; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Bull.; citation_title=Automaticity: a theoretical and conceptual analysis; citation_author=A Moors, J De Houwer; citation_volume=132; citation_publication_date=2006; citation_pages=297; citation_doi=10.1037/0033-2909.132.2.297; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Magnocellular projections as the trigger of top-down facilitation in recognition; citation_author=K Kveraga, J Boshyan, M Bar; citation_volume=27; citation_publication_date=2007; citation_pages=13232-13240; citation_doi=10.1523/JNEUROSCI.3481-07.2007; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=Brain Res. Bull.; citation_title=Connections underlying the synthesis of cognition, memory, and emotion in primate prefrontal cortices; citation_author=H Barbas; citation_volume=52; citation_publication_date=2000; citation_pages=319-330; citation_doi=10.1016/S0361-9230(99)00245-2; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Single-neuron responses to emotional visual stimuli recorded in human ventral prefrontal cortex; citation_author=H Kawasaki; citation_volume=4; citation_publication_date=2001; citation_pages=15-16; citation_doi=10.1038/82850; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Individual differences in trait anxiety predict the response of the basolateral amygdala to unconsciously processed fearful faces; citation_author=A Etkin; citation_volume=44; citation_publication_date=2004; citation_pages=1043-1055; citation_doi=10.1016/j.neuron.2004.12.006; citation_id=CR48"/>
    <meta name="citation_reference" content="citation_journal_title=Biol. Psychiatry; citation_title=Exaggerated amygdala response to masked facial stimuli in posttraumatic stress disorder: a functional MRI study; citation_author=SL Rauch; citation_volume=47; citation_publication_date=2000; citation_pages=769-776; citation_doi=10.1016/S0006-3223(00)00828-3; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Biol. Psychiatry; citation_title=Increased amygdala response to masked emotional faces in depressed subjects resolves with antidepressant treatment: an fMRI study; citation_author=YI Sheline; citation_volume=50; citation_publication_date=2001; citation_pages=651-658; citation_doi=10.1016/S0006-3223(01)01263-X; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=Anat. Embryol. (Berl); citation_title=Cytoarchitectonic mapping of the human amygdala, hippocampal region and entorhinal cortex: intersubject variability and probability maps; citation_author=K Amunts; citation_volume=210; citation_publication_date=2005; citation_pages=343-352; citation_doi=10.1007/s00429-005-0025-5; citation_id=CR51"/>
    <meta name="citation_reference" content="Ahrens, J., Geveci, B. &amp; Law, C. ParaView: An end-user tool for large-data visualization. in The Visualization Handbook (eds. Hansen, C.D. &amp; Johnson, C.R.) 717 (Citeseer, 2005)."/>
    <meta name="citation_reference" content="Lundqvist, D., Flykt, A. &amp; &#214;hman, A. The Karolinska Directed Emotional Faces&#8211;KDEF (Department of Clinical Neuroscience, Psychology Section, Karolinska Institutet, 1998)."/>
    <meta name="citation_reference" content="citation_journal_title=Front. Psychol.; citation_title=Warsaw set of emotional facial expression pictures&#8212;validation study of facial display photographs; citation_author=M Olszanowski, G Pochwatko, K Kukli&#324;ski, M &#346;cibor-Rylski, R Ohme; citation_volume=5; citation_publication_date=2015; citation_pages=1516; citation_doi=10.3389/fpsyg.2014.01516; citation_id=CR54"/>
    <meta name="citation_reference" content="citation_journal_title=Cogn. Emot.; citation_title=Presentation and validation of the Radboud Faces Database; citation_author=O Langner, R Dotsch, G Bijlstra, DHJ Wigboldus, ST Hawk, A van Knippenberg; citation_volume=24; citation_publication_date=2010; citation_pages=1377-1388; citation_doi=10.1080/02699930903485076; citation_id=CR55"/>
    <meta name="citation_reference" content="citation_journal_title=Cognition; citation_title=Dr. Angry and Mr. Smile: When categorization flexibly modifies the perception of faces in rapid visual presentations; citation_author=PG Schyns, A Oliva; citation_volume=69; citation_publication_date=1999; citation_pages=243-265; citation_doi=10.1016/S0010-0277(98)00069-9; citation_id=CR56"/>
    <meta name="citation_reference" content="citation_journal_title=Psychophysiology; citation_title=How inappropriate high-pass filters can produce artifactual effects and incorrect conclusions in ERP studies of language and cognition; citation_author=D Tanner, K Morgan-Short, SJ Luck; citation_volume=52; citation_publication_date=2015; citation_pages=997-1009; citation_doi=10.1111/psyp.12437; citation_id=CR57"/>
    <meta name="citation_reference" content="citation_journal_title=Comput. Intell. Neurosci.; citation_title=Brainstorm: a user-friendly application for MEG/EEG analysis; citation_author=F Tadel, S Baillet, JC Mosher, D Pantazis, RM Leahy; citation_volume=2011; citation_publication_date=2011; citation_pages=879716; citation_doi=10.1155/2011/879716; citation_id=CR58"/>
    <meta name="citation_reference" content="citation_journal_title=Biomed. Eng. Online; citation_title=OpenMEEG: opensource software for quasistatic bioelectromagnetics; citation_author=A Gramfort, T Papadopoulo, E Olivi, M Clerc; citation_volume=9; citation_publication_date=2010; citation_pages=45; citation_doi=10.1186/1475-925X-9-45; citation_id=CR59"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Keep it simple: a case for using classical minimum norm estimation in the analysis of EEG and MEG data; citation_author=O Hauk; citation_volume=21; citation_publication_date=2004; citation_pages=1612-1621; citation_doi=10.1016/j.neuroimage.2003.12.018; citation_id=CR60"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Med. Imaging; citation_title=Design and construction of a realistic digital brain phantom; citation_author=DL Collins; citation_volume=17; citation_publication_date=1998; citation_pages=463-468; citation_doi=10.1109/42.712135; citation_id=CR61"/>
    <meta name="citation_reference" content="citation_journal_title=J. Physiol. Paris; citation_title=Intracranial EEG and human brain mapping; citation_author=JP Lachaux, D Rudrauf, P Kahane; citation_volume=97; citation_publication_date=2003; citation_pages=613-628; citation_doi=10.1016/j.jphysparis.2004.01.018; citation_id=CR62"/>
    <meta name="citation_reference" content="Lang, P.J., Bradley, M.M. &amp; Cuthbert, B.N. International affective picture system (IAPS): affective ratings of pictures and instruction manual (Technical Report A-6) (University of Florida, 2005)."/>
    <meta name="citation_author" content="M&#233;ndez-B&#233;rtolo, Constantino"/>
    <meta name="citation_author_institution" content="Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain"/>
    <meta name="citation_author_institution" content="CEI Campus Moncloa, UCM-UPM, Madrid, Spain"/>
    <meta name="citation_author" content="Moratti, Stephan"/>
    <meta name="citation_author_institution" content="Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain"/>
    <meta name="citation_author_institution" content="Department of Basic Psychology I, Complutense University of Madrid, Madrid, Spain"/>
    <meta name="citation_author_institution" content="Laboratory for Cognitive and Computational Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain"/>
    <meta name="citation_author" content="Toledano, Rafael"/>
    <meta name="citation_author_institution" content="Department of Neurology, Epilepsy Unit, Hospital Ruber Internacional, Madrid, Spain"/>
    <meta name="citation_author" content="Lopez-Sosa, Fernando"/>
    <meta name="citation_author_institution" content="Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain"/>
    <meta name="citation_author" content="Mart&#237;nez-Alvarez, Roberto"/>
    <meta name="citation_author_institution" content="Department of Neurosurgery, Hospital Ruber Internacional, Madrid, Spain"/>
    <meta name="citation_author" content="Mah, Yee H"/>
    <meta name="citation_author_institution" content="Neuroscience Research Centre, Cardiovascular and Cell Sciences Institute, St. George&#39;s, University of London, London, UK"/>
    <meta name="citation_author" content="Vuilleumier, Patrik"/>
    <meta name="citation_author_institution" content="Department of Neuroscience and Neurology, Laboratory for Neurology and Imaging of Cognition, University Hospital and Medical School, University of Geneva, Geneva, Switzerland"/>
    <meta name="citation_author" content="Gil-Nagel, Antonio"/>
    <meta name="citation_author_institution" content="Department of Neurology, Epilepsy Unit, Hospital Ruber Internacional, Madrid, Spain"/>
    <meta name="citation_author" content="Strange, Bryan A"/>
    <meta name="citation_author_institution" content="Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain"/>
    <meta name="citation_author_institution" content="Department of Neuroimaging, Reina Sofia Centre for Alzheimer&#39;s Research, Madrid, Spain"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="A fast pathway for fear in human amygdala"/>
    <meta name="twitter:description" content="Nature Neuroscience - Human intracranial amygdala recordings reveal fast-latency responses to broad and low, but not high, spatial frequency components of fearful, but not happy or neutral, faces,..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig1_HTML.jpg"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/nn.4324"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="A fast pathway for fear in human amygdala - Nature Neuroscience"/>
    <meta property="og:description" content="Human intracranial amygdala recordings reveal fast-latency responses to broad and low, but not high, spatial frequency components of fearful, but not happy or neutral, faces, which are not observed with unpleasant scenes. Amygdala fearful face responses are faster than in fusiform cortex, supporting a phylogenetically old, subcortical pathway to human amygdala."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig1_HTML.jpg"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=nn.4324;doi=10.1038/nn.4324;techmeta=30,9;subjmeta=1284,1300,1457,378,476,477,631,692,699;kwrd=Amygdala,Anxiety,Psychology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=416748873&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.4324%26doi%3D10.1038/nn.4324%26techmeta%3D30,9%26subjmeta%3D1284,1300,1457,378,476,477,631,692,699%26kwrd%3DAmygdala,Anxiety,Psychology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=416748873&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.4324%26doi%3D10.1038/nn.4324%26techmeta%3D30,9%26subjmeta%3D1284,1300,1457,378,476,477,631,692,699%26kwrd%3DAmygdala,Anxiety,Psychology"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/nn.4324'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        A fast pathway for fear in human amygdala
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4324.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2016-08-01">01 August 2016</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">A fast pathway for fear in human amygdala</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Constantino-M_ndez_B_rtolo-Aff1-Aff2" data-author-popup="auth-Constantino-M_ndez_B_rtolo-Aff1-Aff2" data-author-search="Méndez-Bértolo, Constantino">Constantino Méndez-Bértolo</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup><sup class="u-js-hide"> <a href="#na1">na1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Stephan-Moratti-Aff1-Aff3-Aff4" data-author-popup="auth-Stephan-Moratti-Aff1-Aff3-Aff4" data-author-search="Moratti, Stephan">Stephan Moratti</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-0824-8759"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-0824-8759</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff3">3</a>,<a href="#Aff4">4</a></sup><sup class="u-js-hide"> <a href="#na1">na1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Rafael-Toledano-Aff5" data-author-popup="auth-Rafael-Toledano-Aff5" data-author-search="Toledano, Rafael">Rafael Toledano</a><sup class="u-js-hide"><a href="#Aff5">5</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Fernando-Lopez_Sosa-Aff1" data-author-popup="auth-Fernando-Lopez_Sosa-Aff1" data-author-search="Lopez-Sosa, Fernando">Fernando Lopez-Sosa</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Roberto-Mart_nez_Alvarez-Aff6" data-author-popup="auth-Roberto-Mart_nez_Alvarez-Aff6" data-author-search="Martínez-Alvarez, Roberto">Roberto Martínez-Alvarez</a><sup class="u-js-hide"><a href="#Aff6">6</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Yee_H-Mah-Aff7" data-author-popup="auth-Yee_H-Mah-Aff7" data-author-search="Mah, Yee H">Yee H Mah</a><sup class="u-js-hide"><a href="#Aff7">7</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Patrik-Vuilleumier-Aff8" data-author-popup="auth-Patrik-Vuilleumier-Aff8" data-author-search="Vuilleumier, Patrik">Patrik Vuilleumier</a><sup class="u-js-hide"><a href="#Aff8">8</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Antonio-Gil_Nagel-Aff5" data-author-popup="auth-Antonio-Gil_Nagel-Aff5" data-author-search="Gil-Nagel, Antonio">Antonio Gil-Nagel</a><sup class="u-js-hide"><a href="#Aff5">5</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 9 authors for this article" title="Show all 9 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Bryan_A-Strange-Aff1-Aff9" data-author-popup="auth-Bryan_A-Strange-Aff1-Aff9" data-author-search="Strange, Bryan A" data-corresp-id="c1">Bryan A Strange<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0001-6476-4091"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-6476-4091</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff9">9</a></sup> </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 19</b>, <span class="u-visually-hidden">pages </span>1041–1049 (<span data-test="article-publication-year">2016</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">13k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">222 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">262 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/nn.4324/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/amygdala" data-track="click" data-track-action="view subject" data-track-label="link">Amygdala</a></li><li class="c-article-subject-list__subject"><a href="/subjects/anxiety" data-track="click" data-track-action="view subject" data-track-label="link">Anxiety</a></li><li class="c-article-subject-list__subject"><a href="/subjects/psychology" data-track="click" data-track-action="view subject" data-track-label="link">Psychology</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs2" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs2">Abstract</h2><div class="c-article-section__content" id="Abs2-content"><p>A fast, subcortical pathway to the amygdala is thought to have evolved to enable rapid detection of threat. This pathway's existence is fundamental for understanding nonconscious emotional responses, but has been challenged as a result of a lack of evidence for short-latency fear-related responses in primate amygdala, including humans. We recorded human intracranial electrophysiological data and found fast amygdala responses, beginning 74-ms post-stimulus onset, to fearful, but not neutral or happy, facial expressions. These responses had considerably shorter latency than fear responses that we observed in visual cortex. Notably, fast amygdala responses were limited to low spatial frequency components of fearful faces, as predicted by magnocellular inputs to amygdala. Furthermore, fast amygdala responses were not evoked by photographs of arousing scenes, which is indicative of selective early reactivity to socially relevant visual information conveyed by fearful faces. These data therefore support the existence of a phylogenetically old subcortical pathway providing fast, but coarse, threat-related signals to human amygdala.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4324.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4324.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-020-80054-1/MediaObjects/41598_2020_80054_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41598-020-80054-1?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41598-020-80054-1">Rapid processing of fearful faces relies on the right amygdala: evidence from individuals undergoing unilateral temporal lobectomy
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">11 January 2021</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">David Framorando, Eleanor Moses, … Alan J. Pegna</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-020-71885-z/MediaObjects/41598_2020_71885_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41598-020-71885-z?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41598-020-71885-z">Fast responses to images of animate and inanimate objects in the nonhuman primate amygdala
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">11 September 2020</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">E. Cleeren, I. D. Popivanov, … Peter Janssen</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-023-31752-z/MediaObjects/41598_2023_31752_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41598-023-31752-z?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41598-023-31752-z">Potentiated early neural responses to fearful faces are not driven by specific face parts
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">21 March 2023</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Maximilian Bruchmann, Léa Mertens, … Thomas Straube</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711582597,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>A classical model of emotional responses in the brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="LeDoux, J.E. The Emotional Brain (Simon &amp; Schuster, New York, 1996)." href="/articles/nn.4324#ref-CR1" id="ref-link-section-d5467207e535">1</a></sup> holds that the amygdala receives direct subcortical inputs through the superior colliculus and pulvinar<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Day-Brown, J.D., Wei, H., Chomsung, R.D., Petry, H.M. &amp; Bickford, M.E. Pulvinar projections to the striatum and amygdala in the tree shrew. Front. Neuroanat. 4, 143 (2010)." href="/articles/nn.4324#ref-CR2" id="ref-link-section-d5467207e539">2</a></sup>, which enables crude, but rapidly processed, information about fear-related cues to bypass detailed cortical processing in visual pathways<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Tamietto, M. &amp; de Gelder, B. Neural bases of the non-conscious perception of emotional signals. Nat. Rev. Neurosci. 11, 697–709 (2010)." href="/articles/nn.4324#ref-CR3" id="ref-link-section-d5467207e543">3</a></sup>. This 'low-road' model for fear processing is based primarily on rodent data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="LeDoux, J.E. The Emotional Brain (Simon &amp; Schuster, New York, 1996)." href="/articles/nn.4324#ref-CR1" id="ref-link-section-d5467207e547">1</a></sup>. Evidence for a fast pathway in humans has only been inferred indirectly from neuroimaging studies in healthy individuals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Johnson, M.H. Subcortical face processing. Nat. Rev. Neurosci. 6, 766–774 (2005)." href="/articles/nn.4324#ref-CR4" id="ref-link-section-d5467207e551">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Garrido, M.I., Barnes, G.R., Sahani, M. &amp; Dolan, R.J. Functional evidence for a dual route to amygdala. Curr. Biol. 22, 129–134 (2012)." href="/articles/nn.4324#ref-CR5" id="ref-link-section-d5467207e554">5</a></sup> that used subconscious emotional stimulus presentation during functional magnetic resonance imaging (fMRI)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Morris, J.S., Ohman, A. &amp; Dolan, R.J. Conscious and unconscious emotional learning in the human amygdala. Nature 393, 467–470 (1998)." href="/articles/nn.4324#ref-CR6" id="ref-link-section-d5467207e559">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Whalen, P.J. et al. Masked presentations of emotional facial expressions modulate amygdala activity without explicit knowledge. J. Neurosci. 18, 411–418 (1998)." href="/articles/nn.4324#ref-CR7" id="ref-link-section-d5467207e562">7</a></sup> and in cortically blind patients who showed preserved processing of unseen visual fear-related stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Pegna, A.J., Khateb, A., Lazeyras, F. &amp; Seghier, M.L. Discriminating emotional faces without primary visual cortices involves the right amygdala. Nat. Neurosci. 8, 24–25 (2004)." href="/articles/nn.4324#ref-CR8" id="ref-link-section-d5467207e566">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Morris, J.S., DeGelder, B., Weiskrantz, L. &amp; Dolan, R.J. Differential extrageniculostriate and amygdala responses to presentation of emotional faces in a cortically blind field. Brain 124, 1241–1252 (2001)." href="/articles/nn.4324#ref-CR9" id="ref-link-section-d5467207e569">9</a></sup>, possibly mediated by intact fiber connections between pulvinar, superior colliculus and amygdala<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Tamietto, M., Pullens, P., de Gelder, B., Weiskrantz, L. &amp; Goebel, R. Subcortical connections to human amygdala and changes following destruction of the visual cortex. Curr. Biol. 22, 1449–1455 (2012)." href="/articles/nn.4324#ref-CR10" id="ref-link-section-d5467207e573">10</a></sup>, after damage to visual occipital areas. However, given a lack of direct electrophysiological evidence for short-latency fear-related responses in human amygdala<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Oya, H., Kawasaki, H., Howard, M.A. 3rd &amp; Adolphs, R. Electrophysiological responses in the human amygdala discriminate emotion categories of complex visual stimuli. J. Neurosci. 22, 9502–9512 (2002)." href="/articles/nn.4324#ref-CR11" id="ref-link-section-d5467207e577">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e580">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Naccache, L. et al. A direct intracranial record of emotions evoked by subliminal words. Proc. Natl. Acad. Sci. USA 102, 7713–7717 (2005)." href="/articles/nn.4324#ref-CR13" id="ref-link-section-d5467207e583">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Brazdil, M. et al. Neural correlates of affective picture processing—a depth ERP study. NeuroImage 47, 376–383 (2009)." href="/articles/nn.4324#ref-CR14" id="ref-link-section-d5467207e586">14</a></sup>, an alternative to the low-road model suggests that some cortical regions may be equally fast at processing fear as the amygdala<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Pessoa, L. &amp; Adolphs, R. Emotion processing and the amygdala: from a 'low road' to 'many roads' of evaluating biological significance. Nat. Rev. Neurosci. 11, 773–783 (2010)." href="/articles/nn.4324#ref-CR15" id="ref-link-section-d5467207e590">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Vuilleumier, P. How brains beware: neural mechanisms of emotional attention. Trends Cogn. Sci. 9, 585 (2005)." href="/articles/nn.4324#ref-CR16" id="ref-link-section-d5467207e593">16</a></sup>.</p><p>We addressed this controversy by presenting emotional (fearful, happy) and neutral faces to patients with medication-resistant epilepsy in whom stereotactic electrodes had been implanted in the amygdala for pre-surgical evaluation. The faces were presented either as normal photographs (broad spatial frequency, BSF) or were spatially filtered such that only their low (LSF) or high (HSF) spatial frequency components were displayed (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig1">Fig. 1</a>). Because subcortical pathways are thought to carry only crude (LSF) visual input to the amygdala via magnocellular neurons<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Schiller, P.H., Malpeli, J.G. &amp; Schein, S.J. Composition of geniculostriate input to superior colliculus of the rhesus monkey. J. Neurophysiol. 42, 1124–1133 (1979)." href="/articles/nn.4324#ref-CR17" id="ref-link-section-d5467207e603">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Berson, D.M. Retinal and cortical inputs to cat superior colliculus: composition, convergence and laminar specificity. Prog. Brain Res. 75, 17–26 (1988)." href="/articles/nn.4324#ref-CR18" id="ref-link-section-d5467207e606">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Vuilleumier, P., Armony, J.L., Driver, J. &amp; Dolan, R.J. Distinct spatial frequency sensitivities for processing faces and emotional expressions. Nat. Neurosci. 6, 624–631 (2003)." href="/articles/nn.4324#ref-CR19" id="ref-link-section-d5467207e609">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Carretié, L., Hinojosa, J.A., López-Martín, S. &amp; Tapia, M. An electrophysiological study on the interaction between emotional content and spatial frequency of visual stimuli. Neuropsychologia 45, 1187–1195 (2007)." href="/articles/nn.4324#ref-CR20" id="ref-link-section-d5467207e612">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Inagaki, M. &amp; Fujita, I. Reference frames for spatial frequency in face representation differ in the temporal visual cortex and amygdala. J. Neurosci. 31, 10371–10379 (2011)." href="/articles/nn.4324#ref-CR21" id="ref-link-section-d5467207e615">21</a></sup>, we hypothesized that rapid amygdala responses to fearful faces would be restricted to those containing LSF information (that is, LSF and BSF faces). In some patients, electrodes were also implanted in visual cortical areas, thereby enabling direct comparison of latencies to emotional versus neutral face responses in amygdala and ventral visual cortex.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Experimental face stimuli."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1: Experimental face stimuli.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4324/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig1_HTML.jpg?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig1_HTML.jpg" alt="figure 1" loading="lazy" width="675" height="806"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Examples of BSF, LSF and HSF faces with fearful, happy and neutral expressions presented in experiment 1. Note that each stimulus was identity unique (that is, a different actor for each of the 135 faces presented).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4324/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>In experiment 1, intracranial event-related potentials (iERPs) were recorded while patients judged the gender of BSF, LSF and HSF faces displayed on-screen for 500 ms. Patients viewed 135 faces, each of which was 'identity unique', that is, faces pertained to 135 different actors, balanced for gender. The procedure was repeated after a 10-min break (the same stimuli were presented in different random order). We expected that fast amygdala responses would occur for phylogenetically 'prepared' stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Seligman, M.E.P. Phobias and preparedness. Behav. Ther. 2, 307–320 (1971)." href="/articles/nn.4324#ref-CR22" id="ref-link-section-d5467207e641">22</a></sup>, such as faces, and not for more complex emotional stimuli, such as arousing scenes. Thus, in a second experiment, we recorded iERPs while patients viewed complex neutral and unpleasant arousing scenes and performed indoor-outdoor judgments. Electrode contacts in amygdala and visual areas were localized by co-registering each patient's pre-operative structural MRI with their post-operative computed tomography (CT) scan (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2a</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig6">Supplementary Figs. 1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig7">2</a>). By recording from 19 patients with amygdala electrodes, we found very early latency iERPs in human amygdala to fearful, but not happy or neutral, faces that preceded the earliest iERPs observed in face-sensitive fusiform gyrus. As predicted, the fast amygdala response was selectively observed to the low SF component of fearful faces, and was not evoked by complex unpleasant scenes.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fast-latency human amygdala responses to BSF and LSF fearful faces."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2: Fast-latency human amygdala responses to BSF and LSF fearful faces.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4324/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="685" height="777"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>(<b>a</b>,<b>b</b>) Schematic summary of electrode contact localizations in left and right amygdala for all patients included in experiment 1 are displayed (color coded) on serial coronal sections of the MNI canonical T1 image (anterior-posterior position indicated by <i>y</i> coordinates; <b>a</b>) and semi-transparent segmented amygdalae (<b>b</b>) as viewed from above. (<b>c</b>) Amygdala iERPs from ten amygdalae of eight patients (total of 26 contacts) to fearful, happy and neutral faces collapsed over spatial frequencies and averaged. Horizontal bars below depict time clusters expressing a significant main effect of emotion (top) or SF (middle), or a significant interaction between both (bottom) using a cluster threshold of <i>P</i> &lt; 0.05 (gray) or <i>P</i> &lt; 0.01 (black) on cluster-based non-parametric permutation statistic, based on MANOVA <i>F</i> values (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 2</a>). An emotion by spatial frequency interaction was observed from 74–122 ms post-stimulus onset (at cluster threshold <i>P</i> &lt; 0.05; from 76–110 ms at cluster threshold <i>P</i> &lt; 0.01). A significant main effect of emotion was observed in time clusters from 106–144 ms, 148–204 ms and 282–302 ms, and main effect of spatial frequency from 308–334 ms (all at cluster threshold <i>P</i> &lt; 0.05). At cluster threshold <i>P</i> &lt; 0.01, a significant main effect of emotion is observed during two clusters at 158–162 ms and 184–200 ms. Shaded area indicates s.e.m. (<b>d</b>) Amygdala iERPs to emotional and neutral faces, collapsed over BSF and LSF only. (<b>e</b>) Dot plots of responses to fearful faces, collapsed over BSF and LSF, of the ten individual amygdalae during the early interaction (left) and the late main effect of emotion (right) time windows (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 3</a>). Each amygdala is represented by a triangle, with orientation (left or right pointing) indicating left or right amygdala, respectively. Color coding is depicted as in <b>a</b>; note that patients 6 and 16 were implanted bilaterally. Dot plots are superimposed on mean activity across all amygdalae (error bars indicate s.e.m.). (<b>f</b>) Amygdala iERPs to fearful BSF, LSF and HSF faces. (<b>g</b>) Horizontal bars depict time windows in which responses to each stimulus type are significantly different from zero with a cluster threshold of <i>P</i> &lt; 0.05 (gray) or <i>P</i> &lt; 0.01 (black) on cluster-based non-parametric permutation statistic, based on one-sample <i>t</i> test (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 5</a>).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4324/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Fast amygdala responses to fearful faces</h3><p>In experiment 1, we tested 16 patients with amygdala electrodes, of whom eight satisfied our inclusion criteria (two right, four left and two bilateral; <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/nn.4324#Tab1">Table 1</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2a,b</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 1</a>). Providing direct support for the low-road model of fear detection, our amygdala recordings revealed a prominent fast deflection for fearful faces that was different from that for both happy and neutral faces as early as 74 ms post-stimulus (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2c</a>). Cluster-based permutation testing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Maris, E. &amp; Oostenveld, R. Nonparametric statistical testing of EEG and MEG data. J. Neurosci. Methods 164, 177–190 (2007)." href="/articles/nn.4324#ref-CR23" id="ref-link-section-d5467207e774">23</a></sup> using multivariate analysis of variance (MANOVA) with within-subject factors of emotion (fearful, happy, neutral) and spatial frequency (SF) (broadband, HSF, LSF) was applied to all post-stimulus time points. A time cluster expressing a significant emotion by SF interaction was observed between 76–110 ms after face presentation (at cluster threshold <i>P</i> &lt; 0.01; summed <i>F</i> value = 455.89, <i>P</i> = 0.001), which extended between 74–122 ms at a more liberal cluster threshold of <i>P</i> &lt; 0.05 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2c</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 2</a>).</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Patient demographic and clinical data</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/articles/nn.4324/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Given our prior hypothesis that fast, fear-specific responses in human amygdala arise via a magnocellular pathway, planned comparisons on iERP amplitudes across the interaction time cluster were performed to directly test for fear-specific early responses restricted to BSF and LSF faces. Thus, a set of four linear contrasts were computed, and ensuing <i>P</i> values were corrected for false discovery rate (<i>P</i><sub>fdr</sub>) for these four tests. Testing responses to fearful versus happy and neutral faces (fearful ≠ (happy = neutral)) at each SF revealed a significant effect for BSF and LSF, but not HSF, faces for the 76–110-ms window (BSF: <i>F</i><sub>1,9</sub> = 12.22, <i>P</i> = 0.007, <i>P</i><sub>fdr</sub> = 0.016; LSF: <i>F</i><sub>1,9</sub> = 9.55, <i>P</i> = 0.013, <i>P</i><sub>fdr</sub> = 0.017; HSF: <i>F</i><sub>1,9</sub> = 2.72, <i>P</i> = 0.133, <i>P</i><sub>fdr</sub> = 0.133). Responses to BSF and LSF fearful faces were therefore significantly different from responses to neutral and happy faces in this time window (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2d</a>), with this negative deflection to BSF and LSF fearful faces being observed in eight of the ten amygdalae recorded (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2e</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 3</a>). Furthermore, short-latency amygdala responses to BSF and LSF fearful faces were significantly different to those elicited by HSF fearful faces (fearful HSF ≠ (fearful BSF = fearful LSF)) (<i>F</i><sub>1,9</sub> = 11.51, <i>P</i> = 0.008, <i>P</i><sub>fdr</sub> = 0.016). Thus, amygdala responses to BSF and LSF fearful faces did not differ, but were both significantly different from HSF fearful face responses (<i>post hoc t</i> tests comparing iERP amplitudes across the interaction time cluster; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2f</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 4</a>). Altogether, these data indicate a selective fast amygdala response to the LSF components of fearful faces.</p><p>To determine the onset of deflections to each face stimulus type individually, we applied cluster-based permutation statistics to test for the onset of iERPs that were significantly different from zero for each stimulus type separately for the entire post-stimulus period. Notably, significant fast-latency effects, beginning <span class="stix">∼</span>70 ms post-stimulus presentation, were limited to BSF and LSF fearful face responses (for BSF fearful faces, from 72–118 ms at cluster threshold <i>P</i> &lt; 0.01, summed <i>t</i> value = −73.20; <i>P</i> = 0.023, and from 68–194 ms at cluster threshold <i>P</i> &lt; 0.05; for LSF fearful faces from 72–146 ms at cluster threshold <i>P</i> &lt; 0.01, summed <i>t</i> value = −124.82; <i>P</i> = 0.013, and from 66–192 ms at cluster threshold <i>P</i> &lt; 0.05; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2g</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 5</a>).</p><p>Next, given that we recorded from four right and six left hemisphere amygdalae, we separated iERPs as a function of hemisphere (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig8">Supplementary Fig. 3</a>). A fast deflection is seen for fearful faces in both left and right amygdala. To test for a laterality effect on the time window expressing an emotion by SF interaction (76–110 ms), we entered mean amplitude differences across this time window for each emotion contrast, collapsing across BSFs and LSFs, into a Kruskal-Wallis test comparing right versus left amygdalae. Although the magnitude of the fast fear response appeared larger for right amygdala (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig8">Supplementary Fig. 3</a>), consistent with right-lateralized amygdala responses to fearful faces in cortically blind patients<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Pegna, A.J., Khateb, A., Lazeyras, F. &amp; Seghier, M.L. Discriminating emotional faces without primary visual cortices involves the right amygdala. Nat. Neurosci. 8, 24–25 (2004)." href="/articles/nn.4324#ref-CR8" id="ref-link-section-d5467207e1997">8</a></sup>, we observed no significant laterality effects (right versus left amygdalae tests for fearful minus neutral χ<sup>2</sup>(1) = 2.23, <i>P</i> = 0.136; fearful minus happy χ<sup>2</sup>(1) = 0.73, <i>P</i> = 0.394; happy minus neutral χ<sup>2</sup>(1) = 0.05, <i>P</i> = 0.831).</p><h3 class="c-article__sub-heading" id="Sec4">Later latency amygdala responses to emotional faces</h3><p>The early effects that we observed contrast with previous reports of rather late (200 ms) intracranially recorded human amygdala responses to fearful faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2025">12</a></sup> or complex emotional scenes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Oya, H., Kawasaki, H., Howard, M.A. 3rd &amp; Adolphs, R. Electrophysiological responses in the human amygdala discriminate emotion categories of complex visual stimuli. J. Neurosci. 22, 9502–9512 (2002)." href="/articles/nn.4324#ref-CR11" id="ref-link-section-d5467207e2029">11</a></sup>. Here, the emotion (fearful, happy, neutral) by SF (BSF, HSF and LSF) cluster-based permutation MANOVA test with a less conservative cluster threshold of <i>P</i> &lt; 0.05 also revealed a relatively early main effect of emotion in two time clusters: between 106–144 and 148–204 ms, and 282–302 ms. At cluster threshold <i>P</i> &lt; 0.01, only two clusters (between 158–162 and 184–200 ms) showed a main effect of emotion (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2c</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 2</a>). <i>Post hoc t</i> tests (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 6</a>) revealed that, irrespective of frequency, in clusters prior to 200 ms, responses to fearful faces were greater than those to both neutral and happy faces, but, in the late time window (288–302 ms), fearful face responses were only greater than those to neutral faces.</p><h3 class="c-article__sub-heading" id="Sec5">Effect of repetition on amygdala responses</h3><p>Previous iERP recordings have shown habituation of amygdala responses with multiple repetitions of emotional face presentation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2060">12</a></sup>, which may, in those recordings, have obscured a fast amygdala response. To safeguard against habituation effects, we presented each patient with 135 identity-unique faces that were repeated only once in a second block. Nonetheless, to specifically verify repetition effects on amygdala iERPs in our procedure, we performed an additional MANOVA for the mean amplitude across the early interaction time window (76–110 ms), including a within-subject factor 'block'. We observed no emotion by SF by block interaction (<i>F</i><sub>4,6</sub> = 0.71, <i>P</i> = 0.615) for responses in the early latency interaction window, or a block by emotion (<i>F</i><sub>2,8</sub> = 0.16, <i>P</i> = 0.853) or frequency by block (<i>F</i><sub>2,8</sub> = 1.90, <i>P</i> = 0.211) interaction. Only an emotion by frequency interaction (<i>F</i><sub>4,6</sub> = 19.15, <i>P</i> = 0.001) was significant (equivalent tests for later time windows expressing main effects of emotion and frequency are given in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 7</a>).</p><h3 class="c-article__sub-heading" id="Sec6">Fearful face responses are localized to lateral amygdala</h3><p>The amygdala comprises several subnuclei, and the lateral component is considered to be the sensory gateway to the amygdala<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="LeDoux, J.E. The Emotional Brain (Simon &amp; Schuster, New York, 1996)." href="/articles/nn.4324#ref-CR1" id="ref-link-section-d5467207e2105">1</a></sup>. Our iERP analyses collapsed over contacts that were anatomically limited to the amygdala, but spanned its medial-lateral extent (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2a,b</a>). To refine the anatomical origin of the amygdala iERPs that we observed, we next performed a source localization analysis. For each patient, the minimum norm was applied to average responses to BSF and LSF fearful faces from all contacts (in and outside the amygdala) of each amygdala electrode to obtain mean current source densities for the time windows of the early interaction (76–110 ms) and late main effect of emotion (282–302 ms) (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig3">Fig. 3a</a>). For patient 10, source localization was not possible, as seven of ten channels displayed a flat signal. An overlap of thresholded source localizations (50% of peak activity) of the remaining patients revealed consistent localization of responses to lateral amygdala during the early interaction time window (eight of nine amygdala responses; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig3">Fig. 3b</a>). Source estimation was less consistent for the late positive-going main effect of emotion (six of nine amygdala responses; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig3">Fig. 3b</a>). However, both source localizations of time intervals for early negative-going and late positive-going waveforms overlapped substantially in lateral amygdala (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig3">Fig. 3c</a>). The latter observation is interesting, as the polarity inversion between early and late responses may indicate recruitment of different neuronal populations. However, spatially overlapping source localized early and late fear responses in lateral amygdala could instead be consistent with different afferent inputs in the same neural population. Also note that including responses from all amygdala electrode contacts (both in and outside the amygdala), and demonstrating current source in lateral amygdala, eschews the possibility that iERPs are conducted from brain areas outside of the amygdala.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Amygdala iERPs to fearful faces originate from lateral amygdala."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3: Amygdala iERPs to fearful faces originate from lateral amygdala.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4324/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig3_HTML.jpg?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig3_HTML.jpg" alt="figure 3" loading="lazy" width="685" height="181"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>(<b>a</b>) Source localization of the response to BSF and LSF fearful faces in the early time window (76–110 ms) from a representative amygdala (left amygdala of patient 16, 11 contacts). The current source map (thresholded at 50% of maximum activity) is overlaid on a coronal section of the pre-operative T1 MRI from patient 16. The amygdala electrode is illustrated schematically (white stripes represent amygdala contacts used for source localization; the black stripe is a bad channel with no signal). The color bar indicates estimated current source strength in picoamperes (pA). (<b>b</b>,<b>c</b>) Group source localization maps for seven patients with nine amygdala electrodes (total of 56 contacts in and outside the amygdala). (<b>b</b>) Co-incidence maps of voxels that show the number of source localization cases (<i>N</i>), normalized to MNI space, that reached 50% of maximum activity, overlaid on two coronal sections of the canonical MNI (anterior-posterior locus of each section is given by the y coordinate above). The color bar indicates the number of overlapping cases for the early interaction (left section, MNI coordinates of: <i>x</i> = –26; <i>z</i> = –22; <i>y</i> = –4) and the later (282–302) main effect of emotion (right section, peak overlap: <i>x</i> = –26; <i>z</i> = –26; <i>y</i> = –4) time windows. Note that right amygdalae source solutions were flipped to be overlaid onto the left amygdala for representation purposes. (<b>c</b>) The co-incidence maps for both time windows in <b>b</b> have been thresholded at <i>N</i> ≥ 6 and superimposed to show that they overlap in lateral inferior amygdala. The inset depicts a magnified view of the amygdala region.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4324/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec7">Emotional face responses in ventral visual cortex</h3><p>The demonstration of SF-selective, fast-latency amygdala responses to fearful faces does not exclude the possibility that, for the same stimuli, similar latency responses are present in visual cortical areas that provide input to the amygdala. To address this, we analyzed cortical responses in patients who also had electrode contacts in ventral visual areas. Seven of the patients that completed experiment 1 had undergone electrode implantation in both amygdala and ventral visual cortex, and met all inclusion criteria. The primate amygdala receives extensive input from uni- and multi-modal areas of the temporal lobe<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Aggleton, J., Burton, M. &amp; Passingham, R. Cortical and subcortical afferents to the amygdala of the rhesus monkey (Macaca mulatta). Brain Res. 190, 347–368 (1980)." href="/articles/nn.4324#ref-CR24" id="ref-link-section-d5467207e2198">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Stefanacci, L. &amp; Amaral, D.G. Topographic organization of cortical inputs to the lateral nucleus of the macaque monkey amygdala: a retrograde tracing study. J. Comp. Neurol. 421, 52–79 (2000)." href="/articles/nn.4324#ref-CR25" id="ref-link-section-d5467207e2201">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Amaral, D.G. &amp; Insausti, R. Retrograde transport of D-[3H]-aspartate injected into the monkey amygdaloid complex. Exp. Brain Res. 88, 375–388 (1992)." href="/articles/nn.4324#ref-CR26" id="ref-link-section-d5467207e2204">26</a></sup>, but there is no evidence for amygdala afferents from the occipital lobe<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Aggleton, J., Burton, M. &amp; Passingham, R. Cortical and subcortical afferents to the amygdala of the rhesus monkey (Macaca mulatta). Brain Res. 190, 347–368 (1980)." href="/articles/nn.4324#ref-CR24" id="ref-link-section-d5467207e2208">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Stefanacci, L. &amp; Amaral, D.G. Topographic organization of cortical inputs to the lateral nucleus of the macaque monkey amygdala: a retrograde tracing study. J. Comp. Neurol. 421, 52–79 (2000)." href="/articles/nn.4324#ref-CR25" id="ref-link-section-d5467207e2211">25</a></sup>. We therefore focused our analyses on five patients with electrodes with contacts in fusiform gyrus (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4a</a>), a face-sensitive region of the inferior temporal lobe<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Kanwisher, N., McDermott, J. &amp; Chun, M.M. The fusiform face area: a module in human extrastriate cortex specialized for face perception. J. Neurosci. 17, 4302–4311 (1997)." href="/articles/nn.4324#ref-CR27" id="ref-link-section-d5467207e2218">27</a></sup>. Two of these patients had two different electrodes in fusiform gyrus, yielding seven groups of fusiform contacts. In a first analysis, we determined an index of face-selectivity for these fusiform contacts by comparing responses to broadband neutral faces relative to neutral scenes (presented in experiment 2, described below). One fusiform contact group was excluded from this analysis because of a signal artifact in experiment 2 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4a</a>); thus, iERPs from six contact groups were compared at the group level using cluster-based permutation analysis. This analysis, comparing all post-stimulus time points, revealed a significant cluster between 164–176 ms (summed <i>t</i> values = −32.07, <i>P =</i> 0.03), suggesting a selective fusiform response to faces versus scenes at a latency consistent with the face-sensitive N170 potential<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Eimer, M. The face-sensitive N170 component of the event-related brain potential. in The Oxford Handbook of Face Perception (eds. Calder, A., Rhodes, G., Johnson M. &amp; Haxby, J.) 329–344 (Oxford University Press, 2011)." href="/articles/nn.4324#ref-CR28" id="ref-link-section-d5467207e2232">28</a></sup> (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4b</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fast responses to fear are not observed in fusiform gyrus."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4: Fast responses to fear are not observed in fusiform gyrus.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4324/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig4_HTML.jpg?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig4_HTML.jpg" alt="figure 4" loading="lazy" width="685" height="392"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>(<b>a</b>) Summary illustration of contact sites in the fusiform gyrus, depicted as colored shapes, and superimposed on a semi-transparent MNI template brain. Different groups of contacts from the same patient are displayed in the same color. The asterisk indicates that the contact group was excluded from the comparison of broadband neutral faces versus neutral scenes as a result of a signal artifact in experiment 2. (<b>b</b>) Averaged iERPs to BSF neutral faces (solid line) and neutral complex scenes (dashed line) from six fusiform contact groups (four patients, total of 11 contacts). Responses to faces were significantly greater than those to scenes between 164–176 ms (cluster threshold <i>P</i> &lt; 0.01) on cluster-based non-parametric permutation statistic, based on two-sample <i>t</i> test. Horizontal bars indicate time clusters expressing significant effects, as described in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Figure 2</a>. Shaded area indicates s.e.m. (<b>c</b>–<b>f</b>) Fusiform gyrus iERPs from five patients and seven contact groups (total of 13 contacts) to fearful, happy and neutral faces, collapsed across frequencies (experiment 1; <b>c</b>). No significant main effect of emotion was observed on cluster-based non-parametric permutation statistic, based on MANOVA <i>F</i> values (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 8</a>). There was a main effect of spatial frequency from 206–240 ms (cluster threshold <i>P</i> &lt; 0.01) and an emotion by spatial frequency interaction from 290–334 ms (cluster threshold <i>P</i> &lt; 0.05). (<b>d</b>) Fusiform iERPs to BSF, HSF and LSF faces, collapsed across emotion. (<b>e</b>) Fusiform gyrus iERPs to only fearful and neutral faces, collapsed across spatial frequencies. A main effect of emotion was significant from 172–218 ms, as well as a main effect of frequency from 170–186 ms (both at cluster threshold <i>P</i> &lt; 0.05). Significant main effects of frequency between 200 and 300 ms, as well as an emotion (fear, neutral) by spatial frequency (BSF, HSF and LSF) interaction around 300 ms, were also observed (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 8</a>). (<b>f</b>) Fusiform iERPs to BSF, HSF and LSF fearful faces only. (<b>g</b>) Dot plot of responses observed in each of the seven fusiform contact sites to fearful faces, collapsed over BSF and LSF, during the early interaction time window derived from the amygdala iERP statistical analysis (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 11</a>). Colored markers are depicted as in <b>a</b>. Dot plots are superimposed on the mean (±s.e.m.) activity across all fusiform contact sites.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4324/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We next examined the interaction between emotional facial expression and SF in the iERPs recorded from the seven groups of fusiform contacts during experiment 1. Group-averaged fusiform responses to face stimuli (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4c</a>) were characterized by a positive peak at <span class="stix">∼</span>120 ms post-stimulus onset, followed by a negative deflection peaking at 170 ms and then a slower positive component. Cluster-based permutation testing employing an emotion (fearful, happy, neutral) by SF (BSF, HSF, LSF) MANOVA showed only a main effect of frequency from 206–240 ms at cluster threshold <i>P</i> &lt; 0.01 (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 8</a>). <i>Post hoc</i> tests in this time window revealed that, although responses to broad and LSF faces were greater than to HSF faces, broad and LSF responses did not differ (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 9</a>), reflecting later latency negative deflections to HSF faces relative to BSF and LSF (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4d</a>). In contrast with effects observed in the amygdala, we did not observe a significant interaction at early latencies, even after relaxing the cluster threshold to <i>P</i> &lt; 0.05 (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 8</a>). At this lower threshold, the earliest observed effects were a main effect of frequency from 204–258 ms followed by an emotion by SF interaction from 290–334 ms (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 9</a>). To our surprise, no significant main effect of emotion was obtained. However, given that enhanced fusiform responses were observed less frequently to happy than to fearful faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Vuilleumier, P. &amp; Pourtois, G. Distributed and interactive brain mechanisms during emotion face perception: evidence from functional neuroimaging. Neuropsychologia 45, 174–194 (2007)." href="/articles/nn.4324#ref-CR29" id="ref-link-section-d5467207e2353">29</a></sup>, we repeated this analysis, comparing only fearful and neutral stimuli (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4e</a>). This analysis yielded a significant main effect of emotion in a 172–218 ms time cluster (summed <i>F</i> values, 229.44; <i>P</i> &lt; 0.001, at cluster threshold <i>P</i> &lt; 0.05), earlier than previously reported iERP latencies to fearful versus neutral faces recorded in ventral visual cortex (<span class="stix">∼</span>300 ms)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2370">12</a></sup>, but, notably, 100 ms later than the effects observed in the amygdala. No earlier emotion or interaction effects were observed at either cluster threshold (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 8</a>). We observed main effects of SF (two clusters spanning 202–284 ms at both cluster thresholds, and a separate cluster from 170–186 at cluster threshold <i>P</i> &lt; 0.05) followed by an emotion by SF interaction around 300 ms at both cluster thresholds (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Tables 8</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">10</a>).</p><p>Recording from both amygdala and face-sensitive fusiform cortex enabled a comparison of fear-evoked responses between these areas. Thus, in the four patients with electrodes in both amygdala and fusiform cortex, we compared emotional face responses between these two areas in the early emotion by SF interaction time window. The mean amplitude difference between emotions (fear versus happy, fear versus neutral, and happy versus neutral) across the 76–110-ms window, collapsing over BSF and LSF, was calculated for both the amygdala and fusiform gyrus, separately. These six difference values (three emotion differences for amygdala and fusiform contacts, respectively) for each of the four patients were entered into a Friedman test. This test showed a significant interaction between emotion and brain region (χ<sup>2</sup>(5) =12.71, <i>P</i> = 0.026). Further Friedman tests for each region separately revealed a significant emotion effect in amygdala (χ<sup>2</sup>(2) = 8, <i>P</i> = 0.018) but not in fusiform (χ<sup>2</sup>(2) = 2, <i>P</i> = 0.368).</p><p>It remains possible, however, that fast afferent input from fusiform cortex arrives at the amygdala before a differential response to fearful versus neutral or happy faces is observed in the fusiform, that is, emotion selectivity arises in the amygdala, but still depends on up-stream fusiform activity. Given that fast amygdala responses are observed to BSF and LSF fearful faces, we next tested for the earliest onset of any upward or downward deflection in fusiform contacts to BSF and LSF fearful faces, adopting a liberal statistical approach: we employed a one-tailed <i>t</i> test against zero for each time point of the entire post-stimulus period, applying an uncorrected alpha level of 0.05 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4f</a>). The first significant deflection for BSF fearful faces was negative and spanned 174–192 ms (174 ms: <i>t</i><sub>6</sub> = −2.53, <i>P</i> = 0.044 uncorrected); for LSF fearful faces there was a significant positive deflection from 104–124 ms (104 ms: <i>t</i><sub>6</sub> = 3.68, <i>P</i> = 0.010 uncorrected) and a negative deflection from 178–204 (178 ms: <i>t</i><sub>6</sub> = −2.57, <i>P</i> = 0.042 uncorrected). Thus, even applying liberal statistical criteria, the earliest deflection in fusiform cortex to BSF and LSF fearful faces (104 ms) occurred more than 30 ms after the onset of SF-dependent amygdala responses to fearful faces observed following cluster-based correction. Lastly, to control for the fact that the polarity of evoked potentials is unpredictable and can vary across individual contact sites, we tested absolute values of each post-stimulus time point of fusiform responses against zero in a one-tailed <i>t</i> test, again at uncorrected alpha of 0.05. The first significant effect for LSF fearful faces is again at 104 ms and for BSF fearful faces is at 108 ms. We also plotted the average response amplitude to fearful faces, collapsed over BSF and LSF, of all seven fusiform contact sites during the early amygdala interaction time window (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4g</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 11</a>), which show minimal deviations from zero. The absence of fast responses in ventral stream also safeguards against the possibility that short-latency effects in the amygdala are a result of activity derived from the common reference electrodes.</p><h3 class="c-article__sub-heading" id="Sec8">Emotional scenes do not evoke fast amygdala responses</h3><p>In experiment 2, amygdala iERPs were recorded during presentation of neutral and unpleasant complex pictures, such as household scenes and mutilated bodies, respectively. The task was completed by 13 patients with amygdala electrodes, of whom 9 satisfied inclusion criteria (three right, four left, two bilateral; <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/nn.4324#Tab1">Table 1</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig5">Fig. 5a,b</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 12</a>). Six of these nine patients also completed experiments 1. Notably, we found that the earliest latency at which iERPs evoked by unpleasant and neutral pictures differed significantly was from <span class="stix">∼</span>190 ms post-stimulus onset. Cluster-based permutations comparing emotional and neutral pictures revealed two significant clusters (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig5">Fig. 5c</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 13</a>), which, on relaxing the cluster threshold to <i>P</i> &lt; 0.05, collapsed into one cluster spanning 192–280 ms (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig5">Fig. 5c</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 13</a>). To calculate latencies at which iERPs to each picture type differed significantly from zero, we employed the same procedure as in experiment 1. With a cluster threshold of <i>P</i> &lt; 0.01, we observed significant differences from zero baseline from 186 ms and 226 ms for unpleasant and neutral pictures, respectively (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig5">Fig. 5d</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 14</a>), which, on relaxing the cluster threshold to <i>P</i> &lt; 0.05, began at 162 ms and 202 ms.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fast-latency amygdala responses are not evoked by complex emotional pictures."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5: Fast-latency amygdala responses are not evoked by complex emotional pictures.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4324/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig5_HTML.jpg?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig5_HTML.jpg" alt="figure 5" loading="lazy" width="685" height="431"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>(<b>a</b>,<b>b</b>) Schematic summary of electrode contact localizations in left and right amygdala for all patients included in experiment 2, as described in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Figure 2</a>. (<b>c</b>) Human amygdala iERPs from nine patients (11 amygdalae with a total of 32 contacts) to unpleasant pictures (experiment 2) were significantly different from those evoked by neutral pictures only from 192 ms to 280 ms (at cluster threshold <i>P</i> &lt; 0.05), encompassing two smaller clusters from 224 ms to 252 ms and from 258 ms to 278 ms, resulting from a cluster threshold <i>P</i> &lt; 0.01, on cluster-based non-parametric permutation statistic, based on paired-sample <i>t</i> test (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 13</a>). Shaded area indicates s.e.m. (<b>d</b>) Horizontal bars depict time windows in which responses to unpleasant (top) and neutral (bottom) pictures were significantly different from zero, on cluster-based non-parametric permutation statistic, based on one-sample <i>t</i> test (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 14</a>). Different cluster thresholds (<i>P</i> &lt; 0.05 and <i>P</i> &lt; 0.01) are coded as in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Figure 2</a>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4324/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Thus, no differential response to emotional versus neutral scenes was observed in the early time window in which fast responses to BSF and LSF fearful faces occurred in experiment 1. To formally test for a difference between fast amygdala responses to fearful faces and emotional scenes, we compared mean amplitudes of iERPs from experiment 1 versus 2 in the time cluster exhibiting an early facial emotion by frequency interaction (76–110 ms; <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 15</a>). That is, we tested for a difference between early responses to fearful relative to neutral faces versus the response in the same early time window for emotional relative to neutral scenes (for these analyses we collapsed BSF and LSF face trials). In a first analysis, we entered normalized mean amplitudes from all amygdalae in both experiments (10 from experiment 1 and 11 experiment 2) into a repeated-measures ANOVA with within-subject factor emotion (negative, neutral) and between-subject factor experiment (experiments 1 and 2). This revealed a significant emotion by experiment interaction (<i>F</i><sub>1,19</sub> = 23.54, <i>P</i> = 0.001). Next, we restricted our sample to the six patients (eight amygdalae) completing both tasks, and performed an ANOVA with within-subject factors emotion and task, which revealed a significant emotion by task interaction (<i>F</i><sub>1,7</sub> = 16.96, <i>P</i> = 0.004).</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Discussion</h2><div class="c-article-section__content" id="Sec9-content"><p>The existence of a subcortical route to the amygdala for rapid processing of ecologically important stimuli has markedly influenced basic and clinical research on emotional processing in the brain. However, one important limitation of this low-road model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="LeDoux, J.E. The Emotional Brain (Simon &amp; Schuster, New York, 1996)." href="/articles/nn.4324#ref-CR1" id="ref-link-section-d5467207e2587">1</a></sup> has been an absence of support from direct electrophysiological recordings in primates. An alternative account suggests that rapid visual processing of emotional stimuli can be mediated by other visual pathways involving visual cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Pessoa, L. &amp; Adolphs, R. Emotion processing and the amygdala: from a 'low road' to 'many roads' of evaluating biological significance. Nat. Rev. Neurosci. 11, 773–783 (2010)." href="/articles/nn.4324#ref-CR15" id="ref-link-section-d5467207e2591">15</a></sup>. Our results provide direct empirical support for the low-road model, as we found that human amygdala intracranial responses to fearful, but not neutral or happy, faces at very fast latency (<span class="stix">∼</span>70 ms) were SF dependent. This effect was localized to lateral amygdala, where sensory inputs from thalamo-amygdala and cortico-amygdala pathways converge<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="LeDoux, J.E. The Emotional Brain (Simon &amp; Schuster, New York, 1996)." href="/articles/nn.4324#ref-CR1" id="ref-link-section-d5467207e2595">1</a></sup>. We found that this selective amygdala response preceded any evoked activity in face-sensitive ventral visual cortex to the same stimuli by more than 30 ms, and preceded the onset of a differential response to fearful faces in ventral visual cortex by <span class="stix">∼</span>100 ms. Our findings are therefore consistent with a bottom-up amygdala response originating via a more direct subcortical magnocellular route rather than top-down influences from higher level visual processing stages. In contrast, the later latency main effect of emotion in the amygdala (beginning from <span class="stix">∼</span>120 ms) was more consistent with emotional information that arrives at the amygdala having been processed in visual cortex. In support of this interpretation, this later response was evoked by HSF fearful faces (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Fig. 2f,g</a>), which also modulated fusiform cortex activity (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig4">Fig. 4f</a>), indicating engagement of slower parvocellular pathways along visual cortical areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Livingstone, M. &amp; Hubel, D. Segregation of form, color, movement, and depth: anatomy, physiology and perception. Science 240, 740–749 (1988)." href="/articles/nn.4324#ref-CR30" id="ref-link-section-d5467207e2606">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Merigan, W.H. &amp; Maunsell, J.H.R. How parallel are the primate visual pathways? Annu. Rev. Neurosci. 16, 369–402 (1993)." href="/articles/nn.4324#ref-CR31" id="ref-link-section-d5467207e2609">31</a></sup>. Note that more pronounced later latency (&gt;200 ms) effects have been reported with tasks requiring attention to facial emotional expression<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2613">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Wang, S. et al. Neurons in the human amygdala selective for perceived emotion. Proc. Natl. Acad. Sci. USA 111, E3110–E3119 (2014)." href="/articles/nn.4324#ref-CR32" id="ref-link-section-d5467207e2616">32</a></sup>, but not when patients attended to gender<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2620">12</a></sup>, as we required in our task.</p><p>Evidence for a fast, magnocellular pathway in processing faces in non-human primates is provided by monkey pulvinar recordings showing 50-ms latency responses to face-like stimuli, including cartoon faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Nguyen, M.N. et al. Neuronal responses to face-like stimuli in the monkey pulvinar. Eur. J. Neurosci. 37, 35–51 (2013)." href="/articles/nn.4324#ref-CR33" id="ref-link-section-d5467207e2627">33</a></sup>. By contrast, relatively few intracranial recording studies in non-human primates have compared amygdala responses to static images of threat-related faces to non-threatening expressions. One study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Gothard, K.M., Battaglia, F.P., Erickson, C.A., Spitler, K.M. &amp; Amaral, D.G. Neural responses to facial expression and face identity in the monkey amygdala. J. Neurophysiol. 97, 1671–1683 (2007)." href="/articles/nn.4324#ref-CR34" id="ref-link-section-d5467207e2631">34</a></sup> reported increased neuronal firing to threatening faces at 120–250 ms post-stimulus presentation, which shows homology with the main effect of emotion that we observed in two time clusters between 118–204 ms. We could not, however, evaluate fast-latency responses to threat because the first 100 ms after stimulus-image onset were excluded from analyses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Gothard, K.M., Battaglia, F.P., Erickson, C.A., Spitler, K.M. &amp; Amaral, D.G. Neural responses to facial expression and face identity in the monkey amygdala. J. Neurophysiol. 97, 1671–1683 (2007)." href="/articles/nn.4324#ref-CR34" id="ref-link-section-d5467207e2635">34</a></sup>. Similarly, in a study reporting human single-unit amygdala recordings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Wang, S. et al. Neurons in the human amygdala selective for perceived emotion. Proc. Natl. Acad. Sci. USA 111, E3110–E3119 (2014)." href="/articles/nn.4324#ref-CR32" id="ref-link-section-d5467207e2639">32</a></sup>, emotion-selective units were selected in a time window 250–1,750 ms post-stimulus-onset, rendering analyses agnostic to fearful face responses at fast latencies (before 250 ms).</p><p>The few prior studies reporting field potentials<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2646">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Brazdil, M. et al. Neural correlates of affective picture processing—a depth ERP study. NeuroImage 47, 376–383 (2009)." href="/articles/nn.4324#ref-CR14" id="ref-link-section-d5467207e2649">14</a></sup> or oscillatory responses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Oya, H., Kawasaki, H., Howard, M.A. 3rd &amp; Adolphs, R. Electrophysiological responses in the human amygdala discriminate emotion categories of complex visual stimuli. J. Neurosci. 22, 9502–9512 (2002)." href="/articles/nn.4324#ref-CR11" id="ref-link-section-d5467207e2653">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Sato, W. et al. Rapid amygdala gamma oscillations in response to fearful facial expressions. Neuropsychologia 49, 612–617 (2011)." href="/articles/nn.4324#ref-CR35" id="ref-link-section-d5467207e2656">35</a></sup> from human amygdala depth recordings failed to find the fast-latency amygdala response that we observed. Although two previous studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Sato, W. et al. Rapid amygdala gamma oscillations in response to fearful facial expressions. Neuropsychologia 49, 612–617 (2011)." href="/articles/nn.4324#ref-CR35" id="ref-link-section-d5467207e2660">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Pourtois, G., Spinelli, L., Seeck, M. &amp; Vuilleumier, P. Temporal precedence of emotion over attention modulations in the lateral amygdala: Intracranial ERP evidence from a patient with temporal lobe epilepsy. Cogn. Affect. Behav. Neurosci. 10, 83–93 (2010)." href="/articles/nn.4324#ref-CR36" id="ref-link-section-d5467207e2663">36</a></sup> also presented fearful faces, they found responses at <span class="stix">∼</span>130 ms (approximating the latency of the main effect of emotion that we observed in the amygdala) and used only standard broadband photographs. In another study reporting late (200 ms) iERPs to fearful faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2667">12</a></sup>, a limited number of identities (eight) were each presented 30 times in each of two tasks. Human electrocorticographic (ECoG) recordings demonstrate item-specific repetition suppression of electrophysiological responses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Rodriguez Merzagora, A. et al. Repeated stimuli elicit diminished high-gamma electrocorticographic responses. NeuroImage 85, 844–852 (2014)." href="/articles/nn.4324#ref-CR37" id="ref-link-section-d5467207e2671">37</a></sup>; thus, multiple repetitions of the same stimuli may have resulted in habituation of an amygdala fast response in this previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2676">12</a></sup>. To eschew this possibility, we presented patients with 135 identity-unique facial expressions, and did not observe habituation following a single repetition. A further factor likely to have improved our ability to detect fast amygdala responses is that, in seven of eight patients included in experiment 1, pathology was outside of the medial temporal lobe entered into our analyses (<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/nn.4324#Tab1">Table 1</a>), consistent with preserved amygdala function. Lastly, given that we localized fast responses to lateral amygdala, studies with recording sites more medial than those described here<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Wang, S. et al. Neurons in the human amygdala selective for perceived emotion. Proc. Natl. Acad. Sci. USA 111, E3110–E3119 (2014)." href="/articles/nn.4324#ref-CR32" id="ref-link-section-d5467207e2683">32</a></sup> may be unable to detect fast-latency responses.</p><p>The failure of previous human intracranial studies to find a rapid amygdala response to complex emotional pictures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Oya, H., Kawasaki, H., Howard, M.A. 3rd &amp; Adolphs, R. Electrophysiological responses in the human amygdala discriminate emotion categories of complex visual stimuli. J. Neurosci. 22, 9502–9512 (2002)." href="/articles/nn.4324#ref-CR11" id="ref-link-section-d5467207e2690">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Brazdil, M. et al. Neural correlates of affective picture processing—a depth ERP study. NeuroImage 47, 376–383 (2009)." href="/articles/nn.4324#ref-CR14" id="ref-link-section-d5467207e2693">14</a></sup> may reflect a fundamentally faster processing time for fearful faces, which have important motivational and communicative value among primates<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Dimberg, U. &amp; Öhman, A. Behold the wrath: Psychophysiological responses to facial stimuli. Motiv. Emotion 20, 149–182 (1996)." href="/articles/nn.4324#ref-CR38" id="ref-link-section-d5467207e2697">38</a></sup>, relative to emotional scenes with multiple objects. Using complex emotional scenes, we also found that only late-latency human amygdala iERP amplitudes were modulated by emotion. The fact that fast responses were limited to fearful faces provides support for evolutionary theories of amygdala automaticity to social threat signals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Anderson, A.K., Christoff, K., Panitz, D., De Rosa, E. &amp; Gabrieli, J.D.E. Neural correlates of the automatic processing of threat facial signals. J. Neurosci. 23, 5627–5633 (2003)." href="/articles/nn.4324#ref-CR39" id="ref-link-section-d5467207e2701">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Öhman, A. Automaticity and the amygdala: nonconscious responses to emotional faces. Curr. Dir. Psychol. Sci. 11, 62–66 (2002)." href="/articles/nn.4324#ref-CR40" id="ref-link-section-d5467207e2704">40</a></sup>. From an evolutionary perspective, stimuli associated with recurrent survival threats, such as fearful faces, require minimal neural processing for identification, a notion referred to as 'preparedness'<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Seligman, M.E.P. Phobias and preparedness. Behav. Ther. 2, 307–320 (1971)." href="/articles/nn.4324#ref-CR22" id="ref-link-section-d5467207e2708">22</a></sup>. Moreover, the emergence of social communities and social signals of emotions during evolution presumably contributed to making amygdala-centered circuits particularly responsive to threat cues communicated by other conspecifics, including facial expressions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Öhman, A. Automaticity and the amygdala: nonconscious responses to emotional faces. Curr. Dir. Psychol. Sci. 11, 62–66 (2002)." href="/articles/nn.4324#ref-CR40" id="ref-link-section-d5467207e2712">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Kling, A.S. &amp; Brothers, L.A. The amygdala and social behavior. in The Amygdala: Neurobiological Aspects of Emotion, Memory, and Mental Dysfunction (ed. Aggleton, J.P.) 353–377 (Wiley-Liss, 1992)." href="/articles/nn.4324#ref-CR41" id="ref-link-section-d5467207e2715">41</a></sup>. Although the fast-latency response that we observed is selective for fearful versus happy and neutral faces, fast responses may also occur to other negative facial expressions such as anger. It remains to be tested whether fast human amygdala responses occur to simple, biologically relevant stimuli, such as snakes, that provided survival threat during evolution<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Seligman, M.E.P. Phobias and preparedness. Behav. Ther. 2, 307–320 (1971)." href="/articles/nn.4324#ref-CR22" id="ref-link-section-d5467207e2720">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Ohman, A. &amp; Mineka, S. Fears, phobias and preparedness: toward an evolved module of fear and fear learning. Psychol. Rev. 108, 483–522 (2001)." href="/articles/nn.4324#ref-CR42" id="ref-link-section-d5467207e2723">42</a></sup>.</p><p>Accounts of automaticity in fear processing also suggest that amygdala responses to emotional stimuli occur regardless of attentional resources available or competition between concurrent inputs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Vuilleumier, P. How brains beware: neural mechanisms of emotional attention. Trends Cogn. Sci. 9, 585 (2005)." href="/articles/nn.4324#ref-CR16" id="ref-link-section-d5467207e2731">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Anderson, A.K., Christoff, K., Panitz, D., De Rosa, E. &amp; Gabrieli, J.D.E. Neural correlates of the automatic processing of threat facial signals. J. Neurosci. 23, 5627–5633 (2003)." href="/articles/nn.4324#ref-CR39" id="ref-link-section-d5467207e2734">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Pessoa, L., McKenna, M., Gutierrez, E. &amp; Ungerleider, L. Neural processing of emotional faces requires attention. Proc. Natl. Acad. Sci. USA 99, 11458–11463 (2002)." href="/articles/nn.4324#ref-CR43" id="ref-link-section-d5467207e2737">43</a></sup>, and are not necessarily under voluntary control<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Moors, A. &amp; De Houwer, J. Automaticity: a theoretical and conceptual analysis. Psychol. Bull. 132, 297 (2006)." href="/articles/nn.4324#ref-CR44" id="ref-link-section-d5467207e2741">44</a></sup>. We did not explicitly manipulate attention in either experiments 1 or 2; amygdala responses were observed during incidental tasks of gender or indoor/outdoor judgments, respectively. Nonetheless, we note that automatic amygdala responses independent of attention would be predicted by the existence of fast, subcortical inputs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Vuilleumier, P. How brains beware: neural mechanisms of emotional attention. Trends Cogn. Sci. 9, 585 (2005)." href="/articles/nn.4324#ref-CR16" id="ref-link-section-d5467207e2745">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Anderson, A.K., Christoff, K., Panitz, D., De Rosa, E. &amp; Gabrieli, J.D.E. Neural correlates of the automatic processing of threat facial signals. J. Neurosci. 23, 5627–5633 (2003)." href="/articles/nn.4324#ref-CR39" id="ref-link-section-d5467207e2748">39</a></sup>, for which our data provide, to the best of our knowledge, the first direct electrophysiological support in humans. However, it remains possible that amygdala responses to coarse inputs without attention may involve other cortical or subcortical pathways receiving privileged early access to coarse (LSF) visual information<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Vuilleumier, P. How brains beware: neural mechanisms of emotional attention. Trends Cogn. Sci. 9, 585 (2005)." href="/articles/nn.4324#ref-CR16" id="ref-link-section-d5467207e2752">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Kveraga, K., Boshyan, J. &amp; Bar, M. Magnocellular projections as the trigger of top-down facilitation in recognition. J. Neurosci. 27, 13232–13240 (2007)." href="/articles/nn.4324#ref-CR45" id="ref-link-section-d5467207e2755">45</a></sup>. That is, a fast amygdala response could be driven by inputs from other cortical regions, such as emotion-sensitive ventral or orbitofrontal cortex, which also receive magnocellular pulvinar input<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Barbas, H. Connections underlying the synthesis of cognition, memory, and emotion in primate prefrontal cortices. Brain Res. Bull. 52, 319–330 (2000)." href="/articles/nn.4324#ref-CR46" id="ref-link-section-d5467207e2759">46</a></sup>. This is unlikely, as the <span class="stix">∼</span>70-ms latency response that we observed is faster than increased neuronal firing rates previously reported<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Kawasaki, H. et al. Single-neuron responses to emotional visual stimuli recorded in human ventral prefrontal cortex. Nat. Neurosci. 4, 15–16 (2001)." href="/articles/nn.4324#ref-CR47" id="ref-link-section-d5467207e2764">47</a></sup> in human ventral prefrontal cortex to emotional scenes (120–160-ms latency), and faster than late latency (<span class="stix">∼</span>500 ms) responses to fearful faces observed in human orbitofrontal cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2768">12</a></sup>. Without simultaneously recording from these cortical areas, our data cannot exclude the possibility that short-latency modulations of neural activity by SF and fear relevance also occur in cortical regions receiving magnocellular thalamic input<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Pessoa, L. &amp; Adolphs, R. Emotion processing and the amygdala: from a 'low road' to 'many roads' of evaluating biological significance. Nat. Rev. Neurosci. 11, 773–783 (2010)." href="/articles/nn.4324#ref-CR15" id="ref-link-section-d5467207e2772">15</a></sup>. Whether these brain regions indeed show equivalent fast, LSF-dependent responses to fear-relevant stimuli in humans remains unknown. However, our findings clearly demonstrate that short-latency responses can be observed in human amygdala.</p><p>Our results demonstrate for the first time, to the best of our knowledge, using direct electrophysiological recordings in a homogenous sample of human patients, a fast (74 ms) and selective amygdala response to emotional information. The early amygdala response was specific to fearful, but not happy, facial expressions. Furthermore, the effect was selective to socially relevant, fearful facial information and was not evoked by unpleasant complex pictures. Fast responses were oly observed to LSF, but not HSF, components of fearful faces, consistent with coarse visual input providing limited, but rapid, information via the magnocellular pathway. The latency of amygdala responses to fearful faces was significantly faster than that observed in fusiform cortex. Thus, our data provide support for a low-road circuit for fear detection in the human amygdala. This pathway, and its functional properties, may also constitute an important neural substrate for models of non-conscious processing in anxiety disorders<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Ohman, A. &amp; Mineka, S. Fears, phobias and preparedness: toward an evolved module of fear and fear learning. Psychol. Rev. 108, 483–522 (2001)." href="/articles/nn.4324#ref-CR42" id="ref-link-section-d5467207e2779">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Etkin, A. et al. Individual differences in trait anxiety predict the response of the basolateral amygdala to unconsciously processed fearful faces. Neuron 44, 1043–1055 (2004)." href="/articles/nn.4324#ref-CR48" id="ref-link-section-d5467207e2782">48</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Rauch, S.L. et al. Exaggerated amygdala response to masked facial stimuli in posttraumatic stress disorder: a functional MRI study. Biol. Psychiatry 47, 769–776 (2000)." href="/articles/nn.4324#ref-CR49" id="ref-link-section-d5467207e2785">49</a></sup> and the generalization of fear responses to coarsely defined cues in pathological conditions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Anderson, A.K., Christoff, K., Panitz, D., De Rosa, E. &amp; Gabrieli, J.D.E. Neural correlates of the automatic processing of threat facial signals. J. Neurosci. 23, 5627–5633 (2003)." href="/articles/nn.4324#ref-CR39" id="ref-link-section-d5467207e2789">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Sheline, Y.I. et al. Increased amygdala response to masked emotional faces in depressed subjects resolves with antidepressant treatment: an fMRI study. Biol. Psychiatry 50, 651–658 (2001)." href="/articles/nn.4324#ref-CR50" id="ref-link-section-d5467207e2792">50</a></sup>.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Methods</h2><div class="c-article-section__content" id="Sec10-content"><h3 class="c-article__sub-heading" id="Sec11">Participants.</h3><p>Participants were medication-resistant epilepsy patients with depth electrodes surgically implanted to aid seizure focus localization (<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/nn.4324#Tab1">Table 1</a>). Implantation sites were chosen solely on the basis of clinical criteria. Patients had normal or corrected-to-normal vision and had no history of head trauma or encephalitis. Their amygdalae were radiologically normal on pre-operative MRI (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig6">Supplementary Fig. 1</a>). No statistical methods were used to pre-determine sample sizes but our sample sizes are larger to those reported in previous publications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Oya, H., Kawasaki, H., Howard, M.A. 3rd &amp; Adolphs, R. Electrophysiological responses in the human amygdala discriminate emotion categories of complex visual stimuli. J. Neurosci. 22, 9502–9512 (2002)." href="/articles/nn.4324#ref-CR11" id="ref-link-section-d5467207e2814">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. Neuron 42, 665–676 (2004)." href="/articles/nn.4324#ref-CR12" id="ref-link-section-d5467207e2817">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Naccache, L. et al. A direct intracranial record of emotions evoked by subliminal words. Proc. Natl. Acad. Sci. USA 102, 7713–7717 (2005)." href="/articles/nn.4324#ref-CR13" id="ref-link-section-d5467207e2820">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Brazdil, M. et al. Neural correlates of affective picture processing—a depth ERP study. NeuroImage 47, 376–383 (2009)." href="/articles/nn.4324#ref-CR14" id="ref-link-section-d5467207e2823">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Sato, W. et al. Rapid amygdala gamma oscillations in response to fearful facial expressions. Neuropsychologia 49, 612–617 (2011)." href="/articles/nn.4324#ref-CR35" id="ref-link-section-d5467207e2826">35</a></sup>. All patients signed informed consent. The study had full approval from the Hospital Ruber Internacional Ethics Committee.</p><h3 class="c-article__sub-heading" id="Sec12">Stereotactic electrode implantation.</h3><p>A contrast enhanced MRI was performed pre-operatively under stereotactic conditions to map vascular structures prior to electrode implantation and to calculate stereotactic coordinates for trajectories using the Neuroplan system (Integra Radionics). DIXI Medical Microdeep depth electrodes (multicontact, semi rigid, diameter of 0.8 mm, contact length of 2 mm, inter-contact isolator length of 1.5 mm) were implanted based on the stereotactic Leksell method.</p><h3 class="c-article__sub-heading" id="Sec13">Electrode contact localization.</h3><p>To take advantage of the visibility of individual electrode contacts on CT images, for each patient we co-registered the pre-electrode placement T1-weighted magnetic resonance images (pre-MRI) to post-electrode placement CT (post-CT) whole-brain volumes. MRIs were acquired on a 3 T Signa HDx GE scanner (GE Healthcare). To optimize this co-registration, both brain images were first skull-stripped. For CTs this was done by filtering out all voxels with signal intensities between 100 and 1,300 HU. Skull stripping of the pre-MRI proceeded by first spatially normalizing the image to MNI space employing the <i>New Segment</i> algorithm in SPM8 The resultant inverse normalization parameters were then applied to the brain mask supplied in SPM8 to transform the brain mask into the native space of the pre-MRI. All voxels in pre-MRI lying outside the brain mask and possessing a signal value in the highest 15<sup>th</sup> percentile were filtered out. The skull-stripped pre-MRI was then co-registered and re-sliced to the skull-stripped post-CT. Next, the pre-MRI was affine normalized to the post-CT, thus transforming the pre-MRI image into native post-CT space. The two images were then overlaid, with the post-CT thresholded such that only electrode contacts were visible.</p><h3 class="c-article__sub-heading" id="Sec14">Electrode contact visualization.</h3><p>To construct schematic summary illustrations of the localizations of all amygdala contacts entered into our analyses, the coordinates—in native post-CT space—were identified for the center of each contact in each amygdala. For each patient, the pre-MRI (now in native post-CT space) was then spatially normalized to MNI space, the ensuing normalization parameters applied to each of the amygdala contact coordinates for that patient, and the resultant MNI coordinates indicated on the MNI template brain (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Figs. 2a</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig5">5a</a>). This approach was adopted instead of spatially normalizing the fused pre-MRI and post-CT image to MNI space, because the latter approach distorts contact topography. To provide a three-dimensional view of contact localizations, the cytoarchitectonically defined amygdala<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Amunts, K. et al. Cytoarchitectonic mapping of the human amygdala, hippocampal region and entorhinal cortex: intersubject variability and probability maps. Anat. Embryol. (Berl) 210, 343–352 (2005)." href="/articles/nn.4324#ref-CR51" id="ref-link-section-d5467207e2864">51</a></sup>, provided in the SPM Anatomy toolbox, was obtained by thresholding the separate laterobasal, centromedial, and superficial group probability maps at ≥ 0.3, and combining them into a single amygdala volume. The surface contour of the amygdala volume (in standard MNI space) was then rendered in Paraview<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Ahrens, J., Geveci, B. &amp; Law, C. ParaView: An end-user tool for large-data visualization. in The Visualization Handbook (eds. Hansen, C.D. &amp; Johnson, C.R.) 717 (Citeseer, 2005)." href="/articles/nn.4324#ref-CR52" id="ref-link-section-d5467207e2868">52</a></sup> (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig2">Figs. 2b</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig5">5b</a>).</p><h3 class="c-article__sub-heading" id="Sec15">Experiment 1: emotional faces.</h3><p><i>Stimuli.</i> We compiled faces of 139 different actors (69 female) posing fearful, happy, and neutral expressions from three databases: Karolinska Directed Emotional Faces (<a href="http://www.emotionlab.se/resources/kdef">http://www.emotionlab.se/resources/kdef</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Lundqvist, D., Flykt, A. &amp; Öhman, A. The Karolinska Directed Emotional Faces–KDEF (Department of Clinical Neuroscience, Psychology Section, Karolinska Institutet, 1998)." href="/articles/nn.4324#ref-CR53" id="ref-link-section-d5467207e2897">53</a></sup>, Warsaw Set of Emotional Facial Expression Pictures (<a href="http://www.emotional-face.org/">http://www.emotional-face.org/</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Olszanowski, M., Pochwatko, G., Kukliński, K., Ścibor-Rylski, M. &amp; Ohme, R. Warsaw set of emotional facial expression pictures—validation study of facial display photographs. Front. Psychol. 5, 1516 (2015)." href="/articles/nn.4324#ref-CR54" id="ref-link-section-d5467207e2908">54</a></sup> and Radboud Faces Database (<a href="http://www.socsci.ru.nl:8180/RaFD2/RaFD">http://www.socsci.ru.nl:8180/RaFD2/RaFD</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Langner, O., Dotsch, R., Bijlstra, G., Wigboldus, D.H.J., Hawk, S.T. &amp; van Knippenberg, A. Presentation and validation of the Radboud Faces Database. Cogn. Emot. 24, 1377–1388 (2010)." href="/articles/nn.4324#ref-CR55" id="ref-link-section-d5467207e2920">55</a></sup>. Eye gaze of all face stimuli was directed forward. Images were gray-scaled and enclosed in a rectangular frame (198 × 251 pixels) excluding most hair and background (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4324#Fig1">Fig. 1</a>). Spatial frequency content in the original stimuli (BSF) was filtered using a high-pass cut-off of &gt;24 cycles per image for HSF stimuli, and a low-pass cut-off of &lt;6 cycles per image for LSF stimuli (using Matlab, The Mathworks). Presented faces subtended a visual angle of 7.4°, resulting in spatial frequency cut-offs of 3.24 and 0.81 cycles per degree for HSF and LSF, respectively. Lastly, brightness was equalized across all nine conditions (mean gray scale pixel values 115). Further, we ensured that there were no significant differences in the pixel value distributions between emotions within each spatial frequency (Anderson-Darling <i>k</i>-sample tests: for BSF <i>AD</i> = 1.06, <i>t</i><sub>AD</sub> = −0.88, asymptotic <i>P</i> = 0.843; for HSF <i>AD</i> = 0.06, <i>t</i><sub>AD</sub> = −1.81, asymptotic <i>P</i> = 1; for LSF <i>AD</i> = 1.10, <i>t</i><sub>AD</sub> = −0.84, asymptotic <i>P</i> = 0.824). For each patient, 135 different identities (out of the 139 that composed the whole set) were randomly selected for presentation. Each of the 135 identities was pseudorandomly assigned to one of the nine possible conditions: BSF fearful, HSF fearful, LSF fearful, BSF happy, HSF happy, LSF happy, BSF neutral, HSF neutral and LSF neutral faces. Thus, each condition was composed of 15 different identities, unique to that condition. Pseudo-randomization proceeded such that either eight or seven identities shared gender in each condition. Once the 135 faces were selected, their order of presentation was randomized. The task was repeated twice. In the second block, performed 10 min after the first, the same stimuli were presented as the first block, but in a different pseudo-random order.</p><p><i>Procedure.</i> Experiments were conducted during the second post-operative day. All patients were seizure free for the previous 12h. In each of 2 experimental blocks, faces were centrally displayed on an LCD computer screen for 500 ms followed by a fixation cross for 3500 ms. Patients were required to make a gender judgment, via button press, for each face (this task was employed because gender judgments rely equally on HSF and LSF information, with no dominance by either spatial frequency range<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Schyns, P.G. &amp; Oliva, A. Dr. Angry and Mr. Smile: When categorization flexibly modifies the perception of faces in rapid visual presentations. Cognition 69, 243–265 (1999)." href="/articles/nn.4324#ref-CR56" id="ref-link-section-d5467207e2967">56</a></sup>). Patients remained as still as possible attending the centre of the screen while avoiding verbalizations and minimizing eye-blinks.</p><p><i>Data acquisition.</i> Ongoing intracranial electroencephalogram (iEEG) activity was acquired using an XLTEK EMU128FS amplifier (XLTEK). iEEG data were recorded at each electrode contact site at a 500-Hz sampling rate (online bandpass filter 0.1–150 Hz) and referenced to linked mastoid electrodes. The accuracy of stimulus onset latencies was first measured with a photo-diode and a light-to-voltage converter (TKK Brain Research Unit), and latency uncertainty found to be in the range of 2 ms.</p><h3 class="c-article__sub-heading" id="Sec16">Data analysis.</h3><p><i>Patient inclusion.</i> Of 16 patients with amygdala electrodes who completed the task, four patients did not meet our criteria for spike-free trials (75%) and were thus excluded. A further two patients were excluded due to poor task engagement (12% and 38% trials in which responses were omitted, respectively, compared to an average 0.67% across all other patients). One patient was excluded due to the presence of large-amplitude slow oscillations during recording. Lastly, electrophysiological responses from one patient did not demonstrate any discernible stimulus-evoked components during the 640-ms post-onset interval. Data from this patient were also excluded. Thus, we analyzed iERPs from ten amygdalae from eight patients (four left-sided, two right-sided and two bilaterally implanted). Patient demographics and clinical details are given in <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/nn.4324#Tab1">Table 1</a>. Although patient 5 had procedural and verbal IQ in the borderline and extremely low range, respectively (<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/nn.4324#Tab1">Table 1</a>), this patient's gender judgment performance was comparable to that of other patients (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 1</a>).</p><p><i>Pre-processing</i>. For each amygdala contact, experimental condition, and patient, epochs from −200 to 640-ms peri-stimulus time were extracted from continuous iEEG data. Epochs containing epileptiform activity or artifacts (large-amplitude slow-wave drifts or high-frequency activity) were rejected by trial-by-trial visual inspection, as were epochs corresponding to absent or multiple behavioral responses. Epochs were then detrended, baseline corrected (100-ms pre-stimulus baseline) and no filter was applied. No further off-line filtering of the data was performed to avoid filter effects that may distort waveforms and hence introduce latency artifacts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Tanner, D., Morgan-Short, K. &amp; Luck, S.J. How inappropriate high-pass filters can produce artifactual effects and incorrect conclusions in ERP studies of language and cognition. Psychophysiology 52, 997–1009 (2015)." href="/articles/nn.4324#ref-CR57" id="ref-link-section-d5467207e3000">57</a></sup>. For each experimental condition, data were then averaged across the two blocks. In the case that there was more than one contact within the amygdala, data from all contacts were averaged within trial for that amygdala.</p><p><i>Statistics.</i> We applied a cluster-based non-parametric permutation statistic, based on MANOVA <i>F</i> values with within-subject factors of emotion (fear, happy, neutral) and spatial frequency (BSF, LSF, HSF), to determine the time points of significant interaction between emotion and spatial frequency with respect to iERP amplitude. This approach effectively corrects the family-wise error rate in the context of multiple comparisons of latency bins<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Maris, E. &amp; Oostenveld, R. Nonparametric statistical testing of EEG and MEG data. J. Neurosci. Methods 164, 177–190 (2007)." href="/articles/nn.4324#ref-CR23" id="ref-link-section-d5467207e3012">23</a></sup>. Under the null hypothesis of no differences between levels of each test (main effects of emotion or spatial frequency, and their interaction), the amplitude values at each time point can be permuted between conditions within each factor. After a permutation step, a MANOVA was calculated at each time point for each test separately, with a cluster threshold of <i>P</i> &lt; 0.01 for the main effects and interaction. Thus, significant time clusters were formed by temporal adjacency of supra-threshold effects (a cluster contained at least two significant neighbors along the time dimension). For each cluster, the MANOVA <i>F</i> values (Wilk's lambda) of the corresponding test were summed and the greatest sum among all clusters entered into the permutation distribution. Note that as the permutation distribution is a data-driven non-parametric distribution, no degrees of freedom are given. Permutation steps were repeated 1,000 times and permutation distributions for main effects and interactions created. Initially, empirical cluster sums of MANOVA <i>F</i> values that were greater than the 99<sup>th</sup> centile within the permutation distribution were considered as significant temporal clusters of emotion/spatial frequency main effects or interaction. We next applied a less conservative cluster threshold of <i>P</i> &lt; 0.05 and repeated the permutation testing. The more conservative (<i>P</i> &lt; 0.01) and relaxed (<i>P</i> &lt; 0.05) cluster thresholds were applied in order to balance risk of false positives (that is, that weak, neighboring single-time-point effects combine into a significant cluster) and risk of false negatives, respectively. A MANOVA was chosen over univariate ANOVA to eschew violation of the sphericity assumption. Next, to explore the differences in each significant time cluster (for main effects and interaction), the mean amplitude values for each subject and each condition across the significant clusters were computed for each effect and tested with specific contrasts and <i>post hoc t</i> tests. When applying parametric tests, data distribution was assumed to be normal, but this was not formally tested. Finally, we applied cluster-based permutation statistics on the iERP to each of the nine face stimulus types separately, to test a null hypothesis of deflections being equal to zero for the entire post-stimulus period.</p><p>Of 14 patients with amygdala electrodes who met inclusion criteria on the basis of performance on the gender judgment task, seven also had electrodes in visual areas. Identical data pre-processing steps were employed for these iEEG data as for amygdala contacts, with one patient rejected for not meeting criterion for spike-free trial number. A further patient did not have contacts in the fusiform gyrus. Thus, from five patients, seven groups of fusiform contacts were entered into the same cluster-based permutations statistics as applied to amygdala contact data (again with cluster threshold of <i>P</i> &lt; 0.01 followed by <i>P</i> &lt; 0.05). To test for latency effects of BSF and LSF fearful faces employing non-corrected statistics, we compared iERPs for each stimulus type relative to zero in two-tailed one-sample <i>t</i> tests. Only time clusters with more than four adjacent data points (that is, at least 10 ms) are considered significant.</p><p>For those patients for whom responses were successfully recorded simultaneously from both amygdala and fusiform (four patients), we computed the average values for fearful, happy, and neutral faces across all frequencies. To test the interaction between electrode site (amygdala, fusiform) and emotion (fearful, happy and neutral) we calculated difference values with respect to the three different combinations of the factor levels for emotion at each electrode site. For each emotion, the amplitude differences between electrode sites were also determined. The difference values were submitted to non-parametric Friedman tests. Significant interactions between electrode sites and emotion were further analyzed by Wilcoxon signed ranked tests applied to the factors emotion and electrode site. Data collection and analysis were not performed blind to the conditions of experiments 1 or 2. A <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM9">Supplementary Methods Checklist</a> is available and includes statistics derived from experiments 1 and 2.</p><p><i>Source localization of amygdala responses.</i> Electrodes containing amygdala contacts were selected for each patient, and the average responses to BSF and LSF fearful faces from all contacts of each selected electrode (that is, within and outside the amygdala) were analyzed. Noisy channels were removed. Thus data from 5–12 contacts per electrode were submitted to source localization at the individual patient level, implemented in Brainstorm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Tadel, F., Baillet, S., Mosher, J.C., Pantazis, D. &amp; Leahy, R.M. Brainstorm: a user-friendly application for MEG/EEG analysis. Comput. Intell. Neurosci. 2011, 879716 (2011)." href="/articles/nn.4324#ref-CR58" id="ref-link-section-d5467207e3064">58</a></sup> software. After co-registration of the individual pre-operative MRIs with post-operative CT scans, a dipole grid (20,000 dipoles) restricted to the neocortex, amygdala and hippocampus was used as a brain model to estimate the current source distribution. This dipole grid was used to calculate a forward model employing the boundary element method<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Gramfort, A., Papadopoulo, T., Olivi, E. &amp; Clerc, M. OpenMEEG: opensource software for quasistatic bioelectromagnetics. Biomed. Eng. Online 9, 45 (2010)." href="/articles/nn.4324#ref-CR59" id="ref-link-section-d5467207e3068">59</a></sup>. An <i>l</i>2-weighted minimum norm algorithm (wMNE)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Hauk, O. Keep it simple: a case for using classical minimum norm estimation in the analysis of EEG and MEG data. Neuroimage 21, 1612–1621 (2004)." href="/articles/nn.4324#ref-CR60" id="ref-link-section-d5467207e3075">60</a></sup> was then applied to obtain mean current source densities for the time windows corresponding to the observed early (76–110 ms) response to fear. To measure the consistency of this localization over all amygdalae, each wMNE solution was normalized to MNI space<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Collins, D.L. et al. Design and construction of a realistic digital brain phantom. IEEE Trans. Med. Imaging 17, 463–468 (1998)." href="/articles/nn.4324#ref-CR61" id="ref-link-section-d5467207e3079">61</a></sup> using SPM8. The wMNE solutions for right-sided amygdalae electrodes were flipped on the left-right axis. Lastly, for each of the 20,000 dipoles comprising the neocortex, amygdala and hippocampus, the number of subjects showing at least 50% of the maximum activation at that dipole was counted. This process was then repeated for the later main effect of emotion time window (282–302 ms). Note that for patient 10, source localization was not possible due to two channels within, and five channels lateral to, the amygdala (seven of ten channels) displaying a flat signal, prohibiting the calculation of a potential gradient along the electrode contacts.</p><p><i>Eye movements.</i> Although eye movements were not recorded in the current experiment, it is unlikely that task-related saccadic eye movements can account for the fast amygdala responses we observe. A previous fMRI study comparing responses to fearful versus neutral BSF, HSF and LSF faces reported no significant effects or interaction due to SF or emotion in mean eye-position data over a 200-ms period after stimulus onset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Vuilleumier, P., Armony, J.L., Driver, J. &amp; Dolan, R.J. Distinct spatial frequency sensitivities for processing faces and emotional expressions. Nat. Neurosci. 6, 624–631 (2003)." href="/articles/nn.4324#ref-CR19" id="ref-link-section-d5467207e3088">19</a></sup>. Furthermore, iERP recordings are considered relatively less susceptible to eye movement artifacts compared to scalp-recorded ERPs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Lachaux, J.P., Rudrauf, D. &amp; Kahane, P. Intracranial EEG and human brain mapping. J. Physiol. Paris 97, 613–628 (2003)." href="/articles/nn.4324#ref-CR62" id="ref-link-section-d5467207e3092">62</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec17">Experiment 2: emotional pictures.</h3><p>Experiment 2 proceeded in an identical manner to experiment 1, except for the following:</p><p><i>Stimuli.</i> Patients were presented with 40 emotional and 80 neutral color pictures. These were drawn at random from a pool of 80 high-arousing unpleasant (mutilations and attack) scenes selected from the International Affective Picture System<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Lang, P.J., Bradley, M.M. &amp; Cuthbert, B.N. International affective picture system (IAPS): affective ratings of pictures and instruction manual (Technical Report A-6) (University of Florida, 2005)." href="/articles/nn.4324#ref-CR63" id="ref-link-section-d5467207e3108">63</a></sup> (IAPS), and 160 low-arousing neutral pictures: 149 taken from the IAPS (household scenes and neutral persons) and eleven neutral landscape pictures taken from the world-wide web. Mean normative IAPS picture ratings (SEM) on a nine-point scale for valence were 5.05 (0.05) for neutral, and 2.04 (0.05) for unpleasant pictures, and for arousal were 3.29 (0.06), and 6.3 (0.07) for neutral and unpleasant pictures, respectively. Note that in both experiments 1 and 2, the ratio of negative emotional to non-negative stimuli was 1:2.</p><p><i>Procedure.</i> This experiment was conducted during the third post-operative day. Emotional and neutral pictures were presented pseudo-randomly (presentation time 500 ms; interstimulus interval 3,500 ms) with a constraint that emotional pictures were separated by at least one neutral picture. Patients were required to make an indoor-outdoor judgment to each via button-press. Prior to signing informed consent, patients were shown one example of an unpleasant IAPS picture and instructed that they would see similar pictures both on that day and the next (patients saw the same pictures again the next day during a recognition memory test).</p><h3 class="c-article__sub-heading" id="Sec18">Data acquisition.</h3><p>This was identical to experiment 1, but on post-operative day 3.</p><h3 class="c-article__sub-heading" id="Sec19">Data analysis.</h3><p><i>Patient inclusion.</i> Of 14 patients who completed the task, nine met all inclusion criteria. Two patients were excluded due to poor push-button response rate (36% and 28% trials in which responses were omitted compared to 1.22% mean omissions for the nine patients included in the analysis). A further three patients did not meet our criteria for spike-free trials (75%). Patient demographics and clinical details are given in <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/articles/nn.4324#Tab1">Table 1</a>. Despite borderline and extremely low range IQs of patients 5 and 8, these patients' reaction times on the indoor/outdoor task were comparable to other patients' (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4324#MOESM8">Supplementary Table 12</a>).</p><p><i>Preprocessing.</i> After spike and artifact rejection, data preprocessing was as for experiment 1; epochs of unfiltered data were detrended and baseline corrected (100-ms pre-stimulus baseline).</p><p><i>Statistics.</i> For statistical comparison of evoked responses, we applied the same cluster-based permutation approach as for experiment 1, but a paired <i>t</i> test was used as the initial cluster statistic to compare emotional versus neutral pictures. To calculate the points in time at which iERPs started to differ significantly from zero, we used the same procedure as for experiment 1 iERPs.</p><p>For the four patients with electrodes in the fusiform gyrus who completed both experiments 1 and 2, evoked responses to BSF neutral faces recorded in experiment 1 were compared to those evoked by neutral scenes in experiment 2, again employing cluster-based permutations statistics with a cluster threshold of <i>P</i> &lt; 0.01 (<i>n</i> = 6 groups of contacts). Note that some neutral IAPS pictures (18%) contained human faces embedded within the scenes, which were removed from this analysis.</p><h3 class="c-article__sub-heading" id="Sec20">Data availability.</h3><p>The data that support the findings of this study are available from the corresponding author upon request.</p><h3 class="c-article__sub-heading" id="Sec21">Code availability.</h3><p>Stimulus presentation, electrode contact localization, and all iERP analyses were done using open source software packages. Visual stimuli were presented using Cogent2000 (<a href="http://www.vislab.ucl.ac.uk/cogent_2000.php">http://www.vislab.ucl.ac.uk/cogent_2000.php</a>). Electrode contacts were visualized using SPM8 (<a href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</a>). Signal processing and permutation statistics were implemented in the Fieldtrip toolbox (<a href="http://www.fieldtriptoolbox.org/">http://www.fieldtriptoolbox.org/</a>). The 3-by-3 MANOVA for each permutation was calculated within the R-environment for statistical computing (<a href="https://www.r-project.org/">https://www.r-project.org/</a>; the R-code can be obtained from the authors upon request) and subsequent cluster forming and statistical inference done using the fieldtrip-toolbox. Forward head modeling and cortical source analyses were calculated using the Brainstorm toolbox (<a href="http://neuroimage.usc.edu/brainstorm/">http://neuroimage.usc.edu/brainstorm/</a>). These open source toolboxes, with the exception of R, were run on Matlab.</p></div></div></section>
                </div>
            

            <div>
                <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1"><p class="c-article-references__text" id="ref-CR1">LeDoux, J.E. <i>The Emotional Brain</i> (Simon &amp; Schuster, New York, 1996).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2"><p class="c-article-references__text" id="ref-CR2">Day-Brown, J.D., Wei, H., Chomsung, R.D., Petry, H.M. &amp; Bickford, M.E. Pulvinar projections to the striatum and amygdala in the tree shrew. <i>Front. Neuroanat.</i> <b>4</b>, 143 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fnana.2010.00143" data-track-action="article reference" href="https://doi.org/10.3389%2Ffnana.2010.00143" aria-label="Article reference 2" data-doi="10.3389/fnana.2010.00143">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21120139" aria-label="PubMed reference 2">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2991220" aria-label="PubMed Central reference 2">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Pulvinar%20projections%20to%20the%20striatum%20and%20amygdala%20in%20the%20tree%20shrew&amp;journal=Front.%20Neuroanat.&amp;doi=10.3389%2Ffnana.2010.00143&amp;volume=4&amp;publication_year=2010&amp;author=Day-Brown%2CJD&amp;author=Wei%2CH&amp;author=Chomsung%2CRD&amp;author=Petry%2CHM&amp;author=Bickford%2CME">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3"><p class="c-article-references__text" id="ref-CR3">Tamietto, M. &amp; de Gelder, B. Neural bases of the non-conscious perception of emotional signals. <i>Nat. Rev. Neurosci.</i> <b>11</b>, 697–709 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn2889" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2889" aria-label="Article reference 3" data-doi="10.1038/nrn2889">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXhtFSisbvF" aria-label="CAS reference 3">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20811475" aria-label="PubMed reference 3">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20bases%20of%20the%20non-conscious%20perception%20of%20emotional%20signals&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2889&amp;volume=11&amp;pages=697-709&amp;publication_year=2010&amp;author=Tamietto%2CM&amp;author=de%20Gelder%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4"><p class="c-article-references__text" id="ref-CR4">Johnson, M.H. Subcortical face processing. <i>Nat. Rev. Neurosci.</i> <b>6</b>, 766–774 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn1766" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn1766" aria-label="Article reference 4" data-doi="10.1038/nrn1766">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXhtV2jsL3O" aria-label="CAS reference 4">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16276354" aria-label="PubMed reference 4">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Subcortical%20face%20processing&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn1766&amp;volume=6&amp;pages=766-774&amp;publication_year=2005&amp;author=Johnson%2CMH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5"><p class="c-article-references__text" id="ref-CR5">Garrido, M.I., Barnes, G.R., Sahani, M. &amp; Dolan, R.J. Functional evidence for a dual route to amygdala. <i>Curr. Biol.</i> <b>22</b>, 129–134 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cub.2011.11.056" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cub.2011.11.056" aria-label="Article reference 5" data-doi="10.1016/j.cub.2011.11.056">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38Xhs1Gjsb8%3D" aria-label="CAS reference 5">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22209532" aria-label="PubMed reference 5">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3267035" aria-label="PubMed Central reference 5">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20evidence%20for%20a%20dual%20route%20to%20amygdala&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2011.11.056&amp;volume=22&amp;pages=129-134&amp;publication_year=2012&amp;author=Garrido%2CMI&amp;author=Barnes%2CGR&amp;author=Sahani%2CM&amp;author=Dolan%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6"><p class="c-article-references__text" id="ref-CR6">Morris, J.S., Ohman, A. &amp; Dolan, R.J. Conscious and unconscious emotional learning in the human amygdala. <i>Nature</i> <b>393</b>, 467–470 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/30976" data-track-action="article reference" href="https://doi.org/10.1038%2F30976" aria-label="Article reference 6" data-doi="10.1038/30976">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1cXjs1KntL8%3D" aria-label="CAS reference 6">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9624001" aria-label="PubMed reference 6">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Conscious%20and%20unconscious%20emotional%20learning%20in%20the%20human%20amygdala&amp;journal=Nature&amp;doi=10.1038%2F30976&amp;volume=393&amp;pages=467-470&amp;publication_year=1998&amp;author=Morris%2CJS&amp;author=Ohman%2CA&amp;author=Dolan%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7"><p class="c-article-references__text" id="ref-CR7">Whalen, P.J. et al. Masked presentations of emotional facial expressions modulate amygdala activity without explicit knowledge. <i>J. Neurosci.</i> <b>18</b>, 411–418 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.18-01-00411.1998" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.18-01-00411.1998" aria-label="Article reference 7" data-doi="10.1523/JNEUROSCI.18-01-00411.1998">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1cXjtVOitw%3D%3D" aria-label="CAS reference 7">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9412517" aria-label="PubMed reference 7">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6793390" aria-label="PubMed Central reference 7">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Masked%20presentations%20of%20emotional%20facial%20expressions%20modulate%20amygdala%20activity%20without%20explicit%20knowledge&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.18-01-00411.1998&amp;volume=18&amp;pages=411-418&amp;publication_year=1998&amp;author=Whalen%2CPJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8"><p class="c-article-references__text" id="ref-CR8">Pegna, A.J., Khateb, A., Lazeyras, F. &amp; Seghier, M.L. Discriminating emotional faces without primary visual cortices involves the right amygdala. <i>Nat. Neurosci.</i> <b>8</b>, 24–25 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1364" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1364" aria-label="Article reference 8" data-doi="10.1038/nn1364">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15592466" aria-label="PubMed reference 8">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXhtFWgsA%3D%3D" aria-label="CAS reference 8">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Discriminating%20emotional%20faces%20without%20primary%20visual%20cortices%20involves%20the%20right%20amygdala&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1364&amp;volume=8&amp;pages=24-25&amp;publication_year=2004&amp;author=Pegna%2CAJ&amp;author=Khateb%2CA&amp;author=Lazeyras%2CF&amp;author=Seghier%2CML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9"><p class="c-article-references__text" id="ref-CR9">Morris, J.S., DeGelder, B., Weiskrantz, L. &amp; Dolan, R.J. Differential extrageniculostriate and amygdala responses to presentation of emotional faces in a cortically blind field. <i>Brain</i> <b>124</b>, 1241–1252 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/brain/124.6.1241" data-track-action="article reference" href="https://doi.org/10.1093%2Fbrain%2F124.6.1241" aria-label="Article reference 9" data-doi="10.1093/brain/124.6.1241">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3M3ls1Wrtg%3D%3D" aria-label="CAS reference 9">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11353739" aria-label="PubMed reference 9">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Differential%20extrageniculostriate%20and%20amygdala%20responses%20to%20presentation%20of%20emotional%20faces%20in%20a%20cortically%20blind%20field&amp;journal=Brain&amp;doi=10.1093%2Fbrain%2F124.6.1241&amp;volume=124&amp;pages=1241-1252&amp;publication_year=2001&amp;author=Morris%2CJS&amp;author=DeGelder%2CB&amp;author=Weiskrantz%2CL&amp;author=Dolan%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10"><p class="c-article-references__text" id="ref-CR10">Tamietto, M., Pullens, P., de Gelder, B., Weiskrantz, L. &amp; Goebel, R. Subcortical connections to human amygdala and changes following destruction of the visual cortex. <i>Curr. Biol.</i> <b>22</b>, 1449–1455 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cub.2012.06.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cub.2012.06.006" aria-label="Article reference 10" data-doi="10.1016/j.cub.2012.06.006">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XpsFSjtr8%3D" aria-label="CAS reference 10">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22748315" aria-label="PubMed reference 10">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Subcortical%20connections%20to%20human%20amygdala%20and%20changes%20following%20destruction%20of%20the%20visual%20cortex&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2012.06.006&amp;volume=22&amp;pages=1449-1455&amp;publication_year=2012&amp;author=Tamietto%2CM&amp;author=Pullens%2CP&amp;author=de%20Gelder%2CB&amp;author=Weiskrantz%2CL&amp;author=Goebel%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11"><p class="c-article-references__text" id="ref-CR11">Oya, H., Kawasaki, H., Howard, M.A. 3rd &amp; Adolphs, R. Electrophysiological responses in the human amygdala discriminate emotion categories of complex visual stimuli. <i>J. Neurosci.</i> <b>22</b>, 9502–9512 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.22-21-09502.2002" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.22-21-09502.2002" aria-label="Article reference 11" data-doi="10.1523/JNEUROSCI.22-21-09502.2002">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3sXmsVGms7w%3D" aria-label="CAS reference 11">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12417674" aria-label="PubMed reference 11">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6758059" aria-label="PubMed Central reference 11">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrophysiological%20responses%20in%20the%20human%20amygdala%20discriminate%20emotion%20categories%20of%20complex%20visual%20stimuli&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.22-21-09502.2002&amp;volume=22&amp;pages=9502-9512&amp;publication_year=2002&amp;author=Oya%2CH&amp;author=Kawasaki%2CH&amp;author=Howard%2CMA&amp;author=Adolphs%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12"><p class="c-article-references__text" id="ref-CR12">Krolak-Salmon, P., Henaff, M.A., Vighetto, A., Bertrand, O. &amp; Mauguiere, F. Early amygdala reaction to fear spreading in occipital, temporal, and frontal cortex: a depth electrode ERP study in human. <i>Neuron</i> <b>42</b>, 665–676 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(04)00264-8" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2804%2900264-8" aria-label="Article reference 12" data-doi="10.1016/S0896-6273(04)00264-8">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2cXkvVyltLc%3D" aria-label="CAS reference 12">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15157426" aria-label="PubMed reference 12">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Early%20amygdala%20reaction%20to%20fear%20spreading%20in%20occipital%2C%20temporal%2C%20and%20frontal%20cortex%3A%20a%20depth%20electrode%20ERP%20study%20in%20human&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2804%2900264-8&amp;volume=42&amp;pages=665-676&amp;publication_year=2004&amp;author=Krolak-Salmon%2CP&amp;author=Henaff%2CMA&amp;author=Vighetto%2CA&amp;author=Bertrand%2CO&amp;author=Mauguiere%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13"><p class="c-article-references__text" id="ref-CR13">Naccache, L. et al. A direct intracranial record of emotions evoked by subliminal words. <i>Proc. Natl. Acad. Sci. USA</i> <b>102</b>, 7713–7717 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.0500542102" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.0500542102" aria-label="Article reference 13" data-doi="10.1073/pnas.0500542102">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXkslOmsL4%3D" aria-label="CAS reference 13">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15897465" aria-label="PubMed reference 13">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1140423" aria-label="PubMed Central reference 13">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20direct%20intracranial%20record%20of%20emotions%20evoked%20by%20subliminal%20words&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.0500542102&amp;volume=102&amp;pages=7713-7717&amp;publication_year=2005&amp;author=Naccache%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14"><p class="c-article-references__text" id="ref-CR14">Brazdil, M. et al. Neural correlates of affective picture processing—a depth ERP study. <i>NeuroImage</i> <b>47</b>, 376–383 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2009.03.081" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2009.03.081" aria-label="Article reference 14" data-doi="10.1016/j.neuroimage.2009.03.081">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19362152" aria-label="PubMed reference 14">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlates%20of%20affective%20picture%20processing%E2%80%94a%20depth%20ERP%20study&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2009.03.081&amp;volume=47&amp;pages=376-383&amp;publication_year=2009&amp;author=Brazdil%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15"><p class="c-article-references__text" id="ref-CR15">Pessoa, L. &amp; Adolphs, R. Emotion processing and the amygdala: from a 'low road' to 'many roads' of evaluating biological significance. <i>Nat. Rev. Neurosci.</i> <b>11</b>, 773–783 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn2920" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2920" aria-label="Article reference 15" data-doi="10.1038/nrn2920">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXhtlWmu7bJ" aria-label="CAS reference 15">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20959860" aria-label="PubMed reference 15">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025529" aria-label="PubMed Central reference 15">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotion%20processing%20and%20the%20amygdala%3A%20from%20a%20%27low%20road%27%20to%20%27many%20roads%27%20of%20evaluating%20biological%20significance&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2920&amp;volume=11&amp;pages=773-783&amp;publication_year=2010&amp;author=Pessoa%2CL&amp;author=Adolphs%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16"><p class="c-article-references__text" id="ref-CR16">Vuilleumier, P. How brains beware: neural mechanisms of emotional attention. <i>Trends Cogn. Sci.</i> <b>9</b>, 585 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2005.10.011" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2005.10.011" aria-label="Article reference 16" data-doi="10.1016/j.tics.2005.10.011">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16289871" aria-label="PubMed reference 16">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20brains%20beware%3A%20neural%20mechanisms%20of%20emotional%20attention&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2005.10.011&amp;volume=9&amp;publication_year=2005&amp;author=Vuilleumier%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17"><p class="c-article-references__text" id="ref-CR17">Schiller, P.H., Malpeli, J.G. &amp; Schein, S.J. Composition of geniculostriate input to superior colliculus of the rhesus monkey. <i>J. Neurophysiol.</i> <b>42</b>, 1124–1133 (1979).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.1979.42.4.1124" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.1979.42.4.1124" aria-label="Article reference 17" data-doi="10.1152/jn.1979.42.4.1124">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL3c%2FgvValtA%3D%3D" aria-label="CAS reference 17">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=113508" aria-label="PubMed reference 17">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Composition%20of%20geniculostriate%20input%20to%20superior%20colliculus%20of%20the%20rhesus%20monkey&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.1979.42.4.1124&amp;volume=42&amp;pages=1124-1133&amp;publication_year=1979&amp;author=Schiller%2CPH&amp;author=Malpeli%2CJG&amp;author=Schein%2CSJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18"><p class="c-article-references__text" id="ref-CR18">Berson, D.M. Retinal and cortical inputs to cat superior colliculus: composition, convergence and laminar specificity. <i>Prog. Brain Res.</i> <b>75</b>, 17–26 (1988).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0079-6123(08)60462-8" data-track-action="article reference" href="https://doi.org/10.1016%2FS0079-6123%2808%2960462-8" aria-label="Article reference 18" data-doi="10.1016/S0079-6123(08)60462-8">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL1M%2Fkt12isw%3D%3D" aria-label="CAS reference 18">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3055056" aria-label="PubMed reference 18">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Retinal%20and%20cortical%20inputs%20to%20cat%20superior%20colliculus%3A%20composition%2C%20convergence%20and%20laminar%20specificity&amp;journal=Prog.%20Brain%20Res.&amp;doi=10.1016%2FS0079-6123%2808%2960462-8&amp;volume=75&amp;pages=17-26&amp;publication_year=1988&amp;author=Berson%2CDM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19"><p class="c-article-references__text" id="ref-CR19">Vuilleumier, P., Armony, J.L., Driver, J. &amp; Dolan, R.J. Distinct spatial frequency sensitivities for processing faces and emotional expressions. <i>Nat. Neurosci.</i> <b>6</b>, 624–631 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1057" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1057" aria-label="Article reference 19" data-doi="10.1038/nn1057">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3sXjvF2ktbw%3D" aria-label="CAS reference 19">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12740580" aria-label="PubMed reference 19">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Distinct%20spatial%20frequency%20sensitivities%20for%20processing%20faces%20and%20emotional%20expressions&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1057&amp;volume=6&amp;pages=624-631&amp;publication_year=2003&amp;author=Vuilleumier%2CP&amp;author=Armony%2CJL&amp;author=Driver%2CJ&amp;author=Dolan%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20"><p class="c-article-references__text" id="ref-CR20">Carretié, L., Hinojosa, J.A., López-Martín, S. &amp; Tapia, M. An electrophysiological study on the interaction between emotional content and spatial frequency of visual stimuli. <i>Neuropsychologia</i> <b>45</b>, 1187–1195 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuropsychologia.2006.10.013" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuropsychologia.2006.10.013" aria-label="Article reference 20" data-doi="10.1016/j.neuropsychologia.2006.10.013">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17118408" aria-label="PubMed reference 20">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20electrophysiological%20study%20on%20the%20interaction%20between%20emotional%20content%20and%20spatial%20frequency%20of%20visual%20stimuli&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2006.10.013&amp;volume=45&amp;pages=1187-1195&amp;publication_year=2007&amp;author=Carreti%C3%A9%2CL&amp;author=Hinojosa%2CJA&amp;author=L%C3%B3pez-Mart%C3%ADn%2CS&amp;author=Tapia%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21"><p class="c-article-references__text" id="ref-CR21">Inagaki, M. &amp; Fujita, I. Reference frames for spatial frequency in face representation differ in the temporal visual cortex and amygdala. <i>J. Neurosci.</i> <b>31</b>, 10371–10379 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1114-11.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1114-11.2011" aria-label="Article reference 21" data-doi="10.1523/JNEUROSCI.1114-11.2011">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXptlSjtb0%3D" aria-label="CAS reference 21">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21753014" aria-label="PubMed reference 21">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6623064" aria-label="PubMed Central reference 21">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Reference%20frames%20for%20spatial%20frequency%20in%20face%20representation%20differ%20in%20the%20temporal%20visual%20cortex%20and%20amygdala&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1114-11.2011&amp;volume=31&amp;pages=10371-10379&amp;publication_year=2011&amp;author=Inagaki%2CM&amp;author=Fujita%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22"><p class="c-article-references__text" id="ref-CR22">Seligman, M.E.P. Phobias and preparedness. <i>Behav. Ther.</i> <b>2</b>, 307–320 (1971).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0005-7894(71)80064-3" data-track-action="article reference" href="https://doi.org/10.1016%2FS0005-7894%2871%2980064-3" aria-label="Article reference 22" data-doi="10.1016/S0005-7894(71)80064-3">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Phobias%20and%20preparedness&amp;journal=Behav.%20Ther.&amp;doi=10.1016%2FS0005-7894%2871%2980064-3&amp;volume=2&amp;pages=307-320&amp;publication_year=1971&amp;author=Seligman%2CMEP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23"><p class="c-article-references__text" id="ref-CR23">Maris, E. &amp; Oostenveld, R. Nonparametric statistical testing of EEG and MEG data. <i>J. Neurosci. Methods</i> <b>164</b>, 177–190 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jneumeth.2007.03.024" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jneumeth.2007.03.024" aria-label="Article reference 23" data-doi="10.1016/j.jneumeth.2007.03.024">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17517438" aria-label="PubMed reference 23">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Nonparametric%20statistical%20testing%20of%20EEG%20and%20MEG%20data&amp;journal=J.%20Neurosci.%20Methods&amp;doi=10.1016%2Fj.jneumeth.2007.03.024&amp;volume=164&amp;pages=177-190&amp;publication_year=2007&amp;author=Maris%2CE&amp;author=Oostenveld%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24"><p class="c-article-references__text" id="ref-CR24">Aggleton, J., Burton, M. &amp; Passingham, R. Cortical and subcortical afferents to the amygdala of the rhesus monkey (<i>Macaca mulatta</i>). <i>Brain Res.</i> <b>190</b>, 347–368 (1980).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0006-8993(80)90279-6" data-track-action="article reference" href="https://doi.org/10.1016%2F0006-8993%2880%2990279-6" aria-label="Article reference 24" data-doi="10.1016/0006-8993(80)90279-6">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL3c7ns1CitA%3D%3D" aria-label="CAS reference 24">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=6768425" aria-label="PubMed reference 24">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20and%20subcortical%20afferents%20to%20the%20amygdala%20of%20the%20rhesus%20monkey%20%28Macaca%20mulatta%29&amp;journal=Brain%20Res.&amp;doi=10.1016%2F0006-8993%2880%2990279-6&amp;volume=190&amp;pages=347-368&amp;publication_year=1980&amp;author=Aggleton%2CJ&amp;author=Burton%2CM&amp;author=Passingham%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25"><p class="c-article-references__text" id="ref-CR25">Stefanacci, L. &amp; Amaral, D.G. Topographic organization of cortical inputs to the lateral nucleus of the macaque monkey amygdala: a retrograde tracing study. <i>J. Comp. Neurol.</i> <b>421</b>, 52–79 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/(SICI)1096-9861(20000522)421:1<52::AID-CNE4&gt;3.0.CO;2-O" data-track-action="article reference" href="https://doi.org/10.1002%2F%28SICI%291096-9861%2820000522%29421%3A1%3C52%3A%3AAID-CNE4%3E3.0.CO%3B2-O" aria-label="Article reference 25" data-doi="10.1002/(SICI)1096-9861(20000522)421:1<52::AID-CNE4&gt;3.0.CO;2-O">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3c3ntl2nsQ%3D%3D" aria-label="CAS reference 25">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10813772" aria-label="PubMed reference 25">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Topographic%20organization%20of%20cortical%20inputs%20to%20the%20lateral%20nucleus%20of%20the%20macaque%20monkey%20amygdala%3A%20a%20retrograde%20tracing%20study&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2F%28SICI%291096-9861%2820000522%29421%3A1%3C52%3A%3AAID-CNE4%3E3.0.CO%3B2-O&amp;volume=421&amp;pages=52-79&amp;publication_year=2000&amp;author=Stefanacci%2CL&amp;author=Amaral%2CDG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26"><p class="c-article-references__text" id="ref-CR26">Amaral, D.G. &amp; Insausti, R. Retrograde transport of D-[3H]-aspartate injected into the monkey amygdaloid complex. <i>Exp. Brain Res.</i> <b>88</b>, 375–388 (1992).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1007/BF02259113" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/BF02259113" aria-label="Article reference 26" data-doi="10.1007/BF02259113">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK38XitVygt7k%3D" aria-label="CAS reference 26">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1374347" aria-label="PubMed reference 26">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Retrograde%20transport%20of%20D-%5B3H%5D-aspartate%20injected%20into%20the%20monkey%20amygdaloid%20complex&amp;journal=Exp.%20Brain%20Res.&amp;doi=10.1007%2FBF02259113&amp;volume=88&amp;pages=375-388&amp;publication_year=1992&amp;author=Amaral%2CDG&amp;author=Insausti%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27"><p class="c-article-references__text" id="ref-CR27">Kanwisher, N., McDermott, J. &amp; Chun, M.M. The fusiform face area: a module in human extrastriate cortex specialized for face perception. <i>J. Neurosci.</i> <b>17</b>, 4302–4311 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.17-11-04302.1997" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.17-11-04302.1997" aria-label="Article reference 27" data-doi="10.1523/JNEUROSCI.17-11-04302.1997">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK2sXjtl2mur0%3D" aria-label="CAS reference 27">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9151747" aria-label="PubMed reference 27">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6573547" aria-label="PubMed Central reference 27">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20fusiform%20face%20area%3A%20a%20module%20in%20human%20extrastriate%20cortex%20specialized%20for%20face%20perception&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.17-11-04302.1997&amp;volume=17&amp;pages=4302-4311&amp;publication_year=1997&amp;author=Kanwisher%2CN&amp;author=McDermott%2CJ&amp;author=Chun%2CMM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28"><p class="c-article-references__text" id="ref-CR28">Eimer, M. The face-sensitive N170 component of the event-related brain potential. in <i>The Oxford Handbook of Face Perception</i> (eds. Calder, A., Rhodes, G., Johnson M. &amp; Haxby, J.) 329–344 (Oxford University Press, 2011).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29"><p class="c-article-references__text" id="ref-CR29">Vuilleumier, P. &amp; Pourtois, G. Distributed and interactive brain mechanisms during emotion face perception: evidence from functional neuroimaging. <i>Neuropsychologia</i> <b>45</b>, 174–194 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuropsychologia.2006.06.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuropsychologia.2006.06.003" aria-label="Article reference 29" data-doi="10.1016/j.neuropsychologia.2006.06.003">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16854439" aria-label="PubMed reference 29">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20and%20interactive%20brain%20mechanisms%20during%20emotion%20face%20perception%3A%20evidence%20from%20functional%20neuroimaging&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2006.06.003&amp;volume=45&amp;pages=174-194&amp;publication_year=2007&amp;author=Vuilleumier%2CP&amp;author=Pourtois%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30"><p class="c-article-references__text" id="ref-CR30">Livingstone, M. &amp; Hubel, D. Segregation of form, color, movement, and depth: anatomy, physiology and perception. <i>Science</i> <b>240</b>, 740–749 (1988).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.3283936" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.3283936" aria-label="Article reference 30" data-doi="10.1126/science.3283936">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL1c3gsV2isg%3D%3D" aria-label="CAS reference 30">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3283936" aria-label="PubMed reference 30">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Segregation%20of%20form%2C%20color%2C%20movement%2C%20and%20depth%3A%20anatomy%2C%20physiology%20and%20perception&amp;journal=Science&amp;doi=10.1126%2Fscience.3283936&amp;volume=240&amp;pages=740-749&amp;publication_year=1988&amp;author=Livingstone%2CM&amp;author=Hubel%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31"><p class="c-article-references__text" id="ref-CR31">Merigan, W.H. &amp; Maunsell, J.H.R. How parallel are the primate visual pathways? <i>Annu. Rev. Neurosci.</i> <b>16</b>, 369–402 (1993).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.ne.16.030193.002101" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.ne.16.030193.002101" aria-label="Article reference 31" data-doi="10.1146/annurev.ne.16.030193.002101">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK3s3htlSksw%3D%3D" aria-label="CAS reference 31">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8460898" aria-label="PubMed reference 31">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20parallel%20are%20the%20primate%20visual%20pathways%3F&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.ne.16.030193.002101&amp;volume=16&amp;pages=369-402&amp;publication_year=1993&amp;author=Merigan%2CWH&amp;author=Maunsell%2CJHR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32"><p class="c-article-references__text" id="ref-CR32">Wang, S. et al. Neurons in the human amygdala selective for perceived emotion. <i>Proc. Natl. Acad. Sci. USA</i> <b>111</b>, E3110–E3119 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1318376111" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1318376111" aria-label="Article reference 32" data-doi="10.1073/pnas.1318376111">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhtVOit7vJ" aria-label="CAS reference 32">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24982200" aria-label="PubMed reference 32">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4121793" aria-label="PubMed Central reference 32">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Neurons%20in%20the%20human%20amygdala%20selective%20for%20perceived%20emotion&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1318376111&amp;volume=111&amp;pages=E3110-E3119&amp;publication_year=2014&amp;author=Wang%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33"><p class="c-article-references__text" id="ref-CR33">Nguyen, M.N. et al. Neuronal responses to face-like stimuli in the monkey pulvinar. <i>Eur. J. Neurosci.</i> <b>37</b>, 35–51 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/ejn.12020" data-track-action="article reference" href="https://doi.org/10.1111%2Fejn.12020" aria-label="Article reference 33" data-doi="10.1111/ejn.12020">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23121157" aria-label="PubMed reference 33">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuronal%20responses%20to%20face-like%20stimuli%20in%20the%20monkey%20pulvinar&amp;journal=Eur.%20J.%20Neurosci.&amp;doi=10.1111%2Fejn.12020&amp;volume=37&amp;pages=35-51&amp;publication_year=2013&amp;author=Nguyen%2CMN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34"><p class="c-article-references__text" id="ref-CR34">Gothard, K.M., Battaglia, F.P., Erickson, C.A., Spitler, K.M. &amp; Amaral, D.G. Neural responses to facial expression and face identity in the monkey amygdala. <i>J. Neurophysiol.</i> <b>97</b>, 1671–1683 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00714.2006" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00714.2006" aria-label="Article reference 34" data-doi="10.1152/jn.00714.2006">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD2s%2FptVSnuw%3D%3D" aria-label="CAS reference 34">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17093126" aria-label="PubMed reference 34">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20responses%20to%20facial%20expression%20and%20face%20identity%20in%20the%20monkey%20amygdala&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00714.2006&amp;volume=97&amp;pages=1671-1683&amp;publication_year=2007&amp;author=Gothard%2CKM&amp;author=Battaglia%2CFP&amp;author=Erickson%2CCA&amp;author=Spitler%2CKM&amp;author=Amaral%2CDG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35"><p class="c-article-references__text" id="ref-CR35">Sato, W. et al. Rapid amygdala gamma oscillations in response to fearful facial expressions. <i>Neuropsychologia</i> <b>49</b>, 612–617 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuropsychologia.2010.12.025" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuropsychologia.2010.12.025" aria-label="Article reference 35" data-doi="10.1016/j.neuropsychologia.2010.12.025">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21182851" aria-label="PubMed reference 35">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Rapid%20amygdala%20gamma%20oscillations%20in%20response%20to%20fearful%20facial%20expressions&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2010.12.025&amp;volume=49&amp;pages=612-617&amp;publication_year=2011&amp;author=Sato%2CW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36"><p class="c-article-references__text" id="ref-CR36">Pourtois, G., Spinelli, L., Seeck, M. &amp; Vuilleumier, P. Temporal precedence of emotion over attention modulations in the lateral amygdala: Intracranial ERP evidence from a patient with temporal lobe epilepsy. <i>Cogn. Affect. Behav. Neurosci.</i> <b>10</b>, 83–93 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/CABN.10.1.83" data-track-action="article reference" href="https://doi.org/10.3758%2FCABN.10.1.83" aria-label="Article reference 36" data-doi="10.3758/CABN.10.1.83">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20233957" aria-label="PubMed reference 36">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Temporal%20precedence%20of%20emotion%20over%20attention%20modulations%20in%20the%20lateral%20amygdala%3A%20Intracranial%20ERP%20evidence%20from%20a%20patient%20with%20temporal%20lobe%20epilepsy&amp;journal=Cogn.%20Affect.%20Behav.%20Neurosci.&amp;doi=10.3758%2FCABN.10.1.83&amp;volume=10&amp;pages=83-93&amp;publication_year=2010&amp;author=Pourtois%2CG&amp;author=Spinelli%2CL&amp;author=Seeck%2CM&amp;author=Vuilleumier%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37"><p class="c-article-references__text" id="ref-CR37">Rodriguez Merzagora, A. et al. Repeated stimuli elicit diminished high-gamma electrocorticographic responses. <i>NeuroImage</i> <b>85</b>, 844–852 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2013.07.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2013.07.006" aria-label="Article reference 37" data-doi="10.1016/j.neuroimage.2013.07.006">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23867555" aria-label="PubMed reference 37">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Repeated%20stimuli%20elicit%20diminished%20high-gamma%20electrocorticographic%20responses&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2013.07.006&amp;volume=85&amp;pages=844-852&amp;publication_year=2014&amp;author=Rodriguez%20Merzagora%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38"><p class="c-article-references__text" id="ref-CR38">Dimberg, U. &amp; Öhman, A. Behold the wrath: Psychophysiological responses to facial stimuli. <i>Motiv. Emotion</i> <b>20</b>, 149–182 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1007/BF02253869" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/BF02253869" aria-label="Article reference 38" data-doi="10.1007/BF02253869">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Behold%20the%20wrath%3A%20Psychophysiological%20responses%20to%20facial%20stimuli&amp;journal=Motiv.%20Emotion&amp;doi=10.1007%2FBF02253869&amp;volume=20&amp;pages=149-182&amp;publication_year=1996&amp;author=Dimberg%2CU&amp;author=%C3%96hman%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39"><p class="c-article-references__text" id="ref-CR39">Anderson, A.K., Christoff, K., Panitz, D., De Rosa, E. &amp; Gabrieli, J.D.E. Neural correlates of the automatic processing of threat facial signals. <i>J. Neurosci.</i> <b>23</b>, 5627–5633 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.23-13-05627.2003" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.23-13-05627.2003" aria-label="Article reference 39" data-doi="10.1523/JNEUROSCI.23-13-05627.2003">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3sXltl2qsLc%3D" aria-label="CAS reference 39">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12843265" aria-label="PubMed reference 39">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6741280" aria-label="PubMed Central reference 39">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlates%20of%20the%20automatic%20processing%20of%20threat%20facial%20signals&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.23-13-05627.2003&amp;volume=23&amp;pages=5627-5633&amp;publication_year=2003&amp;author=Anderson%2CAK&amp;author=Christoff%2CK&amp;author=Panitz%2CD&amp;author=De%20Rosa%2CE&amp;author=Gabrieli%2CJDE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40"><p class="c-article-references__text" id="ref-CR40">Öhman, A. Automaticity and the amygdala: nonconscious responses to emotional faces. <i>Curr. Dir. Psychol. Sci.</i> <b>11</b>, 62–66 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/1467-8721.00169" data-track-action="article reference" href="https://doi.org/10.1111%2F1467-8721.00169" aria-label="Article reference 40" data-doi="10.1111/1467-8721.00169">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Automaticity%20and%20the%20amygdala%3A%20nonconscious%20responses%20to%20emotional%20faces&amp;journal=Curr.%20Dir.%20Psychol.%20Sci.&amp;doi=10.1111%2F1467-8721.00169&amp;volume=11&amp;pages=62-66&amp;publication_year=2002&amp;author=%C3%96hman%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41"><p class="c-article-references__text" id="ref-CR41">Kling, A.S. &amp; Brothers, L.A. The amygdala and social behavior. in <i>The Amygdala: Neurobiological Aspects of Emotion, Memory, and Mental Dysfunction</i> (ed. Aggleton, J.P.) 353–377 (Wiley-Liss, 1992).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42"><p class="c-article-references__text" id="ref-CR42">Ohman, A. &amp; Mineka, S. Fears, phobias and preparedness: toward an evolved module of fear and fear learning. <i>Psychol. Rev.</i> <b>108</b>, 483–522 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0033-295X.108.3.483" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.108.3.483" aria-label="Article reference 42" data-doi="10.1037/0033-295X.108.3.483">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3Mvkt1WlsQ%3D%3D" aria-label="CAS reference 42">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11488376" aria-label="PubMed reference 42">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Fears%2C%20phobias%20and%20preparedness%3A%20toward%20an%20evolved%20module%20of%20fear%20and%20fear%20learning&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.108.3.483&amp;volume=108&amp;pages=483-522&amp;publication_year=2001&amp;author=Ohman%2CA&amp;author=Mineka%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43"><p class="c-article-references__text" id="ref-CR43">Pessoa, L., McKenna, M., Gutierrez, E. &amp; Ungerleider, L. Neural processing of emotional faces requires attention. <i>Proc. Natl. Acad. Sci. USA</i> <b>99</b>, 11458–11463 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.172403899" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.172403899" aria-label="Article reference 43" data-doi="10.1073/pnas.172403899">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38XmslSlsrg%3D" aria-label="CAS reference 43">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12177449" aria-label="PubMed reference 43">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC123278" aria-label="PubMed Central reference 43">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20processing%20of%20emotional%20faces%20requires%20attention&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.172403899&amp;volume=99&amp;pages=11458-11463&amp;publication_year=2002&amp;author=Pessoa%2CL&amp;author=McKenna%2CM&amp;author=Gutierrez%2CE&amp;author=Ungerleider%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44"><p class="c-article-references__text" id="ref-CR44">Moors, A. &amp; De Houwer, J. Automaticity: a theoretical and conceptual analysis. <i>Psychol. Bull.</i> <b>132</b>, 297 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0033-2909.132.2.297" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-2909.132.2.297" aria-label="Article reference 44" data-doi="10.1037/0033-2909.132.2.297">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16536645" aria-label="PubMed reference 44">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Automaticity%3A%20a%20theoretical%20and%20conceptual%20analysis&amp;journal=Psychol.%20Bull.&amp;doi=10.1037%2F0033-2909.132.2.297&amp;volume=132&amp;publication_year=2006&amp;author=Moors%2CA&amp;author=De%20Houwer%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45"><p class="c-article-references__text" id="ref-CR45">Kveraga, K., Boshyan, J. &amp; Bar, M. Magnocellular projections as the trigger of top-down facilitation in recognition. <i>J. Neurosci.</i> <b>27</b>, 13232–13240 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.3481-07.2007" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.3481-07.2007" aria-label="Article reference 45" data-doi="10.1523/JNEUROSCI.3481-07.2007">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXhsVeku7nK" aria-label="CAS reference 45">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18045917" aria-label="PubMed reference 45">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6673387" aria-label="PubMed Central reference 45">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Magnocellular%20projections%20as%20the%20trigger%20of%20top-down%20facilitation%20in%20recognition&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.3481-07.2007&amp;volume=27&amp;pages=13232-13240&amp;publication_year=2007&amp;author=Kveraga%2CK&amp;author=Boshyan%2CJ&amp;author=Bar%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46"><p class="c-article-references__text" id="ref-CR46">Barbas, H. Connections underlying the synthesis of cognition, memory, and emotion in primate prefrontal cortices. <i>Brain Res. Bull.</i> <b>52</b>, 319–330 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0361-9230(99)00245-2" data-track-action="article reference" href="https://doi.org/10.1016%2FS0361-9230%2899%2900245-2" aria-label="Article reference 46" data-doi="10.1016/S0361-9230(99)00245-2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3cvisFGhtg%3D%3D" aria-label="CAS reference 46">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10922509" aria-label="PubMed reference 46">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Connections%20underlying%20the%20synthesis%20of%20cognition%2C%20memory%2C%20and%20emotion%20in%20primate%20prefrontal%20cortices&amp;journal=Brain%20Res.%20Bull.&amp;doi=10.1016%2FS0361-9230%2899%2900245-2&amp;volume=52&amp;pages=319-330&amp;publication_year=2000&amp;author=Barbas%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47"><p class="c-article-references__text" id="ref-CR47">Kawasaki, H. et al. Single-neuron responses to emotional visual stimuli recorded in human ventral prefrontal cortex. <i>Nat. Neurosci.</i> <b>4</b>, 15–16 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/82850" data-track-action="article reference" href="https://doi.org/10.1038%2F82850" aria-label="Article reference 47" data-doi="10.1038/82850">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXitVegsg%3D%3D" aria-label="CAS reference 47">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11135639" aria-label="PubMed reference 47">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Single-neuron%20responses%20to%20emotional%20visual%20stimuli%20recorded%20in%20human%20ventral%20prefrontal%20cortex&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F82850&amp;volume=4&amp;pages=15-16&amp;publication_year=2001&amp;author=Kawasaki%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48"><p class="c-article-references__text" id="ref-CR48">Etkin, A. et al. Individual differences in trait anxiety predict the response of the basolateral amygdala to unconsciously processed fearful faces. <i>Neuron</i> <b>44</b>, 1043–1055 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2004.12.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2004.12.006" aria-label="Article reference 48" data-doi="10.1016/j.neuron.2004.12.006">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXhsFeisg%3D%3D" aria-label="CAS reference 48">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15603746" aria-label="PubMed reference 48">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Individual%20differences%20in%20trait%20anxiety%20predict%20the%20response%20of%20the%20basolateral%20amygdala%20to%20unconsciously%20processed%20fearful%20faces&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2004.12.006&amp;volume=44&amp;pages=1043-1055&amp;publication_year=2004&amp;author=Etkin%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49"><p class="c-article-references__text" id="ref-CR49">Rauch, S.L. et al. Exaggerated amygdala response to masked facial stimuli in posttraumatic stress disorder: a functional MRI study. <i>Biol. Psychiatry</i> <b>47</b>, 769–776 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0006-3223(00)00828-3" data-track-action="article reference" href="https://doi.org/10.1016%2FS0006-3223%2800%2900828-3" aria-label="Article reference 49" data-doi="10.1016/S0006-3223(00)00828-3">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3c3nslKisg%3D%3D" aria-label="CAS reference 49">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10812035" aria-label="PubMed reference 49">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Exaggerated%20amygdala%20response%20to%20masked%20facial%20stimuli%20in%20posttraumatic%20stress%20disorder%3A%20a%20functional%20MRI%20study&amp;journal=Biol.%20Psychiatry&amp;doi=10.1016%2FS0006-3223%2800%2900828-3&amp;volume=47&amp;pages=769-776&amp;publication_year=2000&amp;author=Rauch%2CSL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50"><p class="c-article-references__text" id="ref-CR50">Sheline, Y.I. et al. Increased amygdala response to masked emotional faces in depressed subjects resolves with antidepressant treatment: an fMRI study. <i>Biol. Psychiatry</i> <b>50</b>, 651–658 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0006-3223(01)01263-X" data-track-action="article reference" href="https://doi.org/10.1016%2FS0006-3223%2801%2901263-X" aria-label="Article reference 50" data-doi="10.1016/S0006-3223(01)01263-X">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXotFSmu7c%3D" aria-label="CAS reference 50">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11704071" aria-label="PubMed reference 50">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Increased%20amygdala%20response%20to%20masked%20emotional%20faces%20in%20depressed%20subjects%20resolves%20with%20antidepressant%20treatment%3A%20an%20fMRI%20study&amp;journal=Biol.%20Psychiatry&amp;doi=10.1016%2FS0006-3223%2801%2901263-X&amp;volume=50&amp;pages=651-658&amp;publication_year=2001&amp;author=Sheline%2CYI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51"><p class="c-article-references__text" id="ref-CR51">Amunts, K. et al. Cytoarchitectonic mapping of the human amygdala, hippocampal region and entorhinal cortex: intersubject variability and probability maps. <i>Anat. Embryol. (Berl)</i> <b>210</b>, 343–352 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1007/s00429-005-0025-5" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s00429-005-0025-5" aria-label="Article reference 51" data-doi="10.1007/s00429-005-0025-5">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD2MnkvVKqsw%3D%3D" aria-label="CAS reference 51">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Cytoarchitectonic%20mapping%20of%20the%20human%20amygdala%2C%20hippocampal%20region%20and%20entorhinal%20cortex%3A%20intersubject%20variability%20and%20probability%20maps&amp;journal=Anat.%20Embryol.%20%28Berl%29&amp;doi=10.1007%2Fs00429-005-0025-5&amp;volume=210&amp;pages=343-352&amp;publication_year=2005&amp;author=Amunts%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52"><p class="c-article-references__text" id="ref-CR52">Ahrens, J., Geveci, B. &amp; Law, C. ParaView: An end-user tool for large-data visualization. in <i>The Visualization Handbook</i> (eds. Hansen, C.D. &amp; Johnson, C.R.) 717 (Citeseer, 2005).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53"><p class="c-article-references__text" id="ref-CR53">Lundqvist, D., Flykt, A. &amp; Öhman, A. <i>The Karolinska Directed Emotional Faces–KDEF</i> (Department of Clinical Neuroscience, Psychology Section, Karolinska Institutet, 1998).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54"><p class="c-article-references__text" id="ref-CR54">Olszanowski, M., Pochwatko, G., Kukliński, K., Ścibor-Rylski, M. &amp; Ohme, R. Warsaw set of emotional facial expression pictures—validation study of facial display photographs. <i>Front. Psychol.</i> <b>5</b>, 1516 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fpsyg.2014.01516" data-track-action="article reference" href="https://doi.org/10.3389%2Ffpsyg.2014.01516" aria-label="Article reference 54" data-doi="10.3389/fpsyg.2014.01516">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25601846" aria-label="PubMed reference 54">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4283518" aria-label="PubMed Central reference 54">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=Warsaw%20set%20of%20emotional%20facial%20expression%20pictures%E2%80%94validation%20study%20of%20facial%20display%20photographs&amp;journal=Front.%20Psychol.&amp;doi=10.3389%2Ffpsyg.2014.01516&amp;volume=5&amp;publication_year=2015&amp;author=Olszanowski%2CM&amp;author=Pochwatko%2CG&amp;author=Kukli%C5%84ski%2CK&amp;author=%C5%9Acibor-Rylski%2CM&amp;author=Ohme%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55"><p class="c-article-references__text" id="ref-CR55">Langner, O., Dotsch, R., Bijlstra, G., Wigboldus, D.H.J., Hawk, S.T. &amp; van Knippenberg, A. Presentation and validation of the Radboud Faces Database. <i>Cogn. Emot.</i> <b>24</b>, 1377–1388 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/02699930903485076" data-track-action="article reference" href="https://doi.org/10.1080%2F02699930903485076" aria-label="Article reference 55" data-doi="10.1080/02699930903485076">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Presentation%20and%20validation%20of%20the%20Radboud%20Faces%20Database&amp;journal=Cogn.%20Emot.&amp;doi=10.1080%2F02699930903485076&amp;volume=24&amp;pages=1377-1388&amp;publication_year=2010&amp;author=Langner%2CO&amp;author=Dotsch%2CR&amp;author=Bijlstra%2CG&amp;author=Wigboldus%2CDHJ&amp;author=Hawk%2CST&amp;author=van%20Knippenberg%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56"><p class="c-article-references__text" id="ref-CR56">Schyns, P.G. &amp; Oliva, A. Dr. Angry and Mr. Smile: When categorization flexibly modifies the perception of faces in rapid visual presentations. <i>Cognition</i> <b>69</b>, 243–265 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0010-0277(98)00069-9" data-track-action="article reference" href="https://doi.org/10.1016%2FS0010-0277%2898%2900069-9" aria-label="Article reference 56" data-doi="10.1016/S0010-0277(98)00069-9">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M3gvFWhug%3D%3D" aria-label="CAS reference 56">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10193048" aria-label="PubMed reference 56">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Dr.%20Angry%20and%20Mr.%20Smile%3A%20When%20categorization%20flexibly%20modifies%20the%20perception%20of%20faces%20in%20rapid%20visual%20presentations&amp;journal=Cognition&amp;doi=10.1016%2FS0010-0277%2898%2900069-9&amp;volume=69&amp;pages=243-265&amp;publication_year=1999&amp;author=Schyns%2CPG&amp;author=Oliva%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57"><p class="c-article-references__text" id="ref-CR57">Tanner, D., Morgan-Short, K. &amp; Luck, S.J. How inappropriate high-pass filters can produce artifactual effects and incorrect conclusions in ERP studies of language and cognition. <i>Psychophysiology</i> <b>52</b>, 997–1009 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/psyp.12437" data-track-action="article reference" href="https://doi.org/10.1111%2Fpsyp.12437" aria-label="Article reference 57" data-doi="10.1111/psyp.12437">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25903295" aria-label="PubMed reference 57">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4506207" aria-label="PubMed Central reference 57">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 57" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20inappropriate%20high-pass%20filters%20can%20produce%20artifactual%20effects%20and%20incorrect%20conclusions%20in%20ERP%20studies%20of%20language%20and%20cognition&amp;journal=Psychophysiology&amp;doi=10.1111%2Fpsyp.12437&amp;volume=52&amp;pages=997-1009&amp;publication_year=2015&amp;author=Tanner%2CD&amp;author=Morgan-Short%2CK&amp;author=Luck%2CSJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58"><p class="c-article-references__text" id="ref-CR58">Tadel, F., Baillet, S., Mosher, J.C., Pantazis, D. &amp; Leahy, R.M. Brainstorm: a user-friendly application for MEG/EEG analysis. <i>Comput. Intell. Neurosci.</i> <b>2011</b>, 879716 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1155/2011/879716" data-track-action="article reference" href="https://doi.org/10.1155%2F2011%2F879716" aria-label="Article reference 58" data-doi="10.1155/2011/879716">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21584256" aria-label="PubMed reference 58">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3090754" aria-label="PubMed Central reference 58">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Brainstorm%3A%20a%20user-friendly%20application%20for%20MEG%2FEEG%20analysis&amp;journal=Comput.%20Intell.%20Neurosci.&amp;doi=10.1155%2F2011%2F879716&amp;volume=2011&amp;publication_year=2011&amp;author=Tadel%2CF&amp;author=Baillet%2CS&amp;author=Mosher%2CJC&amp;author=Pantazis%2CD&amp;author=Leahy%2CRM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59"><p class="c-article-references__text" id="ref-CR59">Gramfort, A., Papadopoulo, T., Olivi, E. &amp; Clerc, M. OpenMEEG: opensource software for quasistatic bioelectromagnetics. <i>Biomed. Eng. Online</i> <b>9</b>, 45 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1186/1475-925X-9-45" data-track-action="article reference" href="https://link.springer.com/doi/10.1186/1475-925X-9-45" aria-label="Article reference 59" data-doi="10.1186/1475-925X-9-45">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20819204" aria-label="PubMed reference 59">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2949879" aria-label="PubMed Central reference 59">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 59" href="http://scholar.google.com/scholar_lookup?&amp;title=OpenMEEG%3A%20opensource%20software%20for%20quasistatic%20bioelectromagnetics&amp;journal=Biomed.%20Eng.%20Online&amp;doi=10.1186%2F1475-925X-9-45&amp;volume=9&amp;publication_year=2010&amp;author=Gramfort%2CA&amp;author=Papadopoulo%2CT&amp;author=Olivi%2CE&amp;author=Clerc%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60"><p class="c-article-references__text" id="ref-CR60">Hauk, O. Keep it simple: a case for using classical minimum norm estimation in the analysis of EEG and MEG data. <i>Neuroimage</i> <b>21</b>, 1612–1621 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2003.12.018" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2003.12.018" aria-label="Article reference 60" data-doi="10.1016/j.neuroimage.2003.12.018">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15050585" aria-label="PubMed reference 60">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 60" href="http://scholar.google.com/scholar_lookup?&amp;title=Keep%20it%20simple%3A%20a%20case%20for%20using%20classical%20minimum%20norm%20estimation%20in%20the%20analysis%20of%20EEG%20and%20MEG%20data&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2003.12.018&amp;volume=21&amp;pages=1612-1621&amp;publication_year=2004&amp;author=Hauk%2CO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61"><p class="c-article-references__text" id="ref-CR61">Collins, D.L. et al. Design and construction of a realistic digital brain phantom. <i>IEEE Trans. Med. Imaging</i> <b>17</b>, 463–468 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/42.712135" data-track-action="article reference" href="https://doi.org/10.1109%2F42.712135" aria-label="Article reference 61" data-doi="10.1109/42.712135">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1cvgsFeitA%3D%3D" aria-label="CAS reference 61">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9735909" aria-label="PubMed reference 61">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 61" href="http://scholar.google.com/scholar_lookup?&amp;title=Design%20and%20construction%20of%20a%20realistic%20digital%20brain%20phantom&amp;journal=IEEE%20Trans.%20Med.%20Imaging&amp;doi=10.1109%2F42.712135&amp;volume=17&amp;pages=463-468&amp;publication_year=1998&amp;author=Collins%2CDL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62"><p class="c-article-references__text" id="ref-CR62">Lachaux, J.P., Rudrauf, D. &amp; Kahane, P. Intracranial EEG and human brain mapping. <i>J. Physiol. Paris</i> <b>97</b>, 613–628 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jphysparis.2004.01.018" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jphysparis.2004.01.018" aria-label="Article reference 62" data-doi="10.1016/j.jphysparis.2004.01.018">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15242670" aria-label="PubMed reference 62">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Intracranial%20EEG%20and%20human%20brain%20mapping&amp;journal=J.%20Physiol.%20Paris&amp;doi=10.1016%2Fj.jphysparis.2004.01.018&amp;volume=97&amp;pages=613-628&amp;publication_year=2003&amp;author=Lachaux%2CJP&amp;author=Rudrauf%2CD&amp;author=Kahane%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63"><p class="c-article-references__text" id="ref-CR63">Lang, P.J., Bradley, M.M. &amp; Cuthbert, B.N. <i>International affective picture system (IAPS): affective ratings of pictures and instruction manual (Technical Report A-6)</i> (University of Florida, 2005).</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.4324?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We thank the electroencephalography technicians at the Hospital Ruber Internacional. This work was supported by Project grant SAF2011-27766 from the Spanish Ministry of Science and Education and Marie Curie Career Integration Fellowship (FP7-PEOPLE-2011-CIG 304248) to B.A.S., a PICATA fellowship of CEI Moncloa (UCM-UPM) to C.M.-B., and a Ramón y Cajal fellowship (RYC-2009-04974) to S.M. This work was supported by Project grant SAF2011-27766 from the Spanish Ministry of Science and Education, Marie Curie Career Integration Fellowship (FP7-PEOPLE-2011-CIG 304248), and BIAL Foundation Grant 119/12 to B.A.S.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><span class="c-article-author-information__subtitle u-visually-hidden" id="author-notes">Author notes</span><ol class="c-article-author-information__list"><li class="c-article-author-information__item" id="na1"><p>Constantino Méndez-Bértolo and Stephan Moratti: These authors contributed equally to this work.</p></li></ol><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Laboratory for Clinical Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain</p><p class="c-article-author-affiliation__authors-list">Constantino Méndez-Bértolo, Stephan Moratti, Fernando Lopez-Sosa &amp; Bryan A Strange</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">CEI Campus Moncloa, UCM-UPM, Madrid, Spain</p><p class="c-article-author-affiliation__authors-list">Constantino Méndez-Bértolo</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Department of Basic Psychology I, Complutense University of Madrid, Madrid, Spain</p><p class="c-article-author-affiliation__authors-list">Stephan Moratti</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Laboratory for Cognitive and Computational Neuroscience, Centre for Biomedical Technology, Technical University of Madrid, Madrid, Spain</p><p class="c-article-author-affiliation__authors-list">Stephan Moratti</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">Department of Neurology, Epilepsy Unit, Hospital Ruber Internacional, Madrid, Spain</p><p class="c-article-author-affiliation__authors-list">Rafael Toledano &amp; Antonio Gil-Nagel</p></li><li id="Aff6"><p class="c-article-author-affiliation__address">Department of Neurosurgery, Hospital Ruber Internacional, Madrid, Spain</p><p class="c-article-author-affiliation__authors-list">Roberto Martínez-Alvarez</p></li><li id="Aff7"><p class="c-article-author-affiliation__address">Neuroscience Research Centre, Cardiovascular and Cell Sciences Institute, St. George's, University of London, London, UK</p><p class="c-article-author-affiliation__authors-list">Yee H Mah</p></li><li id="Aff8"><p class="c-article-author-affiliation__address">Department of Neuroscience and Neurology, Laboratory for Neurology and Imaging of Cognition, University Hospital and Medical School, University of Geneva, Geneva, Switzerland</p><p class="c-article-author-affiliation__authors-list">Patrik Vuilleumier</p></li><li id="Aff9"><p class="c-article-author-affiliation__address">Department of Neuroimaging, Reina Sofia Centre for Alzheimer's Research, Madrid, Spain</p><p class="c-article-author-affiliation__authors-list">Bryan A Strange</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Constantino-M_ndez_B_rtolo-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Constantino Méndez-Bértolo</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Constantino%20M%C3%A9ndez-B%C3%A9rtolo" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Constantino%20M%C3%A9ndez-B%C3%A9rtolo" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Constantino%20M%C3%A9ndez-B%C3%A9rtolo%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Stephan-Moratti-Aff1-Aff3-Aff4"><span class="c-article-authors-search__title u-h3 js-search-name">Stephan Moratti</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Stephan%20Moratti" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Stephan%20Moratti" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Stephan%20Moratti%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Rafael-Toledano-Aff5"><span class="c-article-authors-search__title u-h3 js-search-name">Rafael Toledano</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Rafael%20Toledano" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rafael%20Toledano" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rafael%20Toledano%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Fernando-Lopez_Sosa-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Fernando Lopez-Sosa</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Fernando%20Lopez-Sosa" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Fernando%20Lopez-Sosa" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Fernando%20Lopez-Sosa%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Roberto-Mart_nez_Alvarez-Aff6"><span class="c-article-authors-search__title u-h3 js-search-name">Roberto Martínez-Alvarez</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Roberto%20Mart%C3%ADnez-Alvarez" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Roberto%20Mart%C3%ADnez-Alvarez" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Roberto%20Mart%C3%ADnez-Alvarez%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Yee_H-Mah-Aff7"><span class="c-article-authors-search__title u-h3 js-search-name">Yee H Mah</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Yee%20H%20Mah" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yee%20H%20Mah" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yee%20H%20Mah%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Patrik-Vuilleumier-Aff8"><span class="c-article-authors-search__title u-h3 js-search-name">Patrik Vuilleumier</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Patrik%20Vuilleumier" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Patrik%20Vuilleumier" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Patrik%20Vuilleumier%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Antonio-Gil_Nagel-Aff5"><span class="c-article-authors-search__title u-h3 js-search-name">Antonio Gil-Nagel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Antonio%20Gil-Nagel" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Antonio%20Gil-Nagel" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Antonio%20Gil-Nagel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Bryan_A-Strange-Aff1-Aff9"><span class="c-article-authors-search__title u-h3 js-search-name">Bryan A Strange</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Bryan%20A%20Strange" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Bryan%20A%20Strange" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Bryan%20A%20Strange%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>C.M.-B., S.M., P.V., A.G.-N. and B.A.S. designed the experiments. C.M.-B., F.L.-S. and R.T. collected data and C.M.-B., S.M. and B.A.S. performed analyses. R.T. and A.G.-N. monitored patients and performed clinical evaluation. R.M.-A. performed surgical electrode implantation. Y.H.M. designed and performed electrode contact localization. B.A.S., C.M.-B., S.M. and P.V. wrote the paper with input from all of the other authors.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:bryan.strange@upm.es">Bryan A Strange</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading">Competing interests</h3>
                <p>The authors declare no competing financial interests.</p>
              
            </div></div></section><section data-title="Integrated supplementary information"><div class="c-article-section" id="Sec22-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec22">Integrated supplementary information</h2><div class="c-article-section__content" id="Sec22-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig6"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 1 structural mris." href="/articles/nn.4324/figures/6" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig6_ESM.jpg">Supplementary Figure 1 Structural MRIs.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Coronal and transverse sections of pre-electrode insertion T1 weighted MRIs, illustrating radiologically normal amygdala in the 10 patients for which iERPs are presented. Red arrows indicate the amygdala in which stereotactic electrodes were inserted. L/R: Left/Right.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig7"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 2 electrode contact localizat" href="/articles/nn.4324/figures/7" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig7_ESM.jpg">Supplementary Figure 2 Electrode contact localization in the amygdala for all patients.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Post-operative CT images from each patient have been coregistered with their corresponding pre-operative MRI scan and superimposed to display amygdala contacts in transverse section. In the case of bilateral amygdala implantation, transverse sections are slightly rotated to enable viewing of both left and right contacts in the same cut. Electrode contacts included in each patient’s averaged iERP are indicated in red. Note that post-operative CT quality for Patient 05 precluded adequate coregistration, thus for this patient electrode contacts were localised on post-operative MRI scan (electrode trajectory is visible in the left temporal lobe and correctly targets the amygdala on that side).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 3 amygdala ierps according to" href="/articles/nn.4324/figures/8" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_Fig8_ESM.jpg">Supplementary Figure 3 Amygdala iERPs according to electrode laterality (experiment 1).</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Averaged iERPs from 10 amygdalae of 8 patients (total of 26 contacts) to (<b>a</b>) all spatial frequency and (<b>b</b>) broadband and LSF faces are plotted for fearful, happy, and neutral faces separately for both pools of left (<i>n</i> = 6; seventeen contacts) and right (<i>n</i> = 4; nine contacts) amygdala electrodes.</p></div></div></div></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec23-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec23">Supplementary information</h2><div class="c-article-section__content" id="Sec23-content"><div data-test="supplementary-info"><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary text and figures" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_MOESM8_ESM.pdf" data-supp-info-image="">Supplementary Text and Figures</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Supplementary Figures 1–3 and Supplementary Tables 1–15 (PDF 1439 kb)</p></div></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM9"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary methods checklist" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.4324/MediaObjects/41593_2016_BFnn4324_MOESM9_ESM.pdf" data-supp-info-image="">Supplementary Methods Checklist</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p> (PDF 1227 kb)</p></div></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20fast%20pathway%20for%20fear%20in%20human%20amygdala&amp;author=Constantino%20M%C3%A9ndez-B%C3%A9rtolo%20et%20al&amp;contentID=10.1038%2Fnn.4324&amp;copyright=Springer%20Nature%20Limited&amp;publication=1097-6256&amp;publicationDate=2016-08-01&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/nn.4324" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/nn.4324" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Méndez-Bértolo, C., Moratti, S., Toledano, R. <i>et al.</i> A fast pathway for fear in human amygdala.
                    <i>Nat Neurosci</i> <b>19</b>, 1041–1049 (2016). https://doi.org/10.1038/nn.4324</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.4324?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-03-03">03 March 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-05-12">12 May 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-08-01">01 August 2016</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-08">August 2016</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/nn.4324</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Impairment of unconscious emotional processing after unilateral medial temporal structure resection" href="https://doi.org/10.1038/s41598-024-54868-2">
                                        Impairment of unconscious emotional processing after unilateral medial temporal structure resection
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Wataru Sato</li><li>Naotaka Usui</li><li>Yushi Inoue</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2024)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Non-conscious processing of fear faces: a function of the implicit self-concept of anxiety" href="https://doi.org/10.1186/s12868-023-00781-9">
                                        Non-conscious processing of fear faces: a function of the implicit self-concept of anxiety
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Vivien Günther</li><li>Jonas Pecher</li><li>Thomas Suslow</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>BMC Neuroscience</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Frequency dependent emotion differentiation and directional coupling in amygdala, orbitofrontal and medial prefrontal cortex network with intracranial recordings" href="https://doi.org/10.1038/s41380-022-01883-2">
                                        Frequency dependent emotion differentiation and directional coupling in amygdala, orbitofrontal and medial prefrontal cortex network with intracranial recordings
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Saurabh Sonkusare</li><li>Ding Qiong</li><li>Valerie Voon</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Molecular Psychiatry</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Analysis of convolutional neural networks reveals the computational properties essential for subcortical processing of facial expression" href="https://doi.org/10.1038/s41598-023-37995-0">
                                        Analysis of convolutional neural networks reveals the computational properties essential for subcortical processing of facial expression
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Chanseok Lim</li><li>Mikio Inagaki</li><li>Ichiro Fujita</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Mass-univariate analysis of scalp ERPs reveals large effects of gaze fixation location during face processing that only weakly interact with face emotional expression" href="https://doi.org/10.1038/s41598-023-44355-5">
                                        Mass-univariate analysis of scalp ERPs reveals large effects of gaze fixation location during face processing that only weakly interact with face emotional expression
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Roxane J. Itier</li><li>Amie J. Durston</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2023)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4324.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4324.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=nn.4324;doi=10.1038/nn.4324;techmeta=30,9;subjmeta=1284,1300,1457,378,476,477,631,692,699;kwrd=Amygdala,Anxiety,Psychology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1300599859&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.4324%26doi%3D10.1038/nn.4324%26techmeta%3D30,9%26subjmeta%3D1284,1300,1457,378,476,477,631,692,699%26kwrd%3DAmygdala,Anxiety,Psychology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1300599859&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.4324%26doi%3D10.1038/nn.4324%26techmeta%3D30,9%26subjmeta%3D1284,1300,1457,378,476,477,631,692,699%26kwrd%3DAmygdala,Anxiety,Psychology"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/nn.4324&amp;format=js&amp;last_modified=2016-08-01" async></script>
<img src="/p0htd8mw/article/nn.4324" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>