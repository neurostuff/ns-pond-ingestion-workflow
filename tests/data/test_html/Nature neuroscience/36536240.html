<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Multitask representations in the human cortex transform along a sensory-to-motor hierarchy | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"cognitive-neuroscience;network-models","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/s41593-022-01224-0"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Takuya Ito","John D. Murray"],"publishedAt":1671408000,"publishedAtString":"2022-12-19","title":"Multitask representations in the human cortex transform along a sensory-to-motor hierarchy","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"26","issue":"2"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Multitask representations in the human cortex transform along a sensory-to-motor hierarchy","description":"Human cognition recruits distributed neural processes, yet the organizing computational and functional architectures remain unclear. Here, we characterized the geometry and topography of multitask representations across the human cortex using functional magnetic resonance imaging during 26 cognitive tasks in the same individuals. We measured the representational similarity across tasks within a region and the alignment of representations between regions. Representational alignment varied in a graded manner along the sensory–association–motor axis. Multitask dimensionality exhibited compression then expansion along this gradient. To investigate computational principles of multitask representations, we trained multilayer neural network models to transform empirical visual-to-motor representations. Compression-then-expansion organization in models emerged exclusively in a rich training regime, which is associated with learning optimized representations that are robust to noise. This regime produces hierarchically structured representations similar to empirical cortical patterns. Together, these results reveal computational principles that organize multitask representations across the human cortex to support multitask cognition. What are the representations that enable diverse human cognition? The authors investigate cortical representations across 26 tasks and the conditions by which artificial neural network models reproduce these representations.","datePublished":"2022-12-19T00:00:00Z","dateModified":"2022-12-19T00:00:00Z","pageStart":"306","pageEnd":"315","sameAs":"https://doi.org/10.1038/s41593-022-01224-0","keywords":["Cognitive neuroscience","Network models","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig3_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig4_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig5_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig6_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig7_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig8_HTML.png"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"26","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Takuya Ito","url":"http://orcid.org/0000-0002-2060-4608","affiliation":[{"name":"Yale School of Medicine","address":{"name":"Department of Psychiatry, Yale School of Medicine, New Haven, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"John D. Murray","url":"http://orcid.org/0000-0003-4115-8181","affiliation":[{"name":"Yale School of Medicine","address":{"name":"Department of Psychiatry, Yale School of Medicine, New Haven, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Yale School of Medicine","address":{"name":"Department of Neuroscience, Yale School of Medicine, New Haven, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Yale University","address":{"name":"Department of Physics, Yale University, New Haven, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"john.murray@yale.edu","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/s41593-022-01224-0">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="Multitask representations in the human cortex transform along a sensory-to-motor hierarchy"/>
    <meta name="dc.source" content="Nature Neuroscience 2022 26:2"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2022-12-19"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Human cognition recruits distributed neural processes, yet the organizing computational and functional architectures remain unclear. Here, we characterized the geometry and topography of multitask representations across the human cortex using functional magnetic resonance imaging during 26 cognitive tasks in the same individuals. We measured the representational similarity across tasks within a region and the alignment of representations between regions. Representational alignment varied in a graded manner along the sensory&#8211;association&#8211;motor axis. Multitask dimensionality exhibited compression then expansion along this gradient. To investigate computational principles of multitask representations, we trained multilayer neural network models to transform empirical visual-to-motor representations. Compression-then-expansion organization in models emerged exclusively in a rich training regime, which is associated with learning optimized representations that are robust to noise. This regime produces hierarchically structured representations similar to empirical cortical patterns. Together, these results reveal computational principles that organize multitask representations across the human cortex to support multitask cognition. What are the representations that enable diverse human cognition? The authors investigate cortical representations across 26 tasks and the conditions by which artificial neural network models reproduce these representations."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2022-12-19"/>
    <meta name="prism.volume" content="26"/>
    <meta name="prism.number" content="2"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="306"/>
    <meta name="prism.endingPage" content="315"/>
    <meta name="prism.copyright" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/s41593-022-01224-0"/>
    <meta name="prism.doi" content="doi:10.1038/s41593-022-01224-0"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41593-022-01224-0.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41593-022-01224-0"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="Multitask representations in the human cortex transform along a sensory-to-motor hierarchy"/>
    <meta name="citation_volume" content="26"/>
    <meta name="citation_issue" content="2"/>
    <meta name="citation_publication_date" content="2023/02"/>
    <meta name="citation_online_date" content="2022/12/19"/>
    <meta name="citation_firstpage" content="306"/>
    <meta name="citation_lastpage" content="315"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/s41593-022-01224-0"/>
    <meta name="DOI" content="10.1038/s41593-022-01224-0"/>
    <meta name="size" content="248623"/>
    <meta name="citation_doi" content="10.1038/s41593-022-01224-0"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/s41593-022-01224-0&amp;api_key="/>
    <meta name="description" content="Human cognition recruits distributed neural processes, yet the organizing computational and functional architectures remain unclear. Here, we characterized the geometry and topography of multitask representations across the human cortex using functional magnetic resonance imaging during 26 cognitive tasks in the same individuals. We measured the representational similarity across tasks within a region and the alignment of representations between regions. Representational alignment varied in a graded manner along the sensory&#8211;association&#8211;motor axis. Multitask dimensionality exhibited compression then expansion along this gradient. To investigate computational principles of multitask representations, we trained multilayer neural network models to transform empirical visual-to-motor representations. Compression-then-expansion organization in models emerged exclusively in a rich training regime, which is associated with learning optimized representations that are robust to noise. This regime produces hierarchically structured representations similar to empirical cortical patterns. Together, these results reveal computational principles that organize multitask representations across the human cortex to support multitask cognition. What are the representations that enable diverse human cognition? The authors investigate cortical representations across 26 tasks and the conditions by which artificial neural network models reproduce these representations."/>
    <meta name="dc.creator" content="Ito, Takuya"/>
    <meta name="dc.creator" content="Murray, John D."/>
    <meta name="dc.subject" content="Cognitive neuroscience"/>
    <meta name="dc.subject" content="Network models"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=How to characterize the function of a brain region; citation_author=S Genon, A Reid, R Langner, K Amunts, SB Eickhoff; citation_volume=22; citation_publication_date=2018; citation_pages=350-364; citation_doi=10.1016/j.tics.2018.01.010; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Inferring mental states from neuroimaging data: from reverse inference to large-scale decoding; citation_author=RA Poldrack; citation_volume=72; citation_publication_date=2011; citation_pages=692-697; citation_doi=10.1016/j.neuron.2011.11.001; citation_id=CR2"/>
    <meta name="citation_reference" content="Gallant, J., Nishimoto, S., Naslaris, T. &amp; Wu, M. C. K. In Visual Population Codes: Toward a Common Multivariate Framework for Cell Recording and Functional Imaging (eds Kriegeskort N. &amp; Krieman G.) Ch. 6 (The MIT Press, 2011)."/>
    <meta name="citation_reference" content="citation_journal_title=Front. Syst. Neurosci.; citation_title=Representational similarity analysis&#8212;connecting the branches of systems neuroscience; citation_author=N Kriegeskorte, M Mur, P Bandettini; citation_volume=2; citation_publication_date=2008; citation_pages=4; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Comput. Biol.; citation_title=Deep supervised, but not unsupervised, models may explain IT cortical representation; citation_author=SM Khaligh-Razavi, N Kriegeskorte; citation_volume=10; citation_publication_date=2014; citation_pages=e1003915; citation_doi=10.1371/journal.pcbi.1003915; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Functional specificity in the human brain: a window into the functional architecture of the mind; citation_author=N Kanwisher; citation_volume=107; citation_publication_date=2010; citation_pages=11163-11170; citation_doi=10.1073/pnas.1005062107; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Persistent activity in the prefrontal cortex during working memory; citation_author=CE Curtis, M D&#8217;Esposito; citation_volume=7; citation_publication_date=2003; citation_pages=415-423; citation_doi=10.1016/S1364-6613(03)00197-9; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Computational neuroimaging and population receptive fields; citation_author=BA Wandell, J Winawer; citation_volume=19; citation_publication_date=2015; citation_pages=349-357; citation_doi=10.1016/j.tics.2015.03.009; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Structure of population activity in primary motor cortex for single finger flexion and extension; citation_author=SA Arbuckle; citation_volume=40; citation_publication_date=2020; citation_pages=9210-9223; citation_doi=10.1523/JNEUROSCI.0999-20.2020; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Functional specialization and flexibility in human association cortex; citation_author=BTT Yeo; citation_volume=25; citation_publication_date=2015; citation_pages=3654-3672; citation_doi=10.1093/cercor/bhu217; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Correspondence of the brain&#8217;s functional architecture during activation and rest; citation_author=SM Smith; citation_volume=106; citation_publication_date=2009; citation_pages=13040-13045; citation_doi=10.1073/pnas.0905267106; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Situating the default-mode network along a principal gradient of macroscale cortical organization; citation_author=DS Margulies; citation_volume=113; citation_publication_date=2016; citation_pages=12574-12579; citation_doi=10.1073/pnas.1608282113; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Performance-optimized hierarchical models predict neural responses in higher visual cortex; citation_author=DLK Yamins; citation_volume=111; citation_publication_date=2014; citation_pages=8619-8624; citation_doi=10.1073/pnas.1403112111; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Natural speech reveals the semantic maps that tile human cerebral cortex; citation_author=AG Huth, WAD Heer, TL Griffiths, FE Theunissen, L Jack; citation_volume=532; citation_publication_date=2016; citation_pages=453-458; citation_doi=10.1038/nature17637; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Behav. Sci.; citation_title=Extensive sampling for complete models of individual brains; citation_author=T Naselaris, E Allen, K Kay; citation_volume=40; citation_publication_date=2021; citation_pages=45-51; citation_doi=10.1016/j.cobeha.2020.12.008; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Behav. Sci.; citation_title=How to study the neural mechanisms of multiple tasks; citation_author=GR Yang, MW Cole, K Rajan; citation_volume=29; citation_publication_date=2019; citation_pages=134-143; citation_doi=10.1016/j.cobeha.2019.07.001; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Quantitative models reveal the organization of diverse cognitive functions in the brain; citation_author=T Nakai, S Nishimoto; citation_volume=11; citation_publication_date=2020; citation_pages=1142; citation_doi=10.1038/s41467-020-14913-w; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Functional boundaries in the human cerebellum revealed by a multi-domain task battery; citation_author=M King, CR Hernandez-Castillo, RA Poldrack, RB Ivry, J Diedrichsen; citation_volume=22; citation_publication_date=2019; citation_pages=1371-1378; citation_doi=10.1038/s41593-019-0436-x; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Gradients in brain organization; citation_author=BC Bernhardt, J Smallwood, S Keilholz, DS Margulies; citation_volume=251; citation_publication_date=2022; citation_pages=118987; citation_doi=10.1016/j.neuroimage.2022.118987; citation_id=CR19"/>
    <meta name="citation_reference" content="Ansuini, A., Laio, A., Macke, J. H. &amp; Zoccolan, D. Intrinsic dimension of data representations in deep neural networks. In Advances in Neural Information Processing Systems Vol. 32 (Curran Associates, Inc., 2019)."/>
    <meta name="citation_reference" content="Recanatesi, S. et al. Dimensionality compression and expansion in deep neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.1906.00443
                  
                 (2019)."/>
    <meta name="citation_reference" content="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Rich and lazy learning of task representations in brains and neural networks. Preprint at bioRxiv 
                  https://doi.org/10.1101/2021.04.23.441128
                  
                 (2021)."/>
    <meta name="citation_reference" content="Woodworth, B. et al. Kernel and rich regimes in overparametrized models. In Conference on Learning Theory 3635&#8211;3673 (PMLR, 2020)."/>
    <meta name="citation_reference" content="Glasser, M. F. et al. A multi-modal parcellation of human cerebral cortex. Nature 536, 171&#8211;178 (2016)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Functional network organization of the human brain; citation_author=JD Power; citation_volume=72; citation_publication_date=2011; citation_pages=665-678; citation_doi=10.1016/j.neuron.2011.09.006; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=The organization of the human cerebral cortex estimated by intrinsic functional connectivity; citation_author=BT Yeo; citation_volume=106; citation_publication_date=2011; citation_pages=1125-1165; citation_doi=10.1152/jn.00338.2011; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Intrinsic and task-evoked network architectures of the human brain; citation_author=MW Cole, DS Bassett, JD Power, TS Braver, SE Petersen; citation_volume=83; citation_publication_date=2014; citation_pages=238-251; citation_doi=10.1016/j.neuron.2014.05.014; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Mapping the human brain&#8217;s cortical&#8211;subcortical functional network organization; citation_author=JL Ji; citation_volume=185; citation_publication_date=2019; citation_pages=35-57; citation_doi=10.1016/j.neuroimage.2018.10.006; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Large-scale gradients in human cortical organization; citation_author=JM Huntenburg, P-L Bazin, DS Margulies; citation_volume=22; citation_publication_date=2018; citation_pages=21-31; citation_doi=10.1016/j.tics.2017.11.002; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Decreased segregation of brain systems across the healthy adult lifespan; citation_author=MY Chan, DC Park, NK Savalia, SE Petersen, GS Wig; citation_volume=111; citation_publication_date=2014; citation_pages=E4997-E5006; citation_doi=10.1073/pnas.1415122111; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography; citation_author=JB Burt; citation_volume=21; citation_publication_date=2018; citation_pages=1251-1259; citation_doi=10.1038/s41593-018-0195-0; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Mapping human cortical areas in vivo based on myelin content as revealed by T1-and T2-weighted MRI; citation_author=MF Glasser, DC Van Essen; citation_volume=31; citation_publication_date=2011; citation_pages=11597-11616; citation_doi=10.1523/JNEUROSCI.2180-11.2011; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Behav. Sci.; citation_title=The dimensionality of neural representations for control; citation_author=D Badre, A Bhandari, H Keglovits, A Kikumoto; citation_volume=38; citation_publication_date=2021; citation_pages=20-28; citation_doi=10.1016/j.cobeha.2020.07.002; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=The importance of mixed selectivity in complex cognitive tasks; citation_author=M Rigotti; citation_volume=497; citation_publication_date=2013; citation_pages=585-590; citation_doi=10.1038/nature12160; citation_id=CR34"/>
    <meta name="citation_reference" content="Abbott, L. F., Rajan, K. &amp; Sompolinsky, H. In The Dynamic Brain: An Exploration of Neuronal Variability and Its Functional Significance (eds Ding M. &amp; Glanzman D.) 1&#8211;16 (Oxford University Press, 2011)."/>
    <meta name="citation_reference" content="Gao, P. et al. A theory of multineuronal dimensionality, dynamics and measurement. Preprint at bioRxiv 
                  https://doi.org/10.1101/214262
                  
                 (2017)."/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Comput. Biol.; citation_title=Dimensionality in recurrent spiking networks: global trends in activity and local origins in connectivity; citation_author=S Recanatesi, GK Ocker, MA Buice, E Shea-Brown; citation_volume=15; citation_publication_date=2019; citation_pages=e1006446; citation_doi=10.1371/journal.pcbi.1006446; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=Just above chance: is it harder to decode information from prefrontal cortex hemodynamic activity patterns?; citation_author=A Bhandari, C Gagne, D Badre; citation_volume=30; citation_publication_date=2018; citation_pages=1473-1498; citation_doi=10.1162/jocn_a_01291; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroscientist; citation_title=Small-world brain networks; citation_author=DS Bassett, E Bullmore; citation_volume=12; citation_publication_date=2006; citation_pages=512-523; citation_doi=10.1177/1073858406293182; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Distributed hierarchical processing in the primate cerebral cortex; citation_author=DJ Felleman, DC Essen; citation_volume=1; citation_publication_date=1991; citation_pages=1-47; citation_doi=10.1093/cercor/1.1.1; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Slow cortical dynamics and the accumulation of information over long timescales; citation_author=CJ Honey; citation_volume=76; citation_publication_date=2012; citation_pages=423-434; citation_doi=10.1016/j.neuron.2012.08.011; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=A cortical hierarchy of localized and distributed processes revealed via dissociation of task activations, connectivity changes, and intrinsic timescales; citation_author=T Ito, LJ Hearne, MW Cole; citation_volume=221; citation_publication_date=2020; citation_pages=117141; citation_doi=10.1016/j.neuroimage.2020.117141; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Multi-task connectivity reveals flexible hubs for adaptive task control; citation_author=MW Cole; citation_volume=16; citation_publication_date=2013; citation_pages=1348-1355; citation_doi=10.1038/nn.3470; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Network hubs in the human brain; citation_author=MP Heuvel, O Sporns; citation_volume=17; citation_publication_date=2013; citation_pages=683-696; citation_doi=10.1016/j.tics.2013.09.012; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Human cognition involves the dynamic integration of neural activity and neuromodulatory systems; citation_author=JM Shine; citation_volume=22; citation_publication_date=2019; citation_pages=289; citation_doi=10.1038/s41593-018-0312-0; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=Cell; citation_title=The geometry of abstraction in the hippocampus and prefrontal cortex; citation_author=S Bernardi; citation_volume=183; citation_publication_date=2020; citation_pages=954-967; citation_doi=10.1016/j.cell.2020.09.031; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Orthogonal representations for robust context-dependent task performance in brains and neural networks; citation_author=T Flesch, K Juechems, T Dumbalska, A Saxe, C Summerfield; citation_volume=110; citation_publication_date=2022; citation_pages=1258-1270; citation_doi=10.1016/j.neuron.2022.01.005; citation_id=CR47"/>
    <meta name="citation_reference" content="Ito, T. et al. Compositional generalization through abstract representations in human and artificial neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.2209.07431
                  
                 (2022)."/>
    <meta name="citation_reference" content="citation_journal_title=Cogn. Affect. Behav. Neurosci.; citation_title=Rapid instructed task learning: a new window into the human brain&#8217;s unique capacity for flexible cognitive control; citation_author=MW Cole, P Laurent, A Stocco; citation_volume=13; citation_publication_date=2012; citation_pages=1-22; citation_doi=10.3758/s13415-012-0125-7; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Neurobiol.; citation_title=Going in circles is the way forward: the role of recurrence in visual inference; citation_author=RS Bergen, N Kriegeskorte; citation_volume=65; citation_publication_date=2020; citation_pages=176-193; citation_doi=10.1016/j.conb.2020.11.009; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Evidence that recurrent circuits are critical to the ventral stream&#8217;s execution of core object recognition behavior; citation_author=K Kar, J Kubilius, K Schmidt, EB Issa, JJ DiCarlo; citation_volume=22; citation_publication_date=2019; citation_pages=974-983; citation_doi=10.1038/s41593-019-0392-5; citation_id=CR51"/>
    <meta name="citation_reference" content="Yang, G. R., Joglekar, M. R., Song, H. F., Newsome, W. T. &amp; Wang, X. -J. Task representations in neural networks trained to perform many cognitive tasks. Nat. Neurosci. 22, 297&#8211;306 (2019).
                  https://doi.org/10.1038/s41593-018-0310-2
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Using distance on the Riemannian manifold to compare representations in brain and in models; citation_author=M Shahbazi, A Shirali, H Aghajan, H Nili; citation_volume=239; citation_publication_date=2021; citation_pages=118271; citation_doi=10.1016/j.neuroimage.2021.118271; citation_id=CR53"/>
    <meta name="citation_reference" content="Williams, A. H., Kunz, E., Kornblith, S. &amp; Linderman, S. W. Generalized shape metrics on neural representations. Preprint at 
                  https://doi.org/10.48550/arXiv.2110.14739
                  
                 (2021)."/>
    <meta name="citation_reference" content="Zhi, D., King, M., Hernandez-Castillo, C. R. &amp; Diedrichsen, J. Evaluating brain parcellations using the distance-controlled boundary coefficient. Hum. Brain Mapp. 43, 3706&#8211;3720 (2022)."/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=The minimal preprocessing pipelines for the Human Connectome Project; citation_author=MF Glasser; citation_volume=80; citation_publication_date=2013; citation_pages=105-124; citation_doi=10.1016/j.neuroimage.2013.04.127; citation_id=CR56"/>
    <meta name="citation_reference" content="Ji, J. L. et al. QuNex&#8212;a scalable platform for integrative multi-modal neuroimaging data processing and analysis. Preprint at bioRxiv 
                  https://doi.org/10.1101/2022.06.03.494750
                  
                 (2022)."/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Comput. Biol.; citation_title=Task-evoked activity quenches neural correlations and variability across cortical areas; citation_author=T Ito; citation_volume=16; citation_publication_date=2020; citation_pages=e1007983; citation_doi=10.1371/journal.pcbi.1007983; citation_id=CR58"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity; citation_author=R Ciric; citation_volume=154; citation_publication_date=2017; citation_pages=174-187; citation_doi=10.1016/j.neuroimage.2017.03.020; citation_id=CR59"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=The Human Connectome Project&#8217;s neuroimaging approach; citation_author=MF Glasser; citation_volume=19; citation_publication_date=2016; citation_pages=1175-1187; citation_doi=10.1038/nn.4361; citation_id=CR60"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Measuring functional connectivity during distinct stages of a cognitive task; citation_author=J Rissman, A Gazzaley, M D&#8217;Esposito; citation_volume=23; citation_publication_date=2004; citation_pages=752-763; citation_doi=10.1016/j.neuroimage.2004.06.035; citation_id=CR61"/>
    <meta name="citation_reference" content="citation_journal_title=Hum. Brain Mapp.; citation_title=Statistical parametric maps in functional imaging: a general linear approach; citation_author=KJ Friston; citation_volume=2; citation_publication_date=1994; citation_pages=189-210; citation_doi=10.1002/hbm.460020402; citation_id=CR62"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI; citation_author=A Schaefer; citation_volume=28; citation_publication_date=2018; citation_pages=3095-3114; citation_doi=10.1093/cercor/bhx179; citation_id=CR63"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Correspondences between retinotopic areas and myelin maps in human visual cortex; citation_author=RO Abdollahi; citation_volume=99; citation_publication_date=2014; citation_pages=509-524; citation_doi=10.1016/j.neuroimage.2014.06.042; citation_id=CR64"/>
    <meta name="citation_reference" content="citation_journal_title=Comput. Brain Behav.; citation_title=Measures of neural similarity; citation_author=S Bobadilla-Suarez, C Ahlheim, A Mehrotra, A Panos, BC Love; citation_volume=3; citation_publication_date=2020; citation_pages=369-383; citation_doi=10.1007/s42113-019-00068-5; citation_id=CR65"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Reliability of dissimilarity measures for multi-voxel pattern analysis; citation_author=A Walther; citation_volume=137; citation_publication_date=2016; citation_pages=188-200; citation_doi=10.1016/j.neuroimage.2015.12.012; citation_id=CR66"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Multi-dimensional connectivity: a conceptual and mathematical review; citation_author=A Basti, H Nili, O Hauk, L Marzetti, RN Henson; citation_volume=221; citation_publication_date=2020; citation_pages=117179; citation_doi=10.1016/j.neuroimage.2020.117179; citation_id=CR67"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Generative modeling of brain maps with spatial autocorrelation; citation_author=JB Burt, M Helmer, M Shinn, A Anticevic, JD Murray; citation_volume=220; citation_publication_date=2020; citation_pages=117038; citation_doi=10.1016/j.neuroimage.2020.117038; citation_id=CR68"/>
    <meta name="citation_reference" content="Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics 249&#8211;256 (JMLR Workshop and Conference Proceedings, 2010)."/>
    <meta name="citation_reference" content="Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. Preprint at 
                  https://doi.org/10.48550/arXiv.1412.6980
                  
                 (2015)."/>
    <meta name="citation_author" content="Ito, Takuya"/>
    <meta name="citation_author_institution" content="Department of Psychiatry, Yale School of Medicine, New Haven, USA"/>
    <meta name="citation_author" content="Murray, John D."/>
    <meta name="citation_author_institution" content="Department of Psychiatry, Yale School of Medicine, New Haven, USA"/>
    <meta name="citation_author_institution" content="Department of Neuroscience, Yale School of Medicine, New Haven, USA"/>
    <meta name="citation_author_institution" content="Department of Physics, Yale University, New Haven, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Multitask representations in the human cortex transform along a sensory-to-motor hierarchy"/>
    <meta name="twitter:description" content="Nature Neuroscience - What are the representations that enable diverse human cognition? The authors investigate cortical representations across 26 tasks and the conditions by which artificial..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig1_HTML.png"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/s41593-022-01224-0"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Multitask representations in the human cortex transform along a sensory-to-motor hierarchy - Nature Neuroscience"/>
    <meta property="og:description" content="What are the representations that enable diverse human cognition? The authors investigate cortical representations across 26 tasks and the conditions by which artificial neural network models reproduce these representations."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig1_HTML.png"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41593-022-01224-0;doi=10.1038/s41593-022-01224-0;subjmeta=116,1925,2649,378,631;kwrd=Cognitive+neuroscience,Network+models">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=-857672811&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-022-01224-0%26doi%3D10.1038/s41593-022-01224-0%26subjmeta%3D116,1925,2649,378,631%26kwrd%3DCognitive+neuroscience,Network+models">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=-857672811&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-022-01224-0%26doi%3D10.1038/s41593-022-01224-0%26subjmeta%3D116,1925,2649,378,631%26kwrd%3DCognitive+neuroscience,Network+models"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41593-022-01224-0'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Multitask representations in the human cortex transform along a sensory-to-motor hierarchy
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01224-0.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2022-12-19">19 December 2022</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Multitask representations in the human cortex transform along a sensory-to-motor hierarchy</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Takuya-Ito-Aff1" data-author-popup="auth-Takuya-Ito-Aff1" data-author-search="Ito, Takuya">Takuya Ito</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-2060-4608"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-2060-4608</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-John_D_-Murray-Aff1-Aff2-Aff3" data-author-popup="auth-John_D_-Murray-Aff1-Aff2-Aff3" data-author-search="Murray, John D." data-corresp-id="c1">John D. Murray<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-4115-8181"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-4115-8181</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a></sup> </li></ul>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 26</b>, <span class="u-visually-hidden">pages </span>306–315 (<span data-test="article-publication-year">2023</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">6645 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">3 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">23 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/s41593-022-01224-0/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/cognitive-neuroscience" data-track="click" data-track-action="view subject" data-track-label="link">Cognitive neuroscience</a></li><li class="c-article-subject-list__subject"><a href="/subjects/network-models" data-track="click" data-track-action="view subject" data-track-label="link">Network models</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Human cognition recruits distributed neural processes, yet the organizing computational and functional architectures remain unclear. Here, we characterized the geometry and topography of multitask representations across the human cortex using functional magnetic resonance imaging during 26 cognitive tasks in the same individuals. We measured the representational similarity across tasks within a region and the alignment of representations between regions. Representational alignment varied in a graded manner along the sensory–association–motor axis. Multitask dimensionality exhibited compression then expansion along this gradient. To investigate computational principles of multitask representations, we trained multilayer neural network models to transform empirical visual-to-motor representations. Compression-then-expansion organization in models emerged exclusively in a rich training regime, which is associated with learning optimized representations that are robust to noise. This regime produces hierarchically structured representations similar to empirical cortical patterns. Together, these results reveal computational principles that organize multitask representations across the human cortex to support multitask cognition.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01224-0.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01224-0.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41593-019-0400-9/MediaObjects/41593_2019_400_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41593-019-0400-9?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41593-019-0400-9">Effective learning is accompanied by high-dimensional and efficient representations of neural activity
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">20 May 2019</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Evelyn Tang, Marcelo G. Mattar, … Danielle S. Bassett</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-022-28323-7/MediaObjects/41467_2022_28323_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-022-28323-7?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41467-022-28323-7">Constructing neural network models from brain data reveals representational transformations linked to adaptive behavior
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">03 February 2022</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Takuya Ito, Guangyu Robert Yang, … Michael W. Cole</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-021-22078-3/MediaObjects/41467_2021_22078_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-021-22078-3?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41467-021-22078-3">Qualitative similarities and differences in visual object representations between brains and deep networks
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">25 March 2021</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Georgin Jacob, R. T. Pramod, … S. P. Arun</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711582387,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>Humans perform a variety of tasks in daily life that involve diverse cognitive functions. What are the neural and computational architectures that facilitate multitask cognition? Current efforts to uncover the neural bases of human cognition typically design carefully controlled experiments that target specific cognitive functions while measuring brain activity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Genon, S., Reid, A., Langner, R., Amunts, K. &amp; Eickhoff, S. B. How to characterize the function of a brain region. Trends Cogn. Sci. 22, 350–364 (2018)." href="/articles/s41593-022-01224-0#ref-CR1" id="ref-link-section-d30627514e475">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Poldrack, R. A. Inferring mental states from neuroimaging data: from reverse inference to large-scale decoding. Neuron 72, 692–697 (2011)." href="/articles/s41593-022-01224-0#ref-CR2" id="ref-link-section-d30627514e478">2</a></sup>. While this approach has been fruitful for mapping regional activations by cognitive processes, it is typically unable to reveal the organization of task representations and their transformations across the brain. By contrast, advancements in data analysis have enabled the characterization of representational content and transformations of rich sensory stimuli within the visual cortical hierarchy of individuals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Gallant, J., Nishimoto, S., Naslaris, T. &amp; Wu, M. C. K. In Visual Population Codes: Toward a Common Multivariate Framework for Cell Recording and Functional Imaging (eds Kriegeskort N. &amp; Krieman G.) Ch. 6 (The MIT Press, 2011)." href="#ref-CR3" id="ref-link-section-d30627514e482">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="#ref-CR4" id="ref-link-section-d30627514e482_1">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Khaligh-Razavi, S. M. &amp; Kriegeskorte, N. Deep supervised, but not unsupervised, models may explain IT cortical representation. PLoS Comput. Biol. 10, e1003915 (2014)." href="/articles/s41593-022-01224-0#ref-CR5" id="ref-link-section-d30627514e485">5</a></sup>. However, how the brain’s large-scale organization supports the representational capacity that enables its diverse cognitive functions beyond sensory perception remains poorly studied.</p><p>Univariate task-driven functional magnetic resonance imaging (fMRI) studies have revealed the spatial organization of cognitive specialization across the cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Kanwisher, N. Functional specificity in the human brain: a window into the functional architecture of the mind. Proc. Natl Acad. Sci. USA 107, 11163–11170 (2010)." href="/articles/s41593-022-01224-0#ref-CR6" id="ref-link-section-d30627514e492">6</a></sup> by mapping the stimulus response properties of brain areas and voxels. Such studies have identified regional correlates of working memory<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Curtis, C. E. &amp; D’Esposito, M. Persistent activity in the prefrontal cortex during working memory. Trends Cogn. Sci. 7, 415–423 (2003)." href="/articles/s41593-022-01224-0#ref-CR7" id="ref-link-section-d30627514e496">7</a></sup>, visual processing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Wandell, B. A. &amp; Winawer, J. Computational neuroimaging and population receptive fields. Trends Cogn. Sci. 19, 349–357 (2015)." href="/articles/s41593-022-01224-0#ref-CR8" id="ref-link-section-d30627514e500">8</a></sup> and motor function<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Arbuckle, S. A. et al. Structure of population activity in primary motor cortex for single finger flexion and extension. J. Neurosci. 40, 9210–9223 (2020)." href="/articles/s41593-022-01224-0#ref-CR9" id="ref-link-section-d30627514e504">9</a></sup>, among other cognitive functions. Complementing these studies, meta-analyses of neuroimaging studies have made progress in identifying cortical coactivation patterns across many tasks, affording insight into how brain regions coactivate during tasks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yeo, B. T. T. et al. Functional specialization and flexibility in human association cortex. Cereb. Cortex 25, 3654–3672 (2015)." href="#ref-CR10" id="ref-link-section-d30627514e508">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Smith, S. M. et al. Correspondence of the brain’s functional architecture during activation and rest. Proc. Natl Acad. Sci. USA 106, 13040–13045 (2009)." href="#ref-CR11" id="ref-link-section-d30627514e508_1">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e511">12</a></sup>. Despite these initial advances in describing cortical organization of cognitive processes and their correspondence to intrinsic brain organization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Smith, S. M. et al. Correspondence of the brain’s functional architecture during activation and rest. Proc. Natl Acad. Sci. USA 106, 13040–13045 (2009)." href="/articles/s41593-022-01224-0#ref-CR11" id="ref-link-section-d30627514e516">11</a></sup>, univariate task activation studies are limited in their ability to reveal the fine-grained (voxel-wise) representations within brain regions and how these representations transform across the cortex.</p><p>One leading approach to investigate the structure of task representations within and across cortical regions is representational similarity analysis (RSA)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="/articles/s41593-022-01224-0#ref-CR4" id="ref-link-section-d30627514e523">4</a></sup>. RSA measures geometrical properties of task representations within a brain region by comparing the similarity of multivariate activations (for example, multiple voxels in fMRI) across different task conditions. Representational geometries can then be compared between brain regions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="/articles/s41593-022-01224-0#ref-CR4" id="ref-link-section-d30627514e527">4</a></sup> and between brain data and computational models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Khaligh-Razavi, S. M. &amp; Kriegeskorte, N. Deep supervised, but not unsupervised, models may explain IT cortical representation. PLoS Comput. Biol. 10, e1003915 (2014)." href="/articles/s41593-022-01224-0#ref-CR5" id="ref-link-section-d30627514e531">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proc. Natl Acad. Sci. USA 111, 8619–8624 (2014)." href="/articles/s41593-022-01224-0#ref-CR13" id="ref-link-section-d30627514e534">13</a></sup>. While this approach can identify task-relevant representational geometries for specific brain regions, most studies have typically been limited to isolated tasks in specific domains (for example, perceptual tasks)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Huth, A. G., Heer, W. A. D., Griffiths, T. L., Theunissen, F. E. &amp; Jack, L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458 (2016)." href="/articles/s41593-022-01224-0#ref-CR14" id="ref-link-section-d30627514e538">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Naselaris, T., Allen, E. &amp; Kay, K. Extensive sampling for complete models of individual brains. Curr. Opin. Behav. Sci. 40, 45–51 (2021)." href="/articles/s41593-022-01224-0#ref-CR15" id="ref-link-section-d30627514e541">15</a></sup>. This limits the interpretation of representational geometry within and between brain regions because such tasks only recruit a small subset of the diverse cognitive processes of which humans are capable. By contrast, the study of many tasks can clarify the general cognitive principles by which a single brain architecture can implement many diverse functions.</p><p>Understanding how the human brain achieves multitask cognition is key to understanding what makes human cognition unique and how to engineer it into model systems<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Yang, G. R., Cole, M. W. &amp; Rajan, K. How to study the neural mechanisms of multiple tasks. Curr. Opin. Behav. Sci. 29, 134–143 (2019)." href="/articles/s41593-022-01224-0#ref-CR16" id="ref-link-section-d30627514e548">16</a></sup>. One recent study investigated how different brain areas encode many different tasks across the entire cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Nakai, T. &amp; Nishimoto, S. Quantitative models reveal the organization of diverse cognitive functions in the brain. Nat. Commun. 11, 1142 (2020)." href="/articles/s41593-022-01224-0#ref-CR17" id="ref-link-section-d30627514e552">17</a></sup>. This study revealed clustering of task representations in the cortex and which brain areas were selective to each task type. We build on that study using RSA to characterize how the topography of representations organize along cortical hierarchies and how the local representational properties of each brain region (such as its dimensionality) change across that cortical hierarchy. Explicitly quantifying representational transformations across cortical hierarchies would provide insight into the computational principles underlying human-like cognitive processing.</p><p>Here, we investigated multitask representations across the cortical hierarchy and how artificial neural network models (ANNs) can approximate these representations. To investigate these questions, we used a recently published human fMRI dataset with 26 tasks collected per participant<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e560">18</a></sup>. To characterize the cortex-wide organization of multitask representations, we relate the representational topographies to established large-scale cortical gradients<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Bernhardt, B. C., Smallwood, J., Keilholz, S. &amp; Margulies, D. S. Gradients in brain organization. NeuroImage 251, 118987 (2022)." href="/articles/s41593-022-01224-0#ref-CR19" id="ref-link-section-d30627514e564">19</a></sup> (reflecting hierarchy) derived from resting-state functional connectivity (RSFC). Relating multitask representational organization, which is derived from task fMRI, to RSFC hierarchical gradients, which are derived from task-free MRI, directly grounds regional variations in task representation with the intrinsic organization of the human cortex.</p><p>To study how representations transformed across brain regions, we first quantified the multitask representations within each cortical area using RSA. We then measured the alignment of representations between all pairs of cortical areas. This revealed that the axis of greatest representation variation spanned from sensory to association to motor organization. We next quantified the dimensionality of multitask representations across this sensory-to-motor hierarchy, finding that multitask representational dimensionality first compressed from sensory to association areas and then expanded from association to motor areas. This stands in contrast to the expansion then compression of hidden representations documented in task-optimized deep ANNs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Ansuini, A., Laio, A., Macke, J. H. &amp; Zoccolan, D. Intrinsic dimension of data representations in deep neural networks. In Advances in Neural Information Processing Systems Vol. 32 (Curran Associates, Inc., 2019)." href="/articles/s41593-022-01224-0#ref-CR20" id="ref-link-section-d30627514e571">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Recanatesi, S. et al. Dimensionality compression and expansion in deep neural networks. Preprint at &#xA;                  https://doi.org/10.48550/arXiv.1906.00443&#xA;                  &#xA;                 (2019)." href="/articles/s41593-022-01224-0#ref-CR21" id="ref-link-section-d30627514e574">21</a></sup>. To investigate the computational principles by which we could reproduce brain-like representations, we trained feedforward ANNs directly on multitask brain activity. Compression-then-expansion organization in ANNs emerged exclusively in a rich feature learning regime, which is associated with learned representations that are robust to noise<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Rich and lazy learning of task representations in brains and neural networks. Preprint at bioRxiv &#xA;                  https://doi.org/10.1101/2021.04.23.441128&#xA;                  &#xA;                 (2021)." href="/articles/s41593-022-01224-0#ref-CR22" id="ref-link-section-d30627514e578">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Woodworth, B. et al. Kernel and rich regimes in overparametrized models. In Conference on Learning Theory 3635–3673 (PMLR, 2020)." href="/articles/s41593-022-01224-0#ref-CR23" id="ref-link-section-d30627514e581">23</a></sup>. This regime produced hierarchically structured representations similar to those in the brain. Together, our findings reveal the hierarchical organization of multitask representations in the human brain and establish a framework to produce brain-like representations in computational models.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Analytic approach to studying multitask representations</h3><p>RSA was central to our data analytic approach (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig1">1</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="/articles/s41593-022-01224-0#ref-CR4" id="ref-link-section-d30627514e600">4</a></sup>. RSA approximates the representational geometry of a set of multivariate task activations by comparing the similarity of activation vectors across different conditions. By performing RSA on each brain region, we could produce representational similarity matrices (RSMs) for every brain region (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig1">1a</a>). We used the Glasser parcellation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Glasser, M. F. et al. A multi-modal parcellation of human cerebral cortex. Nature 536, 171–178 (2016)." href="/articles/s41593-022-01224-0#ref-CR24" id="ref-link-section-d30627514e607">24</a></sup>, which provides an atlas of 360 cortical brain regions, to measure the RSMs for each cortical region using the vertices (surface voxels) within each predefined region. Critically, RSMs were calculated for each individual, ensuring that fine-grained (vertex-wise) representational geometries would not be lost through cross-individual averaging of activations at the vertex level (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig17">9</a>). These region-specific RSMs enabled us to perform a variety of new analyses, such as comparing RSMs of cortical areas (that is, the representational alignment (RA); Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig1">1b</a>), quantifying the representational dimensionality across cortical areas (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig1">1c</a>) and identifying the conditions by which computational models can reproduce brain-like representations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig1">1d</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Overview of analytic approaches to study the geometry and topography of multitask representations in fMRI data."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1: Overview of analytic approaches to study the geometry and topography of multitask representations in fMRI data.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="439"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p><b>a</b>, Representational geometry of brain parcels is characterized by RSA (using cosine similarity) applied to individual-specific vertex activation patterns within each parcel<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="/articles/s41593-022-01224-0#ref-CR4" id="ref-link-section-d30627514e638">4</a></sup>. Using individual-specific activation patterns ensures that fine-grained (voxel-wise) representational geometries would not be lost through cross-participant averaging. This enables estimation of an RSM for each brain region using vertices within that region. <b>b</b>, Using each region’s RSM, we can characterize the topography of representations by measuring the RA (the similarity of regional RSMs) between all pairs of brain regions. <b>c</b>, We next asked how the dimensionality of representations changes across the sensory–motor hierarchy. An example (Ex) of a high-dimensional representation is one with a strong diagonal but weak off-diagonal. By contrast, a low-dimensional representation is one with a lack of structure in the RSM and uniform similarity in activation patterns between conditions. <b>d</b>, Given the empirical results, we identified the conditions by which similar hierarchical representations emerge in the internal layers of feedforward neural network models trained to produce sensory-to-motor transformations.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec4">A publicly available dataset with 26 cognitive tasks</h3><p>Characterizing multitask representations across the cortex required a dataset with many tasks per individual. We used the publicly available multidomain task battery (MDTB) human fMRI dataset with 26 cognitive tasks, comprising up to 45 unique task conditions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e667">18</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig2">2a</a>). Data were collected across four sessions, enabling within-participant cross-validation analyses across task conditions (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01224-0#Sec13">Methods</a> for a list of prior studies using this dataset).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Leveraging the MDTB dataset to investigate multitask representations."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2: Leveraging the MDTB dataset to investigate multitask representations.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="263"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p><b>a</b>, The MDTB dataset consists of 26 distinct tasks with up to 45 unique task conditions per individual and was previously made publicly available<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Power, J. D. et al. Functional network organization of the human brain. Neuron 72, 665–678 (2011)." href="/articles/s41593-022-01224-0#ref-CR25" id="ref-link-section-d30627514e691">25</a></sup>. The tasks were split across two sets. Every individual performed each set of tasks twice across different fMRI sessions. (IAPS = International Affective Picture System; CPRO = Concrete Permuted Rule Operations; alt = alternatives). <b>b</b>, Task blocks were interleaved across each fMRI session. For each block, instructions were presented for 5 s, followed by a task that was performed continuously for 30 s until the subsequent block. <b>c</b>, Whole-cortex group-level activation maps for 12 of 26 cognitive tasks (see Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig9">1</a> for all task activation maps); AU, arbitrary units.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec5">Measuring the RA across brain areas</h3><p>We used the multitask RSM of each cortical area to investigate how representations varied across the cortex (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3a</a>). To characterize the regional variation of multitask representations, RA was computed as the cosine similarity between two regions’ RSMs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3b</a>). This produced a whole-cortex RA matrix (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3c</a>). Intuitively, RA would be high between two visual regions that both have discriminable visual task representations (that is, highly decodable) but non-discriminable motor task representations. One common way to characterize the large-scale organization of the cortex is through RSFC<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Power, J. D. et al. Functional network organization of the human brain. Neuron 72, 665–678 (2011)." href="/articles/s41593-022-01224-0#ref-CR25" id="ref-link-section-d30627514e729">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. J. Neurophysiol. 106, 1125–1165 (2011)." href="/articles/s41593-022-01224-0#ref-CR26" id="ref-link-section-d30627514e732">26</a></sup>. We found that the similarity of multitask RA and RSFC was moderate (<i>ρ</i> = 0.37, <i>P</i> &lt; 0.0001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3d</a>). This suggested that while the RA matrix appeared to recover overall aspects of intrinsic RSFC organization, the RA matrix offered unique information from RSFC. Critically, characterizing multitask RA in relation to the well-established RSFC organization literature<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e746">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Power, J. D. et al. Functional network organization of the human brain. Neuron 72, 665–678 (2011)." href="#ref-CR25" id="ref-link-section-d30627514e749">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. J. Neurophysiol. 106, 1125–1165 (2011)." href="#ref-CR26" id="ref-link-section-d30627514e749_1">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Cole, M. W., Bassett, D. S., Power, J. D., Braver, T. S. &amp; Petersen, S. E. Intrinsic and task-evoked network architectures of the human brain. Neuron 83, 238–251 (2014)." href="/articles/s41593-022-01224-0#ref-CR27" id="ref-link-section-d30627514e752">27</a></sup> would clarify how the brain’s representational capacity emerges from its resting-state organization.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Cortical organization of multitask representations."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3: Cortical organization of multitask representations.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="498"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p><b>a</b>, Three example RSMs taken from visual, motor and prefrontal areas. RSMs consisted of 45 task conditions that were cross-validated across imaging runs. <b>b</b>, RA between pairs of cortical areas is quantified by measuring the cosine similarity between their RSMs. <b>c</b>,<b>d</b>, RA (<b>c</b>) and RSFC (<b>d</b>) for all pairs of cortical areas. <b>e</b>,<b>f</b>, Previously identified RSFC networks. <b>g</b>, Segregation (<i>S</i><sub>region</sub>) of the RA and RSFC matrices, defined as the difference of within-network (<i>X</i><sub>within</sub>) and between-network (<i>X</i><sub>between</sub>) values divided by within-network values. <b>h</b>, Unimodal regions (<i>n</i> = 114) have greater segregation for RA than RSFC, and transmodal regions (<i>n</i> = 246) have less segregation for RA than RSFC. This was despite no difference in overall segregation between RA and RSFC. Data were analyzed by two-sided <i>t</i>-test (<i>P</i> &lt; 10 × 10<sup>–34</sup>). <b>i</b>,<b>j</b>, The cortical topography of RA segregation is correlated with the RSFC principal gradient, a proxy of intrinsic hierarchy. Blue and red dots reflect transmodal/unimodal regions, respectively. Box plot bounds define the first and third quartiles of the distribution, box whiskers indicate the 95% confidence interval, and the center line indicates the median.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec6">RA relates to the brain’s intrinsic organization</h3><p>We next characterized RA in the context of the well-established RSFC. RSFC can be used to assign each cortical area to a functional network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Power, J. D. et al. Functional network organization of the human brain. Neuron 72, 665–678 (2011)." href="/articles/s41593-022-01224-0#ref-CR25" id="ref-link-section-d30627514e848">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. J. Neurophysiol. 106, 1125–1165 (2011)." href="/articles/s41593-022-01224-0#ref-CR26" id="ref-link-section-d30627514e851">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Ji, J. L. et al. Mapping the human brain’s cortical–subcortical functional network organization. NeuroImage 185, 35–57 (2019)." href="/articles/s41593-022-01224-0#ref-CR28" id="ref-link-section-d30627514e854">28</a></sup>, and this network organization strongly relates to cognitive task activation patterns<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Smith, S. M. et al. Correspondence of the brain’s functional architecture during activation and rest. Proc. Natl Acad. Sci. USA 106, 13040–13045 (2009)." href="/articles/s41593-022-01224-0#ref-CR11" id="ref-link-section-d30627514e858">11</a></sup>. How does the alignment of task representations correspond with the functional networks of the human brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Huntenburg, J. M., Bazin, P. -L. &amp; Margulies, D. S. Large-scale gradients in human cortical organization. Trends Cogn. Sci. 22, 21–31 (2018)." href="/articles/s41593-022-01224-0#ref-CR29" id="ref-link-section-d30627514e862">29</a></sup>? To address this, we measured the segregation of RA in relation to the segregation of RSFC. Conceptually, segregation measures how clustered a network’s (for example, default mode network) representations/FC are in relation to other networks of the brain (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3g,h</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Chan, M. Y., Park, D. C., Savalia, N. K., Petersen, S. E. &amp; Wig, G. S. Decreased segregation of brain systems across the healthy adult lifespan. Proc. Natl Acad. Sci. USA 111, E4997–E5006 (2014)." href="/articles/s41593-022-01224-0#ref-CR30" id="ref-link-section-d30627514e869">30</a></sup>. Thus, if a visual region’s representations are highly unique to the visual network, then its segregation would be high. Unimodal regions had significantly higher RA segregation than transmodal regions (<i>t</i><sub>358</sub> = 12.99, <i>P</i> &lt; 10 × 10<sup>–31</sup>; Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig10">2d</a>). Despite not observing a significant difference in segregation between RA and RSFC across the whole brain (<i>t</i><sub>358</sub> = −1.24, <i>P</i> = 0.22), RA had exaggerated differences in segregation by network; unimodal networks had higher segregation for RA than RSFC (<i>t</i><sub>112</sub> = −3.33, <i>P</i> = 0.001), and transmodal networks had lower segregation for RA (<i>t</i><sub>244</sub> = −4.24, <i>P</i> &lt; 10 × 10<sup>–4</sup>; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3f,g,h</a>). Thus, representations in unimodal regions were more isolated, while transmodal regions shared their representations more broadly with other networks and systems.</p><p>Prior work has revealed that the human brain’s functional hierarchy can be proxied through identifying topographic cortical gradients using task-free MRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e917">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Burt, J. B. et al. Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography. Nat. Neurosci. 21, 1251–1259 (2018)." href="/articles/s41593-022-01224-0#ref-CR31" id="ref-link-section-d30627514e920">31</a></sup>. Specifically, extracting the first principal component of the RSFC matrix produces a unimodal–transmodal hierarchy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e924">12</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3i</a>), which is highly correlated with the cortical T1-weighted/T2-weighted (T1w/T2w) map (an MRI-contrast correlate of intracortical myelin)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Glasser, M. F. &amp; Van Essen, D. C. Mapping human cortical areas in vivo based on myelin content as revealed by T1-and T2-weighted MRI. J. Neurosci. 31, 11597–11616 (2011)." href="/articles/s41593-022-01224-0#ref-CR32" id="ref-link-section-d30627514e931">32</a></sup>. RA segregation was strongly associated with the RSFC principal gradient (<i>r</i> = 0.39, <i>P</i><sub>non-parametric</sub> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3i,j</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e946">12</a></sup> and the T1w/T2w myelin map (<i>r</i> = 0.36, <i>P</i><sub>non-parametric</sub> &lt; 0.001; Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig10">2f,g</a>). While prior studies have studied hierarchical organization in humans using resting-state, transcriptomic or structural imaging techniques, these findings situate multitask representational topography within the intrinsic hierarchical organization.</p><h3 class="c-article__sub-heading" id="Sec7">Hierarchical organization of representational dimensionality</h3><p>Recent studies have investigated task representational dimensionality during task performance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Badre, D., Bhandari, A., Keglovits, H. &amp; Kikumoto, A. The dimensionality of neural representations for control. Curr. Opin. Behav. Sci. 38, 20–28 (2021)." href="/articles/s41593-022-01224-0#ref-CR33" id="ref-link-section-d30627514e970">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Rigotti, M. et al. The importance of mixed selectivity in complex cognitive tasks. Nature 497, 585–590 (2013)." href="/articles/s41593-022-01224-0#ref-CR34" id="ref-link-section-d30627514e973">34</a></sup>. Note that representational dimensionality refers to the dimensionality of the task space rather than the neural space. However, most prior studies evaluated the representational dimensionality of either a specific task (for example, perceptual task) or within a specific brain region, such as the prefrontal cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Rigotti, M. et al. The importance of mixed selectivity in complex cognitive tasks. Nature 497, 585–590 (2013)." href="/articles/s41593-022-01224-0#ref-CR34" id="ref-link-section-d30627514e977">34</a></sup>. Here, we evaluated the representational dimensionality across many tasks and across the entire cortex.</p><p>We measured the representational dimensionality by measuring the participation ratio of the RSM for each cortical region (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig4">4a</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Abbott, L. F., Rajan, K. &amp; Sompolinsky, H. In The Dynamic Brain: An Exploration of Neuronal Variability and Its Functional Significance (eds Ding M. &amp; Glanzman D.) 1–16 (Oxford University Press, 2011)." href="#ref-CR35" id="ref-link-section-d30627514e987">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Gao, P. et al. A theory of multineuronal dimensionality, dynamics and measurement. Preprint at bioRxiv &#xA;                  https://doi.org/10.1101/214262&#xA;                  &#xA;                 (2017)." href="#ref-CR36" id="ref-link-section-d30627514e987_1">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Recanatesi, S., Ocker, G. K., Buice, M. A. &amp; Shea-Brown, E. Dimensionality in recurrent spiking networks: global trends in activity and local origins in connectivity. PLoS Comput. Biol. 15, e1006446 (2019)." href="/articles/s41593-022-01224-0#ref-CR37" id="ref-link-section-d30627514e990">37</a></sup>. Intuitively, the participation ratio is a statistical estimate of dimensionality and is related to the flatness of the RSM’s eigenspectrum. An implication of this is that regions with low representational dimensionality have stereotyped task responses that are largely shared across many tasks (that is, task responses coexist in a low-dimensional linear subspace). We also estimated the multitask (45-way) decoding as a complementary measure of dimensionality because decoding has been previously used to estimate dimensionality<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Rigotti, M. et al. The importance of mixed selectivity in complex cognitive tasks. Nature 497, 585–590 (2013)." href="/articles/s41593-022-01224-0#ref-CR34" id="ref-link-section-d30627514e994">34</a></sup>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="The representational dimensionality of task activations follows hierarchical organization."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4: The representational dimensionality of task activations follows hierarchical organization.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="937"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p><b>a</b>, We estimated multitask representational dimensionality using two approaches: (1) estimating the dimensionality of the cross-validated RSM, where <i>λ</i><sub><i>i</i></sub> refers to the <i>i</i>th eigenvalue of the RSM, and (2) calculating the within-participant decoding accuracy (acc) across all possible task conditions (<i>n</i> = 45), with cross-validation across sessions (split-half). <b>b</b>,<b>c</b>, The representational dimensionality (<b>b</b>) and multitask decoding accuracy (<b>c</b>) of each cortical parcel. <b>d</b>, Across the cortex (<i>n</i> = 360), representational dimensionality (rep. dim.) was positively correlated with the first principal gradient of RSFC, with unimodal regions containing higher representational dimensionality than transmodal regions (two-sided unpaired <i>t</i>-test; <i>P</i> &lt; 10 × 10<sup>–9</sup>). Red dots reflect unimodal regions (<i>n</i> = 114), and blue dots reflect transmodal regions (<i>n</i> = 246; see Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig11">3</a> for equivalent plots for the decoding approach). Box plot bounds define the first and third quartiles of the distribution, box whiskers indicate the 95% confidence interval, and the center line indicates the median; ***<i>P</i> = &lt;0.0001.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Representational dimensionality and the multitask decoding accuracy were highly correlated across cortical areas, indicating the reliability of these measures (<i>r</i> = 0.94, <i>P</i><sub>non-parametric</sub> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig4">4b,c</a>). Next, we addressed whether representational dimensionality was related to intrinsic hierarchical organization. Indeed, representational dimensionality and multitask decoding were highly correlated with the RSFC principal gradient (<i>r</i> = 0.49, <i>P</i><sub>non-parametric</sub> &lt; 0.001) and T1w/T2w myelin map (<i>r</i> = 0.41, <i>P</i><sub>non-parametric</sub> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig4">4d</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig11">3</a>). This illustrated that like representational segregation, representational dimensionality was also higher in unimodal regions than in transmodal regions (<i>t</i><sub>358</sub> = 6.54, <i>P</i> &lt; 10 × 10<sup>–9</sup>; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig4">4d</a>). These findings are consistent with previous studies that found that higher-order association areas typically have relatively low decoding accuracies, even for tasks that heavily involve those regions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Bhandari, A., Gagne, C. &amp; Badre, D. Just above chance: is it harder to decode information from prefrontal cortex hemodynamic activity patterns? J. Cogn. Neurosci. 30, 1473–1498 (2018)." href="/articles/s41593-022-01224-0#ref-CR38" id="ref-link-section-d30627514e1119">38</a></sup>.</p><p>As control analyses, we tested for the effect of parcel size and number of task conditions. After conditioning on parcel size as a covariate using linear regression, the associations between representational dimensionality and hierarchy remained significant (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig11">3c</a>). We tested for robustness to the number of task conditions by randomly sampling subsets of task conditions and found that the hierarchical differences in representational dimensionality were robust with at least 10 task conditions (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig12">4a–c</a>).</p><h3 class="c-article__sub-heading" id="Sec8">Compression then expansion of task representations</h3><p>We next mapped the axis of greatest RA variation, elucidating how representations vary across the cortex. We performed a principal-component analysis (PCA) to extract the first principal gradient of corticocortical RA. In contrast to the unimodal–transmodal principal gradient exhibited from RSFC (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3i</a>), RA’s principal gradient exhibited a sensory-to-motor gradient and explained 29% of variance in the RA matrix (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5a,b</a>). This was more than two times the variance relative to the second RA principal component (13%). This analysis was corroborated using non-negative matrix factorization (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig18">10</a>). This RA sensory-to-motor gradient was highly correlated with the second principal component of RSFC that also reflects a sensory-to-motor cortical organization (<i>r</i> = 0.59, <i>P</i><sub>non-parametric</sub> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5c</a>). Thus, the axis of greatest RA variation places sensory and motor area representations on opposite ends (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5d</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Principal component of the RA matrix reveals a sensory-to-motor gradient that compresses then expands task representations."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5: Principal component of the RA matrix reveals a sensory-to-motor gradient that compresses then expands task representations.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="372"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p><b>a</b>, Similar to estimating intrinsic RSFC gradients, we extracted the first principal component of the cortical RA matrix. <b>b</b>, The average component loadings (for each region) averaged across sensory (<i>n</i> = 75), association (<i>n</i> = 246) and motor (<i>n</i> = 39) regions in the brain. <b>c</b>, The RA principal gradient showed striking similarity to the second RSFC (that is, sensory–motor) gradient<b>. d</b>, Correlation (<i>n</i> = 360) between the sensory–motor RSFC gradient and the principal RA gradient. <b>e</b>,<b>f</b>, We plotted the representational dimensionality against both the RSFC sensory–motor gradient (<b>e</b>) and RA principal gradient (<b>f</b>), finding that a second-order convex polynomial model was a better fit than a first-order polynomial model and an exponential decay model (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig13">5</a>). This suggested that representational dimensionality compressed then expanded across the sensory–motor hierarchy. <b>g</b>, Same as in <b>e</b> and <b>f</b> but after grouping together sensory (visual and auditory network; <i>n</i> = 75), motor (somatomotor network; <i>n</i> = 39) and association (all other networks; <i>n</i> = 246) parcels according to network affiliation. Data were analyzed by two-sided, two-sample <i>t</i>-test with a Bonferroni correction. <b>h</b>, Same as in <b>e</b> and <b>f</b> but after placing regions into 10 bins (<i>n</i> = 36 each) sorted according to the RA hierarchy (that is, binning regions together with similar loadings). Using a continuous piecewise linear regression, a significant negative-then-positive slope best accounted for dimensionality, consistent with compression then expansion of dimensionality. Data were analyzed by two-sided <i>t</i>-test. Box plot bounds define the first and third quartiles of the distribution, box whiskers indicate the 95% confidence interval, and the center line indicates the median. Error bands reflect a 95% confidence interval in <b>d</b>–<b>f</b>; ***<i>P</i> &lt; 0.0001; *<i>P</i> &lt; 0.05.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>To understand how representations transform from sensory to motor ends, we evaluated the representational dimensionality across the sensory-to-motor hierarchy. We fit several competing statistical models to evaluate how representational dimensionality (dependent variable) changed as a function of the sensory–motor gradient (independent variable), including linear, quadratic and exponential decay models. Using the Akaike/Bayesian information criterion (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig13">5</a>), a convex quadratic fit best explained representational dimensionality as a function of the sensory-to-motor hierarchy (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5e</a>). We corroborated this result using the RA principal gradient rather than the second RSFC sensory–motor gradient, illustrating the robustness of this phenomenon (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5f</a>). The quadratic dependence was robust to subsampling the task conditions (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig12">4d–f</a>). This analysis revealed that representational dimensionality compressed then expanded across the sensory-to-motor hierarchy.</p><p>To verify compression then expansion from sensory-to-motor systems, we grouped regions by cortical systems. Both sensory and motor systems had greater dimensionality than association regions (sensory versus association, <i>t</i><sub>319</sub> = 7.22, <i>P</i> &lt; 10 × 10<sup>–11</sup>; motor versus association, <i>t</i><sub>283</sub> = 2.59, <i>P</i> = 0.01; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5g</a>). To further establish compression then expansion along the RA hierarchy, we created 10 bins of brain regions sorted by the loadings of the RA principal gradient (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5h</a>). We fitted a continuous piecewise regression model, varying the breakpoint between the two line segments at every intermediary bin. We selected the model with highest <i>R</i><sup>2</sup>, which resulted in the piecewise model with a breakpoint at bin 3 (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01224-0#Sec13">Methods</a>). We then tested the statistical significance for the coefficients of the piecewise regression (for a negative slope from bin 1 to 3 and a positive slope from bin 3 to 10). Indeed, a negative slope from bin 1 to 3 (<i>t</i><sub>7</sub> = −12.51, <i>P</i> &lt; 0.001) and a positive slope from bin 3 to 10 (two sided; <i>t</i><sub>7</sub> = 2.55, <i>P</i> = 0.038) confirmed the compression then expansion of dimensionality across the sensory-to-motor hierarchy.</p><h3 class="c-article__sub-heading" id="Sec9">Compression then expansion of task representations in ANNs</h3><p>We next investigated the computational mechanisms that produced the compression then expansion of representational dimensionality observed in fMRI data. Interestingly, two recent ANN studies observed expansion then compression of representational dimensionality when trained on image recognition tasks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Ansuini, A., Laio, A., Macke, J. H. &amp; Zoccolan, D. Intrinsic dimension of data representations in deep neural networks. In Advances in Neural Information Processing Systems Vol. 32 (Curran Associates, Inc., 2019)." href="/articles/s41593-022-01224-0#ref-CR20" id="ref-link-section-d30627514e1344">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Recanatesi, S. et al. Dimensionality compression and expansion in deep neural networks. Preprint at &#xA;                  https://doi.org/10.48550/arXiv.1906.00443&#xA;                  &#xA;                 (2019)." href="/articles/s41593-022-01224-0#ref-CR21" id="ref-link-section-d30627514e1347">21</a></sup>. Therefore, we first asked how the compression-then-expansion phenomena of representational dimensionality emerges in ANNs. We used multilayer, feedforward linear ANNs with tied weights to study how fMRI activations in visual areas were successively transformed into motor activations under different learning regimes (ANNs with untied weights are presented in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig15">7</a> and with other optimization parameters in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig16">8</a>).</p><p>Prior research has shown that small alterations to weight initialization parameters can greatly impact the learned hidden representations in ANNs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Rich and lazy learning of task representations in brains and neural networks. Preprint at bioRxiv &#xA;                  https://doi.org/10.1101/2021.04.23.441128&#xA;                  &#xA;                 (2021)." href="/articles/s41593-022-01224-0#ref-CR22" id="ref-link-section-d30627514e1360">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Woodworth, B. et al. Kernel and rich regimes in overparametrized models. In Conference on Learning Theory 3635–3673 (PMLR, 2020)." href="/articles/s41593-022-01224-0#ref-CR23" id="ref-link-section-d30627514e1363">23</a></sup>. Specifically, those studies found that during a ‘rich’ training regime (in which network initializations had small weight variances), ANNs learned lower-dimensional and structured representations. By contrast, during a ‘lazy’ training regime (large variance weight initializations), task performance was achieved by randomly projecting input features into a high-dimensional embedding in hidden layers. Therefore, we examined representations as a function of the rich and lazy training regimen.</p><p>Using the sensory-to-motor RSFC gradient 2 (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5c</a>), we selected two brain regions on opposite ends of this axis (that is, lowest and highest loadings). This resulted in a visual and a motor parcel (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6a</a>). Note that these sensory and motor parcels had highly similar RSMs to primary visual cortex and primary motor cortex, respectively, suggesting that the gradient-selected parcels were appropriate to model early sensory to late motor transformations in data (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig14">6a–c</a>). We took the visual parcel’s fMRI activations of each of the 45 task conditions (that is, a 45 task condition × vertex-wise activations input matrix) and trained an ANN with 10 hidden layers using weight initializations with different standard deviations to predict motor activations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6b</a>). We trained 20 random initializations for each weight initialization (ranging from 0.2 to 2.0 in increments of 0.2).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Multitask representations in the human cortex were consistent with ANN representations trained in a rich regime."><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6: Multitask representations in the human cortex were consistent with ANN representations trained in a rich regime.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="442"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p><b>a</b>, We identified the brain parcels at the bottom (visual parcel) and top (motor output parcel) of the sensory–motor RSFC gradient 2 and extracted their vertex-wise task activation patterns. <b>b</b>, We trained a feedforward ANN with 10 hidden layers to predict task activations in the motor parcel using vertex-wise activations from the visual parcel. <b>c</b>, The representational dimensionality (participation ratio of RSMs) of each layer with different weight initialization (weight init.) standard deviations. We observed compression then expansion of representations in rich training regimes. <b>d</b>, We fit a second-order polynomial regression to the dimensionality across weight initializations. We plotted the quadratic coefficient (coeff.; positive for convex) and the overall <i>R</i><sup>2</sup> fit to assess how dimensionality changed across ANN layers. <i>R</i><sup>2</sup> peaked during rich training regimes and was consistent with a convex fit. <b>e</b>, We compared the overall similarity of the RSMs of ANNs at each layer with the RSMs for every region in the brain, finding stronger similarity when the ANN was trained in the rich regime (&lt;1.0 s.d. initialization); <i>n</i> = 20 ANN initializations. Data were analyzed by two-sided <i>t</i>-test (<i>P</i> &lt; 10 × 10<sup>–34</sup>). <b>f</b>, We compared the RSMs of ANNs to the empirical brain RSMs at each bin along the sensory–motor gradient for rich (&lt;1.0) and lazy (&gt;1.0) learning regimes; <i>n</i> = 20 ANN initializations. <b>g</b>, Empirical gradient bins were defined by partitioning the sensory–motor RSFC gradient 2 into 10 distinct sets of regions sorted by their gradient loadings. Box plot bounds define the first and third quartiles of the distribution, box whiskers indicate the 95% confidence interval, and the center line indicates the median.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>After ANN training, we measured the representational dimensionality of each ANN’s hidden layer. Rich training regimes (for example, weight initialization s.d. = 0.2; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01224-0#Sec13">Methods</a>) showed compression then expansion across layers, consistent with empirical data (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6c</a>). Similar to the empirical data, we fit a second-order polynomial regression to model dimensionality as a function of layer depth. In the rich regime, in particular for weight initializations starting at an s.d. of 0.2, the quadratic fit was convex and had higher <i>R</i><sup>2</sup> values (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6d</a>). Thus, rich regimes produced compression then expansion of hierarchical representations.</p><p>The rich training regime could produce a compression then expansion of learned representations in ANNs, reproducing the empirical brain data and in contrast to what is typically found in task-optimized ANNs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Ansuini, A., Laio, A., Macke, J. H. &amp; Zoccolan, D. Intrinsic dimension of data representations in deep neural networks. In Advances in Neural Information Processing Systems Vol. 32 (Curran Associates, Inc., 2019)." href="/articles/s41593-022-01224-0#ref-CR20" id="ref-link-section-d30627514e1466">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Recanatesi, S. et al. Dimensionality compression and expansion in deep neural networks. Preprint at &#xA;                  https://doi.org/10.48550/arXiv.1906.00443&#xA;                  &#xA;                 (2019)." href="/articles/s41593-022-01224-0#ref-CR21" id="ref-link-section-d30627514e1469">21</a></sup>. But do the compressed-then-expanded representations exhibit greater similarity to empirical brain representations? Hidden representations learned in the rich regime (that is, &lt;1.0 s.d. weight initializations) were more similar to those found in empirical data (rich, cosine = 0.42; lazy, cosine = 0.37; rich versus lazy, <i>t</i><sub>198</sub> = 15.28, <i>P</i> &lt; 10 × 10<sup>–34</sup>; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6e</a>). We then partitioned brain parcels into 10 bins of 36 parcels and sorted them according to their loading relative to the sensory–motor RSFC gradient (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6g</a>). We correlated the RSMs of each bin with each ANN layer according to depth (for example, similarity of RSMs for ANN layer <i>i</i> with fMRI bin <i>i</i>). The later 8/10 bins/layers had higher similarity in the rich regime (for 8/10, false discovery rate (FDR)-corrected <i>P</i> value of 10<sup>−16</sup>). While the first two fMRI bins had greater correspondence with the lazy learning regime, these first two bins primarily consisted of visual areas. Empirically, visual areas contained high-dimensional representations. Because the lazy learning embeds input features in a high-dimensional space, the higher similarity of lazily trained ANNs with visual regions was unsurprising. Thus, with the exception of early visual areas, richly trained ANNs have greater correspondence with fMRI data in terms of both representational dimensionality and content.</p><h3 class="c-article__sub-heading" id="Sec10">Richly trained ANNs learn structured transformations</h3><p>Having modeled the successive transformation of fMRI activations from visual to motor regions in feedforward ANNs, we evaluated the properties of ANNs that contributed to better correspondence with brain data. First, we characterized the structure of representations that emerged in ANNs trained under different learning regimes. This was done through a similar analytic strategy as in empirical data. For each layer, we computed its RSM using each of the 45 task activation patterns and computed the cosine similarity of that layer’s RSM with the RSMs from all other layers (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7a</a>). This produced a layer-by-layer RA matrix (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7d</a>). ANNs trained in the rich regime learned structured representations that were consistent with structured representations in data; adjacent layers had high RA to each other, but distal layers had low RA to each other (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7b–d</a>). We quantified this by calculating the mean of the RA matrix for each weight initialization (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7e</a>) and the dimensionality of the RA matrix (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7f,g</a>). The higher (lazier) the weight initialization, the greater the overall RA across layers and the lower the dimensionality (rich versus lazy cosine difference = −0.12, <i>t</i><sub>18</sub> = −124.70, <i>P</i> &lt; 10 × 10<sup>–28</sup>; rich versus lazy variance explained by the first principal component = −15.52%, <i>t</i><sub>18</sub> = −99.10, <i>P</i> &lt; 10 × 10<sup>–26</sup>). In contrast to the rich training regime, the lazy regime had nearly no meaningful transformations in the hidden layers for weight initializations, with s.d. &gt; 1.2; outputs were generated from the readout weights only (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7d</a>). The ANN’s internal representations were a direct byproduct of its learned (via training) connectivity structure. Analysis of the optimized network weights revealed that richly trained networks exhibited small-world network structure and low-dimensional connectivity (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig14">6</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Analysis of the ANN revealed that richly trained ANNs learn diverse and structured representations consistent with empirical data."><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7: Analysis of the ANN revealed that richly trained ANNs learn diverse and structured representations consistent with empirical data.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig7_HTML.png?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="464"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p><b>a</b>, We computed the RA between all layers by computing the cosine similarity between the RSMs of each hidden layer. <b>b</b>,<b>c</b>, For comparison, we sorted the empirical fMRI RA by the RSFC sensory–motor (second) gradient (<b>b</b>) and downsampled it into 10 discrete bins for comparison with the ANN analysis (<b>c</b>). <b>d</b>, The RA for ANNs by layer across weight initializations. ANNs trained in the rich regime (for example, weight initializations of &lt;1) learned differentiated and structured representations. By contrast, ANNs trained in the lazy regime largely produced impoverished representations that only transformed sensory representations in the final layer. <b>e</b>, The average cosine similarity of each RA matrix by weight initialization (<i>n</i> = 20 per weight initialization). <b>f</b>, Cumulative variance explained plot of the first three components of the RA matrix under different weight initializations. <b>g</b>, Variance explained of only the first principal component of the RA matrix (<i>n</i> = 20), which captures RA dimensionality; the larger the variance explained, the lower the dimensionality. Box plot bounds define the first and third quartiles of the distribution, box whiskers indicate the 95% confidence interval, and the center line indicates the median.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec11">Transformational trajectories from visual to motor areas</h3><p>To provide an intuition of the transformations in rich and lazy ANNs in the task-state space, we characterized the transformational trajectories from visual to motor representations. This involved plotting ANN representations in a two-dimensional space. The <i>y</i> axis reflected the alignment (inner product) with visual (input) RSM, and the <i>x</i> axis reflected the alignment with motor (output) RSM. While a linear transformation would map visual to motor representations directly (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig8">8a</a>), we hypothesized that compression then expansion would occur by first compressing representations along the visual axis and then expanding along the motor axis (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig8">8a</a>). This is in contrast to the alternative, where motor representations first expand with minimal loss of visual representations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig8">8a</a>). In agreement with this theory, richly trained ANNs first compressed along the visual axis, followed by growth along the motor axis (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig8">8b</a>). This is consistent with the notion that higher-order brain areas (that is, similar to intermediate layers in an ANN) contain distinct representations from input (visual) and output (motor) representations, are low dimensional and integrate input and output representations. By contrast, lazy ANN representations maintained high similarity to visual input representations, with visual-to-motor representational transformations primarily implemented in the readout weights.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8" data-title="Trajectories of representational transformations from visual to motor content."><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8: Trajectories of representational transformations from visual to motor content.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig8_HTML.png?as=webp"><img aria-describedby="Fig8" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="196"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p><b>a</b>, A theory of how representations transform across layers/brain areas from visual to motor representations. Axes reflect the similarity (computed as the inner product) to the visual input region’s RSM (<i>y</i> axis) and the motor output region’s RSM (<i>x</i> axis). Hidden layer representations can then be plotted along these two dimensions by calculating the inner product between the sensory and motor RSMs. <b>b</b>, We plotted the ANN’s internal representations along these two dimensions and found that rich representations are consistent with compression first along the visual axis and then expansion along the motor axis. By contrast, lazy ANNs preserve visual representations in hidden layers until the final readout weights transform visual into motor representations. Note that the <i>y</i> and <i>x</i> axes are not necessarily orthogonal and are plotted as such for visualization purposes. Each dot in the scatter plots reflects a different ANN initialization and layer.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01224-0/figures/8" data-track-dest="link:Figure8 Full size image" aria-label="Full size image figure 8" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Discussion</h2><div class="c-article-section__content" id="Sec12-content"><p>Using RSA-based techniques, we mapped the multitask representational organization of the human cortex. Representations in sensory and motor cortices were more isolated from the rest of the cortex yet had higher dimensionality. By contrast, representations in association regions were lower dimensional but were situated between sensory and motor representations. This revealed a representational hierarchy that compressed then expanded from sensory to association to motor areas. To explore the computational mechanisms of hierarchical representations in the brain, we used feedforward ANNs to study how representations compressed then expanded from input to output. During a rich training regime, ANNs learned structured and hierarchical representations that (1) compressed then expanded representations and (2) had greater similarity to representations found in fMRI data. Further analysis of the ANN revealed that this training regime produced low-dimensional weights with a heavy-tailed distribution, consistent with empirical brain networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Bassett, D. S. &amp; Bullmore, E. Small-world brain networks. Neuroscientist 12, 512–523 (2006)." href="/articles/s41593-022-01224-0#ref-CR39" id="ref-link-section-d30627514e1675">39</a></sup>. Together, these findings characterize the topographic organization of multitask representations in the cortex and provide a framework for understanding how brain-like representations emerge in ANNs.</p><p>We combined multitask analyses with RSA. While RSA has been widely used since its original inception more than a decade ago<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="/articles/s41593-022-01224-0#ref-CR4" id="ref-link-section-d30627514e1682">4</a></sup>, applications of RSA have typically been limited to the sensory domain (that is, where the rows and columns of RSMs are sensory stimuli). The combined approach of leveraging a multitask design with RSA provides a unique opportunity to investigate how different brain regions represent diverse task information. One recent study collected many tasks per participant and, by using individualized encoding models, identified clusters of tasks in a latent cognitive space and how task specialization emerged across the cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Nakai, T. &amp; Nishimoto, S. Quantitative models reveal the organization of diverse cognitive functions in the brain. Nat. Commun. 11, 1142 (2020)." href="/articles/s41593-022-01224-0#ref-CR17" id="ref-link-section-d30627514e1686">17</a></sup>. Here, we expand on that study by explicitly quantifying the transformation of representations between cortical areas, investigating how these variations relate to hierarchical organization and addressing how the dimensionality of task representations changes across this hierarchy.</p><p>Our findings of cortical gradients in task representations adds to a growing literature identifying hierarchy as a fundamental principle of cortical organization. Early seminal work using tract-tracing techniques revealed hierarchical connectivity organization in the macaque visual cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. Cereb. Cortex 1, 1–47 (1991)." href="/articles/s41593-022-01224-0#ref-CR40" id="ref-link-section-d30627514e1693">40</a></sup>. More recent work has shown that such hierarchical organization can be studied in humans in vivo with MRI and electrophysiology. These studies have focused on identifying structural<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Glasser, M. F. &amp; Van Essen, D. C. Mapping human cortical areas in vivo based on myelin content as revealed by T1-and T2-weighted MRI. J. Neurosci. 31, 11597–11616 (2011)." href="/articles/s41593-022-01224-0#ref-CR32" id="ref-link-section-d30627514e1697">32</a></sup>, transcriptomic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Burt, J. B. et al. Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography. Nat. Neurosci. 21, 1251–1259 (2018)." href="/articles/s41593-022-01224-0#ref-CR31" id="ref-link-section-d30627514e1701">31</a></sup>, RSFC<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e1705">12</a></sup> and intrinsic timescale signatures of hierarchical organization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Honey, C. J. et al. Slow cortical dynamics and the accumulation of information over long timescales. Neuron 76, 423–434 (2012)." href="/articles/s41593-022-01224-0#ref-CR41" id="ref-link-section-d30627514e1709">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Ito, T., Hearne, L. J. &amp; Cole, M. W. A cortical hierarchy of localized and distributed processes revealed via dissociation of task activations, connectivity changes, and intrinsic timescales. NeuroImage 221, 117141 (2020)." href="/articles/s41593-022-01224-0#ref-CR42" id="ref-link-section-d30627514e1712">42</a></sup>. Most of these hierarchical descriptions used task-free MRI data, and here, we establish an overarching link that bridges multitask representations with fundamental hierarchical organization. Other studies that evaluate the role of connectivity organization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Cole, M. W. et al. Multi-task connectivity reveals flexible hubs for adaptive task control. Nat. Neurosci. 16, 1348–1355 (2013)." href="/articles/s41593-022-01224-0#ref-CR43" id="ref-link-section-d30627514e1717">43</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="van den Heuvel, M. P. &amp; Sporns, O. Network hubs in the human brain. Trends Cogn. Sci. 17, 683–696 (2013)." href="/articles/s41593-022-01224-0#ref-CR44" id="ref-link-section-d30627514e1720">44</a></sup> and shared multitask dynamics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Shine, J. M. et al. Human cognition involves the dynamic integration of neural activity and neuromodulatory systems. Nat. Neurosci. 22, 289 (2019)." href="/articles/s41593-022-01224-0#ref-CR45" id="ref-link-section-d30627514e1724">45</a></sup> have also identified key hub regions in the association cortex. This is consistent with our finding that association areas contain integrative representations that link the sensory and motor representations lying on opposing ends of the sensory-to-motor axis. Future studies can explore how specializations of the association cortex, in long-range anatomical connectivity and local microcircuitry, contribute to the formation of low-dimensional integrative representations.</p><p>Compression then expansion of representations emerged across the sensory-to-motor hierarchy in brain data. Surprisingly, this contrasts with task-optimized ANNs that typically exhibit expansion then compression of representational dimensionality across hidden layers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Ansuini, A., Laio, A., Macke, J. H. &amp; Zoccolan, D. Intrinsic dimension of data representations in deep neural networks. In Advances in Neural Information Processing Systems Vol. 32 (Curran Associates, Inc., 2019)." href="/articles/s41593-022-01224-0#ref-CR20" id="ref-link-section-d30627514e1731">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Recanatesi, S. et al. Dimensionality compression and expansion in deep neural networks. Preprint at &#xA;                  https://doi.org/10.48550/arXiv.1906.00443&#xA;                  &#xA;                 (2019)." href="/articles/s41593-022-01224-0#ref-CR21" id="ref-link-section-d30627514e1734">21</a></sup>. Algorithmically, representational expansion then compression in ANNs affords high task performance due to the projection of input features into a high-dimensional embedding in the hidden layers. These high-dimensional representations subsequently allow for easy selection of the few features that are useful for task performance. What might be the algorithmic purpose of the compression then expansion of representations observed in the human brain? Recent work at the intersection of machine learning and neuroscience found that, in contrast to projecting input features into a high-dimensional space, lower-dimensional factorized representations (that is, ‘abstract’ or ‘disentangled’) may be useful for generalization because they can easily be recycled in novel contexts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bernardi, S. et al. The geometry of abstraction in the hippocampus and prefrontal cortex. Cell 183, 954–967 (2020)." href="#ref-CR46" id="ref-link-section-d30627514e1738">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Orthogonal representations for robust context-dependent task performance in brains and neural networks. Neuron 110, 1258–1270 (2022)." href="#ref-CR47" id="ref-link-section-d30627514e1738_1">47</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Ito, T. et al. Compositional generalization through abstract representations in human and artificial neural networks. Preprint at &#xA;                  https://doi.org/10.48550/arXiv.2209.07431&#xA;                  &#xA;                 (2022)." href="/articles/s41593-022-01224-0#ref-CR48" id="ref-link-section-d30627514e1741">48</a></sup>. Moreover, these lower-dimensional factorized representations can be learned by ANNs through a rich training regime<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Orthogonal representations for robust context-dependent task performance in brains and neural networks. Neuron 110, 1258–1270 (2022)." href="/articles/s41593-022-01224-0#ref-CR47" id="ref-link-section-d30627514e1745">47</a></sup>. Here, we expanded on this prior work by (1) leveraging a multitask dataset to demonstrate the generality of these principles (rather than manipulating distinct context representations within a single task paradigm) and (2) revealing the organization of representation transformations across the cortex. Although our findings suggest that the low-dimensional association cortex representations are shared across multiple tasks (which likely aid in out-of-task generalization), the current dataset is unable to evaluate how shared components are used to generalize to novel tasks. This is due to the lack of systematic factorization of task components in this multitask setting, which is required to test whether factorized components can be compositionally reused. Therefore, it will be important for future studies to provide a unified understanding of the contribution of low-dimensional representations for task generalization performance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Cole, M. W., Laurent, P. &amp; Stocco, A. Rapid instructed task learning: a new window into the human brain’s unique capacity for flexible cognitive control. Cogn. Affect. Behav. Neurosci. 13, 1–22 (2012)." href="/articles/s41593-022-01224-0#ref-CR49" id="ref-link-section-d30627514e1749">49</a></sup>.</p><p>Our computational modeling results provide a parsimonious framework to study representational transformations in relation to empirical data. There are multiple directions in modeling and analytics that future studies can explore. First, we used a simple feedforward ANN, motivated by our findings of a dominant sensory-to-motor gradient. Future models can examine the impact of more complex and recurrent ANN architectures of internal representations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="van Bergen, R. S. &amp; Kriegeskorte, N. Going in circles is the way forward: the role of recurrence in visual inference. Curr. Opin. Neurobiol. 65, 176–193 (2020)." href="#ref-CR50" id="ref-link-section-d30627514e1757">50</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kar, K., Kubilius, J., Schmidt, K., Issa, E. B. &amp; DiCarlo, J. J. Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior. Nat. Neurosci. 22, 974–983 (2019)." href="#ref-CR51" id="ref-link-section-d30627514e1757_1">51</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Yang, G. R., Joglekar, M. R., Song, H. F., Newsome, W. T. &amp; Wang, X. -J. Task representations in neural networks trained to perform many cognitive tasks. Nat. Neurosci. 22, 297–306 (2019).&#xA;                  https://doi.org/10.1038/s41593-018-0310-2&#xA;                  &#xA;                " href="/articles/s41593-022-01224-0#ref-CR52" id="ref-link-section-d30627514e1760">52</a></sup>. We found that representations depended strongly on the training regime, which we controlled by weight initialization following prior literature<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Rich and lazy learning of task representations in brains and neural networks. Preprint at bioRxiv &#xA;                  https://doi.org/10.1101/2021.04.23.441128&#xA;                  &#xA;                 (2021)." href="/articles/s41593-022-01224-0#ref-CR22" id="ref-link-section-d30627514e1764">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Woodworth, B. et al. Kernel and rich regimes in overparametrized models. In Conference on Learning Theory 3635–3673 (PMLR, 2020)." href="/articles/s41593-022-01224-0#ref-CR23" id="ref-link-section-d30627514e1767">23</a></sup>. Future modeling should explore alternative training methods for ANNs to examine how they alter the similarity to brain representations. Finally, future studies should examine the metrics used to quantify the similarity between empirical and model representations. For instance, inherent constraints on RSMs can be used to define alternative measures of RA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Shahbazi, M., Shirali, A., Aghajan, H. &amp; Nili, H. Using distance on the Riemannian manifold to compare representations in brain and in models. NeuroImage 239, 118271 (2021)." href="/articles/s41593-022-01224-0#ref-CR53" id="ref-link-section-d30627514e1771">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Williams, A. H., Kunz, E., Kornblith, S. &amp; Linderman, S. W. Generalized shape metrics on neural representations. Preprint at &#xA;                  https://doi.org/10.48550/arXiv.2110.14739&#xA;                  &#xA;                 (2021)." href="/articles/s41593-022-01224-0#ref-CR54" id="ref-link-section-d30627514e1774">54</a></sup>. Therefore, it will be important for future work to explore the space of biologically relevant strategies that produce feature-rich hierarchical representations in models that can be quantitatively related to neural datasets.</p><p>In conclusion, we characterized the multitask representational geometry and topography across the human cortical hierarchy and provide insight into the mechanisms that produce similar representations in ANNs. Overall, analysis of the task representational hierarchy revealed a sensory-to-motor gradient that compressed then expanded task representations. Subsequent modeling of these task activations in ANNs revealed that a rich training regime can reproduce representations that are consistent with brain data. This finding provides a framework to explore how to build ANNs that learn task representations in a brain-like manner. We expect these findings to spur new investigations into how the study of multitask representations in the brain can inform new models of multitask performance in machine learning models.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Methods</h2><div class="c-article-section__content" id="Sec13-content"><h3 class="c-article__sub-heading" id="Sec14">MDTB dataset</h3><p>Portions of this section are paraphrased from the Methods section of the original dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e1793">18</a></sup>. We used the publicly available MDTB dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e1797">18</a></sup>. Prior studies with this dataset investigated the topographic and functional boundaries of the human cerebellum<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e1801">18</a></sup> and the validity of cortical parcellations (or brain atlases) derived from either resting-state or task fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Zhi, D., King, M., Hernandez-Castillo, C. R. &amp; Diedrichsen, J. Evaluating brain parcellations using the distance-controlled boundary coefficient. Hum. Brain Mapp. 43, 3706–3720 (2022)." href="/articles/s41593-022-01224-0#ref-CR55" id="ref-link-section-d30627514e1805">55</a></sup>. The present study used this dataset to investigate a distinct topic: the structure and organization of multitask representational transformations across cortical hierarchies.</p><p>The MDTB dataset contains task fMRI data for 24 individuals collected at Western University (16 females and 8 males; mean age = 23.8 years, s.d. = 2.6; all individuals were right-handed; see ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e1812">18</a></sup> for exclusion criteria). All participants gave informed consent under an experimental protocol approved by the institutional review board at Western University, where the dataset was originally collected. Briefly, the MDTB dataset contains 26 unique cognitive tasks with up to 45 different task conditions per participant. Participants first scanned all tasks in set A and returned for a second session to perform tasks in set B (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig2">2a</a>). Each task set session consisted of two imaging runs. Half of the individuals had sessions separated by 2–3 weeks, while the other half had sessions separated by 1 year. Of the 24 individuals, a separate resting-state fMRI scan was collected for 18 participants. Resting-state FC analyses presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3</a> were performed using this subset of participants.</p><p>A large battery of tasks was selected to broadly recruit cognitive processes from many functional domains (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig2">2a</a>). Set A consisted of cognitive, motor, affective and social tasks. Set B contained eight tasks that were also included in set A (for example, theory of mind and motor sequence tasks) and nine unique tasks. Both sets contained 17 tasks each. Additional details regarding the experimental tasks and conditions have been previously reported (<a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-019-0436-x/MediaObjects/41593_2019_436_MOESM1_ESM.pdf">https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-019-0436-x/MediaObjects/41593_2019_436_MOESM1_ESM.pdf</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e1835">18</a></sup>.</p><p>Tasks were performed once per imaging session for 35-s blocks. Task blocks began with a 5-s instruction screen followed by 30 s of continuous task performance (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig2">2b</a>). While most tasks consisted of 10–15 trials per block, the number of trials per task ranged from 1 to 30 (for example, go/no-go task versus movie watching). Eleven of the 26 tasks were passive, meaning no behavioral responses were required (for example, movie watching). For the remaining tasks, responses were made with left, right or both hands using a four-button box. Responses were made with either index or middle fingers of the assigned hand(s). Performing all tasks within a single imaging run for each participant ensured a common baseline between tasks, enabling fine-grained, voxel-wise multitask analyses.</p><h3 class="c-article__sub-heading" id="Sec15">fMRI preprocessing</h3><p>Resting-state and task-state fMRI data were minimally preprocessed using the Human Connectome Project preprocessing pipeline within the Quantitative Neuroimaging Environment and Toolbox (QuNex, version 0.61.17)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Glasser, M. F. et al. The minimal preprocessing pipelines for the Human Connectome Project. NeuroImage 80, 105–124 (2013)." href="/articles/s41593-022-01224-0#ref-CR56" id="ref-link-section-d30627514e1853">56</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Ji, J. L. et al. QuNex—a scalable platform for integrative multi-modal neuroimaging data processing and analysis. Preprint at bioRxiv &#xA;                  https://doi.org/10.1101/2022.06.03.494750&#xA;                  &#xA;                 (2022)." href="/articles/s41593-022-01224-0#ref-CR57" id="ref-link-section-d30627514e1856">57</a></sup>. The Human Connectome Project preprocessing pipeline consisted of anatomical reconstruction and segmentation, echo-planar imaging (EPI) reconstruction and segmentation, spatial normalization to the MNI152 template and motion correction. Additional nuisance regression was performed on the minimally preprocessed time series. Consistent with previous reports<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Ito, T. et al. Task-evoked activity quenches neural correlations and variability across cortical areas. PLoS Comput. Biol. 16, e1007983 (2020)." href="/articles/s41593-022-01224-0#ref-CR58" id="ref-link-section-d30627514e1860">58</a></sup>, this included six motion parameters, their derivatives and the quadratics of those parameters (24 motion regressors in total). We also removed the mean physiological time series extracted from the white matter and ventricle voxels. We also included the quadratic, derivatives and the derivatives of the quadratic time series of each of the white matter and ventricle time series (eight physiological nuisance signals). This amounted to 32 nuisance parameters in total and was a nuisance regression model that was previously benchmarked<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Ciric, R. et al. Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity. NeuroImage 154, 174–187 (2017)." href="/articles/s41593-022-01224-0#ref-CR59" id="ref-link-section-d30627514e1864">59</a></sup>. In addition to nuisance regressors, task fMRI data were also modeled with task regressors to extract activation estimates described below.</p><h3 class="c-article__sub-heading" id="Sec16">fMRI task activation estimation</h3><p>We performed a single-individual task general linear model (GLM) analysis on fMRI task data to estimate vertex-wise surface activations for each task condition on the Connectivity Informatics Technology Initiative file format (CIFTI) grayordinate space<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Glasser, M. F. et al. The Human Connectome Project’s neuroimaging approach. Nat. Neurosci. 19, 1175–1187 (2016)." href="/articles/s41593-022-01224-0#ref-CR60" id="ref-link-section-d30627514e1876">60</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Rissman, J., Gazzaley, A. &amp; D’Esposito, M. Measuring functional connectivity during distinct stages of a cognitive task. NeuroImage 23, 752–763 (2004)." href="/articles/s41593-022-01224-0#ref-CR61" id="ref-link-section-d30627514e1879">61</a></sup>. We modeled a separate regressor for every trial within each imaging run, similar to a beta series model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Rissman, J., Gazzaley, A. &amp; D’Esposito, M. Measuring functional connectivity during distinct stages of a cognitive task. NeuroImage 23, 752–763 (2004)." href="/articles/s41593-022-01224-0#ref-CR61" id="ref-link-section-d30627514e1883">61</a></sup>. The instruction period for each task was not included in the task regressors. This enabled the estimation of specific task conditions within each task block (for example, congruent versus incongruent conditions for the Stroop task). Each regressor (trial) was modeled as a boxcar function from the onset to the offset of the trial (0 s indicates off and 1 s indicates on) and then convolved with the Statistical Parametric Mapping (SPM) canonical hemodynamic response function to account for hemodynamic lags<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Friston, K. J. et al. Statistical parametric maps in functional imaging: a general linear approach. Hum. Brain Mapp. 2, 189–210 (1994)." href="/articles/s41593-022-01224-0#ref-CR62" id="ref-link-section-d30627514e1887">62</a></sup>. Activations for a task condition were then obtained by averaging the activation beta coefficients across trials within each imaging run, resulting in one task condition activation per run. Task GLMs were performed using the LinearRegression function within scikit-learn (version 0.23.2) in Python (version 3.8.5).</p><h3 class="c-article__sub-heading" id="Sec17">RSA and RA</h3><p>We performed a split-half, cross-validated RSA to characterize the geometry of task representations across the cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="/articles/s41593-022-01224-0#ref-CR4" id="ref-link-section-d30627514e1899">4</a></sup>. RSA was performed for each parcel in the multimodal (structural, resting-state and task-based MRI) Glasser et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Glasser, M. F. et al. A multi-modal parcellation of human cerebral cortex. Nature 536, 171–178 (2016)." href="/articles/s41593-022-01224-0#ref-CR24" id="ref-link-section-d30627514e1903">24</a></sup> atlas using vertices within each parcel<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Glasser, M. F. et al. A multi-modal parcellation of human cerebral cortex. Nature 536, 171–178 (2016)." href="/articles/s41593-022-01224-0#ref-CR24" id="ref-link-section-d30627514e1907">24</a></sup>. We specifically chose this parcellation due to improved delineation of somatotopic and visuotopic areal organization that are not accounted for in atlases defined solely on resting-state fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Schaefer, A. et al. Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI. Cereb. Cortex 28, 3095–3114 (2018)." href="/articles/s41593-022-01224-0#ref-CR63" id="ref-link-section-d30627514e1911">63</a></sup>. In particular, the specific features that constituted an improved delineation in the Glasser parcellation (in contrast to other purely data-driven approaches) was the use of prior knowledge (for example, previously published retinotopic maps<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Abdollahi, R. O. et al. Correspondences between retinotopic areas and myelin maps in human visual cortex. NeuroImage 99, 509–524 (2014)." href="/articles/s41593-022-01224-0#ref-CR64" id="ref-link-section-d30627514e1915">64</a></sup>) to guide the division of areal/parcel boundaries. Critically, RSA was performed at the participant level to ensure that fine-grained, voxel-wise representations were participant specific and that activations would not be averaged across participants. Group averaging was computed after RSMs were constructed for each participant at every parcel. We used all task conditions, resulting in a 45 × 45 RSM. We used cosine similarity to measure the distances between task activations. Despite many alternative metrics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Bobadilla-Suarez, S., Ahlheim, C., Mehrotra, A., Panos, A. &amp; Love, B. C. Measures of neural similarity. Comput. Brain Behav. 3, 369–383 (2020)." href="/articles/s41593-022-01224-0#ref-CR65" id="ref-link-section-d30627514e1920">65</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Walther, A. et al. Reliability of dissimilarity measures for multi-voxel pattern analysis. NeuroImage 137, 188–200 (2016)." href="/articles/s41593-022-01224-0#ref-CR66" id="ref-link-section-d30627514e1923">66</a></sup>, we specifically chose the cosine similarity because it also takes into account the overall mean magnitude of activation across a set of vertices (in contrast to Pearson correlation). Cross-validation was achieved by measuring the cosine similarity of activation patterns of the first and second imaging sessions (that is, a split-half cross-validation). This was possible because all tasks (in set A and B) were performed in two separate imaging runs. This ensured a non-trivial diagonal element (that is, not equal to 1), which revealed the test–retest reliability (or similarity) of the activation patterns of the same task condition.</p><p>Interregional RA was calculated by measuring the cosine similarity of the upper triangle elements (including the diagonal) of two region’s RSMs. Related measures have also been previously introduced under the term ‘representational connectivity’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. Front. Syst. Neurosci. 2, 4 (2008)." href="/articles/s41593-022-01224-0#ref-CR4" id="ref-link-section-d30627514e1930">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Shahbazi, M., Shirali, A., Aghajan, H. &amp; Nili, H. Using distance on the Riemannian manifold to compare representations in brain and in models. NeuroImage 239, 118271 (2021)." href="/articles/s41593-022-01224-0#ref-CR53" id="ref-link-section-d30627514e1933">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="Basti, A., Nili, H., Hauk, O., Marzetti, L. &amp; Henson, R. N. Multi-dimensional connectivity: a conceptual and mathematical review. NeuroImage 221, 117179 (2020)." href="/articles/s41593-022-01224-0#ref-CR67" id="ref-link-section-d30627514e1936">67</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec18">Network segregation</h3><p>Network segregation for RSFC and multitask RA was measured as the difference between within-network and between-network FC/RA divided by within-network FC/RA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Chan, M. Y., Park, D. C., Savalia, N. K., Petersen, S. E. &amp; Wig, G. S. Decreased segregation of brain systems across the healthy adult lifespan. Proc. Natl Acad. Sci. USA 111, E4997–E5006 (2014)." href="/articles/s41593-022-01224-0#ref-CR30" id="ref-link-section-d30627514e1949">30</a></sup>. Networks were defined using a previously published whole-brain resting-state network partition<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Ji, J. L. et al. Mapping the human brain’s cortical–subcortical functional network organization. NeuroImage 185, 35–57 (2019)." href="/articles/s41593-022-01224-0#ref-CR28" id="ref-link-section-d30627514e1953">28</a></sup>. Networks were composed of a non-overlapping set of parcels (or brain regions). Parcels are a collection of non-overlapping vertices. Network segregation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Chan, M. Y., Park, D. C., Savalia, N. K., Petersen, S. E. &amp; Wig, G. S. Decreased segregation of brain systems across the healthy adult lifespan. Proc. Natl Acad. Sci. USA 111, E4997–E5006 (2014)." href="/articles/s41593-022-01224-0#ref-CR30" id="ref-link-section-d30627514e1957">30</a></sup> was calculated for each region separately using either the RA or FC matrix. Specifically, the segregation <i>S</i><sub>region</sub> of a region was calculated as</p><div id="Equa" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$S_{{\mathrm{region}}} = \frac{{X_{{\mathrm{within}}} - X_{{\mathrm{between}}}}}{{X_{{\mathrm{within}}}}},$$</span></div></div><p>where <i>X</i><sub>within</sub> is the within-network FC/RA for the region of interest, and <i>X</i><sub>between</sub> is the out-of-network FC/RA.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec19">Representational dimensionality and multitask decoding</h4><p>Representational dimensionality was measured as the participation ratio of the multitask RSM. Representational dimensionality refers to the dimensionality of the task space rather than the neural space. That is, feature dimensions are defined by task conditions rather than as voxels/neurons. The participation ratio was calculated as</p><div id="Equb" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${\mathrm{dim}}_X = \frac{{\left( {\mathop {\sum}\nolimits_{i = 1}^m {\lambda _i} } \right)^2}}{{\mathop {\sum}\nolimits_{i = 1}^m {\lambda _i^2} }},$$</span></div></div><p>where dim<sub><i>X</i></sub> corresponds to the representational dimensionality of region <i>X</i>, and <i>λ</i><sub><i>i</i></sub> corresponds to the eigenvalues of the RSM of region <i>X</i> with <i>m</i> eigenvalues. The flatter the eigenspectrum of region <i>X</i>’s RSM, the higher the dimensionality. An alternative approach to intuiting this measure is that the dimensionality of task RSMs is inversely related to the amount of variance explained by the first few eigenvectors; the higher the dimensionality, the more eigenvectors are required to explain the same amount of variance. To complement representational dimensionality, we also measured the multitask decodability (45-way classification) of each region using a minimum-distance classifier. We used the cosine angle as our measure of distance and split-half cross-validation. Thus, a successful classification indicated that the diagonal element of a region’s cross-validated RSM was greater (that is, smallest distance) than all other off-diagonal elements for a given row (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig4">4a</a>). We performed additional control analyses to account for parcel size (that is, the number of vertices) when calculating representational dimensionality and multitask decodability. This was performed by conditioning on (regressing out) the number of vertices from each measure using linear regression (regression was performed across parcels). We then recalculated the correlation across brain maps (for example, myelin map versus representational dimensionality) using the residual values (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig11">3b,c</a>).</p><h3 class="c-article__sub-heading" id="Sec20">Gradient analysis</h3><p>Cortical gradients were calculated using a PCA on parcellated data. Following prior work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e2245">12</a></sup>, resting-state FC gradients were extracted by applying PCA on the cortical FC matrix. For RA gradients, PCA was applied on the cortical RA matrix. This means that the covariance matrices of FC and RA were first calculated, and then the eigenvectors of those matrices were extracted. One intuitive way to think about elements in the cov(RA) or cov(RSFC) matrix is to ask, do two regions have similar patterns of RA (or FC/correlations) as the rest of cortex? If they have similar patterns of RA/FC, then those two regions would have similar loadings. Consistent with previous studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574–12579 (2016)." href="/articles/s41593-022-01224-0#ref-CR12" id="ref-link-section-d30627514e2249">12</a></sup>, matrices were thresholded to include only the top 20% of values before extracting gradients. All correlation-based statistical tests involving gradients (that is, spatial correlations across the cortex) were performed using spatial autocorrelation-preserving permutation tests that generated random surrogate brain maps<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Burt, J. B., Helmer, M., Shinn, M., Anticevic, A. &amp; Murray, J. D. Generative modeling of brain maps with spatial autocorrelation. NeuroImage 220, 117038 (2020)." href="/articles/s41593-022-01224-0#ref-CR68" id="ref-link-section-d30627514e2253">68</a></sup>. We used the BrainSMASH toolbox to generate 1,000 random surrogate brain maps for each cortical map of interest, and non-parametric <i>P</i> values were calculated from the null distribution. Therefore, the lowest precision non-parametric <i>P</i> value we obtained was 0.001.</p><h3 class="c-article__sub-heading" id="Sec21">Testing for compression then expansion in empirical data</h3><p>Assessing compression then expansion in empirical data involved fitting representational dimensionality to sensory–motor hierarchy loadings using regression models (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5e,f</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig13">5</a>). We used RSFC sensory–motor gradient 2 loadings (<i>x</i> variable) as the regressor to predict the representational dimensionality of each parcel (<i>y</i> variable). For model adjudication, we used used several competing regression models, including</p><div id="Equc" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${{{\mathrm{Linear}}}}\,{{{\mathrm{model}}}}:y = \beta _0 + \beta _1x + {\it{\epsilon }}$$</span></div></div><div id="Equd" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${{{\mathrm{Quadratic}}}}\,{{{\mathrm{model}}}}:y = \beta _0 + \beta _1x + \beta _2x^2 + {\it{\epsilon }}$$</span></div></div><div id="Eque" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$${{{\mathrm{Exponential}}}}\,{{{\mathrm{decay}}}}\,{{{\mathrm{model:}}}}\,y\left( t \right) = N_0e^{ - \lambda t} + {\it{\epsilon }}$$</span></div></div><p>where <i>β</i><sub><i>i</i></sub> was the fitted coefficient term, and <span class="mathjax-tex">\({\it{\epsilon }}\)</span> was the residual error term. For the second-order quadratic model, a positive second-order coefficient indicated a convex quadratic. Selection of the model was based on the lowest Akaike information criterion and Bayesian information criterion (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig13">5</a>).</p><p>To further verify compression then expansion across the sensory–motor hierarchy, we binned together groups of 10 bins of 36 parcels according to their RA principal gradient loading (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5a</a>). To establish compression then expansion along this gradient, we fit a piecewise linear model with the functional form</p><div id="Equf" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$y = \beta _0 + \beta _1x_1 + \beta _2x_2 + {\it{\epsilon }}.$$</span></div></div><p>We trained a piecewise linear model for every possible breakpoint (that is, where <i>x</i><sub>1</sub> <i>&lt;</i> <i>i</i> and <i>x</i><sub>2</sub> &gt; <i>i</i> for every bin <i>i</i> between 1 and 10; eight possible models). Note that <i>x</i><sub>1</sub> represented values for <i>x</i> &lt; <i>i</i> and 0 otherwise, and <i>x</i><sub>2</sub> represented values for <i>x</i> &gt; <i>i</i> and 0 otherwise. After identifying the model with the greatest fit evaluated using <i>R</i><sup>2</sup>, which turned out to be the model with the breakpoint at <i>i</i> = 3, we tested the statistical significance for the beta coefficients <i>β</i><sub>1</sub> and <i>β</i><sub>2</sub>, with the hypothesis that they should be negative and positive, respectively. Negative and positive slopes for <i>β</i><sub>1</sub> and <i>β</i><sub>2</sub>, respectively, would reflect a compression of representational dimensionality from input to the breakpoint and then an expansion from the breakpoint to the output.</p><h3 class="c-article__sub-heading" id="Sec22">ANN modeling and training</h3><p>We modeled the transformation from visual fMRI activations to motor activations using a linear feedforward ANN. This enabled the characterization of the transformation as a sequence of linear transformations. fMRI activations were selected based on lying on opposite ends of the RSFC sensorimotor gradient (that is, region with the lowest/highest loadings). Input activations were normalized across vertices before training. Inputs and outputs corresponded to the vertex-level fMRI task activations for each parcel. We used the RSFC sensorimotor gradient rather than the task-based RA gradient to avoid any potential confounds of selecting activations from the same task data. The input and output parcels corresponded to parcels 338 and 235 in the Glasser et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Glasser, M. F. et al. A multi-modal parcellation of human cerebral cortex. Nature 536, 171–178 (2016)." href="/articles/s41593-022-01224-0#ref-CR24" id="ref-link-section-d30627514e2734">24</a></sup> atlas, respectively. We built the ANN with 10 hidden layers with tied weights (500 units per layer), and the ANN was defined by the equations</p><div id="Equg" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$H_1 = XW_{{\mathrm{in}}} + b_{{\mathrm{in}}}$$</span></div></div><div id="Equh" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$H_i = H_{i - 1}W_{{\mathrm{hid}}} + b_{{\mathrm{hid}}}$$</span></div></div><div id="Equi" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$Y = H_nW_{{\mathrm{out}}} + b_{{\mathrm{out}}} + {\it{\epsilon }}$$</span></div></div><p>where <i>X</i> was the input fMRI activation from the visual parcel, <i>W</i><sub>in</sub> mapped vertex activations into the hidden unit space, <i>b</i><sub>in</sub> was the input bias, <i>H</i><sub><i>i</i></sub> was the hidden unit activations for layer <i>i</i> up to <i>n</i> (that is, 10), <i>W</i><sub><i>hid</i></sub> and <i>b</i><sub><i>hid</i></sub> were the weights and biases for the hidden layers, <i>Y</i> was the predicted motor fMRI activation in the motor parcel, and <span class="mathjax-tex">\({\it{\epsilon }}\)</span> was the residual error term. Using tied weights and a linear model reduced the number of free parameters in the model, thereby constraining the solutions and simplifying the model for subsequent analysis. Using tied weights also increased computational efficiency during training. However, we also ran the model without tied weights (where <i>W</i><sub>hid</sub> and <i>b</i><sub>hid</sub> were distinct for each layer), yielding computationally similar results (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig15">7</a>).</p><p>ANN hidden layer weights were initialized from a Xavier normal distribution, with mean 0 and a scaling factor ranging from 0.2 to 2.0 in increments of 0.2 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 69" title="Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics 249–256 (JMLR Workshop and Conference Proceedings, 2010)." href="/articles/s41593-022-01224-0#ref-CR69" id="ref-link-section-d30627514e3025">69</a></sup>). Biases were initialized to be 0. Training was implemented using a mean squared error cost function and the Adam optimizer with an initial learning rate of 0.0001 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 70" title="Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. Preprint at &#xA;                  https://doi.org/10.48550/arXiv.1412.6980&#xA;                  &#xA;                 (2015)." href="/articles/s41593-022-01224-0#ref-CR70" id="ref-link-section-d30627514e3029">70</a></sup>). Training was stopped once the mean squared error fell below a threshold of 0.2. We also replicated these core mode results using a standard stochastic gradient descent optimizer with a learning rate of 0.01 (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig16">8</a>). Note that smaller learning rates resulted in intractable training times using stochastic gradient descent.</p><p>We fit ANNs for each participant’s activations separately. For every participant, we trained 20 networks with different random initializations. For each ANN analysis, statistics and network properties (for example, dimensionality, weight norms and so on) were averaged across participants, and statistical tests were performed on the 20 random initializations.</p><p>We note that while there is no strict definition of rich versus lazy training, there are several factors that are good proxy measurements of an ANN’s training regime. One such proxy is that training cost/time-rich training is far more computationally costly than lazy training<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Orthogonal representations for robust context-dependent task performance in brains and neural networks. Neuron 110, 1258–1270 (2022)." href="/articles/s41593-022-01224-0#ref-CR47" id="ref-link-section-d30627514e3042">47</a></sup>. Empirically, we observe that rich training has weight initializations that are smaller than the default initialization (s.d. = 1.0), while computationally cheap lazy training includes initializations that are greater than the default. Nevertheless, these definitions can change with ANN architectures because weight initializations can impact the vanishing and exploding gradient issue in ANN training.</p><p>All models were built using PyTorch version 1.4.0 and Python version 3.8.5.</p><h3 class="c-article__sub-heading" id="Sec23">ANN analysis</h3><p>Trained ANNs were subject to analysis to characterize both the learned intermediate representations and weight distribution properties. Model RSMs were generated by propagating participant-level task activations through the hidden layers. Cross-validated RSMs were constructed and analyzed identically to fMRI data (for example, cosine similarity and then participation ratio to estimate its dimensionality; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6c</a>). As in our fMRI analysis, we used a split-half cross-validation where we compared task activations between the first and second imaging sessions of each task set. We fitted the dimensionality across ANN layer depth using a second-order polynomial regression to assess how representational dimensionality changed throughout the network (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6d</a>). Positive and negative second-order coefficients indicated convex and concave quadratics, respectively.</p><p>We compared the representational geometries produced by the ANN with the representational geometries found in empirical fMRI data. To directly compare ANN and empirical RSMs, we partitioned the cortex into 10 bins containing 36 parcels each (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6g</a>). Cortical bins and their ordering were determined by the RSFC sensory–motor gradient, where parcels with similar loadings were placed in adjacent bins (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5a</a>). We computed the cosine similarity of each region’s RSM with each ANN layer’s RSM. To evaluate the correspondence between representations in each cortical bin and each ANN layer, we averaged the cosine values across parcels within each bin (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6f</a>). This was done for ANNs trained under the rich regime (weight initializations less than 1) and the lazy regime (weight initializations greater than 1).</p><p>We assessed the interlayer RA within the ANN for different weight initializations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7a</a>), which is similar to interregion RA measured in fMRI data (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3c</a>). This was defined as the cosine similarity between RSMs between pairs of ANN layers (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7a</a>). We also analyzed the properties of the trained and initialized ANN weights. This included calculation of the Frobenius norm, Fisher kurtosis and singular value decomposition of the weight matrices under different weight initializations. Dimensionality of the ANN’s weights was performed by measuring the participation ratio of the singular values. All statistical analyses were performed in Python version 3.8.5 using the NumPy (version 1.18.5) and SciPy (version 1.6.0) packages.</p><h3 class="c-article__sub-heading" id="Sec24">Reporting summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01224-0#MOESM1">Nature Portfolio Reporting Summary</a> linked to this article.</p></div></div></section>
                </div>
            

            <div>
                <section data-title="Data availability"><div class="c-article-section" id="data-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability">Data availability</h2><div class="c-article-section__content" id="data-availability-content">
              
              <p>All data in this study have been made publicly available on OpenNeuro by King and colleagues (accession number <a href="https://openneuro.org/datasets/ds002105/">ds002105</a> (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. Nat. Neurosci. 22, 1371–1378 (2019)." href="/articles/s41593-022-01224-0#ref-CR18" id="ref-link-section-d30627514e3206">18</a></sup>)).</p>
            </div></div></section><section data-title="Code availability"><div class="c-article-section" id="code-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="code-availability">Code availability</h2><div class="c-article-section__content" id="code-availability-content">
              
              <p>All code related to this study is publicly available on GitHub (<a href="https://github.com/murraylab/multitaskhierarchy">https://github.com/murraylab/multitaskhierarchy</a>). Analyses and models were implemented using Python (version 3.8.5). Cortical visualizations were implemented using workbench (version 1.5.0).</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Genon, S., Reid, A., Langner, R., Amunts, K. &amp; Eickhoff, S. B. How to characterize the function of a brain region. <i>Trends Cogn. Sci.</i> <b>22</b>, 350–364 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2018.01.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2018.01.010" aria-label="Article reference 1" data-doi="10.1016/j.tics.2018.01.010">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20to%20characterize%20the%20function%20of%20a%20brain%20region&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2018.01.010&amp;volume=22&amp;pages=350-364&amp;publication_year=2018&amp;author=Genon%2CS&amp;author=Reid%2CA&amp;author=Langner%2CR&amp;author=Amunts%2CK&amp;author=Eickhoff%2CSB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Poldrack, R. A. Inferring mental states from neuroimaging data: from reverse inference to large-scale decoding. <i>Neuron</i> <b>72</b>, 692–697 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2011.11.001" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2011.11.001" aria-label="Article reference 2" data-doi="10.1016/j.neuron.2011.11.001">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhs1Shtb%2FI" aria-label="CAS reference 2">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Inferring%20mental%20states%20from%20neuroimaging%20data%3A%20from%20reverse%20inference%20to%20large-scale%20decoding&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2011.11.001&amp;volume=72&amp;pages=692-697&amp;publication_year=2011&amp;author=Poldrack%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Gallant, J., Nishimoto, S., Naslaris, T. &amp; Wu, M. C. K. In <i>Visual Population Codes: Toward a Common Multivariate Framework for Cell Recording and Functional Imaging</i> (eds Kriegeskort N. &amp; Krieman G.) Ch. 6 (The MIT Press, 2011).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Kriegeskorte, N., Mur, M. &amp; Bandettini, P. Representational similarity analysis—connecting the branches of systems neuroscience. <i>Front. Syst. Neurosci.</i> <b>2</b>, 4 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Representational%20similarity%20analysis%E2%80%94connecting%20the%20branches%20of%20systems%20neuroscience&amp;journal=Front.%20Syst.%20Neurosci.&amp;volume=2&amp;publication_year=2008&amp;author=Kriegeskorte%2CN&amp;author=Mur%2CM&amp;author=Bandettini%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Khaligh-Razavi, S. M. &amp; Kriegeskorte, N. Deep supervised, but not unsupervised, models may explain IT cortical representation. <i>PLoS Comput. Biol.</i> <b>10</b>, e1003915 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1003915" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1003915" aria-label="Article reference 5" data-doi="10.1371/journal.pcbi.1003915">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20supervised%2C%20but%20not%20unsupervised%2C%20models%20may%20explain%20IT%20cortical%20representation&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1003915&amp;volume=10&amp;publication_year=2014&amp;author=Khaligh-Razavi%2CSM&amp;author=Kriegeskorte%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Kanwisher, N. Functional specificity in the human brain: a window into the functional architecture of the mind. <i>Proc. Natl Acad. Sci. USA</i> <b>107</b>, 11163–11170 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1005062107" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1005062107" aria-label="Article reference 6" data-doi="10.1073/pnas.1005062107">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXot1elu7k%3D" aria-label="CAS reference 6">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20specificity%20in%20the%20human%20brain%3A%20a%20window%20into%20the%20functional%20architecture%20of%20the%20mind&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1005062107&amp;volume=107&amp;pages=11163-11170&amp;publication_year=2010&amp;author=Kanwisher%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Curtis, C. E. &amp; D’Esposito, M. Persistent activity in the prefrontal cortex during working memory. <i>Trends Cogn. Sci.</i> <b>7</b>, 415–423 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S1364-6613(03)00197-9" data-track-action="article reference" href="https://doi.org/10.1016%2FS1364-6613%2803%2900197-9" aria-label="Article reference 7" data-doi="10.1016/S1364-6613(03)00197-9">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Persistent%20activity%20in%20the%20prefrontal%20cortex%20during%20working%20memory&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2FS1364-6613%2803%2900197-9&amp;volume=7&amp;pages=415-423&amp;publication_year=2003&amp;author=Curtis%2CCE&amp;author=D%E2%80%99Esposito%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Wandell, B. A. &amp; Winawer, J. Computational neuroimaging and population receptive fields. <i>Trends Cogn. Sci.</i> <b>19</b>, 349–357 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2015.03.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2015.03.009" aria-label="Article reference 8" data-doi="10.1016/j.tics.2015.03.009">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Computational%20neuroimaging%20and%20population%20receptive%20fields&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2015.03.009&amp;volume=19&amp;pages=349-357&amp;publication_year=2015&amp;author=Wandell%2CBA&amp;author=Winawer%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Arbuckle, S. A. et al. Structure of population activity in primary motor cortex for single finger flexion and extension. <i>J. Neurosci.</i> <b>40</b>, 9210–9223 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.0999-20.2020" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.0999-20.2020" aria-label="Article reference 9" data-doi="10.1523/JNEUROSCI.0999-20.2020">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXis1ehtbfP" aria-label="CAS reference 9">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Structure%20of%20population%20activity%20in%20primary%20motor%20cortex%20for%20single%20finger%20flexion%20and%20extension&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.0999-20.2020&amp;volume=40&amp;pages=9210-9223&amp;publication_year=2020&amp;author=Arbuckle%2CSA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Yeo, B. T. T. et al. Functional specialization and flexibility in human association cortex. <i>Cereb. Cortex</i> <b>25</b>, 3654–3672 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhu217" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhu217" aria-label="Article reference 10" data-doi="10.1093/cercor/bhu217">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20specialization%20and%20flexibility%20in%20human%20association%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhu217&amp;volume=25&amp;pages=3654-3672&amp;publication_year=2015&amp;author=Yeo%2CBTT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Smith, S. M. et al. Correspondence of the brain’s functional architecture during activation and rest. <i>Proc. Natl Acad. Sci. USA</i> <b>106</b>, 13040–13045 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.0905267106" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.0905267106" aria-label="Article reference 11" data-doi="10.1073/pnas.0905267106">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhtVKru7%2FJ" aria-label="CAS reference 11">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Correspondence%20of%20the%20brain%E2%80%99s%20functional%20architecture%20during%20activation%20and%20rest&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.0905267106&amp;volume=106&amp;pages=13040-13045&amp;publication_year=2009&amp;author=Smith%2CSM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. <i>Proc. Natl Acad. Sci. USA</i> <b>113</b>, 12574–12579 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1608282113" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1608282113" aria-label="Article reference 12" data-doi="10.1073/pnas.1608282113">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs1ykurnM" aria-label="CAS reference 12">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Situating%20the%20default-mode%20network%20along%20a%20principal%20gradient%20of%20macroscale%20cortical%20organization&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1608282113&amp;volume=113&amp;pages=12574-12579&amp;publication_year=2016&amp;author=Margulies%2CDS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. <i>Proc. Natl Acad. Sci. USA</i> <b>111</b>, 8619–8624 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1403112111" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1403112111" aria-label="Article reference 13" data-doi="10.1073/pnas.1403112111">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXnslWnsb4%3D" aria-label="CAS reference 13">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance-optimized%20hierarchical%20models%20predict%20neural%20responses%20in%20higher%20visual%20cortex&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1403112111&amp;volume=111&amp;pages=8619-8624&amp;publication_year=2014&amp;author=Yamins%2CDLK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Huth, A. G., Heer, W. A. D., Griffiths, T. L., Theunissen, F. E. &amp; Jack, L. Natural speech reveals the semantic maps that tile human cerebral cortex. <i>Nature</i> <b>532</b>, 453–458 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature17637" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature17637" aria-label="Article reference 14" data-doi="10.1038/nature17637">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Natural%20speech%20reveals%20the%20semantic%20maps%20that%20tile%20human%20cerebral%20cortex&amp;journal=Nature&amp;doi=10.1038%2Fnature17637&amp;volume=532&amp;pages=453-458&amp;publication_year=2016&amp;author=Huth%2CAG&amp;author=Heer%2CWAD&amp;author=Griffiths%2CTL&amp;author=Theunissen%2CFE&amp;author=Jack%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Naselaris, T., Allen, E. &amp; Kay, K. Extensive sampling for complete models of individual brains. <i>Curr. Opin. Behav. Sci.</i> <b>40</b>, 45–51 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cobeha.2020.12.008" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cobeha.2020.12.008" aria-label="Article reference 15" data-doi="10.1016/j.cobeha.2020.12.008">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Extensive%20sampling%20for%20complete%20models%20of%20individual%20brains&amp;journal=Curr.%20Opin.%20Behav.%20Sci.&amp;doi=10.1016%2Fj.cobeha.2020.12.008&amp;volume=40&amp;pages=45-51&amp;publication_year=2021&amp;author=Naselaris%2CT&amp;author=Allen%2CE&amp;author=Kay%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Yang, G. R., Cole, M. W. &amp; Rajan, K. How to study the neural mechanisms of multiple tasks. <i>Curr. Opin. Behav. Sci.</i> <b>29</b>, 134–143 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cobeha.2019.07.001" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cobeha.2019.07.001" aria-label="Article reference 16" data-doi="10.1016/j.cobeha.2019.07.001">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20to%20study%20the%20neural%20mechanisms%20of%20multiple%20tasks&amp;journal=Curr.%20Opin.%20Behav.%20Sci.&amp;doi=10.1016%2Fj.cobeha.2019.07.001&amp;volume=29&amp;pages=134-143&amp;publication_year=2019&amp;author=Yang%2CGR&amp;author=Cole%2CMW&amp;author=Rajan%2CK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Nakai, T. &amp; Nishimoto, S. Quantitative models reveal the organization of diverse cognitive functions in the brain. <i>Nat. Commun.</i> <b>11</b>, 1142 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-020-14913-w" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-020-14913-w" aria-label="Article reference 17" data-doi="10.1038/s41467-020-14913-w">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXkvFahtL0%3D" aria-label="CAS reference 17">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantitative%20models%20reveal%20the%20organization%20of%20diverse%20cognitive%20functions%20in%20the%20brain&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-020-14913-w&amp;volume=11&amp;publication_year=2020&amp;author=Nakai%2CT&amp;author=Nishimoto%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">King, M., Hernandez-Castillo, C. R., Poldrack, R. A., Ivry, R. B. &amp; Diedrichsen, J. Functional boundaries in the human cerebellum revealed by a multi-domain task battery. <i>Nat. Neurosci.</i> <b>22</b>, 1371–1378 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-019-0436-x" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-019-0436-x" aria-label="Article reference 18" data-doi="10.1038/s41593-019-0436-x">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXhtleis7nP" aria-label="CAS reference 18">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20boundaries%20in%20the%20human%20cerebellum%20revealed%20by%20a%20multi-domain%20task%20battery&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-019-0436-x&amp;volume=22&amp;pages=1371-1378&amp;publication_year=2019&amp;author=King%2CM&amp;author=Hernandez-Castillo%2CCR&amp;author=Poldrack%2CRA&amp;author=Ivry%2CRB&amp;author=Diedrichsen%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Bernhardt, B. C., Smallwood, J., Keilholz, S. &amp; Margulies, D. S. Gradients in brain organization. <i>NeuroImage</i> <b>251</b>, 118987 (2022).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2022.118987" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2022.118987" aria-label="Article reference 19" data-doi="10.1016/j.neuroimage.2022.118987">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Gradients%20in%20brain%20organization&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2022.118987&amp;volume=251&amp;publication_year=2022&amp;author=Bernhardt%2CBC&amp;author=Smallwood%2CJ&amp;author=Keilholz%2CS&amp;author=Margulies%2CDS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Ansuini, A., Laio, A., Macke, J. H. &amp; Zoccolan, D. Intrinsic dimension of data representations in deep neural networks. In <i>Advances in Neural Information Processing Systems</i> Vol. 32 (Curran Associates, Inc., 2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Recanatesi, S. et al. Dimensionality compression and expansion in deep neural networks. Preprint at <a href="https://doi.org/10.48550/arXiv.1906.00443" data-track="click" data-track-action="external reference" data-track-label="10.48550/arXiv.1906.00443">https://doi.org/10.48550/arXiv.1906.00443</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Rich and lazy learning of task representations in brains and neural networks. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2021.04.23.441128" data-track="click" data-track-action="external reference" data-track-label="10.1101/2021.04.23.441128">https://doi.org/10.1101/2021.04.23.441128</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Woodworth, B. et al. Kernel and rich regimes in overparametrized models. In <i>Conference on Learning Theory</i> 3635–3673 (PMLR, 2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Glasser, M. F. et al. A multi-modal parcellation of human cerebral cortex. <i>Nature</i> <b>536</b>, 171–178 (2016).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Power, J. D. et al. Functional network organization of the human brain. <i>Neuron</i> <b>72</b>, 665–678 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2011.09.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2011.09.006" aria-label="Article reference 25" data-doi="10.1016/j.neuron.2011.09.006">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhsV2rtrnN" aria-label="CAS reference 25">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20network%20organization%20of%20the%20human%20brain&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2011.09.006&amp;volume=72&amp;pages=665-678&amp;publication_year=2011&amp;author=Power%2CJD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. <i>J. Neurophysiol.</i> <b>106</b>, 1125–1165 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00338.2011" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00338.2011" aria-label="Article reference 26" data-doi="10.1152/jn.00338.2011">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20organization%20of%20the%20human%20cerebral%20cortex%20estimated%20by%20intrinsic%20functional%20connectivity&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00338.2011&amp;volume=106&amp;pages=1125-1165&amp;publication_year=2011&amp;author=Yeo%2CBT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Cole, M. W., Bassett, D. S., Power, J. D., Braver, T. S. &amp; Petersen, S. E. Intrinsic and task-evoked network architectures of the human brain. <i>Neuron</i> <b>83</b>, 238–251 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2014.05.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2014.05.014" aria-label="Article reference 27" data-doi="10.1016/j.neuron.2014.05.014">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhtFWgt7bL" aria-label="CAS reference 27">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Intrinsic%20and%20task-evoked%20network%20architectures%20of%20the%20human%20brain&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2014.05.014&amp;volume=83&amp;pages=238-251&amp;publication_year=2014&amp;author=Cole%2CMW&amp;author=Bassett%2CDS&amp;author=Power%2CJD&amp;author=Braver%2CTS&amp;author=Petersen%2CSE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Ji, J. L. et al. Mapping the human brain’s cortical–subcortical functional network organization. <i>NeuroImage</i> <b>185</b>, 35–57 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2018.10.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2018.10.006" aria-label="Article reference 28" data-doi="10.1016/j.neuroimage.2018.10.006">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Mapping%20the%20human%20brain%E2%80%99s%20cortical%E2%80%93subcortical%20functional%20network%20organization&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2018.10.006&amp;volume=185&amp;pages=35-57&amp;publication_year=2019&amp;author=Ji%2CJL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Huntenburg, J. M., Bazin, P. -L. &amp; Margulies, D. S. Large-scale gradients in human cortical organization. <i>Trends Cogn. Sci.</i> <b>22</b>, 21–31 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2017.11.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2017.11.002" aria-label="Article reference 29" data-doi="10.1016/j.tics.2017.11.002">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Large-scale%20gradients%20in%20human%20cortical%20organization&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2017.11.002&amp;volume=22&amp;pages=21-31&amp;publication_year=2018&amp;author=Huntenburg%2CJM&amp;author=Bazin%2CP-L&amp;author=Margulies%2CDS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Chan, M. Y., Park, D. C., Savalia, N. K., Petersen, S. E. &amp; Wig, G. S. Decreased segregation of brain systems across the healthy adult lifespan. <i>Proc. Natl Acad. Sci. USA</i> <b>111</b>, E4997–E5006 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1415122111" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1415122111" aria-label="Article reference 30" data-doi="10.1073/pnas.1415122111">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhvVGksbvP" aria-label="CAS reference 30">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Decreased%20segregation%20of%20brain%20systems%20across%20the%20healthy%20adult%20lifespan&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1415122111&amp;volume=111&amp;pages=E4997-E5006&amp;publication_year=2014&amp;author=Chan%2CMY&amp;author=Park%2CDC&amp;author=Savalia%2CNK&amp;author=Petersen%2CSE&amp;author=Wig%2CGS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Burt, J. B. et al. Hierarchy of transcriptomic specialization across human cortex captured by structural neuroimaging topography. <i>Nat. Neurosci.</i> <b>21</b>, 1251–1259 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-018-0195-0" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-018-0195-0" aria-label="Article reference 31" data-doi="10.1038/s41593-018-0195-0">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXhsVGis73M" aria-label="CAS reference 31">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Hierarchy%20of%20transcriptomic%20specialization%20across%20human%20cortex%20captured%20by%20structural%20neuroimaging%20topography&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-018-0195-0&amp;volume=21&amp;pages=1251-1259&amp;publication_year=2018&amp;author=Burt%2CJB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Glasser, M. F. &amp; Van Essen, D. C. Mapping human cortical areas in vivo based on myelin content as revealed by T1-and T2-weighted MRI. <i>J. Neurosci.</i> <b>31</b>, 11597–11616 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2180-11.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2180-11.2011" aria-label="Article reference 32" data-doi="10.1523/JNEUROSCI.2180-11.2011">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhtVOru7jJ" aria-label="CAS reference 32">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Mapping%20human%20cortical%20areas%20in%20vivo%20based%20on%20myelin%20content%20as%20revealed%20by%20T1-and%20T2-weighted%20MRI&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2180-11.2011&amp;volume=31&amp;pages=11597-11616&amp;publication_year=2011&amp;author=Glasser%2CMF&amp;author=Van%20Essen%2CDC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Badre, D., Bhandari, A., Keglovits, H. &amp; Kikumoto, A. The dimensionality of neural representations for control. <i>Curr. Opin. Behav. Sci.</i> <b>38</b>, 20–28 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cobeha.2020.07.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cobeha.2020.07.002" aria-label="Article reference 33" data-doi="10.1016/j.cobeha.2020.07.002">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20dimensionality%20of%20neural%20representations%20for%20control&amp;journal=Curr.%20Opin.%20Behav.%20Sci.&amp;doi=10.1016%2Fj.cobeha.2020.07.002&amp;volume=38&amp;pages=20-28&amp;publication_year=2021&amp;author=Badre%2CD&amp;author=Bhandari%2CA&amp;author=Keglovits%2CH&amp;author=Kikumoto%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Rigotti, M. et al. The importance of mixed selectivity in complex cognitive tasks. <i>Nature</i> <b>497</b>, 585–590 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature12160" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature12160" aria-label="Article reference 34" data-doi="10.1038/nature12160">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXotFSltbc%3D" aria-label="CAS reference 34">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20importance%20of%20mixed%20selectivity%20in%20complex%20cognitive%20tasks&amp;journal=Nature&amp;doi=10.1038%2Fnature12160&amp;volume=497&amp;pages=585-590&amp;publication_year=2013&amp;author=Rigotti%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Abbott, L. F., Rajan, K. &amp; Sompolinsky, H. In <i>The Dynamic Brain: An Exploration of Neuronal Variability and Its Functional Significance</i> (eds Ding M. &amp; Glanzman D.) 1–16 (Oxford University Press, 2011).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Gao, P. et al. A theory of multineuronal dimensionality, dynamics and measurement. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/214262" data-track="click" data-track-action="external reference" data-track-label="10.1101/214262">https://doi.org/10.1101/214262</a> (2017).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Recanatesi, S., Ocker, G. K., Buice, M. A. &amp; Shea-Brown, E. Dimensionality in recurrent spiking networks: global trends in activity and local origins in connectivity. <i>PLoS Comput. Biol.</i> <b>15</b>, e1006446 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1006446" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1006446" aria-label="Article reference 37" data-doi="10.1371/journal.pcbi.1006446">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXit1WmtrrF" aria-label="CAS reference 37">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Dimensionality%20in%20recurrent%20spiking%20networks%3A%20global%20trends%20in%20activity%20and%20local%20origins%20in%20connectivity&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1006446&amp;volume=15&amp;publication_year=2019&amp;author=Recanatesi%2CS&amp;author=Ocker%2CGK&amp;author=Buice%2CMA&amp;author=Shea-Brown%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Bhandari, A., Gagne, C. &amp; Badre, D. Just above chance: is it harder to decode information from prefrontal cortex hemodynamic activity patterns? <i>J. Cogn. Neurosci.</i> <b>30</b>, 1473–1498 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn_a_01291" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn_a_01291" aria-label="Article reference 38" data-doi="10.1162/jocn_a_01291">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Just%20above%20chance%3A%20is%20it%20harder%20to%20decode%20information%20from%20prefrontal%20cortex%20hemodynamic%20activity%20patterns%3F&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn_a_01291&amp;volume=30&amp;pages=1473-1498&amp;publication_year=2018&amp;author=Bhandari%2CA&amp;author=Gagne%2CC&amp;author=Badre%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Bassett, D. S. &amp; Bullmore, E. Small-world brain networks. <i>Neuroscientist</i> <b>12</b>, 512–523 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/1073858406293182" data-track-action="article reference" href="https://doi.org/10.1177%2F1073858406293182" aria-label="Article reference 39" data-doi="10.1177/1073858406293182">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Small-world%20brain%20networks&amp;journal=Neuroscientist&amp;doi=10.1177%2F1073858406293182&amp;volume=12&amp;pages=512-523&amp;publication_year=2006&amp;author=Bassett%2CDS&amp;author=Bullmore%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. <i>Cereb. Cortex</i> <b>1</b>, 1–47 (1991).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/1.1.1" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F1.1.1" aria-label="Article reference 40" data-doi="10.1093/cercor/1.1.1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK38zltlGmsg%3D%3D" aria-label="CAS reference 40">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20hierarchical%20processing%20in%20the%20primate%20cerebral%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F1.1.1&amp;volume=1&amp;pages=1-47&amp;publication_year=1991&amp;author=Felleman%2CDJ&amp;author=Essen%2CDC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Honey, C. J. et al. Slow cortical dynamics and the accumulation of information over long timescales. <i>Neuron</i> <b>76</b>, 423–434 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2012.08.011" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2012.08.011" aria-label="Article reference 41" data-doi="10.1016/j.neuron.2012.08.011">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XhsFClt7jN" aria-label="CAS reference 41">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Slow%20cortical%20dynamics%20and%20the%20accumulation%20of%20information%20over%20long%20timescales&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2012.08.011&amp;volume=76&amp;pages=423-434&amp;publication_year=2012&amp;author=Honey%2CCJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Ito, T., Hearne, L. J. &amp; Cole, M. W. A cortical hierarchy of localized and distributed processes revealed via dissociation of task activations, connectivity changes, and intrinsic timescales. <i>NeuroImage</i> <b>221</b>, 117141 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2020.117141" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2020.117141" aria-label="Article reference 42" data-doi="10.1016/j.neuroimage.2020.117141">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20cortical%20hierarchy%20of%20localized%20and%20distributed%20processes%20revealed%20via%20dissociation%20of%20task%20activations%2C%20connectivity%20changes%2C%20and%20intrinsic%20timescales&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2020.117141&amp;volume=221&amp;publication_year=2020&amp;author=Ito%2CT&amp;author=Hearne%2CLJ&amp;author=Cole%2CMW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Cole, M. W. et al. Multi-task connectivity reveals flexible hubs for adaptive task control. <i>Nat. Neurosci.</i> <b>16</b>, 1348–1355 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3470" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3470" aria-label="Article reference 43" data-doi="10.1038/nn.3470">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhtFOhs7bJ" aria-label="CAS reference 43">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-task%20connectivity%20reveals%20flexible%20hubs%20for%20adaptive%20task%20control&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3470&amp;volume=16&amp;pages=1348-1355&amp;publication_year=2013&amp;author=Cole%2CMW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">van den Heuvel, M. P. &amp; Sporns, O. Network hubs in the human brain. <i>Trends Cogn. Sci.</i> <b>17</b>, 683–696 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2013.09.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2013.09.012" aria-label="Article reference 44" data-doi="10.1016/j.tics.2013.09.012">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Network%20hubs%20in%20the%20human%20brain&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2013.09.012&amp;volume=17&amp;pages=683-696&amp;publication_year=2013&amp;author=Heuvel%2CMP&amp;author=Sporns%2CO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">Shine, J. M. et al. Human cognition involves the dynamic integration of neural activity and neuromodulatory systems. <i>Nat. Neurosci.</i> <b>22</b>, 289 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-018-0312-0" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-018-0312-0" aria-label="Article reference 45" data-doi="10.1038/s41593-018-0312-0">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXmtF2jtbY%3D" aria-label="CAS reference 45">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20cognition%20involves%20the%20dynamic%20integration%20of%20neural%20activity%20and%20neuromodulatory%20systems&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-018-0312-0&amp;volume=22&amp;publication_year=2019&amp;author=Shine%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Bernardi, S. et al. The geometry of abstraction in the hippocampus and prefrontal cortex. <i>Cell</i> <b>183</b>, 954–967 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cell.2020.09.031" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2020.09.031" aria-label="Article reference 46" data-doi="10.1016/j.cell.2020.09.031">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXitFSnsrfF" aria-label="CAS reference 46">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20geometry%20of%20abstraction%20in%20the%20hippocampus%20and%20prefrontal%20cortex&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2020.09.031&amp;volume=183&amp;pages=954-967&amp;publication_year=2020&amp;author=Bernardi%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Orthogonal representations for robust context-dependent task performance in brains and neural networks. <i>Neuron</i> <b>110</b>, 1258–1270 (2022).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2022.01.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2022.01.005" aria-label="Article reference 47" data-doi="10.1016/j.neuron.2022.01.005">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB38XitV2rsr8%3D" aria-label="CAS reference 47">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Orthogonal%20representations%20for%20robust%20context-dependent%20task%20performance%20in%20brains%20and%20neural%20networks&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2022.01.005&amp;volume=110&amp;pages=1258-1270&amp;publication_year=2022&amp;author=Flesch%2CT&amp;author=Juechems%2CK&amp;author=Dumbalska%2CT&amp;author=Saxe%2CA&amp;author=Summerfield%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Ito, T. et al. Compositional generalization through abstract representations in human and artificial neural networks. Preprint at <a href="https://doi.org/10.48550/arXiv.2209.07431" data-track="click" data-track-action="external reference" data-track-label="10.48550/arXiv.2209.07431">https://doi.org/10.48550/arXiv.2209.07431</a> (2022).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Cole, M. W., Laurent, P. &amp; Stocco, A. Rapid instructed task learning: a new window into the human brain’s unique capacity for flexible cognitive control. <i>Cogn. Affect. Behav. Neurosci.</i> <b>13</b>, 1–22 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/s13415-012-0125-7" data-track-action="article reference" href="https://doi.org/10.3758%2Fs13415-012-0125-7" aria-label="Article reference 49" data-doi="10.3758/s13415-012-0125-7">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Rapid%20instructed%20task%20learning%3A%20a%20new%20window%20into%20the%20human%20brain%E2%80%99s%20unique%20capacity%20for%20flexible%20cognitive%20control&amp;journal=Cogn.%20Affect.%20Behav.%20Neurosci.&amp;doi=10.3758%2Fs13415-012-0125-7&amp;volume=13&amp;pages=1-22&amp;publication_year=2012&amp;author=Cole%2CMW&amp;author=Laurent%2CP&amp;author=Stocco%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">van Bergen, R. S. &amp; Kriegeskorte, N. Going in circles is the way forward: the role of recurrence in visual inference. <i>Curr. Opin. Neurobiol.</i> <b>65</b>, 176–193 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.conb.2020.11.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2020.11.009" aria-label="Article reference 50" data-doi="10.1016/j.conb.2020.11.009">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Going%20in%20circles%20is%20the%20way%20forward%3A%20the%20role%20of%20recurrence%20in%20visual%20inference&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2020.11.009&amp;volume=65&amp;pages=176-193&amp;publication_year=2020&amp;author=Bergen%2CRS&amp;author=Kriegeskorte%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Kar, K., Kubilius, J., Schmidt, K., Issa, E. B. &amp; DiCarlo, J. J. Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior. <i>Nat. Neurosci.</i> <b>22</b>, 974–983 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-019-0392-5" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-019-0392-5" aria-label="Article reference 51" data-doi="10.1038/s41593-019-0392-5">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXos1SktLk%3D" aria-label="CAS reference 51">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Evidence%20that%20recurrent%20circuits%20are%20critical%20to%20the%20ventral%20stream%E2%80%99s%20execution%20of%20core%20object%20recognition%20behavior&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-019-0392-5&amp;volume=22&amp;pages=974-983&amp;publication_year=2019&amp;author=Kar%2CK&amp;author=Kubilius%2CJ&amp;author=Schmidt%2CK&amp;author=Issa%2CEB&amp;author=DiCarlo%2CJJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Yang, G. R., Joglekar, M. R., Song, H. F., Newsome, W. T. &amp; Wang, X. -J. Task representations in neural networks trained to perform many cognitive tasks. <i>Nat. Neurosci</i>. <b>22</b>, 297–306 (2019).<a href="https://doi.org/10.1038/s41593-018-0310-2" data-track="click" data-track-action="external reference" data-track-label="10.1038/s41593-018-0310-2">https://doi.org/10.1038/s41593-018-0310-2</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Shahbazi, M., Shirali, A., Aghajan, H. &amp; Nili, H. Using distance on the Riemannian manifold to compare representations in brain and in models. <i>NeuroImage</i> <b>239</b>, 118271 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2021.118271" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2021.118271" aria-label="Article reference 53" data-doi="10.1016/j.neuroimage.2021.118271">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20distance%20on%20the%20Riemannian%20manifold%20to%20compare%20representations%20in%20brain%20and%20in%20models&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2021.118271&amp;volume=239&amp;publication_year=2021&amp;author=Shahbazi%2CM&amp;author=Shirali%2CA&amp;author=Aghajan%2CH&amp;author=Nili%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54."><p class="c-article-references__text" id="ref-CR54">Williams, A. H., Kunz, E., Kornblith, S. &amp; Linderman, S. W. Generalized shape metrics on neural representations. Preprint at <a href="https://doi.org/10.48550/arXiv.2110.14739" data-track="click" data-track-action="external reference" data-track-label="10.48550/arXiv.2110.14739">https://doi.org/10.48550/arXiv.2110.14739</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55."><p class="c-article-references__text" id="ref-CR55">Zhi, D., King, M., Hernandez-Castillo, C. R. &amp; Diedrichsen, J. Evaluating brain parcellations using the distance-controlled boundary coefficient. <i>Hum. Brain Mapp</i>. <b>43</b>, 3706–3720 (2022).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56."><p class="c-article-references__text" id="ref-CR56">Glasser, M. F. et al. The minimal preprocessing pipelines for the Human Connectome Project. <i>NeuroImage</i> <b>80</b>, 105–124 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2013.04.127" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2013.04.127" aria-label="Article reference 56" data-doi="10.1016/j.neuroimage.2013.04.127">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20minimal%20preprocessing%20pipelines%20for%20the%20Human%20Connectome%20Project&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2013.04.127&amp;volume=80&amp;pages=105-124&amp;publication_year=2013&amp;author=Glasser%2CMF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57."><p class="c-article-references__text" id="ref-CR57">Ji, J. L. et al. QuNex—a scalable platform for integrative multi-modal neuroimaging data processing and analysis. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2022.06.03.494750" data-track="click" data-track-action="external reference" data-track-label="10.1101/2022.06.03.494750">https://doi.org/10.1101/2022.06.03.494750</a> (2022).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58."><p class="c-article-references__text" id="ref-CR58">Ito, T. et al. Task-evoked activity quenches neural correlations and variability across cortical areas. <i>PLoS Comput. Biol.</i> <b>16</b>, e1007983 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1007983" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1007983" aria-label="Article reference 58" data-doi="10.1371/journal.pcbi.1007983">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhs1anurbN" aria-label="CAS reference 58">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Task-evoked%20activity%20quenches%20neural%20correlations%20and%20variability%20across%20cortical%20areas&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1007983&amp;volume=16&amp;publication_year=2020&amp;author=Ito%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59."><p class="c-article-references__text" id="ref-CR59">Ciric, R. et al. Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity. <i>NeuroImage</i> <b>154</b>, 174–187 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2017.03.020" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2017.03.020" aria-label="Article reference 59" data-doi="10.1016/j.neuroimage.2017.03.020">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 59" href="http://scholar.google.com/scholar_lookup?&amp;title=Benchmarking%20of%20participant-level%20confound%20regression%20strategies%20for%20the%20control%20of%20motion%20artifact%20in%20studies%20of%20functional%20connectivity&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2017.03.020&amp;volume=154&amp;pages=174-187&amp;publication_year=2017&amp;author=Ciric%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60."><p class="c-article-references__text" id="ref-CR60">Glasser, M. F. et al. The Human Connectome Project’s neuroimaging approach. <i>Nat. Neurosci.</i> <b>19</b>, 1175–1187 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4361" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4361" aria-label="Article reference 60" data-doi="10.1038/nn.4361">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 60" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Human%20Connectome%20Project%E2%80%99s%20neuroimaging%20approach&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4361&amp;volume=19&amp;pages=1175-1187&amp;publication_year=2016&amp;author=Glasser%2CMF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61."><p class="c-article-references__text" id="ref-CR61">Rissman, J., Gazzaley, A. &amp; D’Esposito, M. Measuring functional connectivity during distinct stages of a cognitive task. <i>NeuroImage</i> <b>23</b>, 752–763 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2004.06.035" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2004.06.035" aria-label="Article reference 61" data-doi="10.1016/j.neuroimage.2004.06.035">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 61" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20functional%20connectivity%20during%20distinct%20stages%20of%20a%20cognitive%20task&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2004.06.035&amp;volume=23&amp;pages=752-763&amp;publication_year=2004&amp;author=Rissman%2CJ&amp;author=Gazzaley%2CA&amp;author=D%E2%80%99Esposito%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62."><p class="c-article-references__text" id="ref-CR62">Friston, K. J. et al. Statistical parametric maps in functional imaging: a general linear approach. <i>Hum. Brain Mapp.</i> <b>2</b>, 189–210 (1994).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/hbm.460020402" data-track-action="article reference" href="https://doi.org/10.1002%2Fhbm.460020402" aria-label="Article reference 62" data-doi="10.1002/hbm.460020402">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Statistical%20parametric%20maps%20in%20functional%20imaging%3A%20a%20general%20linear%20approach&amp;journal=Hum.%20Brain%20Mapp.&amp;doi=10.1002%2Fhbm.460020402&amp;volume=2&amp;pages=189-210&amp;publication_year=1994&amp;author=Friston%2CKJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63."><p class="c-article-references__text" id="ref-CR63">Schaefer, A. et al. Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI. <i>Cereb. Cortex</i> <b>28</b>, 3095–3114 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhx179" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhx179" aria-label="Article reference 63" data-doi="10.1093/cercor/bhx179">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="http://scholar.google.com/scholar_lookup?&amp;title=Local-global%20parcellation%20of%20the%20human%20cerebral%20cortex%20from%20intrinsic%20functional%20connectivity%20MRI&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhx179&amp;volume=28&amp;pages=3095-3114&amp;publication_year=2018&amp;author=Schaefer%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="64."><p class="c-article-references__text" id="ref-CR64">Abdollahi, R. O. et al. Correspondences between retinotopic areas and myelin maps in human visual cortex. <i>NeuroImage</i> <b>99</b>, 509–524 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2014.06.042" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2014.06.042" aria-label="Article reference 64" data-doi="10.1016/j.neuroimage.2014.06.042">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=Correspondences%20between%20retinotopic%20areas%20and%20myelin%20maps%20in%20human%20visual%20cortex&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2014.06.042&amp;volume=99&amp;pages=509-524&amp;publication_year=2014&amp;author=Abdollahi%2CRO">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="65."><p class="c-article-references__text" id="ref-CR65">Bobadilla-Suarez, S., Ahlheim, C., Mehrotra, A., Panos, A. &amp; Love, B. C. Measures of neural similarity. <i>Comput. Brain Behav.</i> <b>3</b>, 369–383 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1007/s42113-019-00068-5" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s42113-019-00068-5" aria-label="Article reference 65" data-doi="10.1007/s42113-019-00068-5">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BB3s3ot1yitg%3D%3D" aria-label="CAS reference 65">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=Measures%20of%20neural%20similarity&amp;journal=Comput.%20Brain%20Behav.&amp;doi=10.1007%2Fs42113-019-00068-5&amp;volume=3&amp;pages=369-383&amp;publication_year=2020&amp;author=Bobadilla-Suarez%2CS&amp;author=Ahlheim%2CC&amp;author=Mehrotra%2CA&amp;author=Panos%2CA&amp;author=Love%2CBC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="66."><p class="c-article-references__text" id="ref-CR66">Walther, A. et al. Reliability of dissimilarity measures for multi-voxel pattern analysis. <i>NeuroImage</i> <b>137</b>, 188–200 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2015.12.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2015.12.012" aria-label="Article reference 66" data-doi="10.1016/j.neuroimage.2015.12.012">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="http://scholar.google.com/scholar_lookup?&amp;title=Reliability%20of%20dissimilarity%20measures%20for%20multi-voxel%20pattern%20analysis&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2015.12.012&amp;volume=137&amp;pages=188-200&amp;publication_year=2016&amp;author=Walther%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="67."><p class="c-article-references__text" id="ref-CR67">Basti, A., Nili, H., Hauk, O., Marzetti, L. &amp; Henson, R. N. Multi-dimensional connectivity: a conceptual and mathematical review. <i>NeuroImage</i> <b>221</b>, 117179 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2020.117179" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2020.117179" aria-label="Article reference 67" data-doi="10.1016/j.neuroimage.2020.117179">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=Multi-dimensional%20connectivity%3A%20a%20conceptual%20and%20mathematical%20review&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2020.117179&amp;volume=221&amp;publication_year=2020&amp;author=Basti%2CA&amp;author=Nili%2CH&amp;author=Hauk%2CO&amp;author=Marzetti%2CL&amp;author=Henson%2CRN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="68."><p class="c-article-references__text" id="ref-CR68">Burt, J. B., Helmer, M., Shinn, M., Anticevic, A. &amp; Murray, J. D. Generative modeling of brain maps with spatial autocorrelation. <i>NeuroImage</i> <b>220</b>, 117038 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2020.117038" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2020.117038" aria-label="Article reference 68" data-doi="10.1016/j.neuroimage.2020.117038">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=Generative%20modeling%20of%20brain%20maps%20with%20spatial%20autocorrelation&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2020.117038&amp;volume=220&amp;publication_year=2020&amp;author=Burt%2CJB&amp;author=Helmer%2CM&amp;author=Shinn%2CM&amp;author=Anticevic%2CA&amp;author=Murray%2CJD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="69."><p class="c-article-references__text" id="ref-CR69">Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In <i>Proceedings of the 13th International Conference on Artificial Intelligence and Statistics</i> 249–256 (JMLR Workshop and Conference Proceedings, 2010).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="70."><p class="c-article-references__text" id="ref-CR70">Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. Preprint at <a href="https://doi.org/10.48550/arXiv.1412.6980" data-track="click" data-track-action="external reference" data-track-label="10.48550/arXiv.1412.6980">https://doi.org/10.48550/arXiv.1412.6980</a> (2015).</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-022-01224-0?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>This project was supported by NIH grant R01MH112746 (J.D.M.), NSF NeuroNex grant 2015276 (J.D.M.) and a Swartz Foundation Fellowship (T.I.). We acknowledge the Yale Center for Research Computing at Yale University for providing access to the Grace cluster and associated research computing resources. We thank M. King, J. Diedrichsen and colleagues for providing public access to the dataset. We also thank W. Pettine, M. Helmer and J. Miller for comments on earlier drafts of the manuscript.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Psychiatry, Yale School of Medicine, New Haven, CT, USA</p><p class="c-article-author-affiliation__authors-list">Takuya Ito &amp; John D. Murray</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Neuroscience, Yale School of Medicine, New Haven, CT, USA</p><p class="c-article-author-affiliation__authors-list">John D. Murray</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Department of Physics, Yale University, New Haven, CT, USA</p><p class="c-article-author-affiliation__authors-list">John D. Murray</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Takuya-Ito-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Takuya Ito</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Takuya%20Ito" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Takuya%20Ito" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Takuya%20Ito%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-John_D_-Murray-Aff1-Aff2-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">John D. Murray</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=John%20D.%20Murray" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=John%20D.%20Murray" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22John%20D.%20Murray%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>T.I. and J.D.M. conceptualized the project and wrote the paper. T.I. performed the formal analysis and visualization, developed software and wrote the original draft. J.D.M. acquired funding and supervised the project.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:john.murray@yale.edu">John D. Murray</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar4">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div class="c-article-section" id="peer-review-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="peer-review">Peer review</h2><div class="c-article-section__content" id="peer-review-content">
              
              
                <h3 class="c-article__sub-heading" id="FPar3">Peer review information</h3>
                <p><i>Nature Neuroscience</i> thanks Matthew Farrell, Lucina Uddin, and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Extended data"><div class="c-article-section" id="Sec26-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec26">Extended data</h2><div class="c-article-section__content" id="Sec26-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig9"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 1 whole-cortex group activation" href="/articles/s41593-022-01224-0/figures/9" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig9_ESM.jpg">Extended Data Fig. 1 Whole-cortex group activation maps for all 26 cognitive tasks.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Activation maps reflect the GLM beta values and were averaged across conditions within each task.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig10"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 2 comparing segregation of whol" href="/articles/s41593-022-01224-0/figures/10" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig10_ESM.jpg">Extended Data Fig. 2 Comparing segregation of whole-cortex RSFC and RA between unimodal-transmodal areas and functional networks.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a, b)</b> Force-directed graphs comparing RSFC and RA community structure (color-coated by functional networks). <b>c)</b> Segregation of RSFC and <b>d)</b> RA whole-cortex matrices (<i>n</i> = 144 unimodal, <i>n</i> = 246 transmodal). <b>e)</b> The direct comparison of differences in segregation between RA and RSFC for unimodal and transmodal regions (same as Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3h</a>). (Panels <b>c-e</b> are two-sided t-tests.) <b>f, g)</b> Association of regional RA segregation with the cortical myelin map (T1w/T2w structural map). <b>h)</b> Segregation of RSFC by functional networks. <b>i)</b> Segregation of RA by functional networks. Note that for both RA and RSFC, sensorimotor networks have higher segregation than association networks. Boxplot bounds define the 1st and 3rd quartiles of the distribution, box whiskers the 95% confidence interval, and the center line indicates the median. Network key: VIS1 = Visual 1 (<i>n</i> = 6); VIS2 = Visual 2 (<i>n</i> = 54); SMN = Somatomotor (<i>n</i> = 39); VMM = Ventral multimodal (<i>n</i> = 6); AUD = Auditory (<i>n</i> = 15); DAN = Dorsal attention (<i>n</i> = 23); DMN = Default mode (<i>n</i> = 77); CON = Cingulo-opercular (<i>n</i> = 56); PMM = Posterior multimodal (<i>n</i> = 7); FPN = Frontoparietal (<i>n</i> = 50); LAN = Language (<i>n</i> = 23); ORA = Orbital-affective (<i>n</i> = 4). Colors of each network correspond to colors in panel Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig3">3e</a>. (***p = &lt;0.0001, two-sided t-test.).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig11"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 3 representational dimensionali" href="/articles/s41593-022-01224-0/figures/11" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig11_ESM.jpg">Extended Data Fig. 3 Representational dimensionality and multi-task decoding produce similar associations with intrinsic hierarchy, even after controlling for parcel size.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a)</b> Correlation of multi-task decoding with the principal RSFC gradient and myelin map across regions. <b>b)</b> Parcel size (number of vertices within a brain region) and representational dimensionality were positively correlated (r = 0.45, non-parametric p &lt; 0.001). However, after accounting for parcel size (that is, the number of vertices within each parcel) as a covariate (via linear regression), a strong association between decodability and intrinsic hierarchy was maintained. <b>c)</b> Same analysis as in panel <b>b</b>, but using representational dimensionality rather than decodability. All correlations in a, b, and c resulted in a non-parametric p &lt; 0.001 using surrogate brain maps that accounted for spatial autocorrelation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Burt, J. B., Helmer, M., Shinn, M., Anticevic, A. &amp; Murray, J. D. Generative modeling of brain maps with spatial autocorrelation. NeuroImage 220, 117038 (2020)." href="/articles/s41593-022-01224-0#ref-CR68" id="ref-link-section-d30627514e3385">68</a></sup>. This suggests that the association between representational dimensionality and intrinsic hierarchy is independent of parcel size. Error bands reflect a 95% confidence interval.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig12"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 4 random subsamples of the task" href="/articles/s41593-022-01224-0/figures/12" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig12_ESM.jpg">Extended Data Fig. 4 Random subsamples of the task set show similar association with both the unimodal-transmodal and the sensorimotor hierarchy.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a)</b> The association between representational dimensionality and the principal RSFC gradient (unimodal-transmodal hierarchy) with the entire task set. <b>b)</b> We randomly sub-sampled (without replacement) tasks to downsize the RSMs of all parcels, and then measured the correlation between representational dimensionality and RSFC gradient 1. For each sub-sample size, we repeatedly chose (that is, 45 choose n) 20 times to estimate the robustness of the association with arbitrary selection of tasks. The association increased and stabilized as we increased the number of tasks (<i>n</i> = 20). <b>c)</b> Same as in <b>b</b>, but using the myelin map. <b>d)</b> The compression-then-expansion fit of representational dimensionality and the sensorimotor (RSFC gradient 2) hierarchy. <b>e)</b> We estimated the 2nd-order polynomial fit for randomly sub-sampled tasks, and assessed the coefficient of 2nd-order polynomial fit. The higher (and more positive) the parameter, the more convex the compression-then-expansion was. Increased compression-then-expansion as the number of randomly sampled tasks were included (<i>n</i> = 20 random subsamples). <b>f)</b> Same procedure as <b>e</b>, but measuring the R-squared of the polynomial fit rather than the 2nd-order coefficient term. Boxplot bounds define the 1st and 3rd quartiles of the distribution, box whiskers the 95% confidence interval, and the center line indicates the median. Error bands reflect a 95% confidence interval in panels <b>a</b> and <b>d</b>.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig13"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 5 establishing compression-then" href="/articles/s41593-022-01224-0/figures/13" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig13_ESM.jpg">Extended Data Fig. 5 Establishing compression-then-expansion of representational dimensionality across the sensory-motor hierarchy via model adjudication.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a)</b> We fit the representational dimensionality of parcels across the sensory-motor RSFC gradient using three competing models: Quadratic (2nd-order polynomial), linear, and an exponential decay model, where separate models were fit for loadings less than and greater than 0. <b>b)</b> The Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) for all models, which takes into account the maximum likelihood of each model while penalizing the models with more free parameters. Quadratic models had the smallest values for both AIC and BIC. <b>c,d)</b> Same as panels <b>a</b> and <b>b</b>, but using the RA principal gradient. Quadratic models were defined as <span class="mathjax-tex">\(y = \beta _0 + \beta _1x + \beta _2x^2 + {\it{\epsilon }}\)</span>. Linear models were defined as <span class="mathjax-tex">\(y = \beta _0 + \beta _1x + {\it{\epsilon }}\)</span>. Exponential decay models were defined as <span class="mathjax-tex">\(y\left( t \right) = N_0e^{ - \lambda t} + {\it{\epsilon }}\)</span>.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig14"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 6 supplemental information on a" href="/articles/s41593-022-01224-0/figures/14" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig14_ESM.jpg">Extended Data Fig. 6 Supplemental information on ANN modeling during rich and lazy training regimes.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The similarity between <b>a)</b> the RSMs for V1 and the gradient-identified input parcel for model construction and <b>b)</b> the RSMs for M1 and the gradient-selected motor output parcel. Overall, the representational geometries were highly similar between V1 and the input RSM, and M1 and the motor output RSM. <b>d)</b> The training cost (that is, number of training epochs required) for different weight initializations. Visualization of RSMs for example ANNs (one initialization each) for <b>e)</b> rich, <b>f)</b> intermediate (that is, initialization SD = 1.0), and <b>g)</b> lazy training regimes. <b>h-j)</b> Characterizing the structural network mechanisms that give rise to differences in representational structure across learning regimes in the ANN. <b>h)</b> Initialized and trained norm of ANN weights as a function of weight initialization. In line with previous work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Flesch, T., Juechems, K., Dumbalska, T., Saxe, A. &amp; Summerfield, C. Orthogonal representations for robust context-dependent task performance in brains and neural networks. Neuron 110, 1258–1270 (2022)." href="/articles/s41593-022-01224-0#ref-CR47" id="ref-link-section-d30627514e3739">47</a></sup>, the Frobenius norm of the trained ANN, which reflects the variability of the hidden weight projections, were significantly smaller in the rich training regime. <b>i)</b> The kurtosis of the degree distribution during initialization and after training. The kurtosis of the weight distribution measures the tailedness of the weight distribution. Kurtosis (in terms of connectivity weights) reflects the small-worldness of a network, a well-documented feature in empirical brain networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Bassett, D. S. &amp; Bullmore, E. Small-world brain networks. Neuroscientist 12, 512–523 (2006)." href="/articles/s41593-022-01224-0#ref-CR39" id="ref-link-section-d30627514e3746">39</a></sup>. The kurtosis of richly trained networks was higher than in lazily trained networks, producing a heavy-tailed weight distribution. <b>j)</b> We characterized the dimensionality of the ANN weights to gain insight into the successive representational transformations in the ANN across 20 initializations per weight distribution (<i>n</i> = 20). Weight dimensionality was computed by performing a singular value decomposition (SVD) on the weights, and then calculating the participation ratio of the singular values. The dimensionality of the learned weights directly constrains the representations the ANNs produce. Low-dimensionality of the connectivity weights likely aids in cross-task generalization, since low-dimensional connections force the network to extract shared components across tasks. Weight dimensionality was lower in rich training regimes. These findings suggest that across layers, richly trained ANNs with low-dimensional and low-variability weights collectively produced modular patterns of representations across layers, consistent with empirical data. Boxplot bounds define the 1st and 3rd quartiles of the distribution, box whiskers the 95% confidence interval, and the center line indicates the median.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig15"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 7 training an ann with untied w" href="/articles/s41593-022-01224-0/figures/15" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig15_ESM.jpg">Extended Data Fig. 7 Training an ANN with untied weights results in qualitatively similar results.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>We trained a 5-layer ANN with untied weights to produce qualitatively similar results to the ANN in the main manuscript. We reduced the number of layers from 10 to 5 and the number of hidden units from 500 to 250 for computational efficiency. (An ANN with untied weights has significantly greater parameters than one with tied weights.) <b>a)</b> Representational dimensionality of ANN layers for different weight initializations. <b>b)</b> ANN architecture. <b>c)</b> Richly trained ANNs had significantly higher similarity with representations found in empirical data relative to lazily trained ANNs (<i>n</i> = 20). <b>d)</b> Similarity to fMRI data by layer (rich minus lazy ANNs) (<i>n</i> = 20). <b>e)</b> Representational alignment of each ANN’s layer (cosine similarity between RSMs). <b>f)</b> Overall similarity of representations across ANN layers. Greater representational dissimilarity (across layers) is found in richly trained ANNs (<i>n</i> = 20). <b>g)</b> Variance explained of the first principal component for each of the RA matrices in panel <b>e</b> (<i>n</i> = 20). <b>h)</b> Frobenius norm of the weight distribution across initializations. <b>i)</b> The kurtosis (tailedness) of the weight distribution across layers under different weight initialization schemes. <b>j)</b> SVD of ANN weights. <b>k)</b> Dimensionality (participation ratio) of the weights for different initializations (<i>n</i> = 20). Richer training regimes produce low-dimensional weights. Boxplot bounds define the 1st and 3rd quartiles of the distribution, box whiskers the 95% confidence interval, and the center line indicates the median. (***p &lt; 0.0001, two-sided t-test.).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig16"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 8 using standard stochastic gra" href="/articles/s41593-022-01224-0/figures/16" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig16_ESM.jpg">Extended Data Fig. 8 Using standard stochastic gradient descent (without momentum/weight decay) with tied weights also produces qualitatively similar results.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>To explore the impact of model optimization and network size on the learned representations in ANNs, we trained a 5-layer ANN to produce qualitatively similar results to the ANN in the main manuscript (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig6">6</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig7">7</a>). We reduced the number of layers from 10 to 5 for computational efficiency. Instead of using the Adam optimizer (with a learning rate of 0.0001), we used standard stochastic gradient descent with a learning rate of 0.01. (Note that smaller learning rates were highly computationally intractable for learning in the rich training regime.) We did not include model initializations with SD &gt; 1.4 due to exploding gradients. <b>a)</b> Representational dimensionality of ANN layers for different weight initializations. <b>b)</b> ANN architecture. <b>c)</b> Richly trained ANNs had significantly higher similarity with representations found in empirical data relative to lazily trained ANNs (rich&gt;1.0, lazy&lt;1.0) (<i>n</i> = 20). <b>d)</b> Similarity to fMRI data by layer (rich minus lazy ANNs) (<i>n</i> = 20). <b>e)</b> Representational alignment of each ANN’s layer (cosine similarity between RSMs). <b>f)</b> Overall similarity of representations across ANN layers (<i>n</i> = 20). Greater representational dissimilarity (across layers) is found in richly trained ANNs. <b>g)</b> Cumulative variance explained of the first three principal components for each of the RA matrices in panel <b>e</b>. <b>h)</b> Dimensionality (participation ratio) of the learned connectivity weights for different initializations (<i>n</i> = 20). <b>i)</b> Average training cost by weight initialization. Boxplot bounds define the 1st and 3rd quartiles of the distribution, box whiskers the 95% confidence interval, and the center line indicates the median. (**p &lt; 0.001, two-sided t-test.).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig17"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 9 the importance of within-subj" href="/articles/s41593-022-01224-0/figures/17" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig17_ESM.jpg">Extended Data Fig. 9 The importance of within-subject analyses to capture fine-grained representational patterns.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a)</b> Representational dimensionality across the cortical surface when computing dimensionality using the group-averaged RSM (rather than subject-specific RSM). <b>b)</b> We computed the correlation between representational dimensionality with two proxies of the unimodal-transmodal hierarchy: RSFC principal gradient and the myelin map (T1w/T2w contrast). We find that when calculating dimensionality from RSMs derived from group-level activation averages, the association with the unimodal-transmodal hierarchy is significantly reduced. <b>c)</b> We subsequently measured dimensionality across the sensory-association-motor systems, finding that in contrast to within-subject estimates of representational dimensionality, we no longer observed the dimensionality compression from sensory to association systems in group-derived maps (sensory, <i>n</i> = 75; association, <i>n</i> = 246; motor, <i>n</i> = 39). <b>d)</b> Representational dimensionality measured using individual RSMs. (Same as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig4">4b</a>, for visual comparison.) <b>e)</b> Dimensionality across the sensory-association-motor hierarchy using dimensionality computed from individual RSMs (same as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01224-0#Fig5">5g</a>, for visual comparison). Boxplot bounds define the 1st and 3rd quartiles of the distribution, box whiskers the 95% confidence interval, and the center line indicates the median. (***p &lt; 0.0001, *p &lt; 0.05, two-sided t-test.).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig18"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 10 corroborating evidence of th" href="/articles/s41593-022-01224-0/figures/18" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_Fig18_ESM.jpg">Extended Data Fig. 10 Corroborating evidence of the sensory-association-motor axis of hierarchical organization extracted using non-negative matrix factorization (NMF).</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>This revealed that the sensory-to-motor hierarchy was robust to different matrix decomposition algorithms. <b>a)</b> The first component extracted using PCA and <b>b)</b> NMF. <b>c)</b> Correlation between the first components extracted with PCA and NMF. <b>d)</b> Correlation of RA gradient 1 (NMF) with the RSFC sensorimotor hierarchy (RSFC gradient 2).</p></div></div></div></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec27-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec27">Supplementary information</h2><div class="c-article-section__content" id="Sec27-content"><div data-test="supplementary-info"><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="reporting summary" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-022-01224-0/MediaObjects/41593_2022_1224_MOESM1_ESM.pdf" data-supp-info-image="">Reporting Summary</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p>Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.</p><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Multitask%20representations%20in%20the%20human%20cortex%20transform%20along%20a%20sensory-to-motor%20hierarchy&amp;author=Takuya%20Ito%20et%20al&amp;contentID=10.1038%2Fs41593-022-01224-0&amp;copyright=The%20Author%28s%29%2C%20under%20exclusive%20licence%20to%20Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2022-12-19&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41593-022-01224-0" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41593-022-01224-0" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Ito, T., Murray, J.D. Multitask representations in the human cortex transform along a sensory-to-motor hierarchy.
                    <i>Nat Neurosci</i> <b>26</b>, 306–315 (2023). https://doi.org/10.1038/s41593-022-01224-0</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-022-01224-0?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-12-02">02 December 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-10-28">28 October 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-12-19">19 December 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2023-02">February 2023</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41593-022-01224-0</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01224-0.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01224-0.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41593-022-01224-0;doi=10.1038/s41593-022-01224-0;subjmeta=116,1925,2649,378,631;kwrd=Cognitive+neuroscience,Network+models">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-786912767&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-022-01224-0%26doi%3D10.1038/s41593-022-01224-0%26subjmeta%3D116,1925,2649,378,631%26kwrd%3DCognitive+neuroscience,Network+models">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-786912767&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-022-01224-0%26doi%3D10.1038/s41593-022-01224-0%26subjmeta%3D116,1925,2649,378,631%26kwrd%3DCognitive+neuroscience,Network+models"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/s41593-022-01224-0&amp;format=js&amp;last_modified=2022-12-19" async></script>
<img src="/w0icfxbw/article/s41593-022-01224-0" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>