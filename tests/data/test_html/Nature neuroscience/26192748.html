<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Automatic integration of confidence in the brain valuation signal | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"decision;motivation","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/nn.4064"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Maël Lebreton","Raphaëlle Abitbol","Jean Daunizeau","Mathias Pessiglione"],"publishedAt":1437350400,"publishedAtString":"2015-07-20","title":"Automatic integration of confidence in the brain valuation signal","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"18","issue":"8"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Automatic integration of confidence in the brain valuation signal","description":"The ventromedial prefrontal cortex has been identified as a key node for judging the pleasantness of various situations. In a series of fMRI experiments, Lebreton and colleagues demonstrate that the same brain region also computes an implicit representation of confidence, defined as an estimate of judgment accuracy. A key process in decision-making is estimating the value of possible outcomes. Growing evidence suggests that different types of values are automatically encoded in the ventromedial prefrontal cortex (VMPFC). Here we extend this idea by suggesting that any overt judgment is accompanied by a second-order valuation (a confidence estimate), which is also automatically incorporated in VMPFC activity. In accordance with the predictions of our normative model of rating tasks, two behavioral experiments showed that confidence levels were quadratically related to first-order judgments (age, value or probability ratings). The analysis of three functional magnetic resonance imaging data sets using similar rating tasks confirmed that the quadratic extension of first-order ratings (our proxy for confidence) was encoded in VMPFC activity, even if no confidence judgment was required of the participants. Such an automatic aggregation of value and confidence in a same brain region might provide insight into many distortions of judgment and choice.","datePublished":"2015-07-20T00:00:00Z","dateModified":"2015-07-20T00:00:00Z","pageStart":"1159","pageEnd":"1167","sameAs":"https://doi.org/10.1038/nn.4064","keywords":["Decision","Motivation","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig1_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig2_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig3_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig4_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig5_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig6_HTML.jpg"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"18","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Maël Lebreton","affiliation":[{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM)","address":{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM), Paris, France","@type":"PostalAddress"},"@type":"Organization"},{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France","address":{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Raphaëlle Abitbol","affiliation":[{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM)","address":{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM), Paris, France","@type":"PostalAddress"},"@type":"Organization"},{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France","address":{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, ","@type":"PostalAddress"},"@type":"Organization"},{"name":"Centre d'Economie de la Sorbonne, Université Paris 1-Panthéon-Sorbonne","address":{"name":"Centre d'Economie de la Sorbonne, Université Paris 1-Panthéon-Sorbonne, Paris, France","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Jean Daunizeau","affiliation":[{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM)","address":{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM), Paris, France","@type":"PostalAddress"},"@type":"Organization"},{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France","address":{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, ","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Mathias Pessiglione","affiliation":[{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM)","address":{"name":"Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM), Paris, France","@type":"PostalAddress"},"@type":"Organization"},{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France","address":{"name":"INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, ","@type":"PostalAddress"},"@type":"Organization"}],"email":"mathias.pessiglione@gmail.com","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/nn.4064">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="Automatic integration of confidence in the brain valuation signal"/>
    <meta name="dc.source" content="Nature Neuroscience 2015 18:8"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2015-07-20"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2015 Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2015 Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="The ventromedial prefrontal cortex has been identified as a key node for judging the pleasantness of various situations. In a series of fMRI experiments, Lebreton and colleagues demonstrate that the same brain region also computes an implicit representation of confidence, defined as an estimate of judgment accuracy. A key process in decision-making is estimating the value of possible outcomes. Growing evidence suggests that different types of values are automatically encoded in the ventromedial prefrontal cortex (VMPFC). Here we extend this idea by suggesting that any overt judgment is accompanied by a second-order valuation (a confidence estimate), which is also automatically incorporated in VMPFC activity. In accordance with the predictions of our normative model of rating tasks, two behavioral experiments showed that confidence levels were quadratically related to first-order judgments (age, value or probability ratings). The analysis of three functional magnetic resonance imaging data sets using similar rating tasks confirmed that the quadratic extension of first-order ratings (our proxy for confidence) was encoded in VMPFC activity, even if no confidence judgment was required of the participants. Such an automatic aggregation of value and confidence in a same brain region might provide insight into many distortions of judgment and choice."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2015-07-20"/>
    <meta name="prism.volume" content="18"/>
    <meta name="prism.number" content="8"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="1159"/>
    <meta name="prism.endingPage" content="1167"/>
    <meta name="prism.copyright" content="2015 Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/nn.4064"/>
    <meta name="prism.doi" content="doi:10.1038/nn.4064"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/nn.4064.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/nn.4064"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="Automatic integration of confidence in the brain valuation signal"/>
    <meta name="citation_volume" content="18"/>
    <meta name="citation_issue" content="8"/>
    <meta name="citation_publication_date" content="2015/08"/>
    <meta name="citation_online_date" content="2015/07/20"/>
    <meta name="citation_firstpage" content="1159"/>
    <meta name="citation_lastpage" content="1167"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/nn.4064"/>
    <meta name="DOI" content="10.1038/nn.4064"/>
    <meta name="size" content="173087"/>
    <meta name="citation_doi" content="10.1038/nn.4064"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/nn.4064&amp;api_key="/>
    <meta name="description" content="The ventromedial prefrontal cortex has been identified as a key node for judging the pleasantness of various situations. In a series of fMRI experiments, Lebreton and colleagues demonstrate that the same brain region also computes an implicit representation of confidence, defined as an estimate of judgment accuracy. A key process in decision-making is estimating the value of possible outcomes. Growing evidence suggests that different types of values are automatically encoded in the ventromedial prefrontal cortex (VMPFC). Here we extend this idea by suggesting that any overt judgment is accompanied by a second-order valuation (a confidence estimate), which is also automatically incorporated in VMPFC activity. In accordance with the predictions of our normative model of rating tasks, two behavioral experiments showed that confidence levels were quadratically related to first-order judgments (age, value or probability ratings). The analysis of three functional magnetic resonance imaging data sets using similar rating tasks confirmed that the quadratic extension of first-order ratings (our proxy for confidence) was encoded in VMPFC activity, even if no confidence judgment was required of the participants. Such an automatic aggregation of value and confidence in a same brain region might provide insight into many distortions of judgment and choice."/>
    <meta name="dc.creator" content="Lebreton, Ma&#235;l"/>
    <meta name="dc.creator" content="Abitbol, Rapha&#235;lle"/>
    <meta name="dc.creator" content="Daunizeau, Jean"/>
    <meta name="dc.creator" content="Pessiglione, Mathias"/>
    <meta name="dc.subject" content="Decision"/>
    <meta name="dc.subject" content="Motivation"/>
    <meta name="citation_reference" content="Von Neumann, J. &amp; Morgenstern, O. Game Theory and Economic Behavior (Princeton Univ. Press, 1944)."/>
    <meta name="citation_reference" content="citation_journal_title=Economica; citation_title=A note on the pure theory of consumer&#39;s behaviour; citation_author=PA Samuelson; citation_volume=5; citation_publication_date=1938; citation_pages=61-71; citation_doi=10.2307/2548836; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Behav. Brain Res.; citation_title=Neural representations of subjective reward value; citation_author=J Peters, C Buchel; citation_volume=213; citation_publication_date=2010; citation_pages=135-141; citation_doi=10.1016/j.bbr.2010.04.031; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value; citation_author=O Bartra, JT McGuire, JW Kable; citation_volume=76; citation_publication_date=2013; citation_pages=412-427; citation_doi=10.1016/j.neuroimage.2013.02.063; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Soc. Cogn. Affect. Neurosci.; citation_title=Informatic parcellation of the network involved in the computation of subjective value; citation_author=JA Clithero, A Rangel; citation_volume=9; citation_publication_date=2014; citation_pages=1289-1302; citation_doi=10.1093/scan/nst106; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Emotional responses to pleasant and unpleasant music correlate with activity in paralimbic brain regions; citation_author=AJ Blood, R Zatorre, P Bermudez, A Evans; citation_volume=2; citation_publication_date=1999; citation_pages=382-387; citation_doi=10.1038/7299; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Evidence for a common representation of decision values for dissimilar goods in human ventromedial prefrontal cortex; citation_author=VS Chib, A Rangel, S Shimojo, JP O&#39;Doherty; citation_volume=29; citation_publication_date=2009; citation_pages=12315-12320; citation_doi=10.1523/JNEUROSCI.2575-09.2009; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Value computations in ventral medial prefrontal cortex during charitable decision making incorporate input from regions involved in social cognition; citation_author=TA Hare, CF Camerer, DT Knoepfle, JP O&#39;Doherty, A Rangel; citation_volume=30; citation_publication_date=2010; citation_pages=583-590; citation_doi=10.1523/JNEUROSCI.4089-09.2010; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=An automatic valuation system in the human brain: evidence from functional neuroimaging; citation_author=M Lebreton, S Jorge, V Michel, B Thirion, M Pessiglione; citation_volume=64; citation_publication_date=2009; citation_pages=431-439; citation_doi=10.1016/j.neuron.2009.09.040; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Orbitofrontal cortex encodes willingness to pay in everyday economic transactions; citation_author=H Plassmann, J O&#39;Doherty, A Rangel; citation_volume=27; citation_publication_date=2007; citation_pages=9984-9988; citation_doi=10.1523/JNEUROSCI.2131-07.2007; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Choice from non-choice: predicting consumer preferences from blood oxygenation level-dependent signals obtained during passive viewing; citation_author=I Levy, S Lazzaro, R Rutledge, P Glimcher; citation_volume=31; citation_publication_date=2011; citation_pages=118-125; citation_doi=10.1523/JNEUROSCI.3214-10.2011; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Monetary favors and their influence on neural responses and revealed preference; citation_author=AH Harvey, U Kirk, G Denfield, P Montague; citation_volume=30; citation_publication_date=2010; citation_pages=9597-9602; citation_doi=10.1523/JNEUROSCI.1086-10.2010; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Neural mechanisms underlying contextual dependency of subjective values: converging evidence from monkeys and humans; citation_author=R Abitbol; citation_volume=35; citation_publication_date=2015; citation_pages=2308-2320; citation_doi=10.1523/JNEUROSCI.1878-14.2015; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Neural correlates, computation and behavioural impact of decision confidence; citation_author=A Kepecs, N Uchida, H Zariwala, Z Mainen; citation_volume=455; citation_publication_date=2008; citation_pages=227-231; citation_doi=10.1038/nature07200; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Confidence in value-based choice; citation_author=B De Martino, SM Fleming, N Garrett, RJ Dolan; citation_volume=16; citation_publication_date=2013; citation_pages=105-110; citation_doi=10.1038/nn.3279; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Choice, difficulty, and confidence in the brain; citation_author=ET Rolls, F Grabenhorst, G Deco; citation_volume=53; citation_publication_date=2010; citation_pages=694-706; citation_doi=10.1016/j.neuroimage.2010.06.073; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Rev.; citation_title=Two-stage dynamic signal detection: a theory of choice, decision time, and confidence; citation_author=TJ Pleskac, JR Busemeyer; citation_volume=117; citation_publication_date=2010; citation_pages=864-901; citation_doi=10.1037/a0019737; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Gen.; citation_title=Dynamics of postdecisional processing of confidence; citation_author=S Yu, TJ Pleskac, MD Zeigenfuse; citation_volume=144; citation_publication_date=2015; citation_pages=489-510; citation_doi=10.1037/xge0000062; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Cognit. Psychol.; citation_title=The weighing of evidence and the determinants of confidence; citation_author=D Griffin, A Tversky; citation_volume=24; citation_publication_date=1992; citation_pages=411-435; citation_doi=10.1016/0010-0285(92)90013-R; citation_id=CR19"/>
    <meta name="citation_reference" content="Lichtenstein, S., Fischhoff, B. &amp; Phillips, L.D. in Heuristics and Biases 306&#8211;334 (Cambridge Univ. Press, 1982)."/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Your goal is mine: unraveling mimetic desires in the human brain; citation_author=M Lebreton, S Kawa, B Forgeot d&#39;Arc, J Daunizeau, M Pessiglione; citation_volume=32; citation_publication_date=2012; citation_pages=7146-7157; citation_doi=10.1523/JNEUROSCI.4821-11.2012; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Neural mechanisms mediating optimism bias; citation_author=T Sharot, AM Riccardi, CM Raio, EA Phelps; citation_volume=450; citation_publication_date=2007; citation_pages=102-105; citation_doi=10.1038/nature06280; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=Mem. Natl. Acad. Sci.; citation_title=On small differences of sensation; citation_author=CS Pierce, J Jastrow; citation_volume=3; citation_publication_date=1884; citation_pages=73-83; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Am. J. Psychol.; citation_title=A confidence scale defined in terms of expected percentages; citation_author=JK Adams; citation_volume=70; citation_publication_date=1957; citation_pages=432-436; citation_doi=10.2307/1419580; citation_id=CR24"/>
    <meta name="citation_reference" content="Vickers, D. Decision Processes in Visual Perception (Academic, New York, 1979)."/>
    <meta name="citation_reference" content="citation_journal_title=Phil. Trans. R. Soc. Lond. B; citation_title=The neural basis of metacognitive ability; citation_author=SM Fleming, RJ Dolan; citation_volume=367; citation_publication_date=2012; citation_pages=1338-1349; citation_doi=10.1098/rstb.2011.0417; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=Phil. Trans. R. Soc. Lond. B; citation_title=Metacognition in human decision-making: confidence and error monitoring; citation_author=N Yeung, C Summerfield; citation_volume=367; citation_publication_date=2012; citation_pages=1310-1321; citation_doi=10.1098/rstb.2011.0416; citation_id=CR27"/>
    <meta name="citation_reference" content="Daunizeau, J. A note on race models 
                  http://sites.google.com/site/jeandaunizeauswebsite/links/resources
                  
                 (2015)."/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Dissociating valuation and saliency signals during decision-making; citation_author=A Litt, H Plassmann, B Shiv, A Rangel; citation_volume=21; citation_publication_date=2011; citation_pages=95-102; citation_doi=10.1093/cercor/bhq065; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Neuronal representations of cognitive state: reward or attention?; citation_author=JH Maunsell; citation_volume=8; citation_publication_date=2004; citation_pages=261-265; citation_doi=10.1016/j.tics.2004.04.003; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Ann. NY Acad. Sci.; citation_title=Neuronal activity related to anticipated reward in frontal cortex: does it represent value or reflect motivation?; citation_author=MR Roesch, CR Olson; citation_volume=1121; citation_publication_date=2007; citation_pages=431-446; citation_doi=10.1196/annals.1401.004; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Understanding metamemory: neural correlates of the cognitive process and subjective level of confidence in recognition memory; citation_author=EF Chua, DL Schacter, E Rand-Giovannetti, RA Sperling; citation_volume=29; citation_publication_date=2006; citation_pages=1150-1160; citation_doi=10.1016/j.neuroimage.2005.09.058; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Neural correlates of memory confidence; citation_author=S Moritz, J Glascher, T Sommer, C Buchel, DF Braus; citation_volume=33; citation_publication_date=2006; citation_pages=1188-1193; citation_doi=10.1016/j.neuroimage.2006.08.003; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS ONE; citation_title=Ventral striatal activity correlates with memory confidence for old- and new-responses in a difficult recognition test; citation_author=U Schwarze, U Bingel, D Badre, T Sommer; citation_volume=8; citation_publication_date=2013; citation_pages=e54324; citation_doi=10.1371/journal.pone.0054324; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Brain Cogn.; citation_title=Uncertainty and confidence from the triple-network perspective: voxel-based meta-analyses; citation_author=TP White, NH Engen, S S&#248;rensen, M Overgaard, SS Shergill; citation_volume=85; citation_publication_date=2014; citation_pages=191-200; citation_doi=10.1016/j.bandc.2013.12.002; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=Hum. Brain Mapp.; citation_title=Emotional imagery: assessing pleasure and arousal in the brain&#39;s reward circuitry; citation_author=VD Costa, PJ Lang, D Sabatinelli, F Versace, MM Bradley; citation_volume=31; citation_publication_date=2010; citation_pages=1446-1457; citation_doi=10.1002/hbm.20948; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Differential response patterns in the striatum and orbitofrontal cortex to financial reward in humans: a parametric functional magnetic resonance imaging study; citation_author=R Elliott, JL Newman, OA Longe, JFW Deakin; citation_volume=23; citation_publication_date=2003; citation_pages=303-307; citation_doi=10.1523/JNEUROSCI.23-01-00303.2003; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Valence and salience contribute to nucleus accumbens activation; citation_author=JC Cooper, B Knutson; citation_volume=39; citation_publication_date=2008; citation_pages=538-547; citation_doi=10.1016/j.neuroimage.2007.08.009; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Neurosci.; citation_title=The root of all value: a neural common currency for choice; citation_author=D Levy, PW Glimcher; citation_volume=22; citation_publication_date=2012; citation_pages=1027-1038; citation_doi=10.1016/j.conb.2012.06.001; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Sci.; citation_title=Does confidence use a common currency across two visual tasks?; citation_author=V de Gardelle, P Mamassian; citation_volume=25; citation_publication_date=2014; citation_pages=1286-1288; citation_doi=10.1177/0956797614528956; citation_id=CR40"/>
    <meta name="citation_reference" content="Daunizeau, J. On the exponential, sigmoid and softmax mappings 
                  http://sites.google.com/site/jeandaunizeauswebsite/links/resources
                  
                 (2014)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Optimized EPI for fMRI studies of the orbitofrontal cortex; citation_author=R Deichmann, J Gottfried, C Hutton, R Turner; citation_volume=19; citation_publication_date=2003; citation_pages=430-441; citation_doi=10.1016/S1053-8119(03)00073-9; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Conjunction revisited; citation_author=KJ Friston, WD Penny, DE Glaser; citation_volume=25; citation_publication_date=2005; citation_pages=661-667; citation_doi=10.1016/j.neuroimage.2005.01.013; citation_id=CR43"/>
    <meta name="citation_author" content="Lebreton, Ma&#235;l"/>
    <meta name="citation_author_institution" content="Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle &#233;pini&#232;re (ICM), Paris, France"/>
    <meta name="citation_author_institution" content="INSERM UMRS 975, CNRS UMR 7225, Universit&#233; Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, "/>
    <meta name="citation_author" content="Abitbol, Rapha&#235;lle"/>
    <meta name="citation_author_institution" content="Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle &#233;pini&#232;re (ICM), Paris, France"/>
    <meta name="citation_author_institution" content="INSERM UMRS 975, CNRS UMR 7225, Universit&#233; Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, "/>
    <meta name="citation_author_institution" content="Centre d&#39;Economie de la Sorbonne, Universit&#233; Paris 1-Panth&#233;on-Sorbonne, Paris, France"/>
    <meta name="citation_author" content="Daunizeau, Jean"/>
    <meta name="citation_author_institution" content="Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle &#233;pini&#232;re (ICM), Paris, France"/>
    <meta name="citation_author_institution" content="INSERM UMRS 975, CNRS UMR 7225, Universit&#233; Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, "/>
    <meta name="citation_author" content="Pessiglione, Mathias"/>
    <meta name="citation_author_institution" content="Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle &#233;pini&#232;re (ICM), Paris, France"/>
    <meta name="citation_author_institution" content="INSERM UMRS 975, CNRS UMR 7225, Universit&#233; Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, "/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Automatic integration of confidence in the brain valuation signal"/>
    <meta name="twitter:description" content="Nature Neuroscience - The ventromedial prefrontal cortex has been identified as a key node for judging the pleasantness of various situations. In a series of fMRI experiments, Lebreton and..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig1_HTML.jpg"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/nn.4064"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Automatic integration of confidence in the brain valuation signal - Nature Neuroscience"/>
    <meta property="og:description" content="The ventromedial prefrontal cortex has been identified as a key node for judging the pleasantness of various situations. In a series of fMRI experiments, Lebreton and colleagues demonstrate that the same brain region also computes an implicit representation of confidence, defined as an estimate of judgment accuracy."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig1_HTML.jpg"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=nn.4064;doi=10.1038/nn.4064;techmeta=36,59;subjmeta=1409,1662,2649,378,631;kwrd=Decision,Motivation">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=671740052&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.4064%26doi%3D10.1038/nn.4064%26techmeta%3D36,59%26subjmeta%3D1409,1662,2649,378,631%26kwrd%3DDecision,Motivation">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=671740052&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.4064%26doi%3D10.1038/nn.4064%26techmeta%3D36,59%26subjmeta%3D1409,1662,2649,378,631%26kwrd%3DDecision,Motivation"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/nn.4064'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Automatic integration of confidence in the brain valuation signal
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4064.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2015-07-20">20 July 2015</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Automatic integration of confidence in the brain valuation signal</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ma_l-Lebreton-Aff1-Aff2" data-author-popup="auth-Ma_l-Lebreton-Aff1-Aff2" data-author-search="Lebreton, Maël">Maël Lebreton</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Rapha_lle-Abitbol-Aff1-Aff2-Aff3" data-author-popup="auth-Rapha_lle-Abitbol-Aff1-Aff2-Aff3" data-author-search="Abitbol, Raphaëlle">Raphaëlle Abitbol</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a>,<a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jean-Daunizeau-Aff1-Aff2" data-author-popup="auth-Jean-Daunizeau-Aff1-Aff2" data-author-search="Daunizeau, Jean">Jean Daunizeau</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 4 authors for this article" title="Show all 4 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Mathias-Pessiglione-Aff1-Aff2" data-author-popup="auth-Mathias-Pessiglione-Aff1-Aff2" data-author-search="Pessiglione, Mathias" data-corresp-id="c1">Mathias Pessiglione<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup> </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 18</b>, <span class="u-visually-hidden">pages </span>1159–1167 (<span data-test="article-publication-year">2015</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">7706 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">151 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">46 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/nn.4064/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/decision" data-track="click" data-track-action="view subject" data-track-label="link">Decision</a></li><li class="c-article-subject-list__subject"><a href="/subjects/motivation" data-track="click" data-track-action="view subject" data-track-label="link">Motivation</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs2" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs2">Abstract</h2><div class="c-article-section__content" id="Abs2-content"><p>A key process in decision-making is estimating the value of possible outcomes. Growing evidence suggests that different types of values are automatically encoded in the ventromedial prefrontal cortex (VMPFC). Here we extend this idea by suggesting that any overt judgment is accompanied by a second-order valuation (a confidence estimate), which is also automatically incorporated in VMPFC activity. In accordance with the predictions of our normative model of rating tasks, two behavioral experiments showed that confidence levels were quadratically related to first-order judgments (age, value or probability ratings). The analysis of three functional magnetic resonance imaging data sets using similar rating tasks confirmed that the quadratic extension of first-order ratings (our proxy for confidence) was encoded in VMPFC activity, even if no confidence judgment was required of the participants. Such an automatic aggregation of value and confidence in a same brain region might provide insight into many distortions of judgment and choice.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4064.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4064.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs42003-020-01315-3/MediaObjects/42003_2020_1315_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s42003-020-01315-3?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s42003-020-01315-3">Subjective value and decision entropy are jointly encoded by aligned gradients across the human brain
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">21 October 2020</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Sebastian Bobadilla-Suarez, Olivia Guest &amp; Bradley C. Love</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-023-42589-5/MediaObjects/41467_2023_42589_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-023-42589-5?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41467-023-42589-5">Neural and computational underpinnings of biased confidence in human reinforcement learning
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">28 October 2023</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Chih-Chung Ting, Nahuel Salem-Garcia, … Maël Lebreton</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs42003-021-02850-3/MediaObjects/42003_2021_2850_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s42003-021-02850-3?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s42003-021-02850-3">Neurocomputational mechanisms underlying the subjective value of information
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">13 December 2021</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Ariel X.-A. Goh, Daniel Bennett, … Trevor T.-J. Chong</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711582640,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>Decision theory in its elementary form assumes that, when faced with a choice, individuals first assign subjective values to possible outcomes of available actions and then select the action that leads to the most valuable outcomes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Von Neumann, J. &amp; Morgenstern, O. Game Theory and Economic Behavior (Princeton Univ. Press, 1944)." href="/articles/nn.4064#ref-CR1" id="ref-link-section-d30847472e369">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Samuelson, P.A. A note on the pure theory of consumer's behaviour. Economica 5, 61–71 (1938)." href="/articles/nn.4064#ref-CR2" id="ref-link-section-d30847472e372">2</a></sup>. Estimating the value of potential world states is therefore a key step of the decision-making process. At a psychological level, subjective value can be understood as anticipated pleasure and can be measured using pleasantness or desirability rating. A growing body of evidence from both animals and humans suggests that subjective value, whether measured with rating or inferred from choice, is encoded in the VMPFC<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Peters, J. &amp; Buchel, C. Neural representations of subjective reward value. Behav. Brain Res. 213, 135–141 (2010)." href="/articles/nn.4064#ref-CR3" id="ref-link-section-d30847472e376">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Bartra, O., McGuire, J.T. &amp; Kable, J.W. The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value. Neuroimage 76, 412–427 (2013)." href="/articles/nn.4064#ref-CR4" id="ref-link-section-d30847472e379">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Clithero, J.A. &amp; Rangel, A. Informatic parcellation of the network involved in the computation of subjective value. Soc. Cogn. Affect. Neurosci. 9, 1289–1302 (2014)." href="/articles/nn.4064#ref-CR5" id="ref-link-section-d30847472e382">5</a></sup>. Two important properties of the brain's value signal have been uncovered: generality and automaticity. Generality means that the brain value signal can rank seemingly incommensurable items on a common scale. Indeed, the VMPFC has been found to reflect subjective values of faces, houses, cars, paintings, music, food, money, social donation and so forth<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Blood, A.J., Zatorre, R., Bermudez, P. &amp; Evans, A. Emotional responses to pleasant and unpleasant music correlate with activity in paralimbic brain regions. Nat. Neurosci. 2, 382–387 (1999)." href="/articles/nn.4064#ref-CR6" id="ref-link-section-d30847472e386">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Chib, V.S., Rangel, A., Shimojo, S. &amp; O'Doherty, J.P. Evidence for a common representation of decision values for dissimilar goods in human ventromedial prefrontal cortex. J. Neurosci. 29, 12315–12320 (2009)." href="/articles/nn.4064#ref-CR7" id="ref-link-section-d30847472e389">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Hare, T.A., Camerer, C.F., Knoepfle, D.T., O'Doherty, J.P. &amp; Rangel, A. Value computations in ventral medial prefrontal cortex during charitable decision making incorporate input from regions involved in social cognition. J. Neurosci. 30, 583–590 (2010)." href="/articles/nn.4064#ref-CR8" id="ref-link-section-d30847472e392">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e395">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Plassmann, H., O'Doherty, J. &amp; Rangel, A. Orbitofrontal cortex encodes willingness to pay in everyday economic transactions. J. Neurosci. 27, 9984–9988 (2007)." href="/articles/nn.4064#ref-CR10" id="ref-link-section-d30847472e398">10</a></sup>. Automaticity means that subjective values are encoded in VMPFC activity even when unnecessary for the ongoing task—for example, during passive viewing of visual stimuli or during the rating of dimensions independent from value. These automatic value signals were predictive of the choices probed after neuroimaging measurements<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e402">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Levy, I., Lazzaro, S., Rutledge, R. &amp; Glimcher, P. Choice from non-choice: predicting consumer preferences from blood oxygenation level-dependent signals obtained during passive viewing. J. Neurosci. 31, 118–125 (2011)." href="/articles/nn.4064#ref-CR11" id="ref-link-section-d30847472e405">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Harvey, A.H., Kirk, U., Denfield, G. &amp; Montague, P. Monetary favors and their influence on neural responses and revealed preference. J. Neurosci. 30, 9597–9602 (2010)." href="/articles/nn.4064#ref-CR12" id="ref-link-section-d30847472e408">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Abitbol, R. et al. Neural mechanisms underlying contextual dependency of subjective values: converging evidence from monkeys and humans. J. Neurosci. 35, 2308–2320 (2015)." href="/articles/nn.4064#ref-CR13" id="ref-link-section-d30847472e411">13</a></sup>.</p><p>Yet decoding values from VMPFC activity might not be straightforward, since this region has been found to incorporate other factors. In particular, several studies in both rats and humans have reported that orbitofrontal or ventromedial prefrontal regions encode confidence in having made the best choice<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Kepecs, A., Uchida, N., Zariwala, H. &amp; Mainen, Z. Neural correlates, computation and behavioural impact of decision confidence. Nature 455, 227–231 (2008)." href="/articles/nn.4064#ref-CR14" id="ref-link-section-d30847472e418">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="De Martino, B., Fleming, S.M., Garrett, N. &amp; Dolan, R.J. Confidence in value-based choice. Nat. Neurosci. 16, 105–110 (2013)." href="/articles/nn.4064#ref-CR15" id="ref-link-section-d30847472e421">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Rolls, E.T., Grabenhorst, F. &amp; Deco, G. Choice, difficulty, and confidence in the brain. Neuroimage 53, 694–706 (2010)." href="/articles/nn.4064#ref-CR16" id="ref-link-section-d30847472e424">16</a></sup>. Borrowing from established theoretical work in the psychophysics of perceptual decisions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Pleskac, T.J. &amp; Busemeyer, J.R. Two-stage dynamic signal detection: a theory of choice, decision time, and confidence. Psychol. Rev. 117, 864–901 (2010)." href="/articles/nn.4064#ref-CR17" id="ref-link-section-d30847472e428">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Yu, S., Pleskac, T.J. &amp; Zeigenfuse, M.D. Dynamics of postdecisional processing of confidence. J. Exp. Psychol. Gen. 144, 489–510 (2015)." href="/articles/nn.4064#ref-CR18" id="ref-link-section-d30847472e431">18</a></sup>, these studies have modeled confidence as the temporal integration of the (noisy) difference in value between choice options, through either linear accumulation or nonlinear competition between attractors. Here we generalize the notion of confidence-encoding in the VMPFC to all situations that involve a judgment on any dimension (value and others), and not only to those implying a choice between alternative options. In brief, we think of confidence as a second-order judgment on the correctness of a first-order judgment that can be either a choice or a rating<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Griffin, D. &amp; Tversky, A. The weighing of evidence and the determinants of confidence. Cognit. Psychol. 24, 411–435 (1992)." href="/articles/nn.4064#ref-CR19" id="ref-link-section-d30847472e435">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Lichtenstein, S., Fischhoff, B. &amp; Phillips, L.D. in Heuristics and Biases 306–334 (Cambridge Univ. Press, 1982)." href="/articles/nn.4064#ref-CR20" id="ref-link-section-d30847472e438">20</a></sup>. In this perspective, the hypothesis that confidence is encoded in the VMPFC remains compatible with the function attributed to this region: namely, computing subjective value. This is simply because being accurate is valuable: it is the implicit goal of any judgment task. Considering confidence as a value judgment also suggests that the neural confidence signal might share the properties of the neural value signal: it should be general (that is, elicited by any kind of first-order judgment) and automatic (that is, elicited even when no confidence judgment is explicitly required).</p><p>We tested these hypotheses using a combination of published and original data sets acquired in healthy human participants. We reasoned that confidence should vary as a non-monotonic (U-shaped) function of first-order judgments. This is essentially because participants tend to stay on the middle of the rating scale when they have no idea how to respond and move to the extremes when they have more information. Here we provide empirical evidence, using two behavioral studies, for the U-shaped (or quadratic) relationship between second-order confidence rating and four sorts of first-order ratings: pleasantness, age, desirability and probability. We also show, in three functional magnetic resonance imaging (fMRI) studies, that the quadratic extension of all first-order judgments is encoded in VMPFC activity, even in the absence of explicit confidence ratings. We conclude that response confidence is automatically aggregated with the usual stimulus value signal in the VMPFC.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Computational analysis of rating tasks</h3><p>To provide a normative account of our working hypothesis, we suggest a computational decomposition of rating tasks (see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.4064#Sec10">Methods</a>). Starting from a decision-theoretic perspective, we assume that participants aim at minimizing the mismatch between their overt rating and their internal judgment. Any potential rating thus induces a subjective feeling about being right or wrong—that is, an estimation of accuracy that guides the selection of the overt response in the task. This motivates our formal definition of confidence: namely, the expected judgment accuracy. Estimating the expected accuracy is not trivial, for the following two reasons. First, subjects may be uncertain about their judgment. Thus the information that subjects have about their internal judgment may be captured not by a number but by a probability distribution. Second, their internal judgment may not be naturally expressed in the metric imposed by the rating scale. That is, it may have to be mapped onto this external bounded scale through a monotonic function that preserves preference ordering. Taken together, these difficulties imply that subjects must deal with degraded information about how to respond, expressed in terms of a probability distribution on mapped judgments (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1a</a>). Analytical decomposition of the model shows that rating and confidence should correspond to the first and second-order moments of this distribution, respectively. This allows deriving rating and confidence from the mean and variance of the internal probability distribution (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1b</a>). Critically, the model predicts that, irrespective of the actual internal judgments, these two quantities are not independent: confidence is a quadratic function of rating (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1c</a>). In summary, our computational analysis explains, under the intuitive assumption that subjects intend to express their judgment as accurately as possible, both why confidence possesses an intrinsic value and why it is minimal for midscale ratings.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Model simulations."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1: Model simulations.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4064/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig1_HTML.jpg?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig1_HTML.jpg" alt="figure 1" loading="lazy" width="685" height="793"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>(<b>a</b>) Left, the agent's probability distribution <i>p</i>(<i>x</i>) over her internal judgment <i>x</i>, with mean <i>μ</i> and variance <i>σ</i> (which captures judgment uncertainty). The sigmoidal projection mapping is shown in red. Right, the induced probability distribution <i>p</i>[<i>s</i>(<i>x</i>)] over projected judgments <i>s</i>(<i>x</i>), with first-order moment <i>E</i>[<i>s</i>(<i>x</i>)] and second-order moment <i>V</i>[<i>s</i>(<i>x</i>)]). (<b>b</b>) Left, predicted rating <i>r̂</i> = <i>E</i>[<i>s</i>(<i>x</i>)]) is shown with color code as a function of mean <i>μ</i> (<i>y</i> axis) and uncertainty <i>σ</i> (<i>x</i> axis) of internal judgments. Points lying on iso-rating curves show that midrange overt ratings mix both neutral judgments (P<sub>1</sub>) and uncertain judgments (P<sub>2</sub>). Right, predicted confidence <i>q̂</i> = − <i>V</i>[<i>s</i>(<i>x</i>)]) is shown with color code as function of <i>μ</i> (<i>y</i> axis) and <i>σ</i> (<i>x</i> axis). (<b>c</b>) Left, marginal relationship between predicted confidence <i>q̂</i> (<i>y</i> axis) and judgment uncertainty <i>σ</i>, after averaging over judgment mean <i>μ</i>. The variability induced by <i>μ</i> is shown by error bars, which depict 1 s.d. around the mean. Confidence is monotonically related to judgment uncertainty. Right, predicted confidence <i>q̂</i> (<i>y</i> axis) is shown as a function of predicted rating <i>r̂</i> (<i>x</i> axis), for different levels of judgment uncertainty (<i>σ</i> ranges from 0 to 32). The quadratic relationship between confidence and rating is more pronounced at greater <i>σ</i>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4064/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec4">Study 1a: relationship between second-order (confidence) and first-order (age, pleasantness) ratings</h3><p>To establish that a confidence rating is automatically generated and aggregated with the brain value signal, it was first necessary to demonstrate a systematic statistical relationship between rating and confidence. We added a confidence rating task on top of a pleasantness rating task, for which we already had an fMRI data set<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e647">9</a></sup>, and tested a new group of healthy participants (<i>n</i> = 18). A visual stimulus from three possible categories (faces, houses or paintings) was presented on every trial and participants were asked to estimate first the stimulus pleasantness on a discrete scale (from −10 to +10) and then their confidence in their pleasantness rating on a continuous analog scale (from not at all to totally confident) (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig2">Fig. 2a</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Relationship between confidence and stimulus pleasantness or age rating (study 1a)."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2: Relationship between confidence and stimulus pleasantness or age rating (study 1a).</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4064/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="685" height="854"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>(<b>a</b>) Task design. Successive screens displayed in one trial are shown from left to right, with their durations. Subjects had first to estimate the pleasantness or the age of a visual stimulus (face, house or painting) on a −10 to 10 scale. Then they were asked to estimate on a continuous scale how confident they were in their pleasantness or age rating, which was given on the screen. (<b>b</b>) Behavioral results. Both reaction time (left) and confidence rating (middle) vary as U-shaped functions of pleasantness (top) or age (bottom) rating. Reaction time is the interval between stimulus onset and first key press. Trials were grouped in ten bins of ascending ratings sorted at the individual level and then averaged across individuals. At right, each rating bin was divided into tertiles of confidence (light to dark color). Error bars indicate intersubject s.e.m. Solid lines indicate the best second-order polynomial fit.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4064/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Consistent with our predictions, behavioral data showed positive U-shaped association between confidence and pleasantness ratings (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig2">Fig. 2b</a>, top). We used robust multiple regression across trials at the individual level, in order to explain confidence ratings with both linear and squared pleasantness ratings. A random-effect analysis at the group level (one-sample <i>t</i> tests on individual robust regression estimates (β)) confirmed that confidence varied not with pleasantness but with squared pleasantness (linear: β = −0.3 ± 0.04, <i>t</i><sub>17</sub> = −0.80, <i>P</i> = 0.42; quadratic: β = 0.35 ± 0.04, <i>t</i><sub>17</sub> = 9.94, <i>P</i> &lt; 10<sup>−6</sup>). The same pattern (with opposite sign) was observed in the reaction time measured for pleasantness rating, as the time between stimulus onset and first key press (linear: β = 0.01 ± 0.03, <i>t</i><sub>17</sub> = 0.47, <i>P</i> = 0.65; quadratic: β = −0.12 ± 0.02, <i>t</i><sub>17</sub> = −5.42, <i>P</i> = 4.6 × 10<sup>−5</sup>). Consequently, confidence and reaction time were linearly correlated (random-effect analysis on individual Pearson correlation <i>ρ</i> = −0.12 ± 0.04, <i>t</i><sub>17</sub> = −3.44, <i>P</i> = 0.0031). The model predicts that when internal judgments are more uncertain the quadratic effect should be deeper, and not simply shifted toward lower confidence levels (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1c</a>). To test this prediction, we divided each rating bin into tertiles (low, medium and high confidence). The weight of the quadratic term was indeed significantly greater in the low- than in the high-confidence tertiles (high confidence: β = 0.20 ± 0.02; low confidence: β = 0.67 ± 0.06; difference: <i>t</i><sub>17</sub> = 9.21, <i>P</i> &lt; 10<sup>−6</sup>).</p><p>To examine whether this statistical relationship with subjective value could be extended to an orthogonal first-order judgment on a more objective dimension, we added the same confidence rating task on top of an age rating task that we also had used in our previous fMRI study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e752">9</a></sup> and tested another group of healthy participants (<i>n</i> = 22). A visual stimulus from the same three possible categories (faces, houses or paintings) was presented on every trial and participants were asked to estimate first the stimulus age on a discrete scale (from 20 to 50 years old for faces, date of creation between 1400 and 2000 for painting, and date of construction between 1700 and 2000 for houses) and then their confidence in their age rating on a continuous analog scale (from not at all to totally confident) (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig2">Fig. 2a</a>).</p><p>As observed with pleasantness ratings, we found a positive U-shaped association between confidence and age ratings (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig2">Fig. 2b</a>, bottom). In other words, confidence ratings varied not linearly but quadratically with age ratings (linear: β = 0.06 ± 0.04, <i>t</i><sub>21</sub> = 1.55, <i>P</i> = 0.14; quadratic: β = 0.22 ± 0.03, <i>t</i><sub>21</sub> = 6.63, <i>P</i> = 1.5 × 10<sup>−6</sup>). The same pattern (with opposite sign) was observed in the reaction time measured for age rating (linear: β = −0.02 ± 0.02, <i>t</i><sub>21</sub> = −0.90, <i>P</i> = 0.37; quadratic: β = −0.08 ± 0.01, <i>t</i><sub>21</sub> = −4.71, <i>P</i> = 1.2 × 10<sup>−4</sup>). Consequently, confidence and reaction time were linearly correlated (ρ = −0.08 ± 0.02, <i>t</i><sub>21</sub> = −3.58, <i>P</i> = 0.0018). We also observed a trend toward a deepening of quadratic functions with confidence tertiles (high confidence: β = 0.17 ± 0.02; low confidence: β = 0.25 ± 0.06; difference: <i>t</i><sub>21</sub> = 1.93, <i>P</i> = 0.067), although it was less clear than with pleasantness ratings, probably owing to sampling issues (confidence was globally lower in age relative to pleasantness ratings).</p><p>The correlation between reaction time and confidence level corresponds to the intuition that harder (more uncertain) judgments take longer, whatever the domain. It suggests that the uncertainty expressed in confidence ratings is already available during first-order judgment, before elicitation of the second-order judgment. Thus, these behavioral results made it possible to search for neural confidence signals during both pleasantness and age rating tasks, without having to ask subjects to rate their confidence. However, we noted that the quadratic link was stronger with confidence than with reaction time. To compare their capacity to explain confidence level, we included reaction time together with response time (delay between stimulus onset and last key press) and linear and quadratic functions of ratings in a same regression model. The only significant predictor across rating tasks was the quadratic term (pleasantness: β = 0.33 ± 0.03, <i>t</i><sub>17</sub> = 10.15, <i>P</i> &lt; 10<sup>−6</sup>; age: β = 0.23 ± 0.03, <i>t</i><sub>21</sub> = 7.58, <i>P</i> &lt; 10<sup>−6</sup>). This discards the possibility that confidence could be a simple readout of reaction time, and suggests instead that confidence and reaction time both arise from the same underlying uncertainty.</p><h3 class="c-article__sub-heading" id="Sec5">Study 1b: neural representation of confidence in pleasantness and age rating</h3><p>We reanalyzed fMRI data from a previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e848">9</a></sup> that demonstrated linear encoding of pleasantness rating in a set of brain regions including the VMPFC. This study employed the same stimuli (faces, houses and paintings) and the same pleasantness and age rating tasks as in study 1a, except that no confidence rating was ever asked of participants (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3a</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Neural integration of confidence in stimulus pleasantness and age rating (study 1b)."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3: Neural integration of confidence in stimulus pleasantness and age rating (study 1b).</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4064/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig3_HTML.jpg?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig3_HTML.jpg" alt="figure 3" loading="lazy" width="685" height="935"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>(<b>a</b>) Task design. Successive screens displayed in one trial are shown from left to right, with their durations. Subjects first viewed a stimulus (face, house or painting) and then had to rate either its pleasantness or its age. (<b>b</b>) Statistical parametric maps of activation with pleasantness (cluster generating threshold <i>P</i><sub>FWE_vox</sub> &lt; 0.05 and <i>k</i> &gt; 100 voxels) and age ratings (uncorrected voxel threshold <i>P</i><sub>unc_vox</sub> &lt; 0.01). The color code on glass brains (gray to black) and sagittal slices (red to yellow) indicates the <i>t</i>-value of clusters that surpassed the statistical threshold. The [<i>x y z</i>] coordinates of the maxima (blue crosshairs and corresponding red pointers) refer to Montreal Neurological Institute (MNI) space. (<b>c</b>) Conjunction among linear correlation with pleasantness, quadratic correlation with pleasantness and quadratic correlation with age (cluster generating threshold, <i>P</i><sub>unc_vox</sub> &lt; 0.001; cluster family-wise correction, <i>P</i><sub>FWE_clu</sub> &lt; 0.05). (<b>d</b>) Canonical ROI analysis. Trials were grouped for each participant in ten bins of ascending pleasantness (left) or age (right), averaged at the population level and plotted against the BOLD signal estimated in the VMPFC ROI (isolated from group-level linear correlation with pleasantness; <b>b</b>, left). Age was <i>z</i>-scored because the age rating scale varied with stimulus category (face, house, painting). Error bars indicate intersubject s.e.m.; solid lines indicate the best second-order polynomial fit (including both linear and quadratic terms). (<b>e</b>) Time-resolved ROI analysis. A FIR model estimated the effect size of the linear and quadratic expansions of pleasantness (left) and age (right) ratings on the VMPFC signal, every 2 s after painting onset (time 0). The VMPFC ROI is the same as above. Shaded areas represent confidence intervals (means ± intersubject s.e.m.).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4064/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>All age-rating and pleasantness-rating sessions were modeled with a boxcar function covering painting display modulated by a second-order polynomial expansion of pleasantness or age rating (with linear and quadratic terms in separate regressors). Model estimates first confirmed that pleasantness ratings were linearly encoded in the VMPFC (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3b</a>), but age ratings were not, even at a permissive threshold (uncorrected <i>P</i><sub>unc</sub> &lt; 0.01). At the whole-brain level, linear activation with pleasantness was restricted to a VMPFC cluster specifically (peak MNI coordinates [−2 52 −2], <i>k</i> = 214 voxels) when using a statistical threshold family-wise error corrected for multiple comparisons at the voxel level (<i>P</i><sub>FWE_vox</sub> &lt; 0.05).</p><p>To test whether pleasantness and confidence were encoded in the same brain regions, we performed a conjunction analysis between the linear and quadratic expansions of pleasantness ratings, as well as the quadratic expansion of age rating. This conjunction isolated several functional clusters (at a threshold of <i>P</i><sub>FWE_clu</sub> &lt; 0.05) in the visual and frontal cortex, including the VMPFC (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3c</a>). To confirm that confidence was indeed encoded in the VMPFC valuation region, we extracted regression estimates (β values) obtained for the linear and quadratic terms from the VMPFC region of interest (ROI), defined by linear activation with pleasantness rating at the group level (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3b</a>). Linear and quadratic estimates denoted a similar effect size and were both highly significant (one-sample <i>t</i> test on individual β values, linear: β = 0.20 ± 0.02, <i>t</i><sub>19</sub> = 10.75, <i>P</i> &lt; 10<sup>−6</sup>; quadratic: β = 0.16 ± 0.02, <i>t</i><sub>19</sub> = 7.98, <i>P</i> &lt; 10<sup>−6</sup>). Note that the ROI was selected for encoding pleasantness rating, so testing the linear relation with pleasantness is just confirmatory, whereas the quadratic relation is entirely independent of the selection criterion. We also tested in the same VMPFC region the linear and quadratic regression with age. Only the quadratic term was significantly encoded (linear: β = −0.03 ± 0.03, <i>t</i><sub>19</sub> = 1.04, <i>P</i> = 0.31; quadratic: β = 0.07 ± 0.03, <i>t</i><sub>19</sub> = 2.30, <i>P</i> = 0.033). These results were similar whether or not response time was included in the regression model, even if not orthogonalized with respect to the quadratic regressor.</p><p>These results are illustrated by plotting the VMPFC signal obtained for nine bins of ascending pleasantness or age (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3d</a>). While the curve obtained for pleasantness appears as an addition of linear and quadratic terms, the curve obtained for age is purely quadratic (U-shaped). Thus, fMRI data showed that confidence, modeled as squared first-order ratings (pleasantness or age), is encoded in a VMPFC region that also encodes value (linear variation with pleasantness but not age). Integration of confidence in this valuation region can be considered automatic, since no confidence judgment was ever asked of participants in the fMRI study. To further illustrate this finding, we estimated a parametric finite-impulse response (FIR) model, in which the blood oxygen level–dependent (BOLD) signal was fitted every 2 s with both the linear and quadratic extensions of pleasantness or age ratings. This procedure allowed us to estimate the time course of the effect size, which was similar for the linear and quadratic predictors (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3e</a>).</p><h3 class="c-article__sub-heading" id="Sec6">Study 2: neural representation of confidence in desirability rating</h3><p>The same pattern of results, in the same VMPFC ROI, was also observed in another independent fMRI data set<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Lebreton, M., Kawa, S., Forgeot d'Arc, B., Daunizeau, J. &amp; Pessiglione, M. Your goal is mine: unraveling mimetic desires in the human brain. J. Neurosci. 32, 7146–7157 (2012)." href="/articles/nn.4064#ref-CR21" id="ref-link-section-d30847472e1007">21</a></sup> previously recorded in a group of 19 participants during a desirability rating task (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig4">Fig. 4</a>). The task involved subjects rating the desirability of objects (toys, tools or food items) featured in a video where an actor could or could not perform an action directed to this object (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig4">Fig. 4a</a>). Using parametric modulation of activity modeled as a boxcar over video viewing, our previous analysis had shown that, irrespective of actions, desirability ratings were reflected in the VMPFC, as well as in a large occipital cluster (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig4">Fig. 4b</a>, <i>P</i><sub>FWE_clu</sub> &lt; 0.05). We have now added the quadratic extension of desirability as a second parametric modulator in our general linear model, and found again that the VMPFC encoded a conjunction of first-order (desirability) and second-order (confidence) value judgments (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig4">Fig. 4c</a>, <i>P</i><sub>FWE_clu</sub> &lt; 0.05). Regression estimates were extracted from our VMPFC ROI (independently defined from the previous study) and tested at the group level to confirm that they had a similar effect size and were both highly significant (one-sample <i>t</i> tests on individual regression estimates; linear: β = 0.48 ± 0.13, <i>t</i><sub>17</sub> = 3.46, <i>P</i> = 0.0033; quadratic: β = 0.45 ± 0.13, <i>t</i><sub>17</sub> = 3.61, <i>P</i> = 0.0023). The aggregation of linear and quadratic terms was also observable when plotting the signal change as a function of ascending bins (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig4">Fig. 4d</a>) or the time course of effect sizes (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig4">Fig. 4e</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Neural integration of confidence in stimulus desirability rating (study 2)."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4: Neural integration of confidence in stimulus desirability rating (study 2).</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4064/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig4_HTML.jpg?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig4_HTML.jpg" alt="figure 4" loading="lazy" width="685" height="461"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>(<b>a</b>) Task design. Successive screens displayed in one trial are shown from left to right, with their durations. Subjects first watched a video depicting a stimulus (tool, toy or food item), with or without and actor pointing to this stimulus, and then had to judge its desirability on a scale of 0 to 10. (<b>b</b>) Statistical parametric map of activations with desirability ratings (cluster generating threshold, <i>P</i><sub>unc_vox</sub> &lt; 0.001; cluster family-wise correction, <i>P</i><sub>FWE_clu</sub> &lt; 0.05). The color code on glass brains (left maps) and axial slices (right maps) indicates the statistical significance of clusters that surpassed the thresholds. The [<i>x y z</i>] coordinates of the maxima indicated by the blue crosshairs and corresponding red pointers refer to Montreal Neurological Institute (MNI) space. (<b>c</b>) Conjunction between the linear and the quadratic expansions of the parametric desirability ratings (cluster generating threshold, <i>P</i><sub>unc_vox</sub> &lt; 0.005; cluster family-wise correction, <i>P</i><sub>FWE_clu</sub> &lt; 0.05). (<b>d</b>) Canonical ROI analysis. Trials were grouped per participants in six bins of ascending desirability, averaged at the population level and plotted against the BOLD signal estimated in the VMPFC ROI (isolated from group-level linear correlation with pleasantness; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3b</a>, left). Error bars indicate intersubject s.e.m.; solid lines indicate the best second-order polynomial fit (including both linear and quadratic terms). (<b>e</b>) Time-resolved ROI analysis. A FIR model estimated the effect size of the linear and quadratic expansions of desirability ratings on the VMPFC signal every 2 s after stimulus onset (time 0). The VMPFC ROI is the same as above. Shaded areas represent confidence intervals (means ± intersubject s.e.m.).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4064/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>This external replication suggests that integration of confidence in regions isolated for encoding value is a robust phenomenon. It can be extended to judgments of desirability—that is, an anticipated value—as opposed to pleasantness, which might be considered an experienced value.</p><h3 class="c-article__sub-heading" id="Sec7">Study 3a: relationship between second-order (confidence) and first-order (desirability, probability) ratings</h3><p>An obvious confounding factor for confidence is salience, which is generally conceived as unsigned stimulus value. The idea is that very pleasant and very unpleasant stimuli are both salient compared to neutral stimuli. Thus, salience would also vary as a U-shaped (or V-shaped) function of stimulus value. The fact that the VMPFC also signaled confidence in age rating could be taken as evidence against a confound with salience, but one could argue that very old and very new stimuli are more salient than middle-aged ones. We also noted that the results obtained with age rating were globally less clear-cut than with pleasantness rating. We therefore explored another subjective judgment, for which salience and confidence would not covary. We chose probability (likelihood), because salience is not expected to vary as a U-shaped function of probability: by definition very improbable events are salient but very probable events are not. In the new task designed for study 3, participants had to rate either the desirability or the probability of future events (prospects; see examples in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4064#MOESM53">Supplementary Table 1</a>). Participants were asked to rate either the desirability or the probability of factual prospects from various domains (culture, sport, society, economics, diplomacy, science, technology and so forth): for example, France wins the next World Football cup. A first group of healthy participants (<i>n</i> = 18) performed a version of this task (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig5">Fig. 5a</a>) that included rating confidence in first-order judgments (desirability or probability rating). Our hypothesis was that the VMPFC would not encode probability, because probability is, at least theoretically, orthogonal to value. As seen for pleasantness and age, the VMPFC would encode confidence in both desirability and probability. This would confirm our interpretation since it would show that the VMPFC signals the probability of being correct (that is, confidence) but not the probability of external events.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Relationship between confidence and prospect desirability or probability (study 3a)."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5: Relationship between confidence and prospect desirability or probability (study 3a).</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4064/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig5_HTML.jpg?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig5_HTML.jpg" alt="figure 5" loading="lazy" width="685" height="846"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>(<b>a</b>) Task design. Successive screens displayed in one trial are shown from left to right, with their durations. Subjects first read a prospect and then had to estimate either its desirability (between −10 and 10) or its probability of occurrence in the near future (between 0 and 100%). Then, participants were asked to estimate on a continuous scale how confident they were in their first-order rating, which was given on the screen. (<b>b</b>) Behavioral results. Both reaction time (left) and confidence rating (middle) vary as a U-shaped function of either desirability (top) or probability (bottom) rating. Reaction time is the interval between stimulus onset and first key press. Trials were grouped per participants in ten bins of ascending desirability or probability sorted at the individual level and then averaged across individuals. At right, each rating bin was divided into tertiles of confidence (light to dark color). Error bars indicate intersubject s.e.m. Solid lines indicate the best second-order polynomial fit.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4064/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Replicating the result of study 1a regarding subjective value (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig2">Fig. 2b</a>), we found that confidence ratings were well accounted for by squared desirability ratings (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig5">Fig. 5b</a>), but not by the linear regressor (one-sample <i>t</i> tests on individual regression estimates; linear: β = −0.01 ± 0.04, <i>t</i><sub>17</sub> = −0.25, <i>P</i> = 0.80; quadratic: 0.45 ± 0.05, <i>t</i><sub>17</sub> = 9.27, <i>P</i> &lt; 10<sup>−6</sup>). Extending this result, we found that confidence ratings were also explained by squared probability ratings, but only marginally by the linear regressor (quadratic: β = 0.47 ± 0.04, <i>t</i><sub>17</sub> = 10.94, <i>P</i> &lt; 10<sup>−6</sup>; linear: −0.15 ± 0.07, <i>t</i><sub>17</sub> = −2.16, <i>P</i> = 0.045). The unexpected linear trend was likely due to the fact that probability ratings were not exactly centered on 50% but biased toward lower estimates (paired <i>t</i>-test against 50%: rating = 0.42 ± 0.1, <i>t</i><sub>17</sub> = −4.45, <i>P</i> = 3.5 × 10<sup>−4</sup>). In line with model predictions (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1c</a>) and the results of study 1a (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig2">Fig. 2b</a>), the quadratic functions relating first-order rating to confidence level were deeper for low-confidence than for high-confidence tertiles, for both desirability (high confidence: β = 0.30 ± 0.0; low confidence: β = 0.81 ± 0.07; difference: <i>t</i><sub>17</sub> = 7.40, <i>P</i> = 3.5 × 10<sup>−6</sup>) and probability (high confidence: β = 0.34 ± 0.04; low confidence: β = 0.70 ± 0.08; difference: <i>t</i><sub>17</sub> = 4.45, <i>P</i> = 3.5 × 10<sup>−4</sup>).</p><p>Also in accordance with the results of study 1a, reaction time for first-order judgments was negatively correlated with the confidence assigned to these judgments (desirability: ρ = −0.20 ± 0.03, <i>t</i><sub>17</sub> = −7.52, <i>P</i> &lt; 10<sup>−6</sup>; probability: ρ = −0.17 ± 0.2, <i>t</i><sub>17</sub> = −8.66, <i>P</i> &lt; 10<sup>−6</sup>). Again, this suggests that confidence rating was based on a process that was occurring during first-order judgment and that could therefore be captured with fMRI even if no confidence judgment was explicitly required. We also verified with this new data set that, when squared rating and reaction time were incorporated into the same regression model, only squared rating was a significant predictor of confidence level across rating tasks (desirability: β = 0.44 ± 0.05, <i>t</i><sub>17</sub> = 9.58, <i>P</i> &lt; 10<sup>−6</sup>; probability: β = 0.46 ± 0.04, <i>t</i><sub>17</sub> = 10.78, <i>P</i> &lt; 10<sup>−6</sup>). This argues against the possibility that confidence could be a direct readout of reaction time and favors the hypothesis that reaction time is modulated by the same uncertainty as confidence, as well as integrating other sources of variability.</p><h3 class="c-article__sub-heading" id="Sec8">Study 3b: neural representation of confidence in desirability and probability rating</h3><p>A last group of healthy participants (<i>n</i> = 26) was scanned while performing the same task as in study 3a, with the same prospects and judgments, except that no confidence rating was required (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig6">Fig. 6a</a>). Neural activation was modeled as a boxcar covering both prospect presentation and the rating period, with desirability and probability trials in separate regressors. We included the rating period because, at the time of prospect presentation, subjects were not aware of which type of judgment (desirability or probability) would follow. Boxcars were parametrically modulated by response time, in addition to second-order polynomial extension of ratings (with linear and quadratic terms in separate regressors). We first analyzed the modulation by desirability and probability separately, to replicate the finding that the VMPFC encodes subjective value and not any first-order rating. We indeed observed a significant VMPFC activation with desirability (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig6">Fig. 6b</a>, <i>P</i><sub>FWE_clu</sub> &lt; 0.05) but not with probability, even at a permissive threshold (<i>P</i><sub>unc</sub> &lt; 0.01). Note that owing to the psychological phenomenon termed optimism bias<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Sharot, T., Riccardi, A.M., Raio, C.M. &amp; Phelps, E.A. Neural mechanisms mediating optimism bias. Nature 450, 102–105 (2007)." href="/articles/nn.4064#ref-CR22" id="ref-link-section-d30847472e1313">22</a></sup>, desirability and probability judgments were correlated (ρ = 0.30 ± 0.04, <i>t</i><sub>25</sub> = 8.25, <i>P</i> &lt; 10<sup>−6</sup>). However, orthogonalizing the two types of rating did not change any of the fMRI results. If anything, the correlation with desirability should have played against our result regarding probability (no relationship with VMPFC activity).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Neural integration of confidence in prospect desirability and probability rating (study 3b)."><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 6: Neural integration of confidence in prospect desirability and probability rating (study 3b).</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4064/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig6_HTML.jpg?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Fig6_HTML.jpg" alt="figure 6" loading="lazy" width="685" height="1022"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>(<b>a</b>) Task design. Successive screens displayed in one trial are shown from left to right, with their durations. Subjects first read a prospect and then had to rate either its desirability (between −10 and 10) or its probability of occurrence in the near future (between 0 and 100%). (<b>b</b>) Statistical parametric maps of activation with desirability (cluster generating threshold, <i>P</i><sub>unc_vox</sub> &lt; 0.001; cluster family-wise correction, <i>P</i><sub>FWE_clu</sub> &lt; 0.05) and probability (uncorrected voxel threshold, <i>P</i><sub>unc_vox</sub> &lt; 0.01) ratings. The color code on glass brains (gray to black) and sagittal slices (red to yellow) indicates the <i>t</i>-value of clusters that surpassed statistical threshold. The [<i>x y z</i>] coordinates of the maxima indicated by the blue crosshairs and corresponding red pointers refer to Montreal Neurological Institute (MNI) space. (<b>c</b>) Conjunction among linear correlation with desirability, quadratic correlation with desirability and quadratic correlation with probability (cluster generating threshold, <i>P</i><sub>unc_vox</sub> &lt; 0.005; cluster family-wise correction, <i>P</i><sub>FWE_clu</sub> &lt; 0.05). (<b>d</b>) Canonical ROI analysis. Trials were grouped for each participants in ten bins of ascending desirability (left) and probability (right), averaged at the population level and plotted against the BOLD signal estimated in the VMPFC ROI (isolated from group-level linear correlation with pleasantness; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Fig. 3b</a>, left). Error bars indicate intersubject s.e.m.; solid lines indicate the best second-order polynomial fit (including both linear and quadratic terms). (<b>e</b>) Time-resolved ROI analysis. A FIR model estimated the effect size of the linear and quadratic expansions of desirability (left) and probability (right) ratings on the VMPFC signal every 2 s after stimulus onset for linear expansions and every two 2 s after a starting point aligned to scale onset minus 6 s (corresponding to stimulus onset on average) for quadratic expansions. The VMPFC ROI is the same as above. Shaded areas represent confidence intervals (means ± intersubject s.e.m.).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4064/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Then we tested the hypothesis that the VMPFC would also encode confidence with a triple conjunction, including the linear and quadratic extensions of desirability ratings, as well as the quadratic extension of probability rating. At the whole brain level, this conjunction analysis revealed a single cluster, extending over the frontopolar and ventromedial prefrontal cortices (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig6">Fig. 6c</a>, <i>P</i><sub>FWE_clu</sub> &lt; 0.05). These results were confirmed by an analysis focused on our VMPFC ROI, independently defined in study 1b. Regarding desirability judgment, regression estimates extracted from this VMPFC ROI were both highly significant and had a similar effect size for the linear and quadratic functions (one-sample <i>t</i> tests on individual regression estimates; linear: β = 0.08 ± 0.02, <i>t</i><sub>25</sub> = 4.63, <i>P</i> = 9.6 × 10<sup>−5</sup>; quadratic: β = 0.09 ± 0.02, <i>t</i><sub>25</sub> = 4.56, <i>P</i> = 1.2 × 10<sup>−4</sup>). In contrast, regression estimates obtained for probability judgment did not follow a linear function, but only a quadratic one (linear: β = 0.02 ± 0.01, <i>t</i><sub>25</sub> = 1.54, <i>P</i> = 0.14; quadratic: β = 0.06 ± 0.02, <i>t</i><sub>25</sub> = 3.02, <i>P</i> = 0.0058). Again these results were similar whether or not response time was included in the regression model.</p><p>To illustrate encoding of value and confidence in the VMPFC, signal change was plotted against nine bins of ascending desirability or probability (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig6">Fig. 6d</a>) and effect size obtained with a parametric FIR model was plotted as a function of time (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig6">Fig. 6e</a>). Study 3b confirmed the notion that the VMPFC encodes specifically the first-order judgments related to value, and not belief. The U-shape function of probability observed in VMPFC activity further suggests that it encodes a second-order confidence judgment, rather than stimulus salience.</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Discussion</h2><div class="c-article-section__content" id="Sec9-content"><p>A highly replicated finding in neuroeconomics is that value estimates are encoded in a set of specific brain regions, among which the VMPFC appears to be key<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Peters, J. &amp; Buchel, C. Neural representations of subjective reward value. Behav. Brain Res. 213, 135–141 (2010)." href="/articles/nn.4064#ref-CR3" id="ref-link-section-d30847472e1458">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Bartra, O., McGuire, J.T. &amp; Kable, J.W. The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value. Neuroimage 76, 412–427 (2013)." href="/articles/nn.4064#ref-CR4" id="ref-link-section-d30847472e1461">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Clithero, J.A. &amp; Rangel, A. Informatic parcellation of the network involved in the computation of subjective value. Soc. Cogn. Affect. Neurosci. 9, 1289–1302 (2014)." href="/articles/nn.4064#ref-CR5" id="ref-link-section-d30847472e1464">5</a></sup>. Here we demonstrate that VMPFC activity is not a pure reflection of stimulus value because it also incorporates confidence, understood as a second-order judgment on the correctness of a first-order response. Furthermore, we suggest that the integration of response confidence is a general and automatic phenomenon. In the following we successively discuss the computational, behavioral and neuroimaging aspects of our demonstration.</p><p>Our computational model formalizes the notion that confidence is a second-order judgment on the correctness of a first-order response. This definition follows on a long tradition in the psychophysics of perceptual decisions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Pierce, C.S. &amp; Jastrow, J. On small differences of sensation. Mem. Natl. Acad. Sci. 3, 73–83 (1884)." href="/articles/nn.4064#ref-CR23" id="ref-link-section-d30847472e1471">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Adams, J.K. A confidence scale defined in terms of expected percentages. Am. J. Psychol. 70, 432–436 (1957)." href="/articles/nn.4064#ref-CR24" id="ref-link-section-d30847472e1474">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Vickers, D. Decision Processes in Visual Perception (Academic, New York, 1979)." href="/articles/nn.4064#ref-CR25" id="ref-link-section-d30847472e1477">25</a></sup>. In these early studies, as in more recent accounts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Pleskac, T.J. &amp; Busemeyer, J.R. Two-stage dynamic signal detection: a theory of choice, decision time, and confidence. Psychol. Rev. 117, 864–901 (2010)." href="/articles/nn.4064#ref-CR17" id="ref-link-section-d30847472e1481">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Yu, S., Pleskac, T.J. &amp; Zeigenfuse, M.D. Dynamics of postdecisional processing of confidence. J. Exp. Psychol. Gen. 144, 489–510 (2015)." href="/articles/nn.4064#ref-CR18" id="ref-link-section-d30847472e1484">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Fleming, S.M. &amp; Dolan, R.J. The neural basis of metacognitive ability. Phil. Trans. R. Soc. Lond. B 367, 1338–1349 (2012)." href="/articles/nn.4064#ref-CR26" id="ref-link-section-d30847472e1487">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Yeung, N. &amp; Summerfield, C. Metacognition in human decision-making: confidence and error monitoring. Phil. Trans. R. Soc. Lond. B 367, 1310–1321 (2012)." href="/articles/nn.4064#ref-CR27" id="ref-link-section-d30847472e1490">27</a></sup>, confidence has been conceived as a secondary representation arising from the amount of perceptual evidence on which decisions are based. The amount of evidence could be captured by a probability distribution over a decision variable defined as the difference between options in the relevant dimension: for example, a difference in brightness between two visual stimuli. We intended to generalize this idea in several ways. First, the model applies to external signals that can be objectively measured (for example, brightness or age judgments) and also to internal signals that are more subject specific (for example, desirability or probability estimates). Second, the model extends to any kind of judgment, including those that involve just one item (for example, a face), instead of restricting the theory to binary choice—that is, to judgment on the difference between two items. Third, the model generalizes to the cases where more than two responses can be given, as implemented in rating tasks (for example, from −10 to 10, not just yes versus no).</p><p>Previous studies have derived confidence in binary choice from the endpoint of a decision variable that accumulates the results of sequentially sampling a probability distribution<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="De Martino, B., Fleming, S.M., Garrett, N. &amp; Dolan, R.J. Confidence in value-based choice. Nat. Neurosci. 16, 105–110 (2013)." href="/articles/nn.4064#ref-CR15" id="ref-link-section-d30847472e1497">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Pleskac, T.J. &amp; Busemeyer, J.R. Two-stage dynamic signal detection: a theory of choice, decision time, and confidence. Psychol. Rev. 117, 864–901 (2010)." href="/articles/nn.4064#ref-CR17" id="ref-link-section-d30847472e1500">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Yu, S., Pleskac, T.J. &amp; Zeigenfuse, M.D. Dynamics of postdecisional processing of confidence. J. Exp. Psychol. Gen. 144, 489–510 (2015)." href="/articles/nn.4064#ref-CR18" id="ref-link-section-d30847472e1503">18</a></sup>. We tried to adapt this formalism to rating tasks, but it led to major inconsistencies, such as confidence increasing (not decreasing) with the variance of the probability distribution (see Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.4064#Sec10">Methods</a> and ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Daunizeau, J. A note on race models &#xA;                  http://sites.google.com/site/jeandaunizeauswebsite/links/resources&#xA;                  &#xA;                 (2015)." href="/articles/nn.4064#ref-CR28" id="ref-link-section-d30847472e1509">28</a>). The model that we suggest instead captures the processes involved by rating tasks in a more direct manner. It starts with the intuitive assumption that subjects intend to minimize the gap between their overt rating and their internal judgment. This involves specifying a utility function based on this distance and a mapping function for the projection from internal judgment to external rating. We used standard, parsimonious functions, with a squared distance for the utility function and a sigmoid projection for the mapping function. Confidence was naturally defined as the expected response accuracy: that is, the quantity that subjects intend to maximize. Note there is a slight twist in the notion of accuracy here, as it refers in our model to the adequacy of the external response with respect to a subjective judgment (and not to an objective measure), which allows addressing tasks in which there is no good or bad answer. Under these definitions, analytical decomposition allowed us to derive how rating and confidence should vary with the mean and variance of the internal probability distribution and, most importantly, how they relate to each other.</p><p>This formalism captures two intuitions. The first intuition is that we prefer to be more confident, as confidence is the quantity that the model maximizes when selecting a particular rating. This makes a link between confidence and the notion of expected value employed in economic choice. The second intuition is that midscale ratings can be of two sorts: one would be “I know this is indifferent to me” (mean around zero) and the other “I don't know how I feel about this” (high variance). In other words, uncertainty tends to bias the response toward the middle of the scale, which is expressed by the quadratic relationship between rating and confidence.</p><p>To our knowledge, the quadratic link between second-order confidence and first-order ratings has never been specifically explored, despite its intuitive appeal. Our behavioral experiments confirmed this quadratic relationship in four types of first-order rating, including subjective dimensions (pleasantness, desirability and probability rating) as well as objective features of the stimuli (age rating). Although the same quadratic pattern was observed on average, we noted some variations related to individual expertise. For instance, in the age rating task, many subjects found modern paintings easier to date than old ones. Individual expertise may therefore induce a departure from a pure quadratic relationship with objective dimensions, for which the idiosyncratic uncertainty is likely to vary across the scale in an asymmetric manner.</p><p>The use of age and probability as controls was furthermore important to rule out a possible confound of salience with confidence. Salience is a loosely defined concept; it usually refers to the property of an object that attracts attention. In neuroeconomics, it has been defined as unsigned value, such that very appetitive and very aversive items are both highly salient<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Litt, A., Plassmann, H., Shiv, B. &amp; Rangel, A. Dissociating valuation and saliency signals during decision-making. Cereb. Cortex 21, 95–102 (2011)." href="/articles/nn.4064#ref-CR29" id="ref-link-section-d30847472e1523">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Maunsell, J.H. Neuronal representations of cognitive state: reward or attention? Trends Cogn. Sci. 8, 261–265 (2004)." href="/articles/nn.4064#ref-CR30" id="ref-link-section-d30847472e1526">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Roesch, M.R. &amp; Olson, C.R. Neuronal activity related to anticipated reward in frontal cortex: does it represent value or reflect motivation? Ann. NY Acad. Sci. 1121, 431–446 (2007)." href="/articles/nn.4064#ref-CR31" id="ref-link-section-d30847472e1529">31</a></sup>. This means that salience should vary as a V-shaped function of value, which can easily turn into a U shape with the noise inherent in experimental data acquisition. Yet this would only occur if value ratings are centered on the reference point indicating the transition between aversive and appetitive items. However, the observed U-shaped relationship between second-order confidence levels and first-order ratings did not depend on whether we used only appetitive or both appetitive and aversive items, and neither did it depend on whether the rating scale had only positive or both positive and negative numbers. This is consistent with the sigmoid mapping implemented in our model, which normalizes the ratings irrespective of the particular scale imposed on participants. In addition, we also observed a U-shaped relationship between confidence and probability ratings, which allowed us to dissociate confidence from salience. Indeed, salience should vary linearly (not quadratically) with probability, as more probable events are by definition less surprising and therefore less salient.</p><p>Yet several limitations of the model must be acknowledged. A first limitation is that the model does not account for how participants adjust the sigmoid mapping depending on the set of stimuli and rating scale they are given. Some anchoring effect is likely to occur, as subjects probably need a series of trials to learn the range of values covered by the stimuli. To avoid this, we trained participants on a set of stimuli that were not identical but were similar in mean and variance to the stimuli used during the experiments. Thus we believe that the behavioral results were acquired after participants had adjusted the mapping from internal values to external ratings.</p><p>A second limitation is that the model does not describe the dynamics of the rating process, which would be necessary to predict response time. We observed that reaction time also varied as a U-shaped function of first-order ratings, albeit in a noisier manner suggesting that it also includes other sources of variance. We suspect that reaction time is also affected by the processes constructing the internal judgment (for example, pleasantness) and not just by the processes translating the uncertainty of this judgment into an overt rating. Modeling these processes would go far beyond the scope of this study but certainly represents a key challenge for neuroeconomics.</p><p>A third limitation is that our model is formalized at a computational level and does not suggest any neural implementation. Further work would be needed to understand whether the projection of the internal probability distribution to the rating scale and the confidence-based selection of optimal rating are just 'as if' mechanisms or whether they are truly implemented in the brain. In the following, we only highlight one neural correlate: the encoding of confidence in VMPFC activity.</p><p>The analysis of old and new fMRI studies revealed that VMPFC activity was correlated with the quadratic extension of first-order ratings, which we take as a proxy for confidence. Note that the quadratic pattern of activity was not a trivial reflection of response time, which was also included in the general linear model. We found no evidence for VMPFC activity decreasing with response time, even when the squared rating was removed from the general linear model. This observation rules out the possibility that the VMPFC could represent not confidence but overall task difficulty (or easiness), which might be quantified by response time.</p><p>Somewhat ironically, the VMPFC ROI was defined as a region encoding stimulus pleasantness—that is, correlating linearly with first-order ratings. The meta-analysis using the same ROI across studies confirmed the robustness of value encoding in the VMPFC, despite differences in stimuli (perceived items including faces, houses, paintings, toys, food and clothes, or anticipated events including sport, culture, politics and so forth), instructions (pleasantness or desirability rating) and presentation modes (pictures, videos or sentences). ROI selection should have biased the result toward a linear correlation, but the quadratic term turned out to be significant as well. This means that confidence is encoded in the brain region that has been thought to be the location of subjective valuation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e1549">9</a></sup>, as was previously shown in the case of economic choice<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="De Martino, B., Fleming, S.M., Garrett, N. &amp; Dolan, R.J. Confidence in value-based choice. Nat. Neurosci. 16, 105–110 (2013)." href="/articles/nn.4064#ref-CR15" id="ref-link-section-d30847472e1553">15</a></sup>.</p><p>Such a finding may not be surprising under our model, in which confidence is construed as the intrinsic value of the behavioral response. However, as in any model-based fMRI analysis, the correlation with VMPFC activity does not prove that the brain actually uses this confidence signal to guide the response. It could well be that confidence is an epiphenomenon—that is, a by-product of a response that is based on other types of signals. Yet since subjects likely intend to be accurate, it would seem bizarre if they did not use this estimate of response accuracy that is represented in their VMPFC.</p><p>In whole-brain searches, we did not find any other regions showing consistent conjunction of value and confidence encoding across studies. Like any null result, this absence of effect must be taken with caution. While we are conclusive about the VMPFC, we remain open to the possibility that other regions of the so-called brain valuation system also incorporate confidence. This has been suggested in the literature investigating confidence in recognition memory, which has been related to activity in the ventral striatum and posterior cingulate cortex, in addition to the VMPFC<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Chua, E.F., Schacter, D.L., Rand-Giovannetti, E. &amp; Sperling, R.A. Understanding metamemory: neural correlates of the cognitive process and subjective level of confidence in recognition memory. Neuroimage 29, 1150–1160 (2006)." href="/articles/nn.4064#ref-CR32" id="ref-link-section-d30847472e1563">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Moritz, S., Glascher, J., Sommer, T., Buchel, C. &amp; Braus, D.F. Neural correlates of memory confidence. Neuroimage 33, 1188–1193 (2006)." href="/articles/nn.4064#ref-CR33" id="ref-link-section-d30847472e1566">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Schwarze, U., Bingel, U., Badre, D. &amp; Sommer, T. Ventral striatal activity correlates with memory confidence for old- and new-responses in a difficult recognition test. PLoS ONE 8, e54324 (2013)." href="/articles/nn.4064#ref-CR34" id="ref-link-section-d30847472e1569">34</a></sup>. Also, a recent meta-analysis has shown that the most consistent regions encoding confidence judgment across memory and perception tasks are the VMPFC, hippocampus and posterior cingulate cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="White, T.P., Engen, N.H., Sørensen, S., Overgaard, M. &amp; Shergill, S.S. Uncertainty and confidence from the triple-network perspective: voxel-based meta-analyses. Brain Cogn. 85, 191–200 (2014)." href="/articles/nn.4064#ref-CR35" id="ref-link-section-d30847472e1573">35</a></sup>.</p><p>Because the VMPFC exhibited the same quadratic pattern of activity in three fMRI data sets across a variety of first-order ratings (age, pleasantness, probability, desirability), we believe this is a general and robust phenomenon. However, one may find artificial the dissociation of the activity pattern observed with value-related ratings (pleasantness and desirability) into linear and quadratic terms. The notion that two variables (linear, value; quadratic, confidence) were encoded in these conditions is supported by the fact that the quadratic shape was isolated when using first-order ratings that have no value component (age and probability). The latter result also offers evidence that the VMPFC represents only value-related judgment, and not any type of rating. A U-shaped pattern has already been noted in the VMPFC or other brain valuation system regions and has been interpreted as reflecting arousal or salience<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Litt, A., Plassmann, H., Shiv, B. &amp; Rangel, A. Dissociating valuation and saliency signals during decision-making. Cereb. Cortex 21, 95–102 (2011)." href="/articles/nn.4064#ref-CR29" id="ref-link-section-d30847472e1580">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Costa, V.D., Lang, P.J., Sabatinelli, D., Versace, F. &amp; Bradley, M.M. Emotional imagery: assessing pleasure and arousal in the brain's reward circuitry. Hum. Brain Mapp. 31, 1446–1457 (2010)." href="/articles/nn.4064#ref-CR36" id="ref-link-section-d30847472e1583">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Elliott, R., Newman, J.L., Longe, O.A. &amp; Deakin, J.F.W. Differential response patterns in the striatum and orbitofrontal cortex to financial reward in humans: a parametric functional magnetic resonance imaging study. J. Neurosci. 23, 303–307 (2003)." href="/articles/nn.4064#ref-CR37" id="ref-link-section-d30847472e1586">37</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Cooper, J.C. &amp; Knutson, B. Valence and salience contribute to nucleus accumbens activation. Neuroimage 39, 538–547 (2008)." href="/articles/nn.4064#ref-CR38" id="ref-link-section-d30847472e1589">38</a></sup>. A more parsimonious interpretation that accounts for all our results is that the VMPFC encodes confidence (or response value) in addition to stimulus value. The idea of a common neural currency has been separately suggested for value<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Levy, D. &amp; Glimcher, P.W. The root of all value: a neural common currency for choice. Curr. Opin. Neurosci. 22, 1027–1038 (2012)." href="/articles/nn.4064#ref-CR39" id="ref-link-section-d30847472e1593">39</a></sup> and confidence<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="de Gardelle, V. &amp; Mamassian, P. Does confidence use a common currency across two visual tasks? Psychol. Sci. 25, 1286–1288 (2014)." href="/articles/nn.4064#ref-CR40" id="ref-link-section-d30847472e1597">40</a></sup>. Our findings further suggest that the currency represented by the VMPFC signal might be common to value and confidence.</p><p>A crucial finding is that confidence encoding in the VMPFC was observed in the absence of any instruction to report confidence. This is consistent with the subjective experience that a feeling of confidence (or doubt) automatically arises when making a judgment. Our model provides a reason for this automaticity: it comes from confidence being the quantity that is maximized (and therefore estimated) when selecting the best response. Thus, the automatic integration of confidence demonstrated here strengthens the general view of the VMPFC as an automatic valuation system, which has been previously documented in the case of stimulus values<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e1604">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Levy, I., Lazzaro, S., Rutledge, R. &amp; Glimcher, P. Choice from non-choice: predicting consumer preferences from blood oxygenation level-dependent signals obtained during passive viewing. J. Neurosci. 31, 118–125 (2011)." href="/articles/nn.4064#ref-CR11" id="ref-link-section-d30847472e1607">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Harvey, A.H., Kirk, U., Denfield, G. &amp; Montague, P. Monetary favors and their influence on neural responses and revealed preference. J. Neurosci. 30, 9597–9602 (2010)." href="/articles/nn.4064#ref-CR12" id="ref-link-section-d30847472e1610">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Abitbol, R. et al. Neural mechanisms underlying contextual dependency of subjective values: converging evidence from monkeys and humans. J. Neurosci. 35, 2308–2320 (2015)." href="/articles/nn.4064#ref-CR13" id="ref-link-section-d30847472e1613">13</a></sup>.</p><p>We believe that our findings might bring important constraints for building a biologically inspired theory of choice. A first constraint is that any valuation operated by the VMPFC during choice or rating tasks might come with a confidence level (or an uncertainty level). The uncertainty that is typically considered in economic choice is the stochastic component of drift diffusion models: that is, an uncertainty attached to the value difference between the two options. Taking into account the confidence that subjects have in each option valuation might affect choice and response time in nontrivial ways. A second constraint is that VMPFC activity might aggregate the value of many aspects of a given situation. We suspect that such an aggregation of values, including response confidence, has been engaged but overlooked in previous studies. Taking this into consideration would complicate decoding the value of one particular item, since this value might be confounded by the values of contextual features, such as task pleasantness or physical discomfort, which could vary across time or conditions. However, unraveling such mechanisms of value aggregation in the VMPFC might be key to explaining many irrational behaviors. Indeed, aggregation of value and confidence might lead to misattribution, such that one could feel more confident not because one expects to perform better but because one is in a more pleasant context.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Methods</h2><div class="c-article-section__content" id="Sec10-content"><h3 class="c-article__sub-heading" id="Sec11">Computational model.</h3><p>In what follows, we describe a computational model that attempts to explain two phenomena: (i) confidence is a U-shaped function of first-order judgments, and (ii) confidence is linked to the intrinsic value of the behavioral response. We will consider a pleasantness rating task similar to that used in study 1.</p><p>Let <i>x</i> measures how pleasant the item to be rated is on people's internal (subjective) scale. People are asked to rate the item pleasantness on a bounded arbitrary scale. Without loss of generality, we assume that the external scale is bounded between 0 and 1. This implies that people need to map their internal (natural) pleasantness judgment <i>x</i> onto the [0,1] interval. Note that to preserve preference orderings, this mapping must be monotonic. Again, without loss of generality, the sigmoid mapping <i>s</i>:<i>x</i> → <i>s</i>(<i>x</i>) = 1/(1 + e<sup>−<i>x</i></sup>) is the simplest (smoothest) mapping that satisfies these constraints. Let <i>r</i> be the participant's rating on the external scale. The task instructions can now be understood as follows: find a rating <i>r̂</i> that best matches the mapped pleasantness <i>s</i>(<i>x</i>). This induces a utility function <i>U</i>(<i>r</i>,<i>x</i>) = −[<i>r</i> – <i>s</i>(<i>x</i>)]<sup>2</sup> that measures the accuracy of the mapped pleasantness. Here the accuracy is simply the negative of the squared error of the rating. Complying with the task instructions thus reduces to maximizing the utility function <i>U</i>(<i>r</i>,<i>x</i>); that is, maximizing the accuracy of the rating.</p><p>If <i>x</i> was known without ambiguity, the solution to this problem would be trivial:</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><img src="//media.springernature.com/lw268/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Equ1_HTML.gif" class="u-display-block" alt=""></div></div><p>Equation (1) means that, in the absence of uncertainty about <i>x</i>, the optimal rating <i>r̂</i> is simply <i>s</i>(<i>x</i>).</p><p>Now let us assume that people are uncertain about <i>x</i>: that is, the information people have about <i>x</i> is captured by a probability distribution function <i>p</i>(<i>x</i>) with mean <i>μ</i> and variance <i>σ</i>. This means that the utility <i>U</i>(<i>r</i>,<i>x</i>) cannot be evaluated (it is itself uncertain). The decision-theoretic solution to the rating task is thus to maximize the expected utility, which yields a rating that is on average optimal (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1a</a>). In other words, the optimal rating <i>r̂</i> is the solution to the following problem:</p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><img src="//media.springernature.com/lw299/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Equ2_HTML.gif" class="u-display-block" alt=""></div></div><p>where <i>Q</i>(<i>r</i>, <i>μ</i>, <i>σ</i>) is the expected utility (which depends upon the moments of <i>p</i>(<i>x</i>)) and the expectation is taken under the probability distribution <i>p</i>(<i>x</i>). This quantity is important because confidence is, by definition, the expected accuracy of the rating.</p><p>One can show that the expected accuracy can be broken down into two terms:</p><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><img src="//media.springernature.com/lw321/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Equ3_HTML.gif" class="u-display-block" alt=""></div></div><p>where <i>V</i>[<i>s</i>(<i>x</i>)] is the variance of <i>s</i>(<i>x</i>) under <i>p</i>(<i>x</i>).</p><p>Inserting equation (3) into equation (2) yields optimal rating <i>r̂</i>:</p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><img src="//media.springernature.com/lw286/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Equ4_HTML.gif" class="u-display-block" alt=""></div></div><p>where the first line derives from noting that the first term in equation (3) is the only one that explicitly depends on <i>r</i> and the last line is an analytical approximation to the expected sigmoid mapping<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Daunizeau, J. On the exponential, sigmoid and softmax mappings &#xA;                  http://sites.google.com/site/jeandaunizeauswebsite/links/resources&#xA;                  &#xA;                 (2014)." href="/articles/nn.4064#ref-CR41" id="ref-link-section-d30847472e1858">41</a></sup>. Equation (4) tells us how the optimal rating <i>r̂</i> depends on <i>μ</i> and <i>σ</i>, which measures how uncertain people are about the item's pleasantness. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Figure 1b</a> (left panel) shows how <i>E</i>[<i>s</i>(<i>x</i>)] varies as a function of <i>μ</i> and <i>σ</i>.</p><p>In particular, one can show that <img src="//media.springernature.com/lw79/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_IEq1_HTML.gif" style="width:79px;max-width:none;" alt="">; that is, people should aim for the middle of the rating scale when they are maximally uncertain. This explains why items that are rated at the middle of the external scale consist of a mixture of items that are certainly neutral (for example, point P<sub>1</sub> in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1b</a>) and items whose pleasantness is uncertain (for example, point P<sub>2</sub> in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1b</a>).</p><p>Now equation (3) tells us something more: having rated items optimally, people are left with some residual (nonzero) expected error. This means that, although people may optimally rate the item on the external pleasantness scale, they still expect to be wrong. In turn, optimal confidence measures how accurate people expect to be, having chosen the optimal rating:</p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><img src="//media.springernature.com/lw312/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_Equ5_HTML.gif" class="u-display-block" alt=""></div></div><p>where the first line derives from inserting equation (4) into equation (3) and the second line is an analytical approximation to the variance of the sigmoid mapping<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Daunizeau, J. On the exponential, sigmoid and softmax mappings &#xA;                  http://sites.google.com/site/jeandaunizeauswebsite/links/resources&#xA;                  &#xA;                 (2014)." href="/articles/nn.4064#ref-CR41" id="ref-link-section-d30847472e1925">41</a></sup>. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Figure 1b</a> (right panel) shows how <i>V</i>[<i>s</i>(<i>x</i>)] varies as a function of <i>μ</i> and <i>σ</i>. One can show that <i>σQ</i>/<i>σσ</i> ≤ 0; that is, optimal confidence is a monotonically decreasing function of people's uncertainty <i>σ</i> (see <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1c</a>, left). Besides, <img src="//media.springernature.com/lw115/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_IEq2_HTML.gif" style="width:115px;max-width:none;" alt="">; that is, there is no residual error when people are certain about how pleasant the item is.</p><p>Taken together, equations (4) and (5) make two predictions: (i) confidence <img src="//media.springernature.com/lw75/springer-static/image/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_Article_BFnn4064_IEq3_HTML.gif" style="width:75px;max-width:none;" alt=""> is a quadratic function of rating <i>r̂</i> (see <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Fig. 1c</a>, right panel), and (ii) being confident about the rating has high utility (in terms of people's feeling about being accurate). The latter provides a normative explanation for why being confident about the rating is, in and of itself, valuable.</p><p>Lastly, note that the above two predictions hold irrespective of the nature of the rating, as long as the internal uncertainty <i>σ</i> is non-negligible when compared to the extent of the external rating scale.</p><p>We considered alternative models for our empirical findings. For example, De Martino and colleagues<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="De Martino, B., Fleming, S.M., Garrett, N. &amp; Dolan, R.J. Confidence in value-based choice. Nat. Neurosci. 16, 105–110 (2013)." href="/articles/nn.4064#ref-CR15" id="ref-link-section-d30847472e1995">15</a></sup> propose a model for confidence judgments in the context of binary decisions, which can be extended to pleasantness rating tasks as follows. One would assume that two accumulators representing the left (“I do not like it”) and right (“I like it”) halves of the rating scale enter a race that ends whenever one of the accumulator reaches a predefined threshold. The winning accumulator determines both the rating time and the rating sign (if the central position is zero). Both rating magnitude and confidence would then be given by the distance between the two accumulators. Analysis of this race model reveals a nontrivial consequence of the above definition of confidence: confidence level should increase, not decrease, with the variance of the value signal. This contradiction drove us to conclude that reading confidence as the endpoint of an accumulation process is not appropriate, at least in the case of rating tasks. Most relevant mathematical details are laid out in a technical note on race models that is available online<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Daunizeau, J. A note on race models &#xA;                  http://sites.google.com/site/jeandaunizeauswebsite/links/resources&#xA;                  &#xA;                 (2015)." href="/articles/nn.4064#ref-CR28" id="ref-link-section-d30847472e1999">28</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec12">Subjects.</h3><p>The studies were approved by the Ethics Committee for Biomedical Research of the Pitié-Salpêtrière Hospital, where they were conducted. Subjects were recruited via the RISC (Relais d'Information en Sciences Cognitives) website and screened for exclusion criteria: age below 18 or above 39, regular use of drugs or medications, history of psychiatric or neurological disorders and contraindications to MRI scanning (pregnancy, claustrophobia, metallic implants). All subjects gave informed consent before taking part in the study. Unless otherwise specified, subjects were paid 30 for the simple behavioral experiments (studies 1a and 3a) and 100 for the fMRI experiments (studies 1b, 2 and 3b).</p><p>A total of 125 subjects were included in the different studies (study 1a, first group: <i>n</i> = 19, 9 males, age = 22.2 ± 2.4; study 1a, second group: <i>n</i> = 22, 12 males, age = 24.4 ± 2.9; study 1b: <i>n</i> = 20, 10 males, age = 22.0 ± 2.7; study 2: <i>n</i> = 19, 11 males, age = 23.9 ± 4.0; study 3a: <i>n</i> = 19, 10 males, age = 23.1 ± 5.3; study 3b: <i>n</i> = 26, 12 males, age 25.3 ± 5.5). Three subjects were excluded, one in study 1a for abnormally long reaction times (&gt;10 s), one in study 2 because a technical problem occurred during scanning, and the last in study 3a for always giving the same confidence level.</p><h3 class="c-article__sub-heading" id="Sec13">Tasks.</h3><p>All tasks were programmed on a PC using the Cogent 2000 (Wellcome Department of Imaging Neuroscience, London, UK) library of Matlab functions for stimulus presentation. They all involved rating procedures that were implemented as follows.</p><p>In behavioral studies, subjects performed the task on a standard computer. They could move the cursor by pressing left and right arrows on the keyboard. Ratings were all self-paced, and subjects had to press the spacebar to validate their response and go to the next trial.</p><p>In fMRI studies, subjects could move the cursor by pressing a button with the right index finger to go left or with the right middle finger to go right. Again, ratings were all self-paced, and subjects had to press a button with the left index finger to validate their response and go to the next trial.</p><p>In both fMRI and behavioral studies, the initial position of the cursor on the scale was randomized to avoid confounding the ratings with the movements they involved.</p><p>Details specific to the different tasks are described below.</p><p><i>Study 1.</i> Stimuli were 120 faces, 120 houses and 120 paintings, for a total of 360 pictures that we had used in a previous experiment (see picture selection in ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e2058">9</a>). The 360 stimuli were randomly distributed over 6 sessions of 60 trials each (20 faces, 20 houses and 20 pictures).</p><p><i>Study 1a.</i> For the first group, every trial started with a fixation cross, after which one picture was displayed on the center of the screen, at the top of a 21-step rating scale graduated between −10 and 10. Participants were asked to indicate on this scale how pleasant the presented stimulus was. After validation of the pleasantness judgment, a sentence reminding participants of their rating appeared (“You gave a rating of <i>X</i>”), together with another 100-step (almost continuous) rating scale, on which they were asked to indicate how confident they were about their first-order rating (“How confident are you?”, between “Not at all”, and “Totally”). The task was similar for the second group, except that subjects had to rate how old (instead of how pleasant) the presented stimulus was, on a 21-step scale that was adapted to the category (face, house or painting).</p><p><i>Study 1b.</i> This fMRI study is a reanalysis of data obtained in a previous experiment (see ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. Neuron 64, 431–439 (2009)." href="/articles/nn.4064#ref-CR9" id="ref-link-section-d30847472e2074">9</a> for detailed methods). Subjects performed three sessions of the pleasantness rating task and three sessions of the age rating tasks, the order being counterbalanced across subjects. In every trial, the picture was first displayed on the screen for 3 s, following a fixation cross. Then the rating scale appeared, and participants had to indicate on this scale how pleasant or how old the presented stimulus was. There was no confidence rating in this study.</p><p><i>Study 2.</i> This fMRI study is a reanalysis of data obtained in a previous experiment (see ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Lebreton, M., Kawa, S., Forgeot d'Arc, B., Daunizeau, J. &amp; Pessiglione, M. Your goal is mine: unraveling mimetic desires in the human brain. J. Neurosci. 32, 7146–7157 (2012)." href="/articles/nn.4064#ref-CR21" id="ref-link-section-d30847472e2082">21</a> for detailed methods) using a desirability rating task. Stimuli were 240 short (2–5 s) videos featuring different objects (food, toys, clothes and tools), randomly distributed over four 60-trial sessions. In every trial, the video was first played on the screen, following a fixation cross. Then a 0–10 rating scale appeared, and participants had to indicate how much they would like to acquire the object. There was no confidence rating in this study.</p><p><i>Study 3.</i> Stimuli were 270 potential events (prospects; see examples in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4064#MOESM53">Supplementary Table 1</a>) from various domains (politics, sport, society, culture, media, economics, diplomacy, science, technology, etc.). Subjects were instructed to read the text depicting the event and think of how pleased they would feel should this event happen in the next 5 years (for desirability rating) and how likely they estimated this event would be to actually happen in the next 5 years (for probability rating). They were randomly distributed over 5 sessions of 54 trials each (27 desirability rating and 27 probability rating trials, randomly intermixed).</p><p><i>Study 3a.</i> Every trial started with a fixation cross, after which the event was displayed on the screen for a duration of 2 s. Then appeared a 21-step rating scale that could be either a desirability or a probability scale. The desirability scale was graduated between −10 (not desirable at all) and 10 (highly desirable), whereas the probability scale was graduated from 0 (completely unlikely) to 100% (most likely). The scales were accompanied by the word “DESIRABILITY” or “PROBABILITY,” which served as instruction. After validation of the first-order rating, a continuous scale was displayed, on which the subject had to indicate how confident they were (“How confident are you?”, between “Not at all” and “Totally”) about their first-order rating, which was recalled on screen (“You gave a rating of <i>X</i>”).</p><p><i>Study 3b.</i> The preceding task was adapted to comply with fMRI limitations, as well as to assess the automaticity of confidence elicitation. On every trial, one prospect was displayed alone on the screen for a duration drawn from a uniform 5–7 s distribution, following a 1-s fixation cross. The desirability or probability scale only appeared after prospect display, and there was no confidence rating. We also added an extra jitter: one out of eight trials started with a fixation cross lasting 9 s instead of 1 s. Outside the scanner, participants underwent five other sessions where each event was presented a second time, and participants were asked to rate the dimension complementary to the one that was randomly selected in the scanner (that is, probability judgment for events that were assessed on the value dimension in the scanner, and vice versa).</p><h3 class="c-article__sub-heading" id="Sec14">Statistics.</h3><p>No statistical methods were used to predetermine sample sizes, but our sample sizes are similar to those generally employed in the field. Unless otherwise specified, all dependent variables (raw, <i>z</i>-scored or binned behavioral measures and robust regression estimates) were computed at the session level, averaged at the subject level and tested for significance at the group level (random effect analysis) using two-tailed paired <i>t</i>-tests. All robust regressions were performed on <i>z</i>-scored independent and dependent variables. Data distribution was assumed to be normal but this was not formally tested. All statistical analyses were performed with Matlab Statistical Toolbox (Matlab R2014a, The MathWorks, Inc., USA).</p><h3 class="c-article__sub-heading" id="Sec15">Code availability.</h3><p>The code used to generate the simulations illustrating our theoretical model in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig1">Figure 1</a> and to run the behavioral tasks is available upon request.</p><h3 class="c-article__sub-heading" id="Sec16">Neuroimaging data acquisition.</h3><p>For all imaging studies, T2*-weighted echo planar images (EPI) were acquired with blood oxygen level–dependent (BOLD) contrast on a 3.0-T magnetic resonance scanner. We employed a tilted plane acquisition sequence designed to optimize functional sensitivity in the orbitofrontal cortex and medial temporal lobes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Deichmann, R., Gottfried, J., Hutton, C. &amp; Turner, R. Optimized EPI for fMRI studies of the orbitofrontal cortex. Neuroimage 19, 430–441 (2003)." href="/articles/nn.4064#ref-CR42" id="ref-link-section-d30847472e2145">42</a></sup>. To cover the whole brain with good spatial resolution, we used the following parameters:</p><p>Study 1b: TR = 2.29 s, 35 slices, 2 mm slice thickness, 1 mm inter-slice gap</p><p>Study 2: TR = 2.0 s, 35 slices, 2 mm slice thickness, 1.5 mm inter-slice gap.</p><p>Study 3b: TR = 2.03 s, 35 slices, 2 mm slice thickness, 1.6 inter-slice gap.</p><p>T1-weighted structural images were also acquired, co-registered with the mean EPI, normalized using nonlinear transformation to a standard T1 template, and averaged across subjects to allow group level anatomical localization. EPI data were analyzed in an event-related manner, within a general linear model, using the statistical parametric mapping software SPM8 (Wellcome Trust center for NeuroImaging, London, UK) implemented in Matlab. The first 5 volumes of each session were discarded to allow for T1 equilibration effects. Preprocessing consisted of spatial realignment, normalization using the same transformation as structural images, and spatial smoothing using a Gaussian kernel with a full-width at half-maximum (FWHM) of 8 mm.</p><h3 class="c-article__sub-heading" id="Sec17">Neuroimaging data analysis.</h3><p><i>General linear models (GLM).</i> We used the following GLM to explain subject-level time series.</p><p><i>Study 1a.</i> Events were image display, modeled as boxcar function. This categorical regressor was modulated by two parameters accounting for the first- and second-order polynomial expansion of ratings (either age or pleasantness, depending on the session), which were <i>z</i>-scored per category (face, house, painting) beforehand. We also modeled the rating period in another regressor with a boxcar function modulated by response time.</p><p><i>Study 2.</i> Events were video display, modeled as boxcar function. This categorical regressor was modulated by two parameters accounting for the first- and second-order polynomial expansion of desirability ratings. We also modeled the rating period in another regressor with a boxcar function modulated by response time.</p><p><i>Study 3b.</i> The two types of trial, corresponding to desirability and probability rating, were modeled in separate regressors, as boxcar functions covering both stimulus presentation and rating scale. Those events were modulated by four parameters each: the first- and second-order polynomial expansion of <i>z</i>-scored rating (either desirability or probability, depending on trial type), the response time and the prospect length (number of characters).</p><p><i>Whole-brain analysis.</i> All regressors of interest were convolved with a canonical hemodynamic response function. To correct for motion artifacts, subject-specific realignment parameters were modeled as covariates of no interest. Linear contrasts of regression coefficients (β values) were computed at the session level, averaged at the subject level and taken to a group-level random effect analysis, using one-sample <i>t</i>-tests. Conjunction analyses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Friston, K.J., Penny, W.D. &amp; Glaser, D.E. Conjunction revisited. Neuroimage 25, 661–667 (2005)." href="/articles/nn.4064#ref-CR43" id="ref-link-section-d30847472e2202">43</a></sup> were performed to find brain regions encoding two or three parameters of interest.</p><p>Unless otherwise specified, all activations maps were thresholded using family-wise correction for multiple comparison (FWE) either at the voxel level (<i>P</i><sub>FWE_vox</sub> &lt; 0.05) or at the cluster level (<i>P</i><sub>FWE_clu</sub> &lt; 0.05). This cluster-wise correction was estimated by SPM8 using cluster-generating voxel-level thresholds of <i>P</i><sub>unc_vox</sub> &lt; 0.001 or <i>P</i><sub>unc_vox</sub> &lt; 0.005, which led to a minimum cluster size of <i>k</i> ≈ 150–250 voxels (depending on the map being considered).</p><p><i>Region of interest (ROI).</i> The region used in all ROI analyses is the group-level significant cluster revealed in <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4064#Fig3">Figure 3b</a> (top), which corresponds to the brain region that linearly encoded pleasantness rating at a very stringent statistical threshold (<i>P</i><sub>FWE_vox p</sub> &lt; 0.05 and a minimal cluster size of <i>k</i> = 100 voxels) in study 1b.</p><p><i>Bin models.</i> To examine the relationship between the BOLD signal in our ROI and parameters of interest, we constructed bin models. Trials were ranked according to the parameter of interest (for example, pleasantness or desirability rating) and sorted into nine or ten bins (depending on the total number of trials). Trials corresponding to different bins were modeled in separate regressors of a standard GLM, as boxcar functions over stimulus display (study 1b) or over stimulus display plus the rating period (study 3b). These events were convolved with a canonical hemodynamic response function.</p><p><i>Finite-impulse response (FIR) models.</i> To examine the time course of the relationship between BOLD signal and first- or second-order polynomial expansions of subjective ratings, we built parametric FIR models. For studies 1b and 2b, we modeled eight events as sticks every TR (2 s), starting at the onset of stimuli. Each of these events was modulated by both the first and second polynomial expansions of <i>z</i>-scored ratings. For study 3b, desirability and likelihood trials were modeled separately, with sticks every TR (2 s) starting at the stimulus onset (sentence display), modulated by the linear expansions of <i>z</i>-scored ratings and a parameter of no interest accounting for reading time (number of letters in the sentence). We also modeled 11 sticks every TR (2 s) locked on the rating scale onset, from which we subtracted the average duration of the stimulus (6 s), such that these events started on average at the same time as in the previous FIR model. These last 11 events were modulated by the second expansion of <i>z</i>-scored ratings and a parameter of no interest accounting for stimulus duration. To correct for motion artifacts, subject-specific realignment parameters were modeled as covariates of no interest. Regression estimates were computed at the session level, extracted from our ROI, averaged at the subject level and then plotted at a group level.</p><p>A <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4064#MOESM54">Supplementary Methods Checklist</a> is available.</p></div></div></section>
                </div>
            

            <div>
                <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1"><p class="c-article-references__text" id="ref-CR1">Von Neumann, J. &amp; Morgenstern, O. <i>Game Theory and Economic Behavior</i> (Princeton Univ. Press, 1944).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2"><p class="c-article-references__text" id="ref-CR2">Samuelson, P.A. A note on the pure theory of consumer's behaviour. <i>Economica</i> <b>5</b>, 61–71 (1938).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.2307/2548836" data-track-action="article reference" href="https://doi.org/10.2307%2F2548836" aria-label="Article reference 2" data-doi="10.2307/2548836">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20note%20on%20the%20pure%20theory%20of%20consumer%27s%20behaviour&amp;journal=Economica&amp;doi=10.2307%2F2548836&amp;volume=5&amp;pages=61-71&amp;publication_year=1938&amp;author=Samuelson%2CPA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3"><p class="c-article-references__text" id="ref-CR3">Peters, J. &amp; Buchel, C. Neural representations of subjective reward value. <i>Behav. Brain Res.</i> <b>213</b>, 135–141 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.bbr.2010.04.031" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.bbr.2010.04.031" aria-label="Article reference 3" data-doi="10.1016/j.bbr.2010.04.031">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3cnmslWjtQ%3D%3D" aria-label="CAS reference 3">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20representations%20of%20subjective%20reward%20value&amp;journal=Behav.%20Brain%20Res.&amp;doi=10.1016%2Fj.bbr.2010.04.031&amp;volume=213&amp;pages=135-141&amp;publication_year=2010&amp;author=Peters%2CJ&amp;author=Buchel%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4"><p class="c-article-references__text" id="ref-CR4">Bartra, O., McGuire, J.T. &amp; Kable, J.W. The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value. <i>Neuroimage</i> <b>76</b>, 412–427 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2013.02.063" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2013.02.063" aria-label="Article reference 4" data-doi="10.1016/j.neuroimage.2013.02.063">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20valuation%20system%3A%20a%20coordinate-based%20meta-analysis%20of%20BOLD%20fMRI%20experiments%20examining%20neural%20correlates%20of%20subjective%20value&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2013.02.063&amp;volume=76&amp;pages=412-427&amp;publication_year=2013&amp;author=Bartra%2CO&amp;author=McGuire%2CJT&amp;author=Kable%2CJW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5"><p class="c-article-references__text" id="ref-CR5">Clithero, J.A. &amp; Rangel, A. Informatic parcellation of the network involved in the computation of subjective value. <i>Soc. Cogn. Affect. Neurosci.</i> <b>9</b>, 1289–1302 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/scan/nst106" data-track-action="article reference" href="https://doi.org/10.1093%2Fscan%2Fnst106" aria-label="Article reference 5" data-doi="10.1093/scan/nst106">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Informatic%20parcellation%20of%20the%20network%20involved%20in%20the%20computation%20of%20subjective%20value&amp;journal=Soc.%20Cogn.%20Affect.%20Neurosci.&amp;doi=10.1093%2Fscan%2Fnst106&amp;volume=9&amp;pages=1289-1302&amp;publication_year=2014&amp;author=Clithero%2CJA&amp;author=Rangel%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6"><p class="c-article-references__text" id="ref-CR6">Blood, A.J., Zatorre, R., Bermudez, P. &amp; Evans, A. Emotional responses to pleasant and unpleasant music correlate with activity in paralimbic brain regions. <i>Nat. Neurosci.</i> <b>2</b>, 382–387 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/7299" data-track-action="article reference" href="https://doi.org/10.1038%2F7299" aria-label="Article reference 6" data-doi="10.1038/7299">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXitFGjs7c%3D" aria-label="CAS reference 6">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotional%20responses%20to%20pleasant%20and%20unpleasant%20music%20correlate%20with%20activity%20in%20paralimbic%20brain%20regions&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F7299&amp;volume=2&amp;pages=382-387&amp;publication_year=1999&amp;author=Blood%2CAJ&amp;author=Zatorre%2CR&amp;author=Bermudez%2CP&amp;author=Evans%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7"><p class="c-article-references__text" id="ref-CR7">Chib, V.S., Rangel, A., Shimojo, S. &amp; O'Doherty, J.P. Evidence for a common representation of decision values for dissimilar goods in human ventromedial prefrontal cortex. <i>J. Neurosci.</i> <b>29</b>, 12315–12320 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2575-09.2009" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2575-09.2009" aria-label="Article reference 7" data-doi="10.1523/JNEUROSCI.2575-09.2009">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXht12qu7rI" aria-label="CAS reference 7">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Evidence%20for%20a%20common%20representation%20of%20decision%20values%20for%20dissimilar%20goods%20in%20human%20ventromedial%20prefrontal%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2575-09.2009&amp;volume=29&amp;pages=12315-12320&amp;publication_year=2009&amp;author=Chib%2CVS&amp;author=Rangel%2CA&amp;author=Shimojo%2CS&amp;author=O%27Doherty%2CJP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8"><p class="c-article-references__text" id="ref-CR8">Hare, T.A., Camerer, C.F., Knoepfle, D.T., O'Doherty, J.P. &amp; Rangel, A. Value computations in ventral medial prefrontal cortex during charitable decision making incorporate input from regions involved in social cognition. <i>J. Neurosci.</i> <b>30</b>, 583–590 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.4089-09.2010" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.4089-09.2010" aria-label="Article reference 8" data-doi="10.1523/JNEUROSCI.4089-09.2010">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXhtFaht7o%3D" aria-label="CAS reference 8">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Value%20computations%20in%20ventral%20medial%20prefrontal%20cortex%20during%20charitable%20decision%20making%20incorporate%20input%20from%20regions%20involved%20in%20social%20cognition&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.4089-09.2010&amp;volume=30&amp;pages=583-590&amp;publication_year=2010&amp;author=Hare%2CTA&amp;author=Camerer%2CCF&amp;author=Knoepfle%2CDT&amp;author=O%27Doherty%2CJP&amp;author=Rangel%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9"><p class="c-article-references__text" id="ref-CR9">Lebreton, M., Jorge, S., Michel, V., Thirion, B. &amp; Pessiglione, M. An automatic valuation system in the human brain: evidence from functional neuroimaging. <i>Neuron</i> <b>64</b>, 431–439 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2009.09.040" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2009.09.040" aria-label="Article reference 9" data-doi="10.1016/j.neuron.2009.09.040">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhsFylsbvM" aria-label="CAS reference 9">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20automatic%20valuation%20system%20in%20the%20human%20brain%3A%20evidence%20from%20functional%20neuroimaging&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2009.09.040&amp;volume=64&amp;pages=431-439&amp;publication_year=2009&amp;author=Lebreton%2CM&amp;author=Jorge%2CS&amp;author=Michel%2CV&amp;author=Thirion%2CB&amp;author=Pessiglione%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10"><p class="c-article-references__text" id="ref-CR10">Plassmann, H., O'Doherty, J. &amp; Rangel, A. Orbitofrontal cortex encodes willingness to pay in everyday economic transactions. <i>J. Neurosci.</i> <b>27</b>, 9984–9988 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2131-07.2007" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2131-07.2007" aria-label="Article reference 10" data-doi="10.1523/JNEUROSCI.2131-07.2007">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXhtVyksbjF" aria-label="CAS reference 10">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Orbitofrontal%20cortex%20encodes%20willingness%20to%20pay%20in%20everyday%20economic%20transactions&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2131-07.2007&amp;volume=27&amp;pages=9984-9988&amp;publication_year=2007&amp;author=Plassmann%2CH&amp;author=O%27Doherty%2CJ&amp;author=Rangel%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11"><p class="c-article-references__text" id="ref-CR11">Levy, I., Lazzaro, S., Rutledge, R. &amp; Glimcher, P. Choice from non-choice: predicting consumer preferences from blood oxygenation level-dependent signals obtained during passive viewing. <i>J. Neurosci.</i> <b>31</b>, 118–125 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.3214-10.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.3214-10.2011" aria-label="Article reference 11" data-doi="10.1523/JNEUROSCI.3214-10.2011">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXls1yhtg%3D%3D" aria-label="CAS reference 11">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Choice%20from%20non-choice%3A%20predicting%20consumer%20preferences%20from%20blood%20oxygenation%20level-dependent%20signals%20obtained%20during%20passive%20viewing&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.3214-10.2011&amp;volume=31&amp;pages=118-125&amp;publication_year=2011&amp;author=Levy%2CI&amp;author=Lazzaro%2CS&amp;author=Rutledge%2CR&amp;author=Glimcher%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12"><p class="c-article-references__text" id="ref-CR12">Harvey, A.H., Kirk, U., Denfield, G. &amp; Montague, P. Monetary favors and their influence on neural responses and revealed preference. <i>J. Neurosci.</i> <b>30</b>, 9597–9602 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1086-10.2010" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1086-10.2010" aria-label="Article reference 12" data-doi="10.1523/JNEUROSCI.1086-10.2010">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXpslSis7s%3D" aria-label="CAS reference 12">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Monetary%20favors%20and%20their%20influence%20on%20neural%20responses%20and%20revealed%20preference&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1086-10.2010&amp;volume=30&amp;pages=9597-9602&amp;publication_year=2010&amp;author=Harvey%2CAH&amp;author=Kirk%2CU&amp;author=Denfield%2CG&amp;author=Montague%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13"><p class="c-article-references__text" id="ref-CR13">Abitbol, R. et al. Neural mechanisms underlying contextual dependency of subjective values: converging evidence from monkeys and humans. <i>J. Neurosci.</i> <b>35</b>, 2308–2320 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1878-14.2015" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1878-14.2015" aria-label="Article reference 13" data-doi="10.1523/JNEUROSCI.1878-14.2015">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXpvF2msbs%3D" aria-label="CAS reference 13">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20mechanisms%20underlying%20contextual%20dependency%20of%20subjective%20values%3A%20converging%20evidence%20from%20monkeys%20and%20humans&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1878-14.2015&amp;volume=35&amp;pages=2308-2320&amp;publication_year=2015&amp;author=Abitbol%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14"><p class="c-article-references__text" id="ref-CR14">Kepecs, A., Uchida, N., Zariwala, H. &amp; Mainen, Z. Neural correlates, computation and behavioural impact of decision confidence. <i>Nature</i> <b>455</b>, 227–231 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature07200" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature07200" aria-label="Article reference 14" data-doi="10.1038/nature07200">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXhtV2qtLnO" aria-label="CAS reference 14">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlates%2C%20computation%20and%20behavioural%20impact%20of%20decision%20confidence&amp;journal=Nature&amp;doi=10.1038%2Fnature07200&amp;volume=455&amp;pages=227-231&amp;publication_year=2008&amp;author=Kepecs%2CA&amp;author=Uchida%2CN&amp;author=Zariwala%2CH&amp;author=Mainen%2CZ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15"><p class="c-article-references__text" id="ref-CR15">De Martino, B., Fleming, S.M., Garrett, N. &amp; Dolan, R.J. Confidence in value-based choice. <i>Nat. Neurosci.</i> <b>16</b>, 105–110 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3279" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3279" aria-label="Article reference 15" data-doi="10.1038/nn.3279">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38Xhsl2lu7nI" aria-label="CAS reference 15">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Confidence%20in%20value-based%20choice&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3279&amp;volume=16&amp;pages=105-110&amp;publication_year=2013&amp;author=De%20Martino%2CB&amp;author=Fleming%2CSM&amp;author=Garrett%2CN&amp;author=Dolan%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16"><p class="c-article-references__text" id="ref-CR16">Rolls, E.T., Grabenhorst, F. &amp; Deco, G. Choice, difficulty, and confidence in the brain. <i>Neuroimage</i> <b>53</b>, 694–706 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.06.073" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.06.073" aria-label="Article reference 16" data-doi="10.1016/j.neuroimage.2010.06.073">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Choice%2C%20difficulty%2C%20and%20confidence%20in%20the%20brain&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.06.073&amp;volume=53&amp;pages=694-706&amp;publication_year=2010&amp;author=Rolls%2CET&amp;author=Grabenhorst%2CF&amp;author=Deco%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17"><p class="c-article-references__text" id="ref-CR17">Pleskac, T.J. &amp; Busemeyer, J.R. Two-stage dynamic signal detection: a theory of choice, decision time, and confidence. <i>Psychol. Rev.</i> <b>117</b>, 864–901 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0019737" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0019737" aria-label="Article reference 17" data-doi="10.1037/a0019737">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Two-stage%20dynamic%20signal%20detection%3A%20a%20theory%20of%20choice%2C%20decision%20time%2C%20and%20confidence&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2Fa0019737&amp;volume=117&amp;pages=864-901&amp;publication_year=2010&amp;author=Pleskac%2CTJ&amp;author=Busemeyer%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18"><p class="c-article-references__text" id="ref-CR18">Yu, S., Pleskac, T.J. &amp; Zeigenfuse, M.D. Dynamics of postdecisional processing of confidence. <i>J. Exp. Psychol. Gen.</i> <b>144</b>, 489–510 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/xge0000062" data-track-action="article reference" href="https://doi.org/10.1037%2Fxge0000062" aria-label="Article reference 18" data-doi="10.1037/xge0000062">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamics%20of%20postdecisional%20processing%20of%20confidence&amp;journal=J.%20Exp.%20Psychol.%20Gen.&amp;doi=10.1037%2Fxge0000062&amp;volume=144&amp;pages=489-510&amp;publication_year=2015&amp;author=Yu%2CS&amp;author=Pleskac%2CTJ&amp;author=Zeigenfuse%2CMD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19"><p class="c-article-references__text" id="ref-CR19">Griffin, D. &amp; Tversky, A. The weighing of evidence and the determinants of confidence. <i>Cognit. Psychol.</i> <b>24</b>, 411–435 (1992).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0010-0285(92)90013-R" data-track-action="article reference" href="https://doi.org/10.1016%2F0010-0285%2892%2990013-R" aria-label="Article reference 19" data-doi="10.1016/0010-0285(92)90013-R">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20weighing%20of%20evidence%20and%20the%20determinants%20of%20confidence&amp;journal=Cognit.%20Psychol.&amp;doi=10.1016%2F0010-0285%2892%2990013-R&amp;volume=24&amp;pages=411-435&amp;publication_year=1992&amp;author=Griffin%2CD&amp;author=Tversky%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20"><p class="c-article-references__text" id="ref-CR20">Lichtenstein, S., Fischhoff, B. &amp; Phillips, L.D. in <i>Heuristics and Biases</i> 306–334 (Cambridge Univ. Press, 1982).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21"><p class="c-article-references__text" id="ref-CR21">Lebreton, M., Kawa, S., Forgeot d'Arc, B., Daunizeau, J. &amp; Pessiglione, M. Your goal is mine: unraveling mimetic desires in the human brain. <i>J. Neurosci.</i> <b>32</b>, 7146–7157 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.4821-11.2012" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.4821-11.2012" aria-label="Article reference 21" data-doi="10.1523/JNEUROSCI.4821-11.2012">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XnvFKksbw%3D" aria-label="CAS reference 21">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Your%20goal%20is%20mine%3A%20unraveling%20mimetic%20desires%20in%20the%20human%20brain&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.4821-11.2012&amp;volume=32&amp;pages=7146-7157&amp;publication_year=2012&amp;author=Lebreton%2CM&amp;author=Kawa%2CS&amp;author=Forgeot%20d%27Arc%2CB&amp;author=Daunizeau%2CJ&amp;author=Pessiglione%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22"><p class="c-article-references__text" id="ref-CR22">Sharot, T., Riccardi, A.M., Raio, C.M. &amp; Phelps, E.A. Neural mechanisms mediating optimism bias. <i>Nature</i> <b>450</b>, 102–105 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature06280" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature06280" aria-label="Article reference 22" data-doi="10.1038/nature06280">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXht1CgtbnK" aria-label="CAS reference 22">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20mechanisms%20mediating%20optimism%20bias&amp;journal=Nature&amp;doi=10.1038%2Fnature06280&amp;volume=450&amp;pages=102-105&amp;publication_year=2007&amp;author=Sharot%2CT&amp;author=Riccardi%2CAM&amp;author=Raio%2CCM&amp;author=Phelps%2CEA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23"><p class="c-article-references__text" id="ref-CR23">Pierce, C.S. &amp; Jastrow, J. On small differences of sensation. <i>Mem. Natl. Acad. Sci.</i> <b>3</b>, 73–83 (1884).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20small%20differences%20of%20sensation&amp;journal=Mem.%20Natl.%20Acad.%20Sci.&amp;volume=3&amp;pages=73-83&amp;publication_year=1884&amp;author=Pierce%2CCS&amp;author=Jastrow%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24"><p class="c-article-references__text" id="ref-CR24">Adams, J.K. A confidence scale defined in terms of expected percentages. <i>Am. J. Psychol.</i> <b>70</b>, 432–436 (1957).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.2307/1419580" data-track-action="article reference" href="https://doi.org/10.2307%2F1419580" aria-label="Article reference 24" data-doi="10.2307/1419580">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaG1c%2FgtFWjuw%3D%3D" aria-label="CAS reference 24">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20confidence%20scale%20defined%20in%20terms%20of%20expected%20percentages&amp;journal=Am.%20J.%20Psychol.&amp;doi=10.2307%2F1419580&amp;volume=70&amp;pages=432-436&amp;publication_year=1957&amp;author=Adams%2CJK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25"><p class="c-article-references__text" id="ref-CR25">Vickers, D. <i>Decision Processes in Visual Perception</i> (Academic, New York, 1979).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26"><p class="c-article-references__text" id="ref-CR26">Fleming, S.M. &amp; Dolan, R.J. The neural basis of metacognitive ability. <i>Phil. Trans. R. Soc. Lond. B</i> <b>367</b>, 1338–1349 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2011.0417" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2011.0417" aria-label="Article reference 26" data-doi="10.1098/rstb.2011.0417">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20neural%20basis%20of%20metacognitive%20ability&amp;journal=Phil.%20Trans.%20R.%20Soc.%20Lond.%20B&amp;doi=10.1098%2Frstb.2011.0417&amp;volume=367&amp;pages=1338-1349&amp;publication_year=2012&amp;author=Fleming%2CSM&amp;author=Dolan%2CRJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27"><p class="c-article-references__text" id="ref-CR27">Yeung, N. &amp; Summerfield, C. Metacognition in human decision-making: confidence and error monitoring. <i>Phil. Trans. R. Soc. Lond. B</i> <b>367</b>, 1310–1321 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2011.0416" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2011.0416" aria-label="Article reference 27" data-doi="10.1098/rstb.2011.0416">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Metacognition%20in%20human%20decision-making%3A%20confidence%20and%20error%20monitoring&amp;journal=Phil.%20Trans.%20R.%20Soc.%20Lond.%20B&amp;doi=10.1098%2Frstb.2011.0416&amp;volume=367&amp;pages=1310-1321&amp;publication_year=2012&amp;author=Yeung%2CN&amp;author=Summerfield%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28"><p class="c-article-references__text" id="ref-CR28">Daunizeau, J. A note on race models <a href="http://sites.google.com/site/jeandaunizeauswebsite/links/resources" data-track="click" data-track-action="external reference" data-track-label="http://sites.google.com/site/jeandaunizeauswebsite/links/resources">http://sites.google.com/site/jeandaunizeauswebsite/links/resources</a> (2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29"><p class="c-article-references__text" id="ref-CR29">Litt, A., Plassmann, H., Shiv, B. &amp; Rangel, A. Dissociating valuation and saliency signals during decision-making. <i>Cereb. Cortex</i> <b>21</b>, 95–102 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhq065" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhq065" aria-label="Article reference 29" data-doi="10.1093/cercor/bhq065">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Dissociating%20valuation%20and%20saliency%20signals%20during%20decision-making&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhq065&amp;volume=21&amp;pages=95-102&amp;publication_year=2011&amp;author=Litt%2CA&amp;author=Plassmann%2CH&amp;author=Shiv%2CB&amp;author=Rangel%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30"><p class="c-article-references__text" id="ref-CR30">Maunsell, J.H. Neuronal representations of cognitive state: reward or attention? <i>Trends Cogn. Sci.</i> <b>8</b>, 261–265 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2004.04.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2004.04.003" aria-label="Article reference 30" data-doi="10.1016/j.tics.2004.04.003">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuronal%20representations%20of%20cognitive%20state%3A%20reward%20or%20attention%3F&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2004.04.003&amp;volume=8&amp;pages=261-265&amp;publication_year=2004&amp;author=Maunsell%2CJH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31"><p class="c-article-references__text" id="ref-CR31">Roesch, M.R. &amp; Olson, C.R. Neuronal activity related to anticipated reward in frontal cortex: does it represent value or reflect motivation? <i>Ann. NY Acad. Sci.</i> <b>1121</b>, 431–446 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1196/annals.1401.004" data-track-action="article reference" href="https://doi.org/10.1196%2Fannals.1401.004" aria-label="Article reference 31" data-doi="10.1196/annals.1401.004">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuronal%20activity%20related%20to%20anticipated%20reward%20in%20frontal%20cortex%3A%20does%20it%20represent%20value%20or%20reflect%20motivation%3F&amp;journal=Ann.%20NY%20Acad.%20Sci.&amp;doi=10.1196%2Fannals.1401.004&amp;volume=1121&amp;pages=431-446&amp;publication_year=2007&amp;author=Roesch%2CMR&amp;author=Olson%2CCR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32"><p class="c-article-references__text" id="ref-CR32">Chua, E.F., Schacter, D.L., Rand-Giovannetti, E. &amp; Sperling, R.A. Understanding metamemory: neural correlates of the cognitive process and subjective level of confidence in recognition memory. <i>Neuroimage</i> <b>29</b>, 1150–1160 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2005.09.058" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2005.09.058" aria-label="Article reference 32" data-doi="10.1016/j.neuroimage.2005.09.058">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Understanding%20metamemory%3A%20neural%20correlates%20of%20the%20cognitive%20process%20and%20subjective%20level%20of%20confidence%20in%20recognition%20memory&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2005.09.058&amp;volume=29&amp;pages=1150-1160&amp;publication_year=2006&amp;author=Chua%2CEF&amp;author=Schacter%2CDL&amp;author=Rand-Giovannetti%2CE&amp;author=Sperling%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33"><p class="c-article-references__text" id="ref-CR33">Moritz, S., Glascher, J., Sommer, T., Buchel, C. &amp; Braus, D.F. Neural correlates of memory confidence. <i>Neuroimage</i> <b>33</b>, 1188–1193 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2006.08.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2006.08.003" aria-label="Article reference 33" data-doi="10.1016/j.neuroimage.2006.08.003">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlates%20of%20memory%20confidence&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2006.08.003&amp;volume=33&amp;pages=1188-1193&amp;publication_year=2006&amp;author=Moritz%2CS&amp;author=Glascher%2CJ&amp;author=Sommer%2CT&amp;author=Buchel%2CC&amp;author=Braus%2CDF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34"><p class="c-article-references__text" id="ref-CR34">Schwarze, U., Bingel, U., Badre, D. &amp; Sommer, T. Ventral striatal activity correlates with memory confidence for old- and new-responses in a difficult recognition test. <i>PLoS ONE</i> <b>8</b>, e54324 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0054324" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0054324" aria-label="Article reference 34" data-doi="10.1371/journal.pone.0054324">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXktlSkur8%3D" aria-label="CAS reference 34">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Ventral%20striatal%20activity%20correlates%20with%20memory%20confidence%20for%20old-%20and%20new-responses%20in%20a%20difficult%20recognition%20test&amp;journal=PLoS%20ONE&amp;doi=10.1371%2Fjournal.pone.0054324&amp;volume=8&amp;publication_year=2013&amp;author=Schwarze%2CU&amp;author=Bingel%2CU&amp;author=Badre%2CD&amp;author=Sommer%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35"><p class="c-article-references__text" id="ref-CR35">White, T.P., Engen, N.H., Sørensen, S., Overgaard, M. &amp; Shergill, S.S. Uncertainty and confidence from the triple-network perspective: voxel-based meta-analyses. <i>Brain Cogn.</i> <b>85</b>, 191–200 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.bandc.2013.12.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.bandc.2013.12.002" aria-label="Article reference 35" data-doi="10.1016/j.bandc.2013.12.002">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Uncertainty%20and%20confidence%20from%20the%20triple-network%20perspective%3A%20voxel-based%20meta-analyses&amp;journal=Brain%20Cogn.&amp;doi=10.1016%2Fj.bandc.2013.12.002&amp;volume=85&amp;pages=191-200&amp;publication_year=2014&amp;author=White%2CTP&amp;author=Engen%2CNH&amp;author=S%C3%B8rensen%2CS&amp;author=Overgaard%2CM&amp;author=Shergill%2CSS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36"><p class="c-article-references__text" id="ref-CR36">Costa, V.D., Lang, P.J., Sabatinelli, D., Versace, F. &amp; Bradley, M.M. Emotional imagery: assessing pleasure and arousal in the brain's reward circuitry. <i>Hum. Brain Mapp.</i> <b>31</b>, 1446–1457 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/hbm.20948" data-track-action="article reference" href="https://doi.org/10.1002%2Fhbm.20948" aria-label="Article reference 36" data-doi="10.1002/hbm.20948">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotional%20imagery%3A%20assessing%20pleasure%20and%20arousal%20in%20the%20brain%27s%20reward%20circuitry&amp;journal=Hum.%20Brain%20Mapp.&amp;doi=10.1002%2Fhbm.20948&amp;volume=31&amp;pages=1446-1457&amp;publication_year=2010&amp;author=Costa%2CVD&amp;author=Lang%2CPJ&amp;author=Sabatinelli%2CD&amp;author=Versace%2CF&amp;author=Bradley%2CMM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37"><p class="c-article-references__text" id="ref-CR37">Elliott, R., Newman, J.L., Longe, O.A. &amp; Deakin, J.F.W. Differential response patterns in the striatum and orbitofrontal cortex to financial reward in humans: a parametric functional magnetic resonance imaging study. <i>J. Neurosci.</i> <b>23</b>, 303–307 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.23-01-00303.2003" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.23-01-00303.2003" aria-label="Article reference 37" data-doi="10.1523/JNEUROSCI.23-01-00303.2003">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3sXktlagsA%3D%3D" aria-label="CAS reference 37">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Differential%20response%20patterns%20in%20the%20striatum%20and%20orbitofrontal%20cortex%20to%20financial%20reward%20in%20humans%3A%20a%20parametric%20functional%20magnetic%20resonance%20imaging%20study&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.23-01-00303.2003&amp;volume=23&amp;pages=303-307&amp;publication_year=2003&amp;author=Elliott%2CR&amp;author=Newman%2CJL&amp;author=Longe%2COA&amp;author=Deakin%2CJFW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38"><p class="c-article-references__text" id="ref-CR38">Cooper, J.C. &amp; Knutson, B. Valence and salience contribute to nucleus accumbens activation. <i>Neuroimage</i> <b>39</b>, 538–547 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2007.08.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2007.08.009" aria-label="Article reference 38" data-doi="10.1016/j.neuroimage.2007.08.009">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Valence%20and%20salience%20contribute%20to%20nucleus%20accumbens%20activation&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2007.08.009&amp;volume=39&amp;pages=538-547&amp;publication_year=2008&amp;author=Cooper%2CJC&amp;author=Knutson%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39"><p class="c-article-references__text" id="ref-CR39">Levy, D. &amp; Glimcher, P.W. The root of all value: a neural common currency for choice. <i>Curr. Opin. Neurosci.</i> <b>22</b>, 1027–1038 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.conb.2012.06.001" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2012.06.001" aria-label="Article reference 39" data-doi="10.1016/j.conb.2012.06.001">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XpvFGnsL0%3D" aria-label="CAS reference 39">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20root%20of%20all%20value%3A%20a%20neural%20common%20currency%20for%20choice&amp;journal=Curr.%20Opin.%20Neurosci.&amp;doi=10.1016%2Fj.conb.2012.06.001&amp;volume=22&amp;pages=1027-1038&amp;publication_year=2012&amp;author=Levy%2CD&amp;author=Glimcher%2CPW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40"><p class="c-article-references__text" id="ref-CR40">de Gardelle, V. &amp; Mamassian, P. Does confidence use a common currency across two visual tasks? <i>Psychol. Sci.</i> <b>25</b>, 1286–1288 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0956797614528956" data-track-action="article reference" href="https://doi.org/10.1177%2F0956797614528956" aria-label="Article reference 40" data-doi="10.1177/0956797614528956">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Does%20confidence%20use%20a%20common%20currency%20across%20two%20visual%20tasks%3F&amp;journal=Psychol.%20Sci.&amp;doi=10.1177%2F0956797614528956&amp;volume=25&amp;pages=1286-1288&amp;publication_year=2014&amp;author=de%20Gardelle%2CV&amp;author=Mamassian%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41"><p class="c-article-references__text" id="ref-CR41">Daunizeau, J. On the exponential, sigmoid and softmax mappings <a href="http://sites.google.com/site/jeandaunizeauswebsite/links/resources" data-track="click" data-track-action="external reference" data-track-label="http://sites.google.com/site/jeandaunizeauswebsite/links/resources">http://sites.google.com/site/jeandaunizeauswebsite/links/resources</a> (2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42"><p class="c-article-references__text" id="ref-CR42">Deichmann, R., Gottfried, J., Hutton, C. &amp; Turner, R. Optimized EPI for fMRI studies of the orbitofrontal cortex. <i>Neuroimage</i> <b>19</b>, 430–441 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S1053-8119(03)00073-9" data-track-action="article reference" href="https://doi.org/10.1016%2FS1053-8119%2803%2900073-9" aria-label="Article reference 42" data-doi="10.1016/S1053-8119(03)00073-9">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3s3ovVWmtQ%3D%3D" aria-label="CAS reference 42">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimized%20EPI%20for%20fMRI%20studies%20of%20the%20orbitofrontal%20cortex&amp;journal=Neuroimage&amp;doi=10.1016%2FS1053-8119%2803%2900073-9&amp;volume=19&amp;pages=430-441&amp;publication_year=2003&amp;author=Deichmann%2CR&amp;author=Gottfried%2CJ&amp;author=Hutton%2CC&amp;author=Turner%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43"><p class="c-article-references__text" id="ref-CR43">Friston, K.J., Penny, W.D. &amp; Glaser, D.E. Conjunction revisited. <i>Neuroimage</i> <b>25</b>, 661–667 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2005.01.013" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2005.01.013" aria-label="Article reference 43" data-doi="10.1016/j.neuroimage.2005.01.013">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Conjunction%20revisited&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2005.01.013&amp;volume=25&amp;pages=661-667&amp;publication_year=2005&amp;author=Friston%2CKJ&amp;author=Penny%2CWD&amp;author=Glaser%2CDE">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.4064?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The study was funded by a Starting Grant for the European Research Council (ERC-BioMotiv) and a Research Grant from the Schlumberger Foundation. M.L. received a PhD fellowship from the French Ministère de la Recherche and an Amsterdam Brain and Cognition Talent Grant from the University of Amsterdam. R.A. received a PhD fellowship from the Direction Générale de l'Armement and a grant from the Fondation pour la Recherche Médicale. This work also benefited from the program “Investissements d'avenir” (ANR-10-IAIHU-06). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Motivation, Brain and Behavior team, Centre de NeuroImagerie de Recherche (CENIR), Institut du Cerveau et de la Moelle épinière (ICM), Paris, France</p><p class="c-article-author-affiliation__authors-list">Maël Lebreton, Raphaëlle Abitbol, Jean Daunizeau &amp; Mathias Pessiglione</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">INSERM UMRS 975, CNRS UMR 7225, Université Pierre et Marie Curie UPMC-Paris 6 UMR 1127, Paris, France, </p><p class="c-article-author-affiliation__authors-list">Maël Lebreton, Raphaëlle Abitbol, Jean Daunizeau &amp; Mathias Pessiglione</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Centre d'Economie de la Sorbonne, Université Paris 1-Panthéon-Sorbonne, Paris, France</p><p class="c-article-author-affiliation__authors-list">Raphaëlle Abitbol</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Ma_l-Lebreton-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Maël Lebreton</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Ma%C3%ABl%20Lebreton" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ma%C3%ABl%20Lebreton" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ma%C3%ABl%20Lebreton%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Rapha_lle-Abitbol-Aff1-Aff2-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Raphaëlle Abitbol</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Rapha%C3%ABlle%20Abitbol" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rapha%C3%ABlle%20Abitbol" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rapha%C3%ABlle%20Abitbol%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Jean-Daunizeau-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Jean Daunizeau</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Jean%20Daunizeau" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jean%20Daunizeau" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jean%20Daunizeau%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Mathias-Pessiglione-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Mathias Pessiglione</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Mathias%20Pessiglione" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Mathias%20Pessiglione" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Mathias%20Pessiglione%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>M.L. and M.P. designed all experiments. M.L. and R.A. collected the data. M.L. performed the data analysis. J.D. formalized the computational model. M.L. and M.P. wrote the manuscript. All authors discussed the results and commented the manuscript.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:mathias.pessiglione@gmail.com">Mathias Pessiglione</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading">Competing interests</h3>
                <p>The authors declare no competing financial interests.</p>
              
            </div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec18-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec18">Supplementary information</h2><div class="c-article-section__content" id="Sec18-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM53"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary text and figures" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_BFnn4064_MOESM53_ESM.pdf" data-supp-info-image="">Supplementary Text and Figures</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Supplementary Table 1 (PDF 35 kb)</p></div></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM54"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary checklist" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.4064/MediaObjects/41593_2015_BFnn4064_MOESM54_ESM.pdf" data-supp-info-image="">Supplementary Checklist</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p> (PDF 232 kb)</p></div></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Automatic%20integration%20of%20confidence%20in%20the%20brain%20valuation%20signal&amp;author=Ma%C3%ABl%20Lebreton%20et%20al&amp;contentID=10.1038%2Fnn.4064&amp;copyright=Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2015-07-20&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/nn.4064" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/nn.4064" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Lebreton, M., Abitbol, R., Daunizeau, J. <i>et al.</i> Automatic integration of confidence in the brain valuation signal.
                    <i>Nat Neurosci</i> <b>18</b>, 1159–1167 (2015). https://doi.org/10.1038/nn.4064</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.4064?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-04-24">24 April 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-06-19">19 June 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-07-20">20 July 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-08">August 2015</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/nn.4064</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:A tripartite view of the posterior cingulate cortex" href="https://doi.org/10.1038/s41583-022-00661-x">
                                        A tripartite view of the posterior cingulate cortex
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Brett L. Foster</li><li>Seth R. Koslov</li><li>Sarah R. Heilbronner</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Reviews Neuroscience</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Attractor dynamics reflect decision confidence in macaque prefrontal cortex" href="https://doi.org/10.1038/s41593-023-01445-x">
                                        Attractor dynamics reflect decision confidence in macaque prefrontal cortex
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Siyu Wang</li><li>Rossella Falcone</li><li>Bruno B. Averbeck</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Neuroscience</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Studying the neural representations of uncertainty" href="https://doi.org/10.1038/s41593-023-01444-y">
                                        Studying the neural representations of uncertainty
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Edgar Y. Walker</li><li>Stephan Pohl</li><li>Florent Meyniel</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Neuroscience</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Neural and computational underpinnings of biased confidence in human reinforcement learning" href="https://doi.org/10.1038/s41467-023-42589-5">
                                        Neural and computational underpinnings of biased confidence in human reinforcement learning
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Chih-Chung Ting</li><li>Nahuel Salem-Garcia</li><li>Maël Lebreton</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Communications</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Mood fluctuations shift cost–benefit tradeoffs in economic decisions" href="https://doi.org/10.1038/s41598-023-45217-w">
                                        Mood fluctuations shift cost–benefit tradeoffs in economic decisions
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Roeland Heerema</li><li>Pablo Carrillo</li><li>Mathias Pessiglione</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2023)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4064.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4064.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    
        <div class="c-article-associated-content__container">
            <section>
                <h2 class="c-article-associated-content__title u-mb-24">Associated content</h2>
                
                    
                    
                        <div class="u-full-height u-mb-24">
                            
    <article class="u-full-height c-card c-card--flush">
        <div class="c-card__layout u-full-height">
            <div class="c-card__body">
                <h3 class="c-card__title">
                    <a href="https://www.nature.com/articles/nn.4076"
                       class="c-card__link u-link-inherit"
                       data-track="click"
                       data-track-action="view article"
                       data-track-category="associated content"
                       
                       data-track-label="news_and_views">Reassessing VMPFC: full of confidence?</a>
                </h3>
                
<ul data-test="author-list" class="c-author-list c-author-list--compact">
    <li>Helen C Barron</li><li>Mona M Garvert</li><li>Timothy E J Behrens</li>
</ul>

                
    <div class="c-card__section c-meta">
        
            <span class="c-meta__item">Nature Neuroscience</span>
        
        <span class="c-meta__item" data-test="article.type"><span class="c-meta__type">News &amp; Views</span></span>
        
        
            <time class="c-meta__item" datetime="2015-07-28">28 Jul 2015</time>
        
    </div>

            </div>
        </div>
    </article>


                        </div>
                    
                
            </section>
        </div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer[0] = window.dataLayer[0] || {};
            window.dataLayer[0].content = window.dataLayer[0].content || {};
            window.dataLayer[0].content.associatedContentTypes = "news_and_views";
        </script>
    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=nn.4064;doi=10.1038/nn.4064;techmeta=36,59;subjmeta=1409,1662,2649,378,631;kwrd=Decision,Motivation">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-444164298&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.4064%26doi%3D10.1038/nn.4064%26techmeta%3D36,59%26subjmeta%3D1409,1662,2649,378,631%26kwrd%3DDecision,Motivation">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-444164298&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.4064%26doi%3D10.1038/nn.4064%26techmeta%3D36,59%26subjmeta%3D1409,1662,2649,378,631%26kwrd%3DDecision,Motivation"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/nn.4064&amp;format=js&amp;last_modified=2015-08-01" async></script>
<img src="/p87ldvqh/article/nn.4064" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>