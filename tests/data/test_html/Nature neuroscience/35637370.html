<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Common and stimulus-type-specific brain representations of negative affect | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"emotion;neural-decoding;sensory-processing","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/s41593-022-01082-w"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Marta Čeko","Philip A. Kragel","Choong-Wan Woo","Marina López-Solà","Tor D. Wager"],"publishedAt":1653868800,"publishedAtString":"2022-05-30","title":"Common and stimulus-type-specific brain representations of negative affect","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"25","issue":"6"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Common and stimulus-type-specific brain representations of negative affect","description":"The brain contains both generalized and stimulus-type-specific representations of aversive events, but models of how these are integrated and related to subjective experience are lacking. We combined functional magnetic resonance imaging with predictive modeling to identify representations of generalized (common) and stimulus-type-specific negative affect across mechanical pain, thermal pain, aversive sounds and aversive images of four intensity levels each. This allowed us to examine how generalized and stimulus-specific representations jointly contribute to aversive experience. Stimulus-type-specific negative affect was largely encoded in early sensory pathways, whereas generalized negative affect was encoded in a distributed set of midline, forebrain, insular and somatosensory regions. All models specifically predicted negative affect rather than general salience or arousal and accurately predicted negative affect in independent samples, demonstrating robustness and generalizability. Common and stimulus-type-specific models were jointly important for predicting subjective experience. Together, these findings offer an integrated account of how negative affect is constructed in the brain and provide predictive neuromarkers for future studies. Using multiple types of negative affect stimuli, functional magnetic resonance imaging and predictive modeling, Čeko et al. show that the brain integrates generalized and stimulus-type-specific representations of aversive events to jointly predict subjective experience.","datePublished":"2022-05-30T00:00:00Z","dateModified":"2022-05-30T00:00:00Z","pageStart":"760","pageEnd":"770","sameAs":"https://doi.org/10.1038/s41593-022-01082-w","keywords":["Emotion","Neural decoding","Sensory processing","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig3_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig4_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig5_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig6_HTML.png"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"25","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Marta Čeko","url":"http://orcid.org/0000-0001-8679-8145","affiliation":[{"name":"University of Colorado","address":{"name":"Institute of Cognitive Science, University of Colorado, Boulder, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"marta.ceko@colorado.edu","@type":"Person"},{"name":"Philip A. Kragel","url":"http://orcid.org/0000-0001-9463-6381","affiliation":[{"name":"University of Colorado","address":{"name":"Institute of Cognitive Science, University of Colorado, Boulder, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Emory University","address":{"name":"Department of Psychology, Emory University, Atlanta, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Choong-Wan Woo","url":"http://orcid.org/0000-0002-7423-5422","affiliation":[{"name":"Center for Neuroscience Imaging Research, Institute for Basic Science","address":{"name":"Center for Neuroscience Imaging Research, Institute for Basic Science, Suwon, South Korea","@type":"PostalAddress"},"@type":"Organization"},{"name":"Sungkyunkwan University","address":{"name":"Department of Biomedical Engineering, Sungkyunkwan University, Suwon, South Korea","@type":"PostalAddress"},"@type":"Organization"},{"name":"Sungkyunkwan University","address":{"name":"Department of Intelligent Precision Healthcare Convergence, Sungkyunkwan University, Suwon, South Korea","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Marina López-Solà","affiliation":[{"name":"University of Barcelona","address":{"name":"Serra Hunter Programme, Department of Medicine, School of Medicine and Health Sciences, University of Barcelona, Barcelona, Spain","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Tor D. Wager","url":"http://orcid.org/0000-0002-1936-5574","affiliation":[{"name":"University of Colorado","address":{"name":"Institute of Cognitive Science, University of Colorado, Boulder, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Dartmouth College","address":{"name":"Department of Psychological and Brain Sciences, Dartmouth College, Hanover, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"tor.d.wager@dartmouth.edu","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/s41593-022-01082-w">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="Common and stimulus-type-specific brain representations of negative affect"/>
    <meta name="dc.source" content="Nature Neuroscience 2022 25:6"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2022-05-30"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="The brain contains both generalized and stimulus-type-specific representations of aversive events, but models of how these are integrated and related to subjective experience are lacking. We combined functional magnetic resonance imaging with predictive modeling to identify representations of generalized (common) and stimulus-type-specific negative affect across mechanical pain, thermal pain, aversive sounds and aversive images of four intensity levels each. This allowed us to examine how generalized and stimulus-specific representations jointly contribute to aversive experience. Stimulus-type-specific negative affect was largely encoded in early sensory pathways, whereas generalized negative affect was encoded in a distributed set of midline, forebrain, insular and somatosensory regions. All models specifically predicted negative affect rather than general salience or arousal and accurately predicted negative affect in independent samples, demonstrating robustness and generalizability. Common and stimulus-type-specific models were jointly important for predicting subjective experience. Together, these findings offer an integrated account of how negative affect is constructed in the brain and provide predictive neuromarkers for future studies. Using multiple types of negative affect stimuli, functional magnetic resonance imaging and predictive modeling, &#268;eko et al. show that the brain integrates generalized and stimulus-type-specific representations of aversive events to jointly predict subjective experience."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2022-05-30"/>
    <meta name="prism.volume" content="25"/>
    <meta name="prism.number" content="6"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="760"/>
    <meta name="prism.endingPage" content="770"/>
    <meta name="prism.copyright" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/s41593-022-01082-w"/>
    <meta name="prism.doi" content="doi:10.1038/s41593-022-01082-w"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41593-022-01082-w.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41593-022-01082-w"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="Common and stimulus-type-specific brain representations of negative affect"/>
    <meta name="citation_volume" content="25"/>
    <meta name="citation_issue" content="6"/>
    <meta name="citation_publication_date" content="2022/06"/>
    <meta name="citation_online_date" content="2022/05/30"/>
    <meta name="citation_firstpage" content="760"/>
    <meta name="citation_lastpage" content="770"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/s41593-022-01082-w"/>
    <meta name="DOI" content="10.1038/s41593-022-01082-w"/>
    <meta name="size" content="261349"/>
    <meta name="citation_doi" content="10.1038/s41593-022-01082-w"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/s41593-022-01082-w&amp;api_key="/>
    <meta name="description" content="The brain contains both generalized and stimulus-type-specific representations of aversive events, but models of how these are integrated and related to subjective experience are lacking. We combined functional magnetic resonance imaging with predictive modeling to identify representations of generalized (common) and stimulus-type-specific negative affect across mechanical pain, thermal pain, aversive sounds and aversive images of four intensity levels each. This allowed us to examine how generalized and stimulus-specific representations jointly contribute to aversive experience. Stimulus-type-specific negative affect was largely encoded in early sensory pathways, whereas generalized negative affect was encoded in a distributed set of midline, forebrain, insular and somatosensory regions. All models specifically predicted negative affect rather than general salience or arousal and accurately predicted negative affect in independent samples, demonstrating robustness and generalizability. Common and stimulus-type-specific models were jointly important for predicting subjective experience. Together, these findings offer an integrated account of how negative affect is constructed in the brain and provide predictive neuromarkers for future studies. Using multiple types of negative affect stimuli, functional magnetic resonance imaging and predictive modeling, &#268;eko et al. show that the brain integrates generalized and stimulus-type-specific representations of aversive events to jointly predict subjective experience."/>
    <meta name="dc.creator" content="&#268;eko, Marta"/>
    <meta name="dc.creator" content="Kragel, Philip A."/>
    <meta name="dc.creator" content="Woo, Choong-Wan"/>
    <meta name="dc.creator" content="L&#243;pez-Sol&#224;, Marina"/>
    <meta name="dc.creator" content="Wager, Tor D."/>
    <meta name="dc.subject" content="Emotion"/>
    <meta name="dc.subject" content="Neural decoding"/>
    <meta name="dc.subject" content="Sensory processing"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Neurobiol.; citation_title=Neuroscience of affect: brain mechanisms of pleasure and displeasure; citation_author=KC Berridge, ML Kringelbach; citation_volume=23; citation_publication_date=2013; citation_pages=294-303; citation_doi=10.1016/j.conb.2013.01.017; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Neural circuit motifs in valence processing; citation_author=KM Tye; citation_volume=100; citation_publication_date=2018; citation_pages=436-452; citation_doi=10.1016/j.neuron.2018.10.001; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=J. Pers. Soc. Psychol.; citation_title=A circumplex model of affect; citation_author=JA Russell; citation_volume=39; citation_publication_date=1980; citation_pages=1161&#8211;1178; citation_doi=10.1037/h0077714; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=J. Pers. Soc. Psychol.; citation_title=Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant; citation_author=JA Russell, LF Barrett; citation_volume=76; citation_publication_date=1999; citation_pages=805-819; citation_doi=10.1037/0022-3514.76.5.805; citation_id=CR4"/>
    <meta name="citation_reference" content="Gray, J. A. The Psychology of Fear and Stress. (CUP Archive, 1987)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Neural economics and the biological substrates of valuation; citation_author=PR Montague, GS Berns; citation_volume=36; citation_publication_date=2002; citation_pages=265-284; citation_doi=10.1016/S0896-6273(02)00974-1; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Neurons in the orbitofrontal cortex encode economic value; citation_author=C Padoa-Schioppa, JA Assad; citation_volume=441; citation_publication_date=2006; citation_pages=223-226; citation_doi=10.1038/nature04676; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Arch. Gen. Psychiatry; citation_title=A susceptibility gene for affective disorders and the response of the human amygdala; citation_author=AR Hariri; citation_volume=62; citation_publication_date=2005; citation_pages=146-152; citation_doi=10.1001/archpsyc.62.2.146; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Prefrontal cortical function and anxiety: controlling attention to threat-related stimuli; citation_author=S Bishop, J Duncan, M Brett, AD Lawrence; citation_volume=7; citation_publication_date=2004; citation_pages=184-188; citation_doi=10.1038/nn1173; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=Hum. Brain Mapp.; citation_title=Localization of pain-related brain activation: a meta-analysis of neuroimaging data; citation_author=EG Duerden, M-C Albanese; citation_volume=34; citation_publication_date=2013; citation_pages=109-149; citation_doi=10.1002/hbm.21416; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=Am. J. Psychiatry; citation_title=Research domain criteria (RDoC): toward a new classification framework for research on mental disorders; citation_author=T Insel; citation_volume=167; citation_publication_date=2010; citation_pages=748-751; citation_doi=10.1176/appi.ajp.2010.09091379; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=Behav. Neurosci.; citation_title=The case against economic values in the orbitofrontal cortex (or anywhere else in the brain); citation_author=BY Hayden, Y Niv; citation_volume=135; citation_publication_date=2021; citation_pages=192-201; citation_doi=10.1037/bne0000448; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Aversive state processing in the posterior insular cortex; citation_author=DA Gehrlach; citation_volume=22; citation_publication_date=2019; citation_pages=1424-1437; citation_doi=10.1038/s41593-019-0469-1; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex; citation_author=C Corradi-Dell&#8217;Acqua, A Tusche, P Vuilleumier, T Singer; citation_volume=7; citation_publication_date=2016; citation_doi=10.1038/ncomms10904; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Generalizable representations of pain, cognitive control, and negative emotion in medial frontal cortex; citation_author=PA Kragel; citation_volume=21; citation_publication_date=2018; citation_pages=283-289; citation_doi=10.1038/s41593-017-0051-7; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Population coding of affect across stimuli, modalities and individuals; citation_author=J Chikazoe, DH Lee, N Kriegeskorte, AK Anderson; citation_volume=17; citation_publication_date=2014; citation_pages=1114-1122; citation_doi=10.1038/nn.3749; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Functional grouping and cortical-subcortical interactions in emotion: a meta-analysis of neuroimaging studies; citation_author=H Kober; citation_volume=42; citation_publication_date=2008; citation_pages=998-1031; citation_doi=10.1016/j.neuroimage.2008.03.059; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=Front. Psychol.; citation_title=Involvement of sensory regions in affective experience: a meta-analysis; citation_author=AB Satpute; citation_volume=6; citation_publication_date=2015; citation_pages=1860; citation_doi=10.3389/fpsyg.2015.01860; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Cognition Emot.; citation_title=An argument for basic emotions; citation_author=P Ekman; citation_volume=6; citation_publication_date=1992; citation_pages=169-200; citation_doi=10.1080/02699939208411068; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Biol. Psychol.; citation_title=Feelings and the body: the Jamesian perspective on autonomic specificity of emotion; citation_author=BH Friedman; citation_volume=84; citation_publication_date=2010; citation_pages=383-393; citation_doi=10.1016/j.biopsycho.2009.10.006; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Pers. Soc. Psychol. Rev.; citation_title=Solving the emotion paradox: categorization and the experience of emotion; citation_author=LF Barrett; citation_volume=10; citation_publication_date=2006; citation_pages=20-46; citation_doi=10.1207/s15327957pspr1001_2; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Discrete neural signatures of basic emotions; citation_author=H Saarim&#228;ki; citation_volume=26; citation_publication_date=2016; citation_pages=2563-2573; citation_doi=10.1093/cercor/bhv086; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=Soc. Cogn. Affect. Neurosci.; citation_title=Multivariate neural biomarkers of emotional states are categorically distinct; citation_author=PA Kragel, KS LaBar; citation_volume=10; citation_publication_date=2015; citation_pages=1437-1448; citation_doi=10.1093/scan/nsv032; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Biol. Psychol.; citation_title=Autonomic specificity of basic emotions: evidence from pattern classification and cluster analysis; citation_author=CL Stephens, IC Christie, BH Friedman; citation_volume=84; citation_publication_date=2010; citation_pages=463-473; citation_doi=10.1016/j.biopsycho.2010.03.014; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Biol.; citation_title=The parietal operculum preferentially encodes heat pain and not salience; citation_author=B Horing, C Sprenger, C B&#252;chel; citation_volume=17; citation_publication_date=2019; citation_pages=e3000205; citation_doi=10.1371/journal.pbio.3000205; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=PLoS Comput. Biol.; citation_title=A Bayesian model of category-specific emotional brain responses; citation_author=TD Wager; citation_volume=11; citation_publication_date=2015; citation_pages=e1004066; citation_doi=10.1371/journal.pcbi.1004066; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=Sci. Adv.; citation_title=Emotion schemas are embedded in the human visual system; citation_author=PA Kragel, MC Reddan, KS LaBar, TD Wager; citation_volume=5; citation_publication_date=2019; citation_pages=eaaw4358; citation_doi=10.1126/sciadv.aaw4358; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=An amygdalar neural ensemble that encodes the unpleasantness of pain; citation_author=G Corder; citation_volume=363; citation_publication_date=2019; citation_pages=276-281; citation_doi=10.1126/science.aap8586; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=General anesthetics activate a potent central pain-suppression circuit in the amygdala; citation_author=T Hua; citation_volume=23; citation_publication_date=2020; citation_pages=854-868; citation_doi=10.1038/s41593-020-0632-8; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Divergent neural pathways emanating from the lateral parabrachial nucleus mediate distinct components of the pain response; citation_author=MC Chiang; citation_volume=106; citation_publication_date=2020; citation_pages=927-939; citation_doi=10.1016/j.neuron.2020.03.014; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Thirst-associated preoptic neurons encode an aversive motivational drive; citation_author=WE Allen; citation_volume=357; citation_publication_date=2017; citation_pages=1149-1155; citation_doi=10.1126/science.aan6747; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Thirst regulates motivated behavior through modulation of brainwide neural population dynamics; citation_author=WE Allen; citation_volume=364; citation_publication_date=2019; citation_pages=253; citation_doi=10.1126/science.aav3932; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=The cellular basis of distinct thirst modalities; citation_author=A-H Pool; citation_volume=588; citation_publication_date=2020; citation_pages=112-117; citation_doi=10.1038/s41586-020-2821-8; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Partial least squares analysis of neuroimaging data: applications and advances; citation_author=AR McIntosh, NJ Lobaugh; citation_volume=23; citation_publication_date=2004; citation_pages=250-263; citation_doi=10.1016/j.neuroimage.2004.07.020; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Chemom. Intell. Lab. Syst.; citation_title=PLS-regression: a basic tool of chemometrics; citation_author=S Wold, M Sj&#246;str&#246;m, L Eriksson; citation_volume=58; citation_publication_date=2001; citation_pages=109-130; citation_doi=10.1016/S0169-7439(01)00155-1; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Building better biomarkers: brain models in translational neuroimaging; citation_author=C-W Woo, LJ Chang, MA Lindquist, TD Wager; citation_volume=20; citation_publication_date=2017; citation_pages=365-377; citation_doi=10.1038/nn.4478; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=JAMA Psychiatry; citation_title=Establishment of best practices for evidence for prediction: a review; citation_author=RA Poldrack, G Huckins, G Varoquaux; citation_volume=77; citation_publication_date=2020; citation_pages=534-540; citation_doi=10.1001/jamapsychiatry.2019.3671; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Behav. Res. Methods; citation_title=An R package to compute commonality coefficients in the multiple regression case: an introduction to the package and a practical example; citation_author=K Nimon, M Lewis, R Kane, RM Haynes; citation_volume=40; citation_publication_date=2008; citation_pages=457-466; citation_doi=10.3758/BRM.40.2.457; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=On the interpretation of weight vectors of linear models in multivariate neuroimaging; citation_author=S Haufe; citation_volume=87; citation_publication_date=2014; citation_pages=96-110; citation_doi=10.1016/j.neuroimage.2013.10.067; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Front. Integr. Neurosci.; citation_title=Identifying a network of brain regions involved in aversion-related processing: a cross-species translational investigation; citation_author=DJ Hayes, G Northoff; citation_volume=5; citation_publication_date=2011; citation_pages=49; citation_doi=10.3389/fnint.2011.00049; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=The brain basis of positive and negative affect: evidence from a meta-analysis of the human neuroimaging literature; citation_author=KA Lindquist, AB Satpute, TD Wager, J Weber, LF Barrett; citation_volume=26; citation_publication_date=2016; citation_pages=1910-1922; citation_doi=10.1093/cercor/bhv001; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Neural population coding: combining insights from microscopic and mass signals; citation_author=S Panzeri, JH Macke, J Gross, C Kayser; citation_volume=19; citation_publication_date=2015; citation_pages=162-172; citation_doi=10.1016/j.tics.2015.01.002; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=A multisensory investigation of the functional significance of the &#8216;pain matrix&#8217;; citation_author=A Mouraux, A Diukova, MC Lee, RG Wise, GD Iannetti; citation_volume=54; citation_publication_date=2011; citation_pages=2237-2249; citation_doi=10.1016/j.neuroimage.2010.09.084; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Primary sensory cortices contain distinguishable spatial patterns of activity for each sense; citation_author=M Liang, A Mouraux, L Hu, GD Iannetti; citation_volume=4; citation_publication_date=2013; citation_doi=10.1038/ncomms2979; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Reward timing in the primary visual cortex; citation_author=MG Shuler, MF Bear; citation_volume=311; citation_publication_date=2006; citation_pages=1606-1609; citation_doi=10.1126/science.1123513; citation_id=CR45"/>
    <meta name="citation_reference" content="Kragel, P. A. et al. A human colliculus-pulvinar-amygdala pathway encodes negative emotion. Neuron 
                  https://doi.org/10.1016/j.neuron.2021.06.001
                  
                 (2021)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Emotion processing and the amygdala: from a &#8216;low road&#8217; to &#8216;many roads&#8217; of evaluating biological significance; citation_author=L Pessoa, R Adolphs; citation_volume=11; citation_publication_date=2010; citation_pages=773-783; citation_doi=10.1038/nrn2920; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Neuronal organization in the inferior colliculus revisited with cell-type-dependent monosynaptic tracing; citation_author=C Chen, M Cheng, T Ito, S Song; citation_volume=38; citation_publication_date=2018; citation_pages=3318-3332; citation_doi=10.1523/JNEUROSCI.2173-17.2018; citation_id=CR48"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Neocortical circuits in pain and pain relief; citation_author=LL Tan, R Kuner; citation_volume=22; citation_publication_date=2021; citation_pages=458-471; citation_doi=10.1038/s41583-021-00468-2; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=The genetic mediation of individual differences in sensitivity to pain and its inhibition; citation_author=JS Mogil; citation_volume=96; citation_publication_date=1999; citation_pages=7744-7751; citation_doi=10.1073/pnas.96.14.7744; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=Pain; citation_title=Peripheral neuropathic pain: a mechanism-related organizing principle based on sensory profiles; citation_author=R Baron; citation_volume=158; citation_publication_date=2017; citation_pages=261-272; citation_doi=10.1097/j.pain.0000000000000753; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Psychological and neural mechanisms of the affective dimension of pain; citation_author=DD Price; citation_volume=288; citation_publication_date=2000; citation_pages=1769-1772; citation_doi=10.1126/science.288.5472.1769; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Identification of discrete functional subregions of the human periaqueductal gray; citation_author=AB Satpute; citation_volume=110; citation_publication_date=2013; citation_pages=17101-17106; citation_doi=10.1073/pnas.1306095110; citation_id=CR53"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=A thalamic nucleus specific for pain and temperature sensation; citation_author=AD Craig, MC Bushnell, ET Zhang, A Blomqvist; citation_volume=372; citation_publication_date=1994; citation_pages=770-773; citation_doi=10.1038/372770a0; citation_id=CR54"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Quantifying cerebral contributions to pain beyond nociception; citation_author=C-W Woo; citation_volume=8; citation_publication_date=2017; citation_doi=10.1038/ncomms14211; citation_id=CR55"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Dissociating intensity from valence as sensory inputs to emotion; citation_author=AK Anderson, N Sobel; citation_volume=39; citation_publication_date=2003; citation_pages=581-583; citation_doi=10.1016/S0896-6273(03)00504-X; citation_id=CR56"/>
    <meta name="citation_reference" content="citation_journal_title=J. Sex. Med.; citation_title=Gender commonalities and differences in the neural processing of visual sexual stimuli; citation_author=S Wehrum; citation_volume=10; citation_publication_date=2013; citation_pages=1328-1342; citation_doi=10.1111/jsm.12096; citation_id=CR57"/>
    <meta name="citation_reference" content="citation_journal_title=Handb. Exp. Pharmacol.; citation_title=Amygdala pain mechanisms; citation_author=V Neugebauer; citation_volume=227; citation_publication_date=2015; citation_pages=261-284; citation_doi=10.1007/978-3-662-46450-2_13; citation_id=CR58"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Representations of modality-general valence for videos and music derived from fMRI data; citation_author=J Kim, SV Shinkareva, DH Wedell; citation_volume=148; citation_publication_date=2017; citation_pages=42-54; citation_doi=10.1016/j.neuroimage.2017.01.002; citation_id=CR59"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Differential roles of human striatum and amygdala in associative learning; citation_author=J Li, D Schiller, G Schoenbaum, EA Phelps, ND Daw; citation_volume=14; citation_publication_date=2011; citation_pages=1250-1252; citation_doi=10.1038/nn.2904; citation_id=CR60"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Moment-to-moment tracking of state value in the amygdala; citation_author=MA Belova, JJ Paton, CD Salzman; citation_volume=28; citation_publication_date=2008; citation_pages=10023-10030; citation_doi=10.1523/JNEUROSCI.1400-08.2008; citation_id=CR61"/>
    <meta name="citation_reference" content="citation_journal_title=BMC Neurosci.; citation_title=Common brain activations for painful and non-painful aversive stimuli; citation_author=DJ Hayes, G Northoff; citation_volume=13; citation_publication_date=2012; citation_doi=10.1186/1471-2202-13-60; citation_id=CR62"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Mood influences supraspinal pain processing separately from attention; citation_author=C Villemure, MC Bushnell; citation_volume=29; citation_publication_date=2009; citation_pages=705-715; citation_doi=10.1523/JNEUROSCI.3822-08.2009; citation_id=CR63"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Cerebral and spinal modulation of pain by emotions; citation_author=M Roy, M Pich&#233;, J-I Chen, I Peretz, P Rainville; citation_volume=106; citation_publication_date=2009; citation_pages=20900-20905; citation_doi=10.1073/pnas.0904706106; citation_id=CR64"/>
    <meta name="citation_reference" content="citation_journal_title=Soc. Cogn. Affect. Neurosci.; citation_title=The human amygdala is sensitive to the valence of pictures and sounds irrespective of arousal: an fMRI study; citation_author=S Anders, F Eippert, N Weiskopf, R Veit; citation_volume=3; citation_publication_date=2008; citation_pages=233-243; citation_doi=10.1093/scan/nsn017; citation_id=CR65"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Separate neural representations for physical pain and social rejection; citation_author=C-W Woo; citation_volume=5; citation_publication_date=2014; citation_doi=10.1038/ncomms6380; citation_id=CR66"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Using multi-voxel pattern analysis of fMRI data to interpret overlapping functional activations; citation_author=MV Peelen, PE Downing; citation_volume=11; citation_publication_date=2007; citation_pages=4-5; citation_doi=10.1016/j.tics.2006.10.009; citation_id=CR67"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Acute social isolation evokes midbrain craving responses similar to hunger; citation_author=L Tomova; citation_volume=23; citation_publication_date=2020; citation_pages=1597-1605; citation_doi=10.1038/s41593-020-00742-z; citation_id=CR68"/>
    <meta name="citation_reference" content="citation_journal_title=Pain; citation_title=Central sensitization: implications for the diagnosis and treatment of pain; citation_author=CJ Woolf; citation_volume=152; citation_publication_date=2011; citation_pages=S2-S15; citation_doi=10.1016/j.pain.2010.09.030; citation_id=CR69"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage Clin.; citation_title=Fibromyalgia interacts with age to change the brain; citation_author=M Ceko, MC Bushnell, M-A Fitzcharles, P Schweinhardt; citation_volume=3; citation_publication_date=2013; citation_pages=249-260; citation_doi=10.1016/j.nicl.2013.08.015; citation_id=CR70"/>
    <meta name="citation_reference" content="citation_journal_title=Pain; citation_title=Towards a neurophysiological signature for fibromyalgia; citation_author=M L&#243;pez-Sol&#224;; citation_volume=158; citation_publication_date=2017; citation_pages=34-47; citation_doi=10.1097/j.pain.0000000000000707; citation_id=CR71"/>
    <meta name="citation_reference" content="citation_journal_title=Pain Physician; citation_title=Thermal pain in complex regional pain syndrome type I; citation_author=JR Grothusen, G Alexander, K Erwin, R Schwartzman; citation_volume=17; citation_publication_date=2014; citation_pages=71-79; citation_doi=10.36076/ppj.2014/17/71; citation_id=CR72"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Activation of the opioidergic descending pain control system underlies placebo analgesia; citation_author=F Eippert; citation_volume=63; citation_publication_date=2009; citation_pages=533-543; citation_doi=10.1016/j.neuron.2009.07.014; citation_id=CR73"/>
    <meta name="citation_reference" content="citation_journal_title=N. Engl. J. Med.; citation_title=An fMRI-based neurologic signature of physical pain; citation_author=TD Wager; citation_volume=368; citation_publication_date=2013; citation_pages=1388-1397; citation_doi=10.1056/NEJMoa1204471; citation_id=CR74"/>
    <meta name="citation_reference" content="citation_journal_title=Physiol. Behav.; citation_title=Valid across-group comparisons with labeled scales: the gLMS versus magnitude matching; citation_author=LM Bartoshuk; citation_volume=82; citation_publication_date=2004; citation_pages=109-114; citation_doi=10.1016/j.physbeh.2004.02.033; citation_id=CR75"/>
    <meta name="citation_reference" content="citation_journal_title=Food Qual. Prefer.; citation_title=Direct comparison of the generalized visual analog scale and general labeled magnitude scale; citation_author=JE Hayes, AL Allen, SM Bennett; citation_volume=28; citation_publication_date=2013; citation_pages=36-44; citation_doi=10.1016/j.foodqual.2012.07.012; citation_id=CR76"/>
    <meta name="citation_reference" content="citation_journal_title=J. Acoust. Soc. Am.; citation_title=Mapping unpleasantness of sounds to their auditory representation; citation_author=S Kumar, HM Forster, P Bailey, TD Griffiths; citation_volume=124; citation_publication_date=2008; citation_pages=3810-3817; citation_doi=10.1121/1.3006380; citation_id=CR77"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Features versus feelings: dissociable representations of the acoustic features and valence of aversive sounds; citation_author=S Kumar, K Kriegstein, K Friston, TD Griffiths; citation_volume=32; citation_publication_date=2012; citation_pages=14184-14192; citation_doi=10.1523/JNEUROSCI.1759-12.2012; citation_id=CR78"/>
    <meta name="citation_reference" content="Lang, P. J., Bradley, M. M. &amp; Cuthbert, B. N. International affective picture system (IAPS): affective ratings of pictures and instruction manual. Technical Report A-8. University of Florida, Gainesville (2008)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Against hyperacuity in brain reading: spatial smoothing does not hurt multivariate fMRI analyses?; citation_author=HP Op de Beeck; citation_volume=49; citation_publication_date=2010; citation_pages=1943-1948; citation_doi=10.1016/j.neuroimage.2009.02.047; citation_id=CR80"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Thresholding of statistical maps in functional neuroimaging using the false discovery rate; citation_author=CR Genovese, NA Lazar, T Nichols; citation_volume=15; citation_publication_date=2002; citation_pages=870-878; citation_doi=10.1006/nimg.2001.1037; citation_id=CR81"/>
    <meta name="citation_reference" content="citation_journal_title=Educ. Psychol. Meas.; citation_title=The importance of structure coefficients in regression research; citation_author=B Thompson, GM Borrello; citation_volume=45; citation_publication_date=1985; citation_pages=203-209; citation_doi=10.1177/001316448504500202; citation_id=CR82"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Recipes for the linear analysis of EEG; citation_author=LC Parra, CD Spence, AD Gerson, P Sajda; citation_volume=28; citation_publication_date=2005; citation_pages=326-341; citation_doi=10.1016/j.neuroimage.2005.05.032; citation_id=CR83"/>
    <meta name="citation_reference" content="Kohoutov&#225;, L. et al. Toward a unified framework for interpreting machine-learning models in neuroimaging. Nat. Protoc. 
                  https://doi.org/10.1038/s41596-019-0289-5
                  
                 (2020)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Simple group fMRI modeling and inference; citation_author=JA Mumford, T Nichols; citation_volume=47; citation_publication_date=2009; citation_pages=1469-1475; citation_doi=10.1016/j.neuroimage.2009.05.034; citation_id=CR85"/>
    <meta name="citation_reference" content="citation_journal_title=Front. Neuroinformatics; citation_title=BAMS Neuroanatomical Ontology: design and implementation; citation_author=M Bota, LW Swanson; citation_volume=2; citation_publication_date=2008; citation_pages=2; citation_doi=10.3389/neuro.11.002.2008; citation_id=CR86"/>
    <meta name="citation_author" content="&#268;eko, Marta"/>
    <meta name="citation_author_institution" content="Institute of Cognitive Science, University of Colorado, Boulder, USA"/>
    <meta name="citation_author" content="Kragel, Philip A."/>
    <meta name="citation_author_institution" content="Institute of Cognitive Science, University of Colorado, Boulder, USA"/>
    <meta name="citation_author_institution" content="Department of Psychology, Emory University, Atlanta, USA"/>
    <meta name="citation_author" content="Woo, Choong-Wan"/>
    <meta name="citation_author_institution" content="Center for Neuroscience Imaging Research, Institute for Basic Science, Suwon, South Korea"/>
    <meta name="citation_author_institution" content="Department of Biomedical Engineering, Sungkyunkwan University, Suwon, South Korea"/>
    <meta name="citation_author_institution" content="Department of Intelligent Precision Healthcare Convergence, Sungkyunkwan University, Suwon, South Korea"/>
    <meta name="citation_author" content="L&#243;pez-Sol&#224;, Marina"/>
    <meta name="citation_author_institution" content="Serra Hunter Programme, Department of Medicine, School of Medicine and Health Sciences, University of Barcelona, Barcelona, Spain"/>
    <meta name="citation_author" content="Wager, Tor D."/>
    <meta name="citation_author_institution" content="Institute of Cognitive Science, University of Colorado, Boulder, USA"/>
    <meta name="citation_author_institution" content="Department of Psychological and Brain Sciences, Dartmouth College, Hanover, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Common and stimulus-type-specific brain representations of negative affect"/>
    <meta name="twitter:description" content="Nature Neuroscience - Using multiple types of negative affect stimuli, functional magnetic resonance imaging and predictive modeling, &#268;eko et al. show that the brain integrates generalized and..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig1_HTML.png"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/s41593-022-01082-w"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Common and stimulus-type-specific brain representations of negative affect - Nature Neuroscience"/>
    <meta property="og:description" content="Using multiple types of negative affect stimuli, functional magnetic resonance imaging and predictive modeling, &#268;eko et al. show that the brain integrates generalized and stimulus-type-specific representations of aversive events to jointly predict subjective experience."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig1_HTML.png"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41593-022-01082-w;doi=10.1038/s41593-022-01082-w;techmeta=36,59;subjmeta=116,1457,2394,378,3917,631;kwrd=Emotion,Neural+decoding,Sensory+processing">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=1020280871&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-022-01082-w%26doi%3D10.1038/s41593-022-01082-w%26techmeta%3D36,59%26subjmeta%3D116,1457,2394,378,3917,631%26kwrd%3DEmotion,Neural+decoding,Sensory+processing">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=1020280871&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-022-01082-w%26doi%3D10.1038/s41593-022-01082-w%26techmeta%3D36,59%26subjmeta%3D116,1457,2394,378,3917,631%26kwrd%3DEmotion,Neural+decoding,Sensory+processing"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41593-022-01082-w'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Common and stimulus-type-specific brain representations of negative affect
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01082-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2022-05-30">30 May 2022</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Common and stimulus-type-specific brain representations of negative affect</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Marta-_eko-Aff1" data-author-popup="auth-Marta-_eko-Aff1" data-author-search="Čeko, Marta" data-corresp-id="c1">Marta Čeko<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0001-8679-8145"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-8679-8145</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Philip_A_-Kragel-Aff1-Aff2" data-author-popup="auth-Philip_A_-Kragel-Aff1-Aff2" data-author-search="Kragel, Philip A.">Philip A. Kragel</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0001-9463-6381"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-9463-6381</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Choong_Wan-Woo-Aff3-Aff4-Aff5" data-author-popup="auth-Choong_Wan-Woo-Aff3-Aff4-Aff5" data-author-search="Woo, Choong-Wan">Choong-Wan Woo</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-7423-5422"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-7423-5422</a></span><sup class="u-js-hide"><a href="#Aff3">3</a>,<a href="#Aff4">4</a>,<a href="#Aff5">5</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Marina-L_pez_Sol_-Aff6" data-author-popup="auth-Marina-L_pez_Sol_-Aff6" data-author-search="López-Solà, Marina">Marina López-Solà</a><sup class="u-js-hide"><a href="#Aff6">6</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 5 authors for this article" title="Show all 5 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Tor_D_-Wager-Aff1-Aff7" data-author-popup="auth-Tor_D_-Wager-Aff1-Aff7" data-author-search="Wager, Tor D." data-corresp-id="c2">Tor D. Wager<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-1936-5574"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-1936-5574</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff7">7</a></sup> </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 25</b>, <span class="u-visually-hidden">pages </span>760–770 (<span data-test="article-publication-year">2022</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">6769 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">21 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">47 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/s41593-022-01082-w/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/emotion" data-track="click" data-track-action="view subject" data-track-label="link">Emotion</a></li><li class="c-article-subject-list__subject"><a href="/subjects/neural-decoding" data-track="click" data-track-action="view subject" data-track-label="link">Neural decoding</a></li><li class="c-article-subject-list__subject"><a href="/subjects/sensory-processing" data-track="click" data-track-action="view subject" data-track-label="link">Sensory processing</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>The brain contains both generalized and stimulus-type-specific representations of aversive events, but models of how these are integrated and related to subjective experience are lacking. We combined functional magnetic resonance imaging with predictive modeling to identify representations of generalized (common) and stimulus-type-specific negative affect across mechanical pain, thermal pain, aversive sounds and aversive images of four intensity levels each. This allowed us to examine how generalized and stimulus-specific representations jointly contribute to aversive experience. Stimulus-type-specific negative affect was largely encoded in early sensory pathways, whereas generalized negative affect was encoded in a distributed set of midline, forebrain, insular and somatosensory regions. All models specifically predicted negative affect rather than general salience or arousal and accurately predicted negative affect in independent samples, demonstrating robustness and generalizability. Common and stimulus-type-specific models were jointly important for predicting subjective experience. Together, these findings offer an integrated account of how negative affect is constructed in the brain and provide predictive neuromarkers for future studies.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01082-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01082-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41586-024-07178-6/MediaObjects/41586_2024_7178_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41586-024-07178-6?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41586-024-07178-6">Neural signatures of natural behaviour in socializing macaques
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">13 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Camille Testard, Sébastien Tremblay, … Michael L. Platt</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-020-59282-y/MediaObjects/41598_2020_59282_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41598-020-59282-y?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41598-020-59282-y">Emotions and brain function are altered up to one month after a single high dose of psilocybin
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">10 February 2020</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Frederick S. Barrett, Manoj K. Doss, … Roland R. Griffiths</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-024-46508-0/MediaObjects/41467_2024_46508_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-024-46508-0?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41467-024-46508-0">Distributed neural representations of conditioned threat in the human brain
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">12 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Zhenfu Wen, Edward F. Pace-Schott, … Mohammed R. Milad</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'topic',
                        model: 'visits_v2',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711543967,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>Affect is a fundamental property of brain function. The hedonic quality and motivational relevance of sensory stimuli govern the strength of brain responses to sensory cues and drive learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Berridge, K. C. &amp; Kringelbach, M. L. Neuroscience of affect: brain mechanisms of pleasure and displeasure. Curr. Opin. Neurobiol. 23, 294–303 (2013)." href="/articles/s41593-022-01082-w#ref-CR1" id="ref-link-section-d30208738e567">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Tye, K. M. Neural circuit motifs in valence processing. Neuron 100, 436–452 (2018)." href="/articles/s41593-022-01082-w#ref-CR2" id="ref-link-section-d30208738e570">2</a></sup>. Much attention has been devoted to understanding how affect influences behavior and is disrupted in psychopathology and neurological disorders, but less is known about the neural structure of affective processes themselves—how they are represented in the brain and whether they converge on generalized (common) representations of value.</p><p>Affective experiences are often defined in terms of the ‘core’ dimensions valence and arousal<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Russell, J. A. A circumplex model of affect. J. Pers. Soc. Psychol. 39, 1161–1178 (1980)." href="/articles/s41593-022-01082-w#ref-CR3" id="ref-link-section-d30208738e577">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Russell, J. A. &amp; Barrett, L. F. Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant. J. Pers. Soc. Psychol. 76, 805–819 (1999)." href="/articles/s41593-022-01082-w#ref-CR4" id="ref-link-section-d30208738e580">4</a></sup> or approach-avoidance tendencies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Gray, J. A. The Psychology of Fear and Stress. (CUP Archive, 1987)." href="/articles/s41593-022-01082-w#ref-CR5" id="ref-link-section-d30208738e584">5</a></sup>, implicitly assuming a level of interchangeability among stimulus types. Neuroeconomic theories postulate a ‘common currency’ for value<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Montague, P. R. &amp; Berns, G. S. Neural economics and the biological substrates of valuation. Neuron 36, 265–284 (2002)." href="/articles/s41593-022-01082-w#ref-CR6" id="ref-link-section-d30208738e588">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Padoa-Schioppa, C. &amp; Assad, J. A. Neurons in the orbitofrontal cortex encode economic value. Nature 441, 223–226 (2006)." href="/articles/s41593-022-01082-w#ref-CR7" id="ref-link-section-d30208738e591">7</a></sup>, whereby signals from diverse reinforcers are integrated into a common representation that shapes decision-making and behavior. These ideas have shaped clinical research. For example, emotional facial expressions are commonly used as probes of negative affect across clinical conditions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Hariri, A. R. et al. A susceptibility gene for affective disorders and the response of the human amygdala. Arch. Gen. Psychiatry 62, 146–152 (2005)." href="/articles/s41593-022-01082-w#ref-CR8" id="ref-link-section-d30208738e595">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Bishop, S., Duncan, J., Brett, M. &amp; Lawrence, A. D. Prefrontal cortical function and anxiety: controlling attention to threat-related stimuli. Nat. Neurosci. 7, 184–188 (2004)." href="/articles/s41593-022-01082-w#ref-CR9" id="ref-link-section-d30208738e598">9</a></sup>. Likewise, pain neuroimaging has concentrated on a few types of stimuli, most commonly heat, as probes of pain sensitivity in general<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Duerden, E. G. &amp; Albanese, M.-C. Localization of pain-related brain activation: a meta-analysis of neuroimaging data. Hum. Brain Mapp. 34, 109–149 (2013)." href="/articles/s41593-022-01082-w#ref-CR10" id="ref-link-section-d30208738e602">10</a></sup>.</p><p>If different types of affective stimuli can be used interchangeably, any aversive stimulus might be suitable for probing ‘negative affect’ systems (for example, as defined by the National Institutes of Health (NIH) Research Domain Criteria<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Insel, T. et al. Research domain criteria (RDoC): toward a new classification framework for research on mental disorders. Am. J. Psychiatry 167, 748–751 (2010)." href="/articles/s41593-022-01082-w#ref-CR11" id="ref-link-section-d30208738e609">11</a></sup>). If they cannot, important basic and clinical effects could be missed, for example, if a stimulus type used is not relevant for the effect or population studied. Theories of affect and computational accounts of learning, predictive coding and active inference might need to be extended to account for reinforcer-specific and stimulus-type-specific brain processes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Hayden, B. Y. &amp; Niv, Y. The case against economic values in the orbitofrontal cortex (or anywhere else in the brain). Behav. Neurosci. 135, 192–201 (2021)." href="/articles/s41593-022-01082-w#ref-CR12" id="ref-link-section-d30208738e613">12</a></sup>.</p><p>Evidence for shared neural representations is mixed. On one hand, animal studies have identified cross-modal coding of affective information in single neurons<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Padoa-Schioppa, C. &amp; Assad, J. A. Neurons in the orbitofrontal cortex encode economic value. Nature 441, 223–226 (2006)." href="/articles/s41593-022-01082-w#ref-CR7" id="ref-link-section-d30208738e620">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Gehrlach, D. A. et al. Aversive state processing in the posterior insular cortex. Nat. Neurosci. 22, 1424–1437 (2019)." href="/articles/s41593-022-01082-w#ref-CR13" id="ref-link-section-d30208738e623">13</a></sup>, and human functional magnetic resonance imaging (fMRI) studies have identified commonalities across aversive stimulus types in ventromedial and orbital prefrontal cortices (vMPFC and OFC, respectively), anterior midcingulate cortex (aMCC) and anterior insula (aINS)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Corradi-Dell’Acqua, C., Tusche, A., Vuilleumier, P. &amp; Singer, T. Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex. Nat. Commun. 7, 10904 (2016)." href="#ref-CR14" id="ref-link-section-d30208738e627">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kragel, P. A. et al. Generalizable representations of pain, cognitive control, and negative emotion in medial frontal cortex. Nat. Neurosci. 21, 283–289 (2018)." href="#ref-CR15" id="ref-link-section-d30208738e627_1">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chikazoe, J., Lee, D. H., Kriegeskorte, N. &amp; Anderson, A. K. Population coding of affect across stimuli, modalities and individuals. Nat. Neurosci. 17, 1114–1122 (2014)." href="/articles/s41593-022-01082-w#ref-CR16" id="ref-link-section-d30208738e630">16</a></sup>. Meta-analyses have identified potential neural substrates for ‘core’ affective dimensions (valence and arousal) in the OFC, MPFC, nucleus accumbens (NAC)/ventral striatum (vStr) and amygdala<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Kober, H. et al. Functional grouping and cortical-subcortical interactions in emotion: a meta-analysis of neuroimaging studies. Neuroimage 42, 998–1031 (2008)." href="/articles/s41593-022-01082-w#ref-CR17" id="ref-link-section-d30208738e634">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. Front. Psychol. 6, 1860 (2015)." href="/articles/s41593-022-01082-w#ref-CR18" id="ref-link-section-d30208738e637">18</a></sup>. On the other hand, several theories suggest that the brain is organized into separable neural processes for different types of negative affect<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Ekman, P. An argument for basic emotions. Cognition Emot. 6, 169–200 (1992)." href="/articles/s41593-022-01082-w#ref-CR19" id="ref-link-section-d30208738e641">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Friedman, B. H. Feelings and the body: the Jamesian perspective on autonomic specificity of emotion. Biol. Psychol. 84, 383–393 (2010)." href="/articles/s41593-022-01082-w#ref-CR20" id="ref-link-section-d30208738e644">20</a></sup>. Although these are labeled as ‘negative’ or ‘aversive’, these labels may be culturally constructed categories rather than fundamental properties of brain organization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Barrett, L. F. Solving the emotion paradox: categorization and the experience of emotion. Pers. Soc. Psychol. Rev. 10, 20–46 (2006)." href="/articles/s41593-022-01082-w#ref-CR21" id="ref-link-section-d30208738e648">21</a></sup>. fMRI studies have identified distinct activity patterns for different categories of emotion and affective stimulus types<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chikazoe, J., Lee, D. H., Kriegeskorte, N. &amp; Anderson, A. K. Population coding of affect across stimuli, modalities and individuals. Nat. Neurosci. 17, 1114–1122 (2014)." href="/articles/s41593-022-01082-w#ref-CR16" id="ref-link-section-d30208738e653">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Saarimäki, H. et al. Discrete neural signatures of basic emotions. Cereb. Cortex 26, 2563–2573 (2016)." href="#ref-CR22" id="ref-link-section-d30208738e656">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kragel, P. A. &amp; LaBar, K. S. Multivariate neural biomarkers of emotional states are categorically distinct. Soc. Cogn. Affect. Neurosci. 10, 1437–1448 (2015)." href="#ref-CR23" id="ref-link-section-d30208738e656_1">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Stephens, C. L., Christie, I. C. &amp; Friedman, B. H. Autonomic specificity of basic emotions: evidence from pattern classification and cluster analysis. Biol. Psychol. 84, 463–473 (2010)." href="#ref-CR24" id="ref-link-section-d30208738e656_2">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Horing, B., Sprenger, C. &amp; Büchel, C. The parietal operculum preferentially encodes heat pain and not salience. PLoS Biol. 17, e3000205 (2019)." href="#ref-CR25" id="ref-link-section-d30208738e656_3">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wager, T. D. et al. A Bayesian model of category-specific emotional brain responses. PLoS Comput. Biol. 11, e1004066 (2015)." href="#ref-CR26" id="ref-link-section-d30208738e656_4">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Kragel, P. A., Reddan, M. C., LaBar, K. S. &amp; Wager, T. D. Emotion schemas are embedded in the human visual system. Sci. Adv. 5, eaaw4358 (2019)." href="/articles/s41593-022-01082-w#ref-CR27" id="ref-link-section-d30208738e659">27</a></sup> (although these may also reflect constructed categories<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Barrett, L. F. Solving the emotion paradox: categorization and the experience of emotion. Pers. Soc. Psychol. Rev. 10, 20–46 (2006)." href="/articles/s41593-022-01082-w#ref-CR21" id="ref-link-section-d30208738e663">21</a></sup>). Animal studies have identified neuronal ensembles specific to distinct types and aspects of nociception<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Corder, G. et al. An amygdalar neural ensemble that encodes the unpleasantness of pain. Science 363, 276–281 (2019)." href="#ref-CR28" id="ref-link-section-d30208738e667">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hua, T. et al. General anesthetics activate a potent central pain-suppression circuit in the amygdala. Nat. Neurosci. 23, 854–868 (2020)." href="#ref-CR29" id="ref-link-section-d30208738e667_1">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Chiang, M. C. et al. Divergent neural pathways emanating from the lateral parabrachial nucleus mediate distinct components of the pain response. Neuron 106, 927–939 (2020)." href="/articles/s41593-022-01082-w#ref-CR30" id="ref-link-section-d30208738e670">30</a></sup> and affective states like thirst<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Allen, W. E. et al. Thirst-associated preoptic neurons encode an aversive motivational drive. Science 357, 1149–1155 (2017)." href="#ref-CR31" id="ref-link-section-d30208738e674">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Allen, W. E. et al. Thirst regulates motivated behavior through modulation of brainwide neural population dynamics. Science 364, 253 (2019)." href="#ref-CR32" id="ref-link-section-d30208738e674_1">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Pool, A.-H. et al. The cellular basis of distinct thirst modalities. Nature 588, 112–117 (2020)." href="/articles/s41593-022-01082-w#ref-CR33" id="ref-link-section-d30208738e677">33</a></sup>.</p><p>Evidence for common and stimulus-type-specific representations of negative affect have largely been investigated separately, in different studies and paradigms, rather than comparing them directly. The latter was the goal of the current study.</p><p>In study 1, we measured fMRI responses to four types of aversive stimuli—painful heat, painful pressure, aversive images and aversive sounds—and a positive affective control (pleasant images) in <i>N</i> = 55 healthy participants (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig1">1a</a>). Including four intensity levels per type and subjective post-trial ratings on a common rating scale allowed us to identify fMRI patterns that tracked subjective aversiveness across all stimulus types (‘common negative affect’) or in a stimulus-type-specific fashion. Partial least squares regression (PLS-R) provided a framework for jointly estimating both common and stimulus-type-specific representations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="McIntosh, A. R. &amp; Lobaugh, N. J. Partial least squares analysis of neuroimaging data: applications and advances. Neuroimage 23, 250–263 (2004)." href="/articles/s41593-022-01082-w#ref-CR34" id="ref-link-section-d30208738e694">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Wold, S., Sjöström, M. &amp; Eriksson, L. PLS-regression: a basic tool of chemometrics. Chemom. Intell. Lab. Syst. 58, 109–130 (2001)." href="/articles/s41593-022-01082-w#ref-CR35" id="ref-link-section-d30208738e697">35</a></sup> (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">1</a>), and yielded predictive models whose sensitivity and specificity for negative affect could be quantitatively evaluated in new individuals. In several prospective samples (studies 2–6; <i>N</i> = 401 participants), we tested the final models to evaluate their predictive accuracy (replicability), generalizability across studies and generalizability across stimulus types versus specificity to a particular type. This framework allowed us to test: (1) whether there is a neural representation of common ‘negative affect’ across stimulus types that predicts the degree of negative affect experienced in response to any stimulus; (2) whether there are also stimulus-type-specific representations of negative affect; (3) whether these representations are specific to aversive stimuli or also respond to positive stimuli, which could signal encoding of arousal or salience; and (4) the relative importance of common and type-specific representations in jointly predicting negative affect ratings in new individuals, assessing their utility as neuromarkers in future studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Woo, C.-W., Chang, L. J., Lindquist, M. A. &amp; Wager, T. D. Building better biomarkers: brain models in translational neuroimaging. Nat. Neurosci. 20, 365–377 (2017)." href="/articles/s41593-022-01082-w#ref-CR36" id="ref-link-section-d30208738e708">36</a></sup>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Task design and main analyses."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1: Task design and main analyses.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="537"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p><b>a</b>, Multiple aversive experiences task. Four stimulus types (thermal and mechanical pain, aversive sounds and aversive images) at four preselected intensity levels for a total of 96 randomized stimuli over six fMRI runs; aversiveness (‘negative affect’) rated on a common scale after each stimulus presentation, by measuring ‘how much do you want to avoid this experience in the future?’. <b>b</b>, Main analyses: (1) brain model development using PLS-R, model evaluation (sensitivity and specificity); (2) variance decomposition analysis to test how much of the predicted variance in ratings is uniquely attributable to each model versus shared among models; (3) identification of core systems for common (purple) and stimulus-type-specific negative affect; (4) analysis of model encoding in selected multimodal and primary sensory ROIs; (5) validation in independent datasets; and (6) valence tests using positive stimuli and additional validation analyses.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Behavioral results</h3><p>In study 1, <i>N</i> = 55 participants (24 females) experienced four types of aversive stimuli, during fMRI at 3T (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01082-w#Sec13">Methods</a>). Negative affect induced by these stimuli was measured on a uniform scale across stimulus types, allowing direct comparisons across sensory inputs despite variation in stimulus properties. Each stimulus type was rated as moderately to strongly aversive across the four intensity levels, ranging from 0.18 (‘moderate’) to 0.37 (‘strong’, general Label Magnitude Scale (gLMS); Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">1</a>). Negative affect ratings increased with intensity (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig2">2a</a>) for mechanical pain (<i>t</i>(54) = 7.68, <i>P</i> &lt; 0.001), thermal pain (<i>t</i>(54) = 13.86, <i>P</i> &lt; 0.001), aversive sounds (<i>t</i>(54) = 6.47, <i>P</i> &lt; 0.001) and aversive images (<i>t</i>(54) = 11.42, <i>P</i> &lt; 0.001). Stimulus types were comparably aversive, permitting analysis of variation in brain activity across types while approximately matching on (and statistically controlling for) reported negative affect, and individual differences in sensitivity were correlated across types (<i>r</i> = 0.26–0.68; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">2</a>). Ratings for each stimulus level (averaged across trials) within participants were used as outcomes for brain model development.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Model evaluation and joint contributions to predicting negative affect."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2: Model evaluation and joint contributions to predicting negative affect.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="439"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p><b>a</b>, Ratings significantly scaled with stimulus intensity (<i>N</i> = 55 participants; two-sided <i>P</i> &lt; 0.001 for each stimulus type; linear regression). Data are shown as mean values across participants for each stimulus type. Error bars reflect within-participant s.e.m. <b>b</b>, Relationship between observed and predicted ratings (that is, model response). Data are shown as mean values across participants for each stimulus type. Error bars reflect within-participant s.e.m. The common model, trained on all stimuli, significantly predicted ratings to each stimulus type. Stimulus-type-specific models, optimized for specificity by setting other stimulus types at 0 during training, significantly predicted ratings to target (color-matched) stimulus type, but not to off-target stimulus types. <i>r</i>, mean within-participant Pearson correlation between predicted and observed ratings; two-sided <i>P</i> values based on a 10,000 samples bootstrap test of within-participant <i>r</i> values. <b>c</b>, Cross-prediction of ratings across stimulus types tested by Pearson correlation between the predicted and the observed outcomes for each train–test stimulus pair; darker shading indicates a higher Pearson <i>r</i> value<b>. d</b>, For each stimulus type, the within-participant variance in outcome (ratings) explained by the predictors (common model, specific model) is partitioned between the predictors into unique and shared components by computing the full and reduced regression models: total <i>r</i><sup>2</sup>, mean within-participant total variance explained by common and specific models, unique <i>r</i><sup>2</sup> for common model = total <i>r</i><sup>2</sup> − single variance for specific model (yellow slice), unique <i>r</i><sup>2</sup> for specific model = total <i>r</i><sup>2 </sup>− single variance for common model; dark-brown slice, shared <i>r</i><sup>2</sup> = total <i>r</i><sup>2 </sup>− unique <i>r</i><sup>2</sup> specific − unique <i>r</i><sup>2</sup> common (light-brown slice).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec4">Identifying common and stimulus-type-specific brain models</h3><p>Negative affect models were developed using PLS-R on study 1 data and were constrained to simultaneously predict common and stimulus-type-specific effects based on brain-wide patterns within gray matter (‘PLS-R for brain model development’). This produced five multivariate patterns: one for each of the four stimulus types and one for common negative affect. Models were tested using fivefold leave-whole-participant-out cross-validation. Thus, accuracy statistics are based on models trained on other participants (‘Model evaluation’) and additionally validated in independent studies (see below).</p><p>These models provided evidence for both common and stimulus-type-specific coding of negative affect. All five models were sensitive to their target stimuli, as evidenced by significant associations between observed and predicted ratings (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig2">2b</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">3</a>). Below we report correlations, expressed as mean within-participant <i>r</i> ± standard error (s.e.), and the out-of-sample prediction root mean squared error (RMSE; rating scale ranged from 0 to 1) for each model and outcome<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Poldrack, R. A., Huckins, G. &amp; Varoquaux, G. Establishment of best practices for evidence for prediction: a review. JAMA Psychiatry 77, 534–540 (2020)." href="/articles/s41593-022-01082-w#ref-CR37" id="ref-link-section-d30208738e901">37</a></sup>. The common model accurately predicted mechanical pain (<i>r</i> = 0.43 ± 0.07, <i>P</i> &lt; 0.001, RMSE = 0.132), thermal pain (<i>r</i> = 0.66 ± 0.06, <i>P</i> = 0.001, RMSE = 0.192), aversive sounds (<i>r</i> = 0.31 ± 0.07, <i>P</i> &lt; 0.001, RMSE = 0.176) and aversive images (<i>r</i> = 0.49 ± 0.06, <i>P</i> &lt; 0.001, RMSE = 0.179). Some variation in correlation values likely reflects range differences across outcomes, but the RMSE values were similar.</p><p>Each type-specific model predicted negative affect ratings of the intended type: <i>r</i> = 0.25 ± 0.08, <i>P</i> = 0.004, RMSE = 0.156 for mechanical pain; <i>r</i> = 0.60 ± 0.06, <i>P</i> = 0.001, RMSE = 0.205 for thermal pain; <i>r</i> = 0.38 ± 0.06, <i>P</i> &lt; 0.001, RMSE = 0.185 for aversive sounds; and <i>r</i> = 0.64 ± 0.05, <i>P</i> = 0.001, RMSE = 0.172 for aversive images. Type-specific models were specific to target stimuli, as evidenced by poor cross-prediction of off-target ratings (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig2">2b,c</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">3</a>), which were not significantly different from chance, with two exceptions (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">3</a>). Effect sizes were on average five times lower than for on-target predictions. All five brain models remained significant after controlling for session order (‘<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01082-w#Sec15">Study design</a>’), age and sex, and these variables had little impact on ratings (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">4</a>). The brain models also discriminated between the lowest and highest stimulus level (see Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">2</a> for classification accuracy matrix across all stimulus intensity-level pairs).</p><h3 class="c-article__sub-heading" id="Sec5">Relative contributions of models to predicting ratings</h3><p>Next, we asked how common and type-specific brain models combine to predict negative affect. We partitioned the variance explained in ratings into that: (a) unique to the common model, (b) unique to the specific model, and (c) shared across both models. Variance decomposition was computed via full and reduced multiple regression models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Nimon, K., Lewis, M., Kane, R. &amp; Haynes, R. M. An R package to compute commonality coefficients in the multiple regression case: an introduction to the package and a practical example. Behav. Res. Methods 40, 457–466 (2008)." href="/articles/s41593-022-01082-w#ref-CR38" id="ref-link-section-d30208738e986">38</a></sup> on cross-validated model outputs for each individual participant (‘Variance decomposition analysis’) and then averaged across participants.</p><p>Negative affect ratings of all types were predicted by a mixture of common and stimulus-type-specific representations in approximately equal parts (mechanical: 33% common, 34% specific; thermal: 31% common, 23% specific; auditory: 34% common, 29% specific; visual: 21% common, 32%, specific) and some variance shared across the common and specific models (mechanical, 10%; thermal, 32%; auditory, 5%; visual, 25%; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig2">2c</a>). Because negative affect was predicted by a mix of common and stimulus-type-specific representations, these results show that negative affective experience is not completely reducible to a common dimension such as valence.</p><h3 class="c-article__sub-heading" id="Sec6">Core systems for multimodal and stimulus-type-specific negative affect</h3><p>To identify important brain features, we interpret both model weights and model encoding maps (or ‘structure coefficients’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Haufe, S. et al. On the interpretation of weight vectors of linear models in multivariate neuroimaging. Neuroimage 87, 96–110 (2014)." href="/articles/s41593-022-01082-w#ref-CR39" id="ref-link-section-d30208738e1004">39</a></sup>; Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">3</a>). Consistent model weights in bootstrap tests identify important voxels contingent on other features in the multivariate model. Structure coefficients identify voxels individually associated with each model’s output, mapping individual voxels to the overall multivariate model prediction<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Haufe, S. et al. On the interpretation of weight vectors of linear models in multivariate neuroimaging. Neuroimage 87, 96–110 (2014)." href="/articles/s41593-022-01082-w#ref-CR39" id="ref-link-section-d30208738e1011">39</a></sup>. The voxels significant in both maps (that is, their conjunction) are the most consistently associated with the target outcome, with or without other brain covariates, and can be interpreted as core regions contributing to the predictive model. For type-specific models, we calculated a three-way conjunction to additionally require that identified voxels correlate more strongly with model predictions for the target stimulus than for any other type. Thus, a core stimulus-type-specific (selective) system has voxels that reliably contribute to prediction, encode the respective model and are selective for the target model above all other models.</p><p>The core system for common negative affect included OFC, MPFC, MCC, aINS, vStr and amygdala (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3a</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">5</a>). These regions are broadly associated with affect, motivation and multisensory integration, and encode common properties across multiple negative affective stimuli in previous studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Corradi-Dell’Acqua, C., Tusche, A., Vuilleumier, P. &amp; Singer, T. Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex. Nat. Commun. 7, 10904 (2016)." href="#ref-CR14" id="ref-link-section-d30208738e1024">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kragel, P. A. et al. Generalizable representations of pain, cognitive control, and negative emotion in medial frontal cortex. Nat. Neurosci. 21, 283–289 (2018)." href="#ref-CR15" id="ref-link-section-d30208738e1024_1">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chikazoe, J., Lee, D. H., Kriegeskorte, N. &amp; Anderson, A. K. Population coding of affect across stimuli, modalities and individuals. Nat. Neurosci. 17, 1114–1122 (2014)." href="/articles/s41593-022-01082-w#ref-CR16" id="ref-link-section-d30208738e1027">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. Front. Psychol. 6, 1860 (2015)." href="/articles/s41593-022-01082-w#ref-CR18" id="ref-link-section-d30208738e1030">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Hayes, D. J. &amp; Northoff, G. Identifying a network of brain regions involved in aversion-related processing: a cross-species translational investigation. Front. Integr. Neurosci. 5, 49 (2011)." href="/articles/s41593-022-01082-w#ref-CR40" id="ref-link-section-d30208738e1033">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Lindquist, K. A., Satpute, A. B., Wager, T. D., Weber, J. &amp; Barrett, L. F. The brain basis of positive and negative affect: evidence from a meta-analysis of the human neuroimaging literature. Cereb. Cortex 26, 1910–1922 (2016)." href="/articles/s41593-022-01082-w#ref-CR41" id="ref-link-section-d30208738e1036">41</a></sup>. Some voxels in this system also contributed to stimulus-type-specific models, consistent with intermixed neural populations identified in animal studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Tye, K. M. Neural circuit motifs in valence processing. Neuron 100, 436–452 (2018)." href="/articles/s41593-022-01082-w#ref-CR2" id="ref-link-section-d30208738e1040">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Panzeri, S., Macke, J. H., Gross, J. &amp; Kayser, C. Neural population coding: combining insights from microscopic and mass signals. Trends Cogn. Sci. 19, 162–172 (2015)." href="/articles/s41593-022-01082-w#ref-CR42" id="ref-link-section-d30208738e1043">42</a></sup>. The MCC, vStr and aINS also included thermal pain-selective voxels (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig4">4</a>), and the amygdala included visual negative affect-selective voxels.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Core brain systems for multimodal and stimulus-type-specific negative affect."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3: Core brain systems for multimodal and stimulus-type-specific negative affect.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="540"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p><b>a</b>, Core system for common processes; defined as the conjunction (retaining positive values) of the PLS weight map and the PLS model encoding (structure coefficient) map, each thresholded at a false discovery rate (FDR) of <i>q</i> &lt; 0.05 and retaining positive values, for the common model. <b>b</b>, Core type-selective systems; per stimulus type, conjunction of PLS model encoding (structure coefficient) map and the type-selective PLS model encoding map (each thresholded at FDR <i>q</i> &lt; 0.05; showing voxels where model encoding values were significantly greater in that model than in any of the other four models). <b>c</b>,<b>d</b>, River plots show spatial similarity (computed as cosine similarity) between model encoding maps and anatomical parcellations (ROIs), documented in previous neuroimaging studies to show activation to aversive stimuli across stimulus types or preferential activation to individual stimulus types. Ribbons are normalized by the max cosine similarity across all ROIs. Each predictive model is shown in a different color. Maps were thresholded at FDR <i>q</i> &lt; 0.05 and positive voxels were retained only for similarity calculation and interpretation. Ribbon locations in relation to the boxes are arbitrary. Pie charts show relative contributions of each model to each ROI (that is, percentage of voxels with highest cosine similarity for each predictive map). <b>e</b>, Regional importance scores for common versus specific models. <i>x</i> axis, common model importance (percentage of ROI occupied by the common model); <i>y</i> axis, type-specific model importance (specific model with highest percentage); S1, primary somatosensory cortex; M1, primary motor cortex; A1, primary auditory cortex; A2/A3, intermediate auditory cortex; V1, primary visual cortex; V2/V3/V4, intermediate visual cortex; Amy; amygdala; Hp, hippocampus; aINS, anterior insula; RI, retroinsular cortex; dLPFC, dorsolateral prefrontal cortex; IPL, inferior parietal lobule; Precun, precuneus; Caud, caudate; Thal, thalamus; Cblm, cerebellum.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="The proposed neural architecture of multimodal negative affect."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4: The proposed neural architecture of multimodal negative affect.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="619"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Anatomical ROIs were selected a priori (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">7</a>), with the exception of the mechanical pain-selective S1 ROI, which was localized in the current study (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3</a>). Plots show structure coefficients for each model. Structure coefficients were averaged across voxels within ROI tested for significance for each model and across participants (<i>N</i> = 55); one-sample <i>t</i>-test treating subject as random effect; *<i>P</i> &lt; 0.05; **<i>P</i> &lt; 0.01; ***<i>P</i> &lt; 0.001 (for exact <i>P</i> values and the associated <i>t</i>-statistics, see Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">10</a>); <i>t</i>-tests were performed on all data (positive and negative), but only <i>P</i> values associated with positive <i>t</i>-values are marked and interpreted; each dot is a participant, bars reflect group means and error bars reflect within-participant s.e.m. The upper-right inset shows co-localization of processing in the insula, cingulate, somatosensory cortex and thalamus. The lines display selected major anatomical projections based on previous literature. Individual OFC and MPFC regions, MCC subregions, V1–V4 visual cortex and A1–A3 auditory cortex showed similar profiles thus were combined here. Thalamic nuclei: Pulv, pulvinar; Audi, A1–A3, primary and intermediate auditory cortices; Visual, V1/V2/V3/V4, primary and intermediate visual cortex; Audi INS, ventroposterior (auditory) insula (area 52, retroinsular cortex).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Core stimulus-type-selective systems (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3b</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">6</a>) largely mapped onto early sensory pathways cortices, with several exceptions. Bilateral primary somatosensory cortex (S1) was the only area selective for mechanical pain. Portions of right secondary somatosensory cortex (S2) and dorsoposterior insula (dpINS) were selective for thermal pain. Ventroposterior insula (vpINS) and bilateral auditory cortices (areas A1–A3) were selective for auditory negative affect. Bilateral visual cortices (areas V1–V4) were selective for visual negative affect. These findings are in line with recent meta-analyses showing modality-specific processing of aversive input in early sensory cortices<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. Front. Psychol. 6, 1860 (2015)." href="/articles/s41593-022-01082-w#ref-CR18" id="ref-link-section-d30208738e1171">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Hayes, D. J. &amp; Northoff, G. Identifying a network of brain regions involved in aversion-related processing: a cross-species translational investigation. Front. Integr. Neurosci. 5, 49 (2011)." href="/articles/s41593-022-01082-w#ref-CR40" id="ref-link-section-d30208738e1174">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Lindquist, K. A., Satpute, A. B., Wager, T. D., Weber, J. &amp; Barrett, L. F. The brain basis of positive and negative affect: evidence from a meta-analysis of the human neuroimaging literature. Cereb. Cortex 26, 1910–1922 (2016)." href="/articles/s41593-022-01082-w#ref-CR41" id="ref-link-section-d30208738e1177">41</a></sup>. Importantly, however, these areas were not only selectively activated by a particular stimulus type, but also selectively predicted negative affect ratings for one type.</p><p>An extended set of regions was selective for visual negative affect, including anterior occipitotemporal and parahippocampal areas, amygdala and mid-lateral OFC (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3b</a>). In addition, some ‘sensory’ thalamic and early sensory cortices also encoded the common model (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3a</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig4">4</a>), supporting an expanded role for traditionally ‘sensory’ areas in processing of multimodal affective input<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Kragel, P. A., Reddan, M. C., LaBar, K. S. &amp; Wager, T. D. Emotion schemas are embedded in the human visual system. Sci. Adv. 5, eaaw4358 (2019)." href="/articles/s41593-022-01082-w#ref-CR27" id="ref-link-section-d30208738e1193">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Mouraux, A., Diukova, A., Lee, M. C., Wise, R. G. &amp; Iannetti, G. D. A multisensory investigation of the functional significance of the ‘pain matrix’. Neuroimage 54, 2237–2249 (2011)." href="#ref-CR43" id="ref-link-section-d30208738e1196">43</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Liang, M., Mouraux, A., Hu, L. &amp; Iannetti, G. D. Primary sensory cortices contain distinguishable spatial patterns of activity for each sense. Nat. Commun. 4, 1979 (2013)." href="#ref-CR44" id="ref-link-section-d30208738e1196_1">44</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Shuler, M. G. &amp; Bear, M. F. Reward timing in the primary visual cortex. Science 311, 1606–1609 (2006)." href="/articles/s41593-022-01082-w#ref-CR45" id="ref-link-section-d30208738e1199">45</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec7">Individual model contributions to negative affect in regions of interest</h3><p>To probe local contributions to each model, we examined model encoding in a set of a priori regions of interest (ROIs) previously linked to affective processes and sensory-specific regions (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01082-w#Sec13">Methods</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">7</a>). All ROIs contained voxels with significant structure coefficients in at least two models (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3c,d</a>). Each multimodal ROI encoded the common and at least one stimulus-type-specific model; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3c</a>). Sensory ROIs were largely stimulus-type specific, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3d</a>, with some exceptions. Mechanical and thermal pain were encoded in S1 and S2/dpINS cortices. S2/dpINS also encoded auditory negative affect, possibly reflecting their proximity to auditory cortices (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig4">4</a> and <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01082-w#Sec12">Discussion</a>). Auditory cortices (A1–A3) encoded auditory negative affect and thermal pain. Visual cortices (V1–V4) primarily encoded visual negative affect, but also auditory negative affect and pain. Each sensory cortex also contributed to encoding the common negative affect model.</p><p>For each region, we calculated the ratio of importance for common affect versus stimulus-type-specific negative affect, where importance was defined as the percentages of the ROI encoded by each of the common and predominant type-specific models. A negative correlation in the two importance scores (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3e</a>) indicated a trade-off between them. Early sensory ROIs were more type selective, with auditory regions (A1–A3) the most selective (that is, highest type-specific/common ratio; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig3">3d</a>). Visual cortices (V1–V4) were also type selective. Somatosensory cortices (S1 and S2) and dpINS were more mixed, showing overlap with mechanical and thermal pain, auditory and common models.</p><p>Among multimodal affect/motivation-related regions, vMPFC, ventrolateral prefrontal cortex (vLPFC) and dorsomedial prefrontal cortex (dMPFC) showed the highest relative importance for the common model. The MCC and vStr were preferentially important for the common and thermal models. The amygdala was preferentially important for the common and visual models. The aINS and vLPFC/OFC were more mixed, with a relatively low common/type-specific ratio. Voxels in these regions encoded mechanical and thermal pain, auditory and common negative affect models. Overall, anatomical regions encoded distinct combinations of common and type-specific affect. No region encoded negative affect in a purely domain-general fashion.</p><h3 class="c-article__sub-heading" id="Sec8">Organization of regions into sensory and cortico-brainstem pathways</h3><p>Selectivity in early sensory cortices (for example, V1 and A1; ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. Front. Psychol. 6, 1860 (2015)." href="/articles/s41593-022-01082-w#ref-CR18" id="ref-link-section-d30208738e1254">18</a></sup>) suggested that negative affect may be encoded along related ascending thalamocortical and brainstem sensory pathways as well. To test this, we examined model encoding within an expanded set of thalamic and brainstem regions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig4">4</a>). These included: (1) superior colliculus (SC), pulvinar, and lateral geniculate nucleus (LGN), which project to V1 and mediate visual perception; (2) inferior colliculus (IC) and medial geniculate nucleus (MGN), which form an auditory pathway projecting to A1; (3) somatosensory/pain-related thalamocortical pathways including ventroposterior lateral (VPL) and intralaminar (IL) thalamic nuclei; and (4) midbrain rostroventral medulla (RVM) and periaqueductal gray (PAG) and thalamic mediodorsal (MD) nucleus, which (along with IL) are thought to be related to multiple forms of negative affect.</p><p>Visual model encoding was indeed reflected in the SC and LGN, along with interconnected V1 and amygdala, indicating encoding of negative affect related to visual images in the classic LGN–V1 and pulvinar–V1 thalamocortical pathways as well as the SC–pulvinar–amygdala subcortical visual pathways<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Kragel, P. A. et al. A human colliculus-pulvinar-amygdala pathway encodes negative emotion. Neuron &#xA;                  https://doi.org/10.1016/j.neuron.2021.06.001&#xA;                  &#xA;                 (2021)." href="/articles/s41593-022-01082-w#ref-CR46" id="ref-link-section-d30208738e1264">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Pessoa, L. &amp; Adolphs, R. Emotion processing and the amygdala: from a ‘low road’ to ‘many roads’ of evaluating biological significance. Nat. Rev. Neurosci. 11, 773–783 (2010)." href="/articles/s41593-022-01082-w#ref-CR47" id="ref-link-section-d30208738e1267">47</a></sup>. Likewise, auditory negative affect was encoded in an RVM–PAG–IC–MGN–A1 pathway<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Kragel, P. A. et al. A human colliculus-pulvinar-amygdala pathway encodes negative emotion. Neuron &#xA;                  https://doi.org/10.1016/j.neuron.2021.06.001&#xA;                  &#xA;                 (2021)." href="/articles/s41593-022-01082-w#ref-CR46" id="ref-link-section-d30208738e1271">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Chen, C., Cheng, M., Ito, T. &amp; Song, S. Neuronal organization in the inferior colliculus revisited with cell-type-dependent monosynaptic tracing. J. Neurosci. 38, 3318–3332 (2018)." href="/articles/s41593-022-01082-w#ref-CR48" id="ref-link-section-d30208738e1274">48</a></sup>, with additional involvement of S2 and posterior insula (pINS) proximal to the auditory cortex. IC selectively encoded auditory negative affect, and SC selectively encoded visual negative affect.</p><p>Thermal and mechanical pain were encoded in differentiable pathways. Thermal pain was encoded in an RVM–PAG–midline thalamic (MD and IL) pathway connected to MCC and insula (aINS and mid-insula (mINS)) in the cortex and vStr in the forebrain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Tan, L. L. &amp; Kuner, R. Neocortical circuits in pain and pain relief. Nat. Rev. Neurosci. 22, 458–471 (2021)." href="/articles/s41593-022-01082-w#ref-CR49" id="ref-link-section-d30208738e1281">49</a></sup>. Mechanical pain was more strongly related to an S2–mINS pathway (in addition to mechanical pain-specific portions of S1 described above). pINS also showed a fine-grained distinction, with dorsal pINS contributing to pain and ventral pINS contributing to auditory negative affect<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Horing, B., Sprenger, C. &amp; Büchel, C. The parietal operculum preferentially encodes heat pain and not salience. PLoS Biol. 17, e3000205 (2019)." href="/articles/s41593-022-01082-w#ref-CR25" id="ref-link-section-d30208738e1285">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Mouraux, A., Diukova, A., Lee, M. C., Wise, R. G. &amp; Iannetti, G. D. A multisensory investigation of the functional significance of the ‘pain matrix’. Neuroimage 54, 2237–2249 (2011)." href="/articles/s41593-022-01082-w#ref-CR43" id="ref-link-section-d30208738e1288">43</a></sup>. We also observed a dorsoventral distinction in S1 and surrounding areas, with dorsal S1 selective for thermal pain and ventral S1 selective for mechanical pain (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig4">4</a>). These types of pain are often used interchangeably, although they behave differently in different animal strains<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Mogil, J. S. The genetic mediation of individual differences in sensitivity to pain and its inhibition. Proc. Natl Acad. Sci. USA 96, 7744–7751 (1999)." href="/articles/s41593-022-01082-w#ref-CR50" id="ref-link-section-d30208738e1295">50</a></sup> and clinical populations (for example, ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Baron, R. et al. Peripheral neuropathic pain: a mechanism-related organizing principle based on sensory profiles. Pain 158, 261–272 (2017)." href="/articles/s41593-022-01082-w#ref-CR51" id="ref-link-section-d30208738e1299">51</a></sup>).</p><p>Interestingly, common negative affect was encoded in traditionally pain-related neural pathways, from brainstem (RVM–PAG) via thalamic (MD, IL and VPL) nuclei to somatosensory cortices and multimodal cortical and forebrain structures (for example, mINS, aINS and posterior midcingulate cortex (pMCC); Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig4">4</a>). Some regions (MD, IL and PAG) play roles in multiple types of affective behavior<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Price, D. D. Psychological and neural mechanisms of the affective dimension of pain. Science 288, 1769–1772 (2000)." href="/articles/s41593-022-01082-w#ref-CR52" id="ref-link-section-d30208738e1309">52</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Satpute, A. B. et al. Identification of discrete functional subregions of the human periaqueductal gray. Proc. Natl Acad. Sci. USA 110, 17101–17106 (2013)." href="/articles/s41593-022-01082-w#ref-CR53" id="ref-link-section-d30208738e1312">53</a></sup>, whereas others are thought to be more specific to somatic processing (S2, VPL and RVM)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Tan, L. L. &amp; Kuner, R. Neocortical circuits in pain and pain relief. Nat. Rev. Neurosci. 22, 458–471 (2021)." href="/articles/s41593-022-01082-w#ref-CR49" id="ref-link-section-d30208738e1316">49</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Craig, A. D., Bushnell, M. C., Zhang, E. T. &amp; Blomqvist, A. A thalamic nucleus specific for pain and temperature sensation. Nature 372, 770–773 (1994)." href="/articles/s41593-022-01082-w#ref-CR54" id="ref-link-section-d30208738e1319">54</a></sup> but may reflect affect-related brain–body communication.</p><p>Unexpectedly, thermal pain was weakly encoded in RVM and PAG, which are traditionally pain related<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Tan, L. L. &amp; Kuner, R. Neocortical circuits in pain and pain relief. Nat. Rev. Neurosci. 22, 458–471 (2021)." href="/articles/s41593-022-01082-w#ref-CR49" id="ref-link-section-d30208738e1327">49</a></sup>, and strong encoding of visual negative affect in the auditory MGN. This could be due to current limitations of fMRI at this resolution (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01082-w#Sec12">Discussion</a>), or to complex roles of RVM and PAG in pain representation and modulation.</p><h3 class="c-article__sub-heading" id="Sec9">Prediction of negative affect ratings in new samples</h3><p>We tested the replicability, robustness and generalizability of the models developed in study 1 by testing their sensitivity and specificity in predicting negative affect ratings in 401 new participants from different cohorts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Kragel, P. A. et al. Generalizable representations of pain, cognitive control, and negative emotion in medial frontal cortex. Nat. Neurosci. 21, 283–289 (2018)." href="/articles/s41593-022-01082-w#ref-CR15" id="ref-link-section-d30208738e1342">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Woo, C.-W. et al. Quantifying cerebral contributions to pain beyond nociception. Nat. Commun. 8, 14211 (2017)." href="/articles/s41593-022-01082-w#ref-CR55" id="ref-link-section-d30208738e1345">55</a></sup> (studies 2–6; see Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig6">6</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">8</a> for experimental designs and stimulus types). Each model was applied only once to the dataset, without refitting or otherwise altering the model (that is, no model degrees of freedom). Participants made avoidance ratings in study 2, as in study 1, and unpleasantness ratings in studies 3 and 4. Studies 5 and 6 tested sensitivity and specificity to negative versus positive images and pain versus non-painful warmth, respectively.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Prediction of negative affect in new datasets."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5: Prediction of negative affect in new datasets.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="558"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>For each study in <b>a</b>–<b>c</b>, plots 1–5 show the relationship between observed (self-report) and predicted (brain model response) negative affect and insets show subjective ratings per stimulus level. Model response was calculated as the dot product of the PLS pattern weights and fMRI activation maps. Model responses shown in each plot are indicated on top of the plot; those expected to show a significant response given the stimulus type and the associated ‘true-positive’ <i>r</i> values are bolded and color coded; <i>r</i> values of all other above-zero predictions are displayed in black. Broken plot axes are used to enable visualization on the same scale in the same plot. Model response values are derived from full-sample weight maps so that the model weights and test data are in each case independent. <i>r</i>, mean within-participant Pearson correlation between predicted and observed ratings; two-sided <i>P</i> values are based on a bootstrap test using 10,000 samples of within-participant <i>r</i> values. Negative affect ratings: avoidance rating scale (general Labeled Magnitude Scale (gLMS); study 2), unpleasantness rating scale (gLMS; study 3), IAPS normative ratings (study 4). Insets, data are shown as mean rating values across participants for each stimulus type, and error bars reflect within-participant s.e.m.; main plots, data are shown as mean model response values across participants for each stimulus type, and error bars reflect within-participant s.e.m. (horizontal error bars for <i>x</i> values, where applicable; vertical error bars for <i>y</i> values). NS, not significant.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Valence specificity and additional validation tests."><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6: Valence specificity and additional validation tests.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="621"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p><b>a</b>, Aversive visual models (common, specific) did not significantly track normative ratings to pleasant images (from the IAPS) in the same participants (study 1b; cross-validated pattern responses). <i>r</i>, mean within-participant Pearson correlation between predicted and observed ratings; *<i>P</i> &lt; 0.05, **<i>P</i> &lt; 0.01, ***<i>P</i> &lt; 0.001; <i>P</i> values are based on a 10,000-sample bootstrap test of within-participant <i>r</i> values. <b>b</b>, Validation tests of patterns in two additional independent datasets. In study 5, aversive visual models (common, specific) responded to (a) negative visual stimuli (model sensitivity) but not to (b) positive visual stimuli (valence specificity). In study 6, thermal pain models (common, specific) responded to (a) painful heat (model sensitivity) but not to (b) non-painful warm stimuli (valence specificity). Other stimulus-specific model responses were plotted for completeness, and as expected, did not respond to off-target aversive stimuli nor to positive images or warm stimuli. <i>d</i>, Cohen’s <i>d</i> effect size; *<i>P</i> &lt; 0.05, **<i>P</i> &lt; 0.01, ***<i>P</i> &lt; 0.001; one-sample <i>t</i>-test treating the subject as a random effect; bars reflect mean values across participants, and error bars reflect within-participant s.e.m. <b>c</b>, Performance of PLS-R patterns developed in study 1 is summarized across all tested datasets (studies 1b–6b); true-positive responses (significant positive pattern response for on-target stimuli) and true-negative responses (nonsignificant or negative pattern response for off-target stimuli) are displayed in green; false-positive responses (significant pattern response for off-target stimuli) are displayed in yellow; false-negative responses (nonsignificant or negative pattern response for on-target stimuli) are displayed in blue.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01082-w/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Negative affect models developed in study 1 generalized across new samples: they significantly predicted negative affect ratings in most cases, and stimulus-type-specific models were largely sensitive and specific to their target stimulus types (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig6">6</a>).</p><p>The common model predicted ratings for all stimulus types: (a) mechanical pain ratings in study 2 (<i>r</i> = 0.34 ± 0.12, <i>P</i> = 0.006, classification accuracy for the highest versus lowest stimulus levels = 72%, <i>P</i> = 0.02, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5a</a>); (b) thermal pain ratings in study 3 (<i>r</i> = 0.55 ± 0.10, <i>P</i> = 0.001, accuracy = 91%, <i>P</i> &lt; 0.001, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5b</a>); (c) aversive sound ratings in study 2 (<i>r</i> = 0.33 ± 0.09, <i>P</i> &lt; 0.001, accuracy = 78%, <i>P</i> = 0.002, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5a</a>); and (d) aversive image ratings in study 4 (<i>r</i> = 0.32 ± 0.04, <i>P</i> &lt; 0.001, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5c</a>). The common model did not significantly predict aversive ‘knife on bottle’ sound ratings in study 3, however (<i>r</i> = 0.13 ± 0.13, <i>P</i> = 0.39, accuracy = 59%, <i>P</i> = 0.38, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5b</a>; see also below).</p><p>Stimulus-type-specific models were sensitive and largely specific to ratings of target stimuli for mechanical pain in study 2 (<i>r</i> = 0.66 ± 0.07, <i>P</i> &lt; 0.001, accuracy = 91%, <i>P</i> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5a</a>), for thermal pain in study 3 (<i>r</i> = 0.46 ± 0.11, <i>P</i> = 0.001, accuracy = 91%, <i>P</i> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5b</a>) and for aversive images in study 4 (<i>r</i> = 0.42 ± 0.03, <i>P</i> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig6">6c</a>). However, the mechanical pain-specific model was also sensitive to ratings of off-target stimuli in study 3 (<i>r</i> = 0.40, <i>P</i> = 0.004 for thermal pain and <i>r</i> = 0.33, <i>P</i> = 0.006 for aversive sound) and study 4 (<i>r</i> = 0.12, <i>P</i> = 0.008 for aversive images; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">9</a>).</p><p>Study 2 included the inherently aversive ‘knife on bottle’ sound stimuli used in study 1, whereas study 3 included this sound and also emotionally charged ‘auditory vignettes’ from the International Affective Digitized Sounds whose aversiveness was driven mainly by contextual information (people crying, gunshots). The aversive auditory model significantly predicted ratings to ‘knife on bottle’ sounds in both study 2 (<i>r</i> = 0.44 ± 0.10, <i>P</i> = 0.003, accuracy 88%, <i>P</i> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5a</a>) and study 3 (<i>r</i> = 0.42 ± 0.11, <i>P</i> = 0.001, accuracy 75%, <i>P</i> = 0.007, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5b</a>). However, it did not predict ratings to context-driven emotional sounds in study 3 (<i>r</i> = −0.01, <i>P</i> = 0.92) nor did the common model (<i>r</i> = −0.07, <i>P</i> = 0.192; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig5">5b</a>). Thus, the auditory negative affect model captured negative affect driven by intrinsic sound qualities rather than contextually driven emotional content.</p><h3 class="c-article__sub-heading" id="Sec10">Valence specificity and additional validation analyses</h3><p>Our affect models may reflect factors that are not specific to negative valence, such as attention and salience<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Anderson, A. K. &amp; Sobel, N. Dissociating intensity from valence as sensory inputs to emotion. Neuron 39, 581–583 (2003)." href="/articles/s41593-022-01082-w#ref-CR56" id="ref-link-section-d30208738e1660">56</a></sup>. The use of multiple aversive controls for each stimulus type, as reported above (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig2">2b,c</a>), provides evidence that type-specific models are selective to a particular type of negative affect. This rules out a general attention, arousal or salience explanation for the type-specific models, but does not address this issue for the common model.</p><p>We tested specificity to negative affect in another way, by testing whether the models predicted normative pleasantness ratings of positive stimuli. In study 1, neither the common nor visual type-specific models predicted normative pleasantness (mean within-participant <i>r</i> = −0.10, <i>P</i> = 0.30 for the common model and <i>r</i> = −0.12, <i>P</i> = 0.31 for the visual model; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig6">6a</a>). Positive and negative stimuli from the International Affective Picture System (IAPS) were largely matched on normative arousal, excluding the possibility that negative images were simply more arousing. Additional cross-validated PLS-R models trained to predict normative ratings for negative and positive IAPS images (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">Supplementary Methods</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig7">1a</a>) ruled out the possibility that pleasantness ratings might simply be poorly predicted by brain activity. These analyses revealed a double dissociation in brain representations for negative and positive affect (see pattern responses in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig7">1b</a>, and PLS-R weight and model encoding maps in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig7">1c</a>). The negative-specific model predicted normative aversiveness ratings (<i>r</i> = 0.49, <i>P</i> = 0.001), but not normative pleasantness ratings (negative predicted slope, <i>r</i> = −0.41), and the positive-specific model predicted pleasantness ratings (<i>r</i> = 0.75, <i>P</i> = 0.002), but not aversiveness ratings (negative predicted slope, <i>r</i> = −0.11). An additional ‘arousal’ model trained to predict both positive and negative ratings combined predicted rating intensity for both types (<i>r</i> = 0.58, <i>P</i> = 0.001 for negative images and <i>r</i> = 0.69, <i>P</i> = 0.001 for positive images). This analysis shows that normative pleasantness is encoded in brain patterns distinct from our negative affect models.</p><p>We further tested the negative affect models’ specificity for negative valence in two additional independent datasets. In study 5 (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig6">6b</a>), aversive visual models (common, specific) showed a significant pattern response to aversive IAPS images (Cohen’s <i>d</i> = 0.86, <i>P</i> &lt; 0.001 for the common model and <i>d</i> = 1.51, <i>P</i> &lt; 0.001 for the aversive visual-specific model), showing model sensitivity. Neither the common nor visual-specific model responded to positive IAPS images (<i>d</i> = 0.07, <i>P</i> = 0.52 and <i>d</i> = 0.06, <i>P</i> = 0.56, respectively), showing valence specificity. Similarly, in study 6, thermal pain models (common, thermal-specific) responded significantly to painful heat (<i>d</i> = 1.03, <i>P</i> &lt; 0.001 and <i>d</i> = 1.06, <i>P</i> &lt; 0.001, respectively), showing model sensitivity. Neither model responded to non-painful warm stimuli (<i>d</i> = −0.19, <i>P</i> = 0.15 and d = 0.11, <i>P</i> = 0.38, respectively), showing valence specificity. Other stimulus-type-specific models did not respond to positive images or warm stimuli, as expected. Thus, the brain models in study 1 were specific to negatively valenced stimuli in these test datasets and not sensitive to positive pictures. However, other types of appetitive stimuli may activate similar regions and patterns to our models (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig7">1</a>), and more comprehensive tests of specificity across appetitive tasks are needed (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01082-w#Sec12">Discussion</a>).</p><h3 class="c-article__sub-heading" id="Sec11">Summary of predictive performance in independent samples</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig6">6c</a> summarizes the models’ performance across studies 1b–6. Across 55 model generalization tests (5 models × 11 tests), the models’ decisions were correct (that is, true positives on-target and true negatives off-target) in 49 cases. Fifty of these tests were performed on independent study cohorts (studies 2–6). We found two false-negative cases (failures of sensitivity) and three false-positive cases (failures of specificity), as reported above. Together, the models developed in study 1 were sensitive to negative affect and specific to negative versus positive affect, providing preliminary evidence for generalizability that should be tested on a wider array of aversive and appetitive tasks in future studies. Such tests should carefully consider whether conditions tested are positive or negative (for example, affective responses to sexual images are complex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Wehrum, S. et al. Gender commonalities and differences in the neural processing of visual sexual stimuli. J. Sex. Med. 10, 1328–1342 (2013)." href="/articles/s41593-022-01082-w#ref-CR57" id="ref-link-section-d30208738e1801">57</a></sup>).</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec12-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec12">Discussion</h2><div class="c-article-section__content" id="Sec12-content"><p>Understanding how human affect is encoded in the brain is a central neuroscientific question. Psychological theories<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Russell, J. A. A circumplex model of affect. J. Pers. Soc. Psychol. 39, 1161–1178 (1980)." href="#ref-CR3" id="ref-link-section-d30208738e1814">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Russell, J. A. &amp; Barrett, L. F. Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant. J. Pers. Soc. Psychol. 76, 805–819 (1999)." href="#ref-CR4" id="ref-link-section-d30208738e1814_1">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Gray, J. A. The Psychology of Fear and Stress. (CUP Archive, 1987)." href="/articles/s41593-022-01082-w#ref-CR5" id="ref-link-section-d30208738e1817">5</a></sup> and frameworks like the NIH Research Domain Criteria<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Insel, T. et al. Research domain criteria (RDoC): toward a new classification framework for research on mental disorders. Am. J. Psychiatry 167, 748–751 (2010)." href="/articles/s41593-022-01082-w#ref-CR11" id="ref-link-section-d30208738e1821">11</a></sup> have focused on generalized negative valence as a cross-modal construct, and the existence of generalized ‘negative affect’ in the brain is widely assumed. On the other hand, different affective stimuli activate differentiable neural populations and pathways in animal studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Corder, G. et al. An amygdalar neural ensemble that encodes the unpleasantness of pain. Science 363, 276–281 (2019)." href="/articles/s41593-022-01082-w#ref-CR28" id="ref-link-section-d30208738e1825">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Chiang, M. C. et al. Divergent neural pathways emanating from the lateral parabrachial nucleus mediate distinct components of the pain response. Neuron 106, 927–939 (2020)." href="/articles/s41593-022-01082-w#ref-CR30" id="ref-link-section-d30208738e1828">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Pool, A.-H. et al. The cellular basis of distinct thirst modalities. Nature 588, 112–117 (2020)." href="/articles/s41593-022-01082-w#ref-CR33" id="ref-link-section-d30208738e1831">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Neugebauer, V. Amygdala pain mechanisms. Handb. Exp. Pharmacol. 227, 261–284 (2015)." href="/articles/s41593-022-01082-w#ref-CR58" id="ref-link-section-d30208738e1834">58</a></sup> and many clinical effects are found only with specific aversive stimulus types (for example, ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Baron, R. et al. Peripheral neuropathic pain: a mechanism-related organizing principle based on sensory profiles. Pain 158, 261–272 (2017)." href="/articles/s41593-022-01082-w#ref-CR51" id="ref-link-section-d30208738e1838">51</a></sup>). Studies have thus provided evidence for both common and stimulus-type-specific negative affect. However, by focusing on these accounts separately—and typically with only one or two stimulus types tested in the same individuals—inferences about the nature of affect coding in the human brain have been limited.</p><p>Here we combined a multimodal experimental paradigm with a predictive modeling approach designed to uncover whether brain representations of negative affect are generalizable across types, specific to stimulus types, or a combination of both. In study 1, we jointly estimated common (general) and stimulus-type-specific representations of negative affect (subjective ratings) across four types of aversive stimuli. The findings indicate that negative affect is encoded in a combination of general (common) and stimulus-type-specific representations. Studies 2–6 provided further evidence that these representations are generalizable across individuals and cohorts and can be applied separately or jointly to predict negative affect in new studies. Applications to new studies include (a) characterizing neural differences related to disorders and subgroups, (b) predicting or monitoring the progression of mental health disorders over time, and (c) providing targets for behavioral, pharmacological and neural interventions. Further validation will help refine the use cases and boundary conditions for such applications.</p><p>Model encoding maps revealed several principles underlying the architecture of negative affect. First, some voxels encoded a general aversion signal across stimulus types, and this common negative affect representation was distributed across cortical, forebrain and brainstem regions. Extending recent work on cross-modal affect<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chikazoe, J., Lee, D. H., Kriegeskorte, N. &amp; Anderson, A. K. Population coding of affect across stimuli, modalities and individuals. Nat. Neurosci. 17, 1114–1122 (2014)." href="/articles/s41593-022-01082-w#ref-CR16" id="ref-link-section-d30208738e1848">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Kim, J., Shinkareva, S. V. &amp; Wedell, D. H. Representations of modality-general valence for videos and music derived from fMRI data. Neuroimage 148, 42–54 (2017)." href="/articles/s41593-022-01082-w#ref-CR59" id="ref-link-section-d30208738e1851">59</a></sup>, the common model was related to a set of ‘core’ affect areas, including midline aMCC, thalamus, brainstem, cerebellum, amygdala and lateral OFC. Second, affect was represented in a stimulus-type-specific manner in sensory thalamocortical and corticobulbar pathways. Third, the models predicted the intensity of negative affect and did not respond to positive stimuli, at least among tasks studied here. The models therefore probably do not code for arousal, salience, or other unsigned processes related to affective intensity (for example, associability)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Anderson, A. K. &amp; Sobel, N. Dissociating intensity from valence as sensory inputs to emotion. Neuron 39, 581–583 (2003)." href="/articles/s41593-022-01082-w#ref-CR56" id="ref-link-section-d30208738e1855">56</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Li, J., Schiller, D., Schoenbaum, G., Phelps, E. A. &amp; Daw, N. D. Differential roles of human striatum and amygdala in associative learning. Nat. Neurosci. 14, 1250–1252 (2011)." href="/articles/s41593-022-01082-w#ref-CR60" id="ref-link-section-d30208738e1858">60</a></sup>. Their response patterns, and the double dissociation observed between negative and positive affective images, are also inconsistent with bipolar (single-dimension) encoding but consistent with the idea that negative and positive affect are encoded in separable systems<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Berridge, K. C. &amp; Kringelbach, M. L. Neuroscience of affect: brain mechanisms of pleasure and displeasure. Curr. Opin. Neurobiol. 23, 294–303 (2013)." href="/articles/s41593-022-01082-w#ref-CR1" id="ref-link-section-d30208738e1862">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. Front. Psychol. 6, 1860 (2015)." href="/articles/s41593-022-01082-w#ref-CR18" id="ref-link-section-d30208738e1865">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Lindquist, K. A., Satpute, A. B., Wager, T. D., Weber, J. &amp; Barrett, L. F. The brain basis of positive and negative affect: evidence from a meta-analysis of the human neuroimaging literature. Cereb. Cortex 26, 1910–1922 (2016)." href="/articles/s41593-022-01082-w#ref-CR41" id="ref-link-section-d30208738e1868">41</a></sup>. Fourth, several key affect-related regions (for example, the amygdala) contained overlapping populations of voxels that contributed to multiple types of negative affect. This provides a substrate for common and type-specific valence systems to interact within the same anatomical regions.</p><p>A commonly held perspective is that negative affect is encoded chiefly in multimodal forebrain regions such as OFC/vMPFC and amygdala<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chikazoe, J., Lee, D. H., Kriegeskorte, N. &amp; Anderson, A. K. Population coding of affect across stimuli, modalities and individuals. Nat. Neurosci. 17, 1114–1122 (2014)." href="/articles/s41593-022-01082-w#ref-CR16" id="ref-link-section-d30208738e1875">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Kim, J., Shinkareva, S. V. &amp; Wedell, D. H. Representations of modality-general valence for videos and music derived from fMRI data. Neuroimage 148, 42–54 (2017)." href="/articles/s41593-022-01082-w#ref-CR59" id="ref-link-section-d30208738e1878">59</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Belova, M. A., Paton, J. J. &amp; Salzman, C. D. Moment-to-moment tracking of state value in the amygdala. J. Neurosci. 28, 10023–10030 (2008)." href="/articles/s41593-022-01082-w#ref-CR61" id="ref-link-section-d30208738e1881">61</a></sup>. However, we found that negative affect ratings were also linearly encoded by activity in early sensory cortices, with pINS and somatosensory cortex predicting pain, auditory cortex predicting auditory negative affect and visual cortex predicting visual negative affect. These findings align with previous findings that affective associations with visual stimuli are embedded in the visual cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Kragel, P. A., Reddan, M. C., LaBar, K. S. &amp; Wager, T. D. Emotion schemas are embedded in the human visual system. Sci. Adv. 5, eaaw4358 (2019)." href="/articles/s41593-022-01082-w#ref-CR27" id="ref-link-section-d30208738e1885">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Shuler, M. G. &amp; Bear, M. F. Reward timing in the primary visual cortex. Science 311, 1606–1609 (2006)." href="/articles/s41593-022-01082-w#ref-CR45" id="ref-link-section-d30208738e1888">45</a></sup>, and, more broadly, that category-specific affective information is embedded in early sensory areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. Front. Psychol. 6, 1860 (2015)." href="/articles/s41593-022-01082-w#ref-CR18" id="ref-link-section-d30208738e1892">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Mouraux, A., Diukova, A., Lee, M. C., Wise, R. G. &amp; Iannetti, G. D. A multisensory investigation of the functional significance of the ‘pain matrix’. Neuroimage 54, 2237–2249 (2011)." href="/articles/s41593-022-01082-w#ref-CR43" id="ref-link-section-d30208738e1895">43</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Liang, M., Mouraux, A., Hu, L. &amp; Iannetti, G. D. Primary sensory cortices contain distinguishable spatial patterns of activity for each sense. Nat. Commun. 4, 1979 (2013)." href="/articles/s41593-022-01082-w#ref-CR44" id="ref-link-section-d30208738e1898">44</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Hayes, D. J. &amp; Northoff, G. Common brain activations for painful and non-painful aversive stimuli. BMC Neurosci. 13, 60 (2012)." href="/articles/s41593-022-01082-w#ref-CR62" id="ref-link-section-d30208738e1901">62</a></sup>. Our results, however, extend beyond classification of stimulus types to suggest that subjective ratings of stimuli are also encoded in sensory cortices.</p><p>The co-localization of different types of affective representations also provides a basis for multimodal integration and interactions (for example, between pain and emotion<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Villemure, C. &amp; Bushnell, M. C. Mood influences supraspinal pain processing separately from attention. J. Neurosci. 29, 705–715 (2009)." href="/articles/s41593-022-01082-w#ref-CR63" id="ref-link-section-d30208738e1909">63</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Roy, M., Piché, M., Chen, J.-I., Peretz, I. &amp; Rainville, P. Cerebral and spinal modulation of pain by emotions. Proc. Natl Acad. Sci. USA 106, 20900–20905 (2009)." href="/articles/s41593-022-01082-w#ref-CR64" id="ref-link-section-d30208738e1912">64</a></sup>). Although sensory pathways were largely modality specific, some (for example, S1, S2, pINS, SC, IC and LGN) also encoded general negative affect, suggesting integrative processing in these areas. In other areas, including the amygdala and all multimodal cortical regions tested, distinct stimulus-specific representations were encoded in close anatomical proximity to each other.</p><p>The pattern-based approach we used, which shows promise for disentangling general and stimulus-type-specific signals, may help address discrepant findings in previous studies. For example, some studies have reported that the amygdala encodes nonspecific arousal or salience-related signals (or ‘unsigned valence’; for example, refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Anderson, A. K. &amp; Sobel, N. Dissociating intensity from valence as sensory inputs to emotion. Neuron 39, 581–583 (2003)." href="/articles/s41593-022-01082-w#ref-CR56" id="ref-link-section-d30208738e1919">56</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Li, J., Schiller, D., Schoenbaum, G., Phelps, E. A. &amp; Daw, N. D. Differential roles of human striatum and amygdala in associative learning. Nat. Neurosci. 14, 1250–1252 (2011)." href="/articles/s41593-022-01082-w#ref-CR60" id="ref-link-section-d30208738e1922">60</a></sup>), but others have shown valence-specific effects in the amygdala matching for arousal<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Anders, S., Eippert, F., Weiskopf, N. &amp; Veit, R. The human amygdala is sensitive to the valence of pictures and sounds irrespective of arousal: an fMRI study. Soc. Cogn. Affect. Neurosci. 3, 233–243 (2008)." href="/articles/s41593-022-01082-w#ref-CR65" id="ref-link-section-d30208738e1926">65</a></sup>. Here, the amygdala contributed to both general and vision-specific (but not auditory or somatosensory) negative affect, but an overlapping population of voxels encoded an ‘arousal’ signal (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig7">1d,e</a>). Overlapping patterns of fMRI brain response (with different population vectors) could, in principle, separately predict negative affect, positive affect<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chikazoe, J., Lee, D. H., Kriegeskorte, N. &amp; Anderson, A. K. Population coding of affect across stimuli, modalities and individuals. Nat. Neurosci. 17, 1114–1122 (2014)." href="/articles/s41593-022-01082-w#ref-CR16" id="ref-link-section-d30208738e1933">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Woo, C.-W. et al. Separate neural representations for physical pain and social rejection. Nat. Commun. 5, 5380 (2014)." href="/articles/s41593-022-01082-w#ref-CR66" id="ref-link-section-d30208738e1936">66</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="Peelen, M. V. &amp; Downing, P. E. Using multi-voxel pattern analysis of fMRI data to interpret overlapping functional activations. Trends Cogn. Sci. 11, 4–5 (2007)." href="/articles/s41593-022-01082-w#ref-CR67" id="ref-link-section-d30208738e1939">67</a></sup>, and general ‘arousal’. Positive affect might be processed in some of the regions we identified, including vStr, albeit in separable neural populations (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig7">1d,e</a>). This approach can be extended to other tasks as well. For example, vStr might encode more rewarding (appetitive) positive stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Berridge, K. C. &amp; Kringelbach, M. L. Neuroscience of affect: brain mechanisms of pleasure and displeasure. Curr. Opin. Neurobiol. 23, 294–303 (2013)." href="/articles/s41593-022-01082-w#ref-CR1" id="ref-link-section-d30208738e1947">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Tomova, L. et al. Acute social isolation evokes midbrain craving responses similar to hunger. Nat. Neurosci. 23, 1597–1605 (2020)." href="/articles/s41593-022-01082-w#ref-CR68" id="ref-link-section-d30208738e1950">68</a></sup> not investigated in the present work.</p><p>Brain measures that track distinct types of affect may be important for identifying disorder-relevant affective brain responses. For example, we found a double dissociation in mechanical and thermal pain encoding in S1 and pINS/S2, respectively. Responses to thermal, mechanical and chemical pain are relatively uncorrelated (for example, ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Baron, R. et al. Peripheral neuropathic pain: a mechanism-related organizing principle based on sensory profiles. Pain 158, 261–272 (2017)." href="/articles/s41593-022-01082-w#ref-CR51" id="ref-link-section-d30208738e1957">51</a></sup>) and clinical hypersensitivity is often stimulus-type specific<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 69" title="Woolf, C. J. Central sensitization: implications for the diagnosis and treatment of pain. Pain 152, S2–S15 (2011)." href="/articles/s41593-022-01082-w#ref-CR69" id="ref-link-section-d30208738e1961">69</a></sup>. Some disorders are characterized by increased sensitivity to mechanical pain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 70" title="Ceko, M., Bushnell, M. C., Fitzcharles, M.-A. &amp; Schweinhardt, P. Fibromyalgia interacts with age to change the brain. Neuroimage Clin. 3, 249–260 (2013)." href="/articles/s41593-022-01082-w#ref-CR70" id="ref-link-section-d30208738e1965">70</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 71" title="López-Solà, M. et al. Towards a neurophysiological signature for fibromyalgia. Pain 158, 34–47 (2017)." href="/articles/s41593-022-01082-w#ref-CR71" id="ref-link-section-d30208738e1968">71</a></sup> and others to thermal pain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Grothusen, J. R., Alexander, G., Erwin, K. &amp; Schwartzman, R. Thermal pain in complex regional pain syndrome type I. Pain Physician 17, 71–79 (2014)." href="/articles/s41593-022-01082-w#ref-CR72" id="ref-link-section-d30208738e1972">72</a></sup>. We also identified dissociable pINS/S2 regions encoding pain versus auditory affect, and a double dissociation between auditory and visual affect in the IC and SC, respectively. Our approach thus identifies dissociations that have been difficult to separate using standard fMRI methods.</p><p>Finally, our findings provide evidence that accounting for multiple common and stimulus-type-specific representations is important for developing accurate predictive models. Accurate predictions of subjective affective experience required jointly considering common and type-specific measures in all cases we tested. This principle is consistent with a growing literature showing that even basic affective judgments are complex processes that involve coordination of multiple brain systems. Future studies must consider a range of contextual factors and individual differences, which likely influence the nature of affect representations and how they combine to create subjective experience. Nevertheless, present findings demonstrate a substantial degree of consistency across individuals and studies, and establish a baseline for future context-dependent and subgroup-dependent models.</p><p>This paper has several limitations. First, we only included one type of positive stimuli (visual images) and thus, our valence specificity tests are largely limited to visual stimuli, although we provide preliminary evidence for valence specificity for thermal stimuli. Second, not all models performed equally well when tested in new samples; the mechanical pain-specific model in particular might not generalize as well as other models. Third, conventional 3T fMRI cannot be precisely localized to midbrain and brainstem nuclei. However, we and others have found reasonable localization in these areas at 3T, for example, PAG, RVM, SC, IC and other nuclei<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Satpute, A. B. et al. Identification of discrete functional subregions of the human periaqueductal gray. Proc. Natl Acad. Sci. USA 110, 17101–17106 (2013)." href="/articles/s41593-022-01082-w#ref-CR53" id="ref-link-section-d30208738e1982">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Eippert, F. et al. Activation of the opioidergic descending pain control system underlies placebo analgesia. Neuron 63, 533–543 (2009)." href="/articles/s41593-022-01082-w#ref-CR73" id="ref-link-section-d30208738e1985">73</a></sup>, in some cases validated with high resolution (~1 mm) 7T fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Kragel, P. A. et al. A human colliculus-pulvinar-amygdala pathway encodes negative emotion. Neuron &#xA;                  https://doi.org/10.1016/j.neuron.2021.06.001&#xA;                  &#xA;                 (2021)." href="/articles/s41593-022-01082-w#ref-CR46" id="ref-link-section-d30208738e1989">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Satpute, A. B. et al. Identification of discrete functional subregions of the human periaqueductal gray. Proc. Natl Acad. Sci. USA 110, 17101–17106 (2013)." href="/articles/s41593-022-01082-w#ref-CR53" id="ref-link-section-d30208738e1992">53</a></sup>.</p><p>In conclusion, we show that negative affect is encoded in the brain in multiple distributed representations, some generalizable across affective stimulus types and others specific to negative affect elicited by a particular stimulus type. Negative affect is embedded in sensory pathways, and integrative regions represent distinct combinations of negative affect types. The resulting models provide a set of measures that can serve to understand disorders, track the progression of disorders and treatments over time, and serve as targets for interventions. They also lead to further basic and translational research questions. One area for future development concerns how common and distinct representations are integrated, how ‘cross-talk’ across sensory modalities occurs and how ‘cross-talk’ may be enhanced in disorders, helping to explain, for example, pain hypersensitivity after emotional trauma. Another area concerns hierarchical coding, including whether common and type-specific affective codes are parallel or hierarchical, and how context-based predictive signals are integrated info affect representations.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec13">Methods</h2><div class="c-article-section__content" id="Sec13-content"><p>Data from six studies were used in this paper. Study 1 was the primary study used for brain model development and all main analyses. Studies 2, 3 and 4, 5a and 6a contained different aversive stimuli in novel participants and were used for prospective validation of brain models developed in study 1. Study 1b contained pleasant visual stimuli tested in the same participants as study 1 and was used to test whether the aversive brain models are sensitive to other attentionally demanding, salient stimuli (that is, positive images). Studies 5b and 6b contained positive pictures and non-painful warm stimuli and were used for additional valence specificity tests. Experimental parameters for each study are listed in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">8</a>.</p><h3 class="c-article__sub-heading" id="Sec14">Participants</h3><p>Study 1 included 55 adult participants (mean ± s.d. age: 24.9 ± 6.8 years; 31 males, 24 females; 9 left-handed; 47 white and 8 non-white (1 Hispanic, 5 Asian, 1 Black and 1 American Indian)). All participants were healthy, with normal or corrected to normal vision and normal hearing, and with no history of psychiatric, physiological or pain disorders and neurological conditions, no current pain symptoms, and no MRI contraindications. Eligibility was assessed with a general health questionnaire, a pain safety screening form and an MRI safety screening form. Participants were recruited from the Boulder/Denver Metro Area. The institutional review board of the University of Colorado Boulder approved the study, and all participants provided written consent. Participants were compensated at a rate of $12 per hour for behavioral sessions (that is, tasks outside the fMRI scanner) and $24 per hour for fMRI sessions. Data collection and analysis were not performed blind to the conditions of the experiments. No statistical methods were used to predetermine sample sizes, but our sample sizes are similar to those reported in previous publications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kragel, P. A. &amp; LaBar, K. S. Multivariate neural biomarkers of emotional states are categorically distinct. Soc. Cogn. Affect. Neurosci. 10, 1437–1448 (2015)." href="#ref-CR23" id="ref-link-section-d30208738e2017">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Stephens, C. L., Christie, I. C. &amp; Friedman, B. H. Autonomic specificity of basic emotions: evidence from pattern classification and cluster analysis. Biol. Psychol. 84, 463–473 (2010)." href="#ref-CR24" id="ref-link-section-d30208738e2017_1">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Horing, B., Sprenger, C. &amp; Büchel, C. The parietal operculum preferentially encodes heat pain and not salience. PLoS Biol. 17, e3000205 (2019)." href="/articles/s41593-022-01082-w#ref-CR25" id="ref-link-section-d30208738e2020">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Wager, T. D. et al. An fMRI-based neurologic signature of physical pain. N. Engl. J. Med. 368, 1388–1397 (2013)." href="/articles/s41593-022-01082-w#ref-CR74" id="ref-link-section-d30208738e2023">74</a></sup>. No participants were excluded from the analysis.</p><h3 class="c-article__sub-heading" id="Sec15">Study design</h3><p>The study 1 dataset included in the current paper is part of a larger study, in which participants completed two fMRI sessions in a counterbalanced order. In each session, we administered the ‘multimodal aversiveness task’. In the ‘experience’ session, presented here, participants were instructed to ‘experience aversive stimuli as they come’. In the ‘regulate’ session (not presented here), participants were instructed to downregulate aversive stimuli using a cognitive self-regulation strategy. Physiological recordings were collected throughout each session (not presented here).</p><h3 class="c-article__sub-heading" id="Sec16">fMRI task design</h3><p>The ‘multimodal aversive experience task’ was developed for this study to test brain responses to multiple instances of negative affect in the same individuals (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01082-w#Fig1">1a</a>). The task comprised a series of aversive stimuli of different types (painful pressure, painful heat, aversive sounds, aversive images) and a pleasant (positive) stimulus type (pleasant images). In total, participants received 96 aversive stimuli (4 stimulus types × 4 intensities × 6 runs presented in random order) and 24 pleasant stimuli (4 intensities × 6 runs) over six fMRI runs and rated their experience after each stimulus (including the positive stimuli) using a uniform rating scale, detailed below.</p><h3 class="c-article__sub-heading" id="Sec17">Negative affect rating</h3><p>We obtained rating scores of negative affect on the same scale across different stimulus types. Participants rated negative affect (‘aversiveness’) in terms of avoidance (‘how much do you want to avoid this experience in the future?’) on a gLMS scale. The gLMS was chosen over the more common visual analog scale as it might be better suited for cross-modal comparisons and for capturing subjective variance in the high-intensity stimulus range<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 75" title="Bartoshuk, L. M. et al. Valid across-group comparisons with labeled scales: the gLMS versus magnitude matching. Physiol. Behav. 82, 109–114 (2004)." href="/articles/s41593-022-01082-w#ref-CR75" id="ref-link-section-d30208738e2055">75</a></sup>. The gLMS was anchored at ‘not at all’ (0) to ‘most’ (1), with intermediate labels spaced quasi-logarithmically (‘a little bit’ (0.061), ‘moderately’ (0.172), ‘strongly’ (0.354) and ‘very strongly’ (0.533). Before to the fMRI session, participants were instructed in the meaning of scale labels: ‘not at all’ = I feel no need to avoid this experience, ‘a little bit’ = I would put a little effort into avoiding this experience, ‘moderately’ = I would prefer to avoid this experience in the future, ‘strongly’ = I strongly want to avoid this experience in the future, ‘very strongly’ = I very much want to avoid this experience and ‘most’ = I never want to experience this again in my life. During the fMRI experiment, the intermediate labels were removed to minimize clustering of ratings around the labels<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 76" title="Hayes, J. E., Allen, A. L. &amp; Bennett, S. M. Direct comparison of the generalized visual analog scale and general labeled magnitude scale. Food Qual. Prefer. 28, 36–44 (2013)." href="/articles/s41593-022-01082-w#ref-CR76" id="ref-link-section-d30208738e2059">76</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec18">Calibration of pain stimuli</h3><p>Before the fMRI experiment, all participants underwent a short pain calibration session to assure normal pain sensitivity. Participants experienced different levels of thermal and pressure pain stimuli in a random order (thermal: between 43 and 49 °C, pressure: between 4 and 7 kg/cm<sup>2</sup>, maximum duration of 10 s). The highest stimulus level was chosen based on previous studies as tolerable yet painful for most participants. All participants included in the study were able to tolerate all stimuli.</p><h3 class="c-article__sub-heading" id="Sec19">Aversive stimuli</h3><p>Mechanical pain stimuli were administered using an in-house pressure pain device. The pressure pain device is an MRI-safe device with dynamic pressure delivery controlled by LabView (National Instruments). Four stimulus levels were delivered to the left thumbnail for 6 s each (level 1: 4 kg/cm<sup>2</sup>; level 2: 5 kg/cm<sup>2</sup>; level 3: 6 kg/cm<sup>2</sup>; level 4: 7 kg/cm<sup>2</sup>).</p><p>Thermal pain stimuli were administered using an ATS Pathway System (Medoc) with a 16-mm Peltier contact thermode (that is, hot plate). Four stimulus intensity levels were delivered to the thenar eminence of the left hand (level 1: 45 °C; level 2: 46 °C; level 3: 47 °C; level 4: 48 °C) and each stimulus lasted 10 s (1.5–2-s ramp-up, 1.5–2-s ramp-down, 6–7 s at target temperature).</p><p>Aversive sound was administered using MRI-compatible headphones. We used the sound of a knife scraping on a bottle (sound file retrieved from YouTube), which is a reliable aversive auditory stimulus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 77" title="Kumar, S., Forster, H. M., Bailey, P. &amp; Griffiths, T. D. Mapping unpleasantness of sounds to their auditory representation. J. Acoust. Soc. Am. 124, 3810–3817 (2008)." href="/articles/s41593-022-01082-w#ref-CR77" id="ref-link-section-d30208738e2095">77</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Kumar, S., von Kriegstein, K., Friston, K. &amp; Griffiths, T. D. Features versus feelings: dissociable representations of the acoustic features and valence of aversive sounds. J. Neurosci. 32, 14184–14192 (2012)." href="/articles/s41593-022-01082-w#ref-CR78" id="ref-link-section-d30208738e2098">78</a></sup>. Four stimulus intensity levels were delivered at 2,000 Hz for 6 s each (level 1: level 4 minus 8 dB; level 2: level 4 minus 4 dB; level 3: level 4 minus 1 dB; level 4: original YouTube sound file).</p><p>Aversive images were presented on the MRI screen and included normed images from the IAPS database<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 79" title="Lang, P. J., Bradley, M. M. &amp; Cuthbert, B. N. International affective picture system (IAPS): affective ratings of pictures and instruction manual. Technical Report A-8. University of Florida, Gainesville (2008)." href="/articles/s41593-022-01082-w#ref-CR79" id="ref-link-section-d30208738e2105">79</a></sup>. To induce four stimulus intensity levels, we selected four groups of seven images each in a two-step process: (1) preliminary selection based on normed aversiveness ratings (averaged across male and female raters) available in the IAPS database, and (2) final selection based on ratings by <i>N</i> = 10 laboratory members (5 males, 5 females) in response to ‘how aversive is this image? 1–100’. Selected images included photographs of animals (7), bodily illness and injury (12), industrial and human waste (9). Four stimulus levels were delivered to participants for 6 s each.</p><h3 class="c-article__sub-heading" id="Sec20">fMRI data acquisition and preprocessing</h3><p>Whole-brain fMRI data were acquired on a 3T Siemens MAGNETOM Prisma MRI scanner at the Intermountain Neuroimaging Consortium facility at the University of Colorado, Boulder. Structural images were acquired using high-resolution T1 spoiled gradient recall images and were used for anatomical localization and warping to the standard Montreal Neurological Institute (MNI) space only. Functional images were acquired with a multiband EPI sequence (repetition time = 460 ms, echo time = 27.2 ms, field of view = 220 mm, multiband acceleration factor = 8, flip angle = 44°, 64 × 64 matrix, 2.7 × 2.7 × 2.7 mm voxels, 56 interleaved ascending slices, phase encoding posterior » anterior). In total, six runs of 7.17 min in duration ( = 934 measurements) were acquired. Stimulus presentation and behavioral data acquisition were controlled using Psychtoolbox (MATLAB, MathWorks).</p><p>fMRI data were preprocessed using an automated pipeline based on AFNI, FSL and SPM5, and implemented by the Mind Research Network. Briefly, the preprocessing steps included: distortion correction using FSL’s top-up tool (<a href="https://fsl.fmrib.ox.ac.uk/fsl/">https://fsl.fmrib.ox.ac.uk/fsl/</a>), motion correction (affine alignment of first EPI volume (reference image) to T1, followed by affine alignment of all EPI volumes to the reference image and estimation of the motion parameter file (sepi_vr_motion.1D, AFNI; <a href="https://afni.nimh.nih.gov/">https://afni.nimh.nih.gov/</a>), spatial normalization via the participant’s T1 image (T1 normalization to MNI space (nonlinear transform), normalization of EPI image to MNI space (3dNWarpApply, AFNI; <a href="https://afni.nimh.nih.gov/">https://afni.nimh.nih.gov/</a>), interpolation to 2 × 2 × 2 mm<sup>3</sup> voxels and smoothing with a 6-mm FWHM kernel (SPM 8; <a href="https://www.fil.ion.ucl.ac.uk/spm/software/spm8/">https://www.fil.ion.ucl.ac.uk/spm/software/spm8/</a>). Spatial smoothing improves interindividual functional alignment without impairing the sensitivity of multivariate pattern analyses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 80" title="Op de Beeck, H. P. Against hyperacuity in brain reading: spatial smoothing does not hurt multivariate fMRI analyses? Neuroimage 49, 1943–1948 (2010)." href="/articles/s41593-022-01082-w#ref-CR80" id="ref-link-section-d30208738e2154">80</a></sup>. Before first-level analysis, in each run we removed the first 15 volumes of the fMRI data to allow for image intensity stabilization and identified severe global motion outliers (spikes) in the data. Spikes were defined as time points in the data with either the absolute global signal intensity or the Mahalanobis distance across slice-specific global means and spatial standard deviations exceeding ten median absolute deviations.</p><h3 class="c-article__sub-heading" id="Sec21">Behavioral data analysis</h3><p>Behavioral data were analyzed using ‘glmfit_multilevel.m’, a multilevel generalized linear model implemented in custom MATLAB (2019a, MathWorks) code available from the authors’ website (<a href="https://github.com/canlab/CanlabCore">https://github.com/canlab/CanlabCore/</a>). For each stimulus modality (mechanical, thermal, auditory and visual), the outcome variable was the average rating for each stimulus level. The within-participant predictor at the first-level model was stimulus intensity. Data distribution was assumed to be normal but was not formally tested.</p><h3 class="c-article__sub-heading" id="Sec22">fMRI analysis</h3><p>fMRI data were analyzed using SPM12 (<a href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm/</a>) and custom MATLAB (2019a, MathWorks) code available from the authors’ website (<a href="https://github.com/canlab/CanlabCore">https://github.com/canlab/CanlabCore/</a>). A univariate general linear model (GLM) was used to create images for the prediction analyses. Data distribution was assumed to be normal but was not formally tested. The participant-level GLM analyses were conducted in SPM12. The six runs of the fMRI task were concatenated for each participant. Boxcar regressors, convolved with the canonical hemodynamic response function, were constructed to model the 6–10-s stimulation and 4–7-s rating periods. The fixation cross epoch was used as an implicit baseline. A high-pass filter of 180 s was applied. Nuisance variables included: (a) ‘dummy’ regressors coding for each run (intercept for each run); (b) linear drift over time within each run; (c) the six estimated head movement parameters (<i>x</i>, <i>y</i>, <i>z</i>, roll, pitch and yaw), their mean-centered squares, their derivatives, and squared derivative for each run (total = 24 columns); and (d) motion outliers (spikes). Contrasts of interest (beta images) included stimulation periods averaged across six trials for each stimulus intensity (each against implicit baseline). The resulting beta maps computed for each stimulus level of each aversive stimulus type were used for brain model development (study 1). Beta maps computed for each stimulus level of the pleasant (positive) stimulus were used for brain model development in supplementary analyses (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">Supplementary Information</a>).</p><h3 class="c-article__sub-heading" id="Sec23">PLS-R for brain model development</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec24">Statistical approach</h4><p>In study 1, we developed common and stimulus-type-specific predictive models of aversiveness ratings from brain activity across the four stimulus types using PLS-R<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Wold, S., Sjöström, M. &amp; Eriksson, L. PLS-regression: a basic tool of chemometrics. Chemom. Intell. Lab. Syst. 58, 109–130 (2001)." href="/articles/s41593-022-01082-w#ref-CR35" id="ref-link-section-d30208738e2221">35</a></sup>. PLS-R estimates a set of latent brain components (voxel-wise spatial maps) and a set of latent negative affect rating factors that are optimized to be maximally intercorrelated (that is, maximal variance in ratings explained by brain patterns). Compared to standard predictive brain models that typically characterize a single outcome at a time, PLS-R jointly estimates multiple solutions (that is, separate brain patterns for common and stimulus-type-specific outcomes) simultaneously, which is why it is capable of predicting multiple (correlated) stimulus types, as is the case with our data. The predictors (brain activity) are stored in the input matrix <b>X</b> and the outcome variables (ratings) are stored in the input matrix <b>Y</b>. By an iterative application of a singular value decomposition algorithm, which factorizes (decomposes) the cross-product matrix of the two input matrices, PLS-R finds latent variables, also called component scores, that model <b>X</b> (for example, brain activity) and simultaneously predict <b>Y</b> (for example, ratings). Each run of the singular value decomposition algorithm produces orthogonal latent variables and corresponding regression weights for predictions. By estimating different latent sources, PLS-R can provide improved estimates of common and specific patterns (versus single-outcome models such as PCR), but these are not necessarily fully independent of each other.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec25">Implementation</h4><p>PLS-R was conducted using ‘plsregress.m’ in MATLAB (version R2019b). Predictors (<b>X</b>) constituted 880 whole-brain activation maps associated with participants (55) <i>x</i> stimulus intensity level (4) <i>x</i> stimulus type (4), aggregated into an images <i>x</i> voxels matrix (stacked across participants), and split into training and test sets using fivefold blocked cross-validation (leaving out all images associated with test-set participants together). The activation maps were derived via univariate GLM analysis in which we modeled stimulation periods against implicit baseline and averaged across trials of each stimulus level of each stimulus type to obtain 16 contrast images for each participant. We constructed the outcome (<b>Y</b>) matrix to include negative affect ratings across all stimulus types (<b>Y</b><sub><b>1</b></sub>) as well as stimulus-type-specific negative affect (<b>Y</b><sub><b>2</b> </sub>– <b>Y</b><sub><b>5</b></sub>, ratings for each stimulus type separately, with values of 0 for other stimulus types). By setting the <b>Y</b> value of other stimulus types to 0 we constrained each pattern to be stimulus-type specific. The linear combination of latent brain factors that explains <b>Y</b><sub><b>1</b></sub> reflects a common model of negative affect across stimulus types. Likewise, brain patterns predictive of <b>Y</b><sub><b>2</b> </sub>– <b>Y</b><sub><b>5</b></sub> are models optimized to be selective to mechanical pain, thermal pain, aversive sounds and aversive images. Each model was then projected into a single predictive spatial map.</p><p>To estimate their predictive accuracy, and specificity for the target outcome, and generalization to new individual participants, these patterns were applied to fMRI activation maps obtained from new participants in cross-validation test sets (fivefold; leaving out all data for each test participant) and prospectively applied to independent studies (<i>N</i> = 247; see ‘<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01082-w#Sec40">Validation in independent datasets</a>’ below). Model (pattern) responses were calculated using the dot product of each pattern weight map with the univariate GLM-derived fMRI activation map for each participant for each stimulus level. Weight maps applied to study 1 and study 1b were based on data from out-of-sample individuals (cross-validated estimates), and the final pattern weights applied to studies 2–6 were based on the full study sample (full samples estimates).</p><h3 class="c-article__sub-heading" id="Sec26">Model evaluation</h3><p>To evaluate the models’ performance, we assessed in each participant the RMSE for each model’s predictions of its target outcome (that is, four average ratings per stimulus type) and the ability to significantly predict increasing negative affect within a participant. To provide an interpretable effect size metric, we estimated in each participant the Pearson correlation (<i>r</i>) between observed and cross-validated predicted ratings and tested whether the output of one model predicted the specific type of negative affect it was trained to predict (sensitivity) and not other types (specificity).</p><h3 class="c-article__sub-heading" id="Sec27">Classification between stimulus levels</h3><p>For each brain model, we computed the classification accuracy between each pair of stimulus intensity levels (1 versus 2, 2 versus 3, 3 versus 4, 1 versus 3, 2 versus 4 and 1 versus 4) from receiver operating characteristic curves using forced-choice classification. Forced-choice classification uses the maximum value of a relative comparison within a participant and is therefore ‘threshold free’. <i>P</i> values were calculated using a two-sided independent binomial test.</p><h3 class="c-article__sub-heading" id="Sec28">Cross-prediction</h3><p>To test how well each PLS-R brain pattern predicted other stimulus types, we used a cross-prediction procedure on cross-validated estimates. In this procedure, a Pearson correlation was calculated for each participant separately between the predicted and the observed outcomes (that is, negative affect ratings) for each stimulus type. The mean within-participant correlation coefficient for each train–test stimulus pair is visualized in a cross-correlation matrix.</p><h3 class="c-article__sub-heading" id="Sec29">Variance decomposition analysis</h3><p>For each stimulus type separately, full and reduced regression models (commonality analysis, implemented in R<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Nimon, K., Lewis, M., Kane, R. &amp; Haynes, R. M. An R package to compute commonality coefficients in the multiple regression case: an introduction to the package and a practical example. Behav. Res. Methods 40, 457–466 (2008)." href="/articles/s41593-022-01082-w#ref-CR38" id="ref-link-section-d30208738e2351">38</a></sup>) were used in each participant to partition the variance in outcome (ratings) explained by the predictors (common model, specific model) into unique and shared components. First, total <i>r</i><sup>2</sup> was defined as the mean total variance explained by common and specific models in a multiple regression. The unique <i>r</i><sup>2</sup> for the common model (UVC) was computed as: total <i>r</i><sup>2 </sup>− single variance for the specific model, whereas unique <i>r</i><sup>2</sup> for the specific model (UVS) was computed as: total <i>r</i><sup>2 </sup>− single variance for the common model. Shared variance between common and specific models was computed as: total <i>r</i><sup>2 </sup>− UVS − UVC. Proportions of variance explained were computed on cross-validated model outputs.</p><h3 class="c-article__sub-heading" id="Sec30">Identifying core systems involved in negative affect</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec31">General approach</h4><p>Core regions for multimodal (common) negative affect processes were defined as having voxels that reliably contribute to model prediction (that is, model weights) and are related to model predictions in an interpretable way (that is, model encoding voxels where the prediction correlates with fMRI activation). Core regions for stimulus-type-specific processes were defined as above, with an additional ‘type-selectivity filter’ applied to identify the most important regions. Thus, a core stimulus type-specific system was defined as having voxels that reliably contribute to prediction, encode the model and are selective for this model above all other models (3-way conjunction).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec32">Step 1: model weight maps</h4><p>To determine which brain areas made reliable contributions to the prediction and to threshold voxel weights for interpretation and display, we constructed 10,000 bootstrap samples (with replacement) consisting of paired brain and outcome data and performed PLS-R on each. The <i>z</i>-scores at each voxel were estimated based on the mean and standard error of the bootstrap distributions, and the statistical map was thresholded based on the corresponding <i>P</i> values. The maps were thresholded voxel-wise at <i>q</i> &lt; 0.05 (FDR corrected)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 81" title="Genovese, C. R., Lazar, N. A. &amp; Nichols, T. Thresholding of statistical maps in functional neuroimaging using the false discovery rate. Neuroimage 15, 870–878 (2002)." href="/articles/s41593-022-01082-w#ref-CR81" id="ref-link-section-d30208738e2409">81</a></sup>. Uncorrected maps thresholded at <i>t</i> &gt; 3 were used for display purposes in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">3a</a>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec33">Step 2: model encoding maps</h4><p>Model encoding (‘structure coefficient’) maps were computed for each participant by regressing the PLS-R model predictions on voxel-wise fMRI activation maps (four maps per person for each condition, corresponding to averages for each stimulus level). Structure coefficients identify voxels individually associated with each model’s output, mapping individual voxels to the overall multivariate model prediction<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Haufe, S. et al. On the interpretation of weight vectors of linear models in multivariate neuroimaging. Neuroimage 87, 96–110 (2014)." href="/articles/s41593-022-01082-w#ref-CR39" id="ref-link-section-d30208738e2428">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Thompson, B. &amp; Borrello, G. M. The importance of structure coefficients in regression research. Educ. Psychol. Meas. 45, 203–209 (1985)." href="#ref-CR82" id="ref-link-section-d30208738e2431">82</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Parra, L. C., Spence, C. D., Gerson, A. D. &amp; Sajda, P. Recipes for the linear analysis of EEG. Neuroimage 28, 326–341 (2005)." href="#ref-CR83" id="ref-link-section-d30208738e2431_1">83</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 84" title="Kohoutová, L. et al. Toward a unified framework for interpreting machine-learning models in neuroimaging. Nat. Protoc. &#xA;                  https://doi.org/10.1038/s41596-019-0289-5&#xA;                  &#xA;                 (2020)." href="/articles/s41593-022-01082-w#ref-CR84" id="ref-link-section-d30208738e2434">84</a></sup>. The analysis was performed using a standard summary statistics-based mixed-effects GLM<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 85" title="Mumford, J. A. &amp; Nichols, T. Simple group fMRI modeling and inference. Neuroimage 47, 1469–1475 (2009)." href="/articles/s41593-022-01082-w#ref-CR85" id="ref-link-section-d30208738e2438">85</a></sup>, with robust regression at the second level, thresholded at FDR <i>q</i> &lt; 0.05 corrected for multiple comparisons. Uncorrected maps thresholded at <i>t</i> &gt; 3 were used for display purposes in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">3b</a>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec34">Step 3: core system</h4><p>The core system map for each model was derived via a conjunction of model weight maps thresholded at FDR <i>q</i> &lt; 0.05 created in step 1 and model encoding maps thresholded at FDR <i>q</i> &lt; 0.05 created in step 2 (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">4a</a>). The conjunction was restricted to preserve positive values.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec35">Step 4a: type-selective model encoding maps</h4><p>Voxels where model encoding values were significantly greater in one model than in any of the other four models (that is, type-selective voxels) were calculated for each participant as a supremum statistic image for the target model encoding map minus the maximum of the four remaining model encoding maps (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">4b</a>). A second-level robust <i>t</i>-test, thresholded at FDR <i>q</i> &lt; 0.05 corrected for multiple comparisons and preserving positive statistics only, identified regions selective for the respective model on participant group level.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec36">Step 4b: core stimulus type-specific systems</h4><p>Core stimulus-type-specific systems were derived via conjunction of the core system maps thresholded at FDR <i>q</i> &lt; 0.05 created in step 3 and the type-selective encoding maps thresholded at FDR <i>q</i> &lt; 0.05 created in step 4a.</p><h3 class="c-article__sub-heading" id="Sec37">Spatial similarity between model encoding maps and a priori regions of interest</h3><p>River plots were created to depict spatial similarity between model encoding maps and a set of anatomical parcellations (ROIs), documented in previous neuroimaging studies as regions showing preferential activation to somatic pain stimuli, aversive auditory and aversive visual stimuli or regions showing activation to aversive stimuli across stimulus types (meta-analyses in refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. Front. Psychol. 6, 1860 (2015)." href="/articles/s41593-022-01082-w#ref-CR18" id="ref-link-section-d30208738e2510">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Lindquist, K. A., Satpute, A. B., Wager, T. D., Weber, J. &amp; Barrett, L. F. The brain basis of positive and negative affect: evidence from a meta-analysis of the human neuroimaging literature. Cereb. Cortex 26, 1910–1922 (2016)." href="/articles/s41593-022-01082-w#ref-CR41" id="ref-link-section-d30208738e2513">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Hayes, D. J. &amp; Northoff, G. Common brain activations for painful and non-painful aversive stimuli. BMC Neurosci. 13, 60 (2012)." href="/articles/s41593-022-01082-w#ref-CR62" id="ref-link-section-d30208738e2516">62</a></sup> and confirmed using Neurosynth in <i>N</i> = 238 fMRI studies with the search term ‘aversive’). Spatial similarity was calculated as cosine similarity between the ROI and the gray matter masked model encoding group map thresholded at <i>q</i> &lt; 0.05 FDR and retaining positive values for interpretation.</p><h3 class="c-article__sub-heading" id="Sec38">Regional model importance scores</h3><p>The common/type-specific ratio was derived for each ROI separately from model encoding values. The common model importance score was defined as the relative percentage of the ROI encoded by the common model. The type-specific model importance score was defined as the percentage of ROI encoded by the predominant specific model (that is, the model encoded by the maximum number of voxels).</p><h3 class="c-article__sub-heading" id="Sec39">Testing model-selectivity along afferent pathways</h3><p>To test the relative contribution of each model to negative affect representation in selected ROIs along the afferent processing pathways<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 86" title="Bota, M. &amp; Swanson, L. W. BAMS Neuroanatomical Ontology: design and implementation. Front. Neuroinformatics 2, 2 (2008)." href="/articles/s41593-022-01082-w#ref-CR86" id="ref-link-section-d30208738e2542">86</a></sup>, we extracted from each anatomically defined ROI and for each model separately the mean structure coefficients across participants. Significance of each model was tested using a one-sample <i>t</i>-test.</p><h3 class="c-article__sub-heading" id="Sec40">Validation in independent datasets</h3><p>We tested whether brain models derived in study 1 (<i>N</i> = 55) could predict negative affect ratings in new individuals by applying PLS-R-derived brain patterns to three independent test datasets (study 2, <i>N</i> = 32; study 3, <i>N</i> = 32; study 3, <i>N</i> = 183; see Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">8</a> for sample characteristics and study design). Pattern response was estimated for each test participant in each test condition by computing the dot product of each PLS-R-derived full-sample pattern with the participant’s brain activation map, yielding a single scalar value. We estimated the sensitivity and specificity of each stimulus-type-specific pattern by testing whether the pattern responds significantly to the increasing level of self-reported negative affect for the respective (target) stimulus type (sensitivity to change in behavior; significant positive response with a positive slope) but has a nonsignificant response to other types of stimuli (specificity; nonsignificant or negative response or negative slope). For the common model, we tested whether the pattern responds significantly to the increasing level of self-reported negative affect across different aversive stimulus types. As in our main analyses, we calculated the mean within-participant Pearson correlation coefficient and the RMSE between the observed and predicted ratings as measures of model performance.</p><h3 class="c-article__sub-heading" id="Sec41">Valence specificity test and additional validation analyses</h3><p>First, we tested the common and stimulus-type-specific patterns derived in study 1 on a set of pleasant visual stimuli collected in the same participants (labeled as study 1b; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">8</a>). Pattern response was estimated as explained above. We used the cross-validated PLS-R pattern—testing in the same participants—to compute the dot product with each participant’s brain activation map.</p><p>Second, we tested the PLS-R patterns derived in study 1 on two additional datasets, study 5 (<i>N</i> = 95 participants, fMRI brain responses to negative and positive images; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">8</a>) and study 6 (<i>N</i> = 59; fMRI brain responses to painful and non-painful thermal stimulation; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">8</a>). Pattern response was estimated as explained above. We used the full-sample PLS-R pattern to compute the dot product with each participant’s brain activation map.</p><p>Third, we summarized the performance of PLS-R patterns derived in study 1 across all tested datasets (studies 1b–6b) in a single matrix showing (1) true-positive responses (significant positive pattern response for on-target stimuli) and true-negative responses (nonsignificant or negative pattern response for off-target stimuli) in green; (2) false-positive responses (significant pattern response for off-target stimuli) in yellow; and (3) false-negative responses (nonsignificant or negative pattern response for on-target stimuli) in blue.</p><h3 class="c-article__sub-heading" id="Sec42">Reporting summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM2">Nature Research Reporting Summary</a> linked to this article.</p></div></div></section>
                </div>
            

            <div>
                <section data-title="Data availability"><div class="c-article-section" id="data-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability">Data availability</h2><div class="c-article-section__content" id="data-availability-content">
              
              <p>Brain patterns generated and analyzed during the current study, as well as source data for figures are freely available via . The dataset used in study 6 is available at <a href="https://github.com/cocoanlab/interpret_ml_neuroimaging">https://github.com/cocoanlab/interpret_ml_neuroimaging/</a>.</p>
            </div></div></section><section data-title="Code availability"><div class="c-article-section" id="code-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="code-availability">Code availability</h2><div class="c-article-section__content" id="code-availability-content">
              
              <p>Code for analysis and for generating figures is openly shared at <a href="https://github.com/canlab/2021_Ceko_MPA2_Aversive">https://github.com/canlab/2021_Ceko_MPA2_Aversive/</a>. Analyses reported in this paper were performed using code release v1.0.1 (<a href="https://doi.org/10.5281/zenodo.6452244">https://doi.org/10.5281/zenodo.6452244</a>).</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Berridge, K. C. &amp; Kringelbach, M. L. Neuroscience of affect: brain mechanisms of pleasure and displeasure. <i>Curr. Opin. Neurobiol.</i> <b>23</b>, 294–303 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.conb.2013.01.017" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2013.01.017" aria-label="Article reference 1" data-doi="10.1016/j.conb.2013.01.017">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhslCitrw%3D" aria-label="CAS reference 1">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23375169" aria-label="PubMed reference 1">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3644539" aria-label="PubMed Central reference 1">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuroscience%20of%20affect%3A%20brain%20mechanisms%20of%20pleasure%20and%20displeasure&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2013.01.017&amp;volume=23&amp;pages=294-303&amp;publication_year=2013&amp;author=Berridge%2CKC&amp;author=Kringelbach%2CML">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Tye, K. M. Neural circuit motifs in valence processing. <i>Neuron</i> <b>100</b>, 436–452 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2018.10.001" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2018.10.001" aria-label="Article reference 2" data-doi="10.1016/j.neuron.2018.10.001">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXitVSisrfM" aria-label="CAS reference 2">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30359607" aria-label="PubMed reference 2">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6590698" aria-label="PubMed Central reference 2">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20circuit%20motifs%20in%20valence%20processing&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2018.10.001&amp;volume=100&amp;pages=436-452&amp;publication_year=2018&amp;author=Tye%2CKM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Russell, J. A. A circumplex model of affect. <i>J. Pers. Soc. Psychol.</i> <b>39</b>, 1161–1178 (1980).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/h0077714" data-track-action="article reference" href="https://doi.org/10.1037%2Fh0077714" aria-label="Article reference 3" data-doi="10.1037/h0077714">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20circumplex%20model%20of%20affect&amp;journal=J.%20Pers.%20Soc.%20Psychol.&amp;doi=10.1037%2Fh0077714&amp;volume=39&amp;publication_year=1980&amp;author=Russell%2CJA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Russell, J. A. &amp; Barrett, L. F. Core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant. <i>J. Pers. Soc. Psychol.</i> <b>76</b>, 805–819 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0022-3514.76.5.805" data-track-action="article reference" href="https://doi.org/10.1037%2F0022-3514.76.5.805" aria-label="Article reference 4" data-doi="10.1037/0022-3514.76.5.805">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M3otFCksg%3D%3D" aria-label="CAS reference 4">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10353204" aria-label="PubMed reference 4">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Core%20affect%2C%20prototypical%20emotional%20episodes%2C%20and%20other%20things%20called%20emotion%3A%20dissecting%20the%20elephant&amp;journal=J.%20Pers.%20Soc.%20Psychol.&amp;doi=10.1037%2F0022-3514.76.5.805&amp;volume=76&amp;pages=805-819&amp;publication_year=1999&amp;author=Russell%2CJA&amp;author=Barrett%2CLF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Gray, J. A. <i>The Psychology of Fear and Stress</i>. (CUP Archive, 1987).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Montague, P. R. &amp; Berns, G. S. Neural economics and the biological substrates of valuation. <i>Neuron</i> <b>36</b>, 265–284 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(02)00974-1" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2802%2900974-1" aria-label="Article reference 6" data-doi="10.1016/S0896-6273(02)00974-1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38XotlansLs%3D" aria-label="CAS reference 6">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12383781" aria-label="PubMed reference 6">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20economics%20and%20the%20biological%20substrates%20of%20valuation&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2802%2900974-1&amp;volume=36&amp;pages=265-284&amp;publication_year=2002&amp;author=Montague%2CPR&amp;author=Berns%2CGS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Padoa-Schioppa, C. &amp; Assad, J. A. Neurons in the orbitofrontal cortex encode economic value. <i>Nature</i> <b>441</b>, 223–226 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature04676" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature04676" aria-label="Article reference 7" data-doi="10.1038/nature04676">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD28XksVGnsrk%3D" aria-label="CAS reference 7">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16633341" aria-label="PubMed reference 7">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2630027" aria-label="PubMed Central reference 7">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Neurons%20in%20the%20orbitofrontal%20cortex%20encode%20economic%20value&amp;journal=Nature&amp;doi=10.1038%2Fnature04676&amp;volume=441&amp;pages=223-226&amp;publication_year=2006&amp;author=Padoa-Schioppa%2CC&amp;author=Assad%2CJA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Hariri, A. R. et al. A susceptibility gene for affective disorders and the response of the human amygdala. <i>Arch. Gen. Psychiatry</i> <b>62</b>, 146–152 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/archpsyc.62.2.146" data-track-action="article reference" href="https://doi.org/10.1001%2Farchpsyc.62.2.146" aria-label="Article reference 8" data-doi="10.1001/archpsyc.62.2.146">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXhvFGmsLo%3D" aria-label="CAS reference 8">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15699291" aria-label="PubMed reference 8">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20susceptibility%20gene%20for%20affective%20disorders%20and%20the%20response%20of%20the%20human%20amygdala&amp;journal=Arch.%20Gen.%20Psychiatry&amp;doi=10.1001%2Farchpsyc.62.2.146&amp;volume=62&amp;pages=146-152&amp;publication_year=2005&amp;author=Hariri%2CAR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Bishop, S., Duncan, J., Brett, M. &amp; Lawrence, A. D. Prefrontal cortical function and anxiety: controlling attention to threat-related stimuli. <i>Nat. Neurosci.</i> <b>7</b>, 184–188 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1173" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1173" aria-label="Article reference 9" data-doi="10.1038/nn1173">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2cXmvVGmtw%3D%3D" aria-label="CAS reference 9">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=14703573" aria-label="PubMed reference 9">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Prefrontal%20cortical%20function%20and%20anxiety%3A%20controlling%20attention%20to%20threat-related%20stimuli&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1173&amp;volume=7&amp;pages=184-188&amp;publication_year=2004&amp;author=Bishop%2CS&amp;author=Duncan%2CJ&amp;author=Brett%2CM&amp;author=Lawrence%2CAD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Duerden, E. G. &amp; Albanese, M.-C. Localization of pain-related brain activation: a meta-analysis of neuroimaging data. <i>Hum. Brain Mapp.</i> <b>34</b>, 109–149 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/hbm.21416" data-track-action="article reference" href="https://doi.org/10.1002%2Fhbm.21416" aria-label="Article reference 10" data-doi="10.1002/hbm.21416">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22131304" aria-label="PubMed reference 10">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Localization%20of%20pain-related%20brain%20activation%3A%20a%20meta-analysis%20of%20neuroimaging%20data&amp;journal=Hum.%20Brain%20Mapp.&amp;doi=10.1002%2Fhbm.21416&amp;volume=34&amp;pages=109-149&amp;publication_year=2013&amp;author=Duerden%2CEG&amp;author=Albanese%2CM-C">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Insel, T. et al. Research domain criteria (RDoC): toward a new classification framework for research on mental disorders. <i>Am. J. Psychiatry</i> <b>167</b>, 748–751 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1176/appi.ajp.2010.09091379" data-track-action="article reference" href="https://doi.org/10.1176%2Fappi.ajp.2010.09091379" aria-label="Article reference 11" data-doi="10.1176/appi.ajp.2010.09091379">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20595427" aria-label="PubMed reference 11">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Research%20domain%20criteria%20%28RDoC%29%3A%20toward%20a%20new%20classification%20framework%20for%20research%20on%20mental%20disorders&amp;journal=Am.%20J.%20Psychiatry&amp;doi=10.1176%2Fappi.ajp.2010.09091379&amp;volume=167&amp;pages=748-751&amp;publication_year=2010&amp;author=Insel%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Hayden, B. Y. &amp; Niv, Y. The case against economic values in the orbitofrontal cortex (or anywhere else in the brain). <i>Behav. Neurosci.</i> <b>135</b>, 192–201 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/bne0000448" data-track-action="article reference" href="https://doi.org/10.1037%2Fbne0000448" aria-label="Article reference 12" data-doi="10.1037/bne0000448">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34060875" aria-label="PubMed reference 12">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20case%20against%20economic%20values%20in%20the%20orbitofrontal%20cortex%20%28or%20anywhere%20else%20in%20the%20brain%29&amp;journal=Behav.%20Neurosci.&amp;doi=10.1037%2Fbne0000448&amp;volume=135&amp;pages=192-201&amp;publication_year=2021&amp;author=Hayden%2CBY&amp;author=Niv%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Gehrlach, D. A. et al. Aversive state processing in the posterior insular cortex. <i>Nat. Neurosci.</i> <b>22</b>, 1424–1437 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-019-0469-1" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-019-0469-1" aria-label="Article reference 13" data-doi="10.1038/s41593-019-0469-1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXhs1Ohtb7I" aria-label="CAS reference 13">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31455886" aria-label="PubMed reference 13">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Aversive%20state%20processing%20in%20the%20posterior%20insular%20cortex&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-019-0469-1&amp;volume=22&amp;pages=1424-1437&amp;publication_year=2019&amp;author=Gehrlach%2CDA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Corradi-Dell’Acqua, C., Tusche, A., Vuilleumier, P. &amp; Singer, T. Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex. <i>Nat. Commun.</i> <b>7</b>, 10904 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/ncomms10904" data-track-action="article reference" href="https://doi.org/10.1038%2Fncomms10904" aria-label="Article reference 14" data-doi="10.1038/ncomms10904">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26988654" aria-label="PubMed reference 14">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4802033" aria-label="PubMed Central reference 14">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Cross-modal%20representations%20of%20first-hand%20and%20vicarious%20pain%2C%20disgust%20and%20fairness%20in%20insular%20and%20cingulate%20cortex&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fncomms10904&amp;volume=7&amp;publication_year=2016&amp;author=Corradi-Dell%E2%80%99Acqua%2CC&amp;author=Tusche%2CA&amp;author=Vuilleumier%2CP&amp;author=Singer%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Kragel, P. A. et al. Generalizable representations of pain, cognitive control, and negative emotion in medial frontal cortex. <i>Nat. Neurosci.</i> <b>21</b>, 283–289 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-017-0051-7" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-017-0051-7" aria-label="Article reference 15" data-doi="10.1038/s41593-017-0051-7">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXltVyhsr4%3D" aria-label="CAS reference 15">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29292378" aria-label="PubMed reference 15">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5801068" aria-label="PubMed Central reference 15">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Generalizable%20representations%20of%20pain%2C%20cognitive%20control%2C%20and%20negative%20emotion%20in%20medial%20frontal%20cortex&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-017-0051-7&amp;volume=21&amp;pages=283-289&amp;publication_year=2018&amp;author=Kragel%2CPA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Chikazoe, J., Lee, D. H., Kriegeskorte, N. &amp; Anderson, A. K. Population coding of affect across stimuli, modalities and individuals. <i>Nat. Neurosci.</i> <b>17</b>, 1114–1122 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3749" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3749" aria-label="Article reference 16" data-doi="10.1038/nn.3749">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhtVais7jM" aria-label="CAS reference 16">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24952643" aria-label="PubMed reference 16">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4317366" aria-label="PubMed Central reference 16">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Population%20coding%20of%20affect%20across%20stimuli%2C%20modalities%20and%20individuals&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3749&amp;volume=17&amp;pages=1114-1122&amp;publication_year=2014&amp;author=Chikazoe%2CJ&amp;author=Lee%2CDH&amp;author=Kriegeskorte%2CN&amp;author=Anderson%2CAK">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Kober, H. et al. Functional grouping and cortical-subcortical interactions in emotion: a meta-analysis of neuroimaging studies. <i>Neuroimage</i> <b>42</b>, 998–1031 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2008.03.059" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2008.03.059" aria-label="Article reference 17" data-doi="10.1016/j.neuroimage.2008.03.059">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18579414" aria-label="PubMed reference 17">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20grouping%20and%20cortical-subcortical%20interactions%20in%20emotion%3A%20a%20meta-analysis%20of%20neuroimaging%20studies&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2008.03.059&amp;volume=42&amp;pages=998-1031&amp;publication_year=2008&amp;author=Kober%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Satpute, A. B. et al. Involvement of sensory regions in affective experience: a meta-analysis. <i>Front. Psychol.</i> <b>6</b>, 1860 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fpsyg.2015.01860" data-track-action="article reference" href="https://doi.org/10.3389%2Ffpsyg.2015.01860" aria-label="Article reference 18" data-doi="10.3389/fpsyg.2015.01860">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26696928" aria-label="PubMed reference 18">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4678183" aria-label="PubMed Central reference 18">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Involvement%20of%20sensory%20regions%20in%20affective%20experience%3A%20a%20meta-analysis&amp;journal=Front.%20Psychol.&amp;doi=10.3389%2Ffpsyg.2015.01860&amp;volume=6&amp;publication_year=2015&amp;author=Satpute%2CAB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Ekman, P. An argument for basic emotions. <i>Cognition Emot.</i> <b>6</b>, 169–200 (1992).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/02699939208411068" data-track-action="article reference" href="https://doi.org/10.1080%2F02699939208411068" aria-label="Article reference 19" data-doi="10.1080/02699939208411068">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20argument%20for%20basic%20emotions&amp;journal=Cognition%20Emot.&amp;doi=10.1080%2F02699939208411068&amp;volume=6&amp;pages=169-200&amp;publication_year=1992&amp;author=Ekman%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Friedman, B. H. Feelings and the body: the Jamesian perspective on autonomic specificity of emotion. <i>Biol. Psychol.</i> <b>84</b>, 383–393 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.biopsycho.2009.10.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.biopsycho.2009.10.006" aria-label="Article reference 20" data-doi="10.1016/j.biopsycho.2009.10.006">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19879320" aria-label="PubMed reference 20">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Feelings%20and%20the%20body%3A%20the%20Jamesian%20perspective%20on%20autonomic%20specificity%20of%20emotion&amp;journal=Biol.%20Psychol.&amp;doi=10.1016%2Fj.biopsycho.2009.10.006&amp;volume=84&amp;pages=383-393&amp;publication_year=2010&amp;author=Friedman%2CBH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Barrett, L. F. Solving the emotion paradox: categorization and the experience of emotion. <i>Pers. Soc. Psychol. Rev.</i> <b>10</b>, 20–46 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1207/s15327957pspr1001_2" data-track-action="article reference" href="https://doi.org/10.1207%2Fs15327957pspr1001_2" aria-label="Article reference 21" data-doi="10.1207/s15327957pspr1001_2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16430327" aria-label="PubMed reference 21">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Solving%20the%20emotion%20paradox%3A%20categorization%20and%20the%20experience%20of%20emotion&amp;journal=Pers.%20Soc.%20Psychol.%20Rev.&amp;doi=10.1207%2Fs15327957pspr1001_2&amp;volume=10&amp;pages=20-46&amp;publication_year=2006&amp;author=Barrett%2CLF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Saarimäki, H. et al. Discrete neural signatures of basic emotions. <i>Cereb. Cortex</i> <b>26</b>, 2563–2573 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhv086" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhv086" aria-label="Article reference 22" data-doi="10.1093/cercor/bhv086">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25924952" aria-label="PubMed reference 22">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Discrete%20neural%20signatures%20of%20basic%20emotions&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhv086&amp;volume=26&amp;pages=2563-2573&amp;publication_year=2016&amp;author=Saarim%C3%A4ki%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Kragel, P. A. &amp; LaBar, K. S. Multivariate neural biomarkers of emotional states are categorically distinct. <i>Soc. Cogn. Affect. Neurosci.</i> <b>10</b>, 1437–1448 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/scan/nsv032" data-track-action="article reference" href="https://doi.org/10.1093%2Fscan%2Fnsv032" aria-label="Article reference 23" data-doi="10.1093/scan/nsv032">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25813790" aria-label="PubMed reference 23">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4631142" aria-label="PubMed Central reference 23">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Multivariate%20neural%20biomarkers%20of%20emotional%20states%20are%20categorically%20distinct&amp;journal=Soc.%20Cogn.%20Affect.%20Neurosci.&amp;doi=10.1093%2Fscan%2Fnsv032&amp;volume=10&amp;pages=1437-1448&amp;publication_year=2015&amp;author=Kragel%2CPA&amp;author=LaBar%2CKS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Stephens, C. L., Christie, I. C. &amp; Friedman, B. H. Autonomic specificity of basic emotions: evidence from pattern classification and cluster analysis. <i>Biol. Psychol.</i> <b>84</b>, 463–473 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.biopsycho.2010.03.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.biopsycho.2010.03.014" aria-label="Article reference 24" data-doi="10.1016/j.biopsycho.2010.03.014">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20338217" aria-label="PubMed reference 24">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Autonomic%20specificity%20of%20basic%20emotions%3A%20evidence%20from%20pattern%20classification%20and%20cluster%20analysis&amp;journal=Biol.%20Psychol.&amp;doi=10.1016%2Fj.biopsycho.2010.03.014&amp;volume=84&amp;pages=463-473&amp;publication_year=2010&amp;author=Stephens%2CCL&amp;author=Christie%2CIC&amp;author=Friedman%2CBH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Horing, B., Sprenger, C. &amp; Büchel, C. The parietal operculum preferentially encodes heat pain and not salience. <i>PLoS Biol.</i> <b>17</b>, e3000205 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pbio.3000205" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pbio.3000205" aria-label="Article reference 25" data-doi="10.1371/journal.pbio.3000205">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXisVGqu7fN" aria-label="CAS reference 25">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31404058" aria-label="PubMed reference 25">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6705876" aria-label="PubMed Central reference 25">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20parietal%20operculum%20preferentially%20encodes%20heat%20pain%20and%20not%20salience&amp;journal=PLoS%20Biol.&amp;doi=10.1371%2Fjournal.pbio.3000205&amp;volume=17&amp;publication_year=2019&amp;author=Horing%2CB&amp;author=Sprenger%2CC&amp;author=B%C3%BCchel%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Wager, T. D. et al. A Bayesian model of category-specific emotional brain responses. <i>PLoS Comput. Biol.</i> <b>11</b>, e1004066 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1004066" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1004066" aria-label="Article reference 26" data-doi="10.1371/journal.pcbi.1004066">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25853490" aria-label="PubMed reference 26">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4390279" aria-label="PubMed Central reference 26">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Bayesian%20model%20of%20category-specific%20emotional%20brain%20responses&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1004066&amp;volume=11&amp;publication_year=2015&amp;author=Wager%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Kragel, P. A., Reddan, M. C., LaBar, K. S. &amp; Wager, T. D. Emotion schemas are embedded in the human visual system. <i>Sci. Adv.</i> <b>5</b>, eaaw4358 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/sciadv.aaw4358" data-track-action="article reference" href="https://doi.org/10.1126%2Fsciadv.aaw4358" aria-label="Article reference 27" data-doi="10.1126/sciadv.aaw4358">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31355334" aria-label="PubMed reference 27">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6656543" aria-label="PubMed Central reference 27">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotion%20schemas%20are%20embedded%20in%20the%20human%20visual%20system&amp;journal=Sci.%20Adv.&amp;doi=10.1126%2Fsciadv.aaw4358&amp;volume=5&amp;publication_year=2019&amp;author=Kragel%2CPA&amp;author=Reddan%2CMC&amp;author=LaBar%2CKS&amp;author=Wager%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Corder, G. et al. An amygdalar neural ensemble that encodes the unpleasantness of pain. <i>Science</i> <b>363</b>, 276–281 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aap8586" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aap8586" aria-label="Article reference 28" data-doi="10.1126/science.aap8586">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXpvFCntw%3D%3D" aria-label="CAS reference 28">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30655440" aria-label="PubMed reference 28">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20amygdalar%20neural%20ensemble%20that%20encodes%20the%20unpleasantness%20of%20pain&amp;journal=Science&amp;doi=10.1126%2Fscience.aap8586&amp;volume=363&amp;pages=276-281&amp;publication_year=2019&amp;author=Corder%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Hua, T. et al. General anesthetics activate a potent central pain-suppression circuit in the amygdala. <i>Nat. Neurosci.</i> <b>23</b>, 854–868 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-020-0632-8" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-020-0632-8" aria-label="Article reference 29" data-doi="10.1038/s41593-020-0632-8">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXpsFyisL0%3D" aria-label="CAS reference 29">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32424286" aria-label="PubMed reference 29">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7329612" aria-label="PubMed Central reference 29">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=General%20anesthetics%20activate%20a%20potent%20central%20pain-suppression%20circuit%20in%20the%20amygdala&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-020-0632-8&amp;volume=23&amp;pages=854-868&amp;publication_year=2020&amp;author=Hua%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Chiang, M. C. et al. Divergent neural pathways emanating from the lateral parabrachial nucleus mediate distinct components of the pain response. <i>Neuron</i> <b>106</b>, 927–939 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2020.03.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2020.03.014" aria-label="Article reference 30" data-doi="10.1016/j.neuron.2020.03.014">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXntlSjtro%3D" aria-label="CAS reference 30">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32289251" aria-label="PubMed reference 30">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Divergent%20neural%20pathways%20emanating%20from%20the%20lateral%20parabrachial%20nucleus%20mediate%20distinct%20components%20of%20the%20pain%20response&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2020.03.014&amp;volume=106&amp;pages=927-939&amp;publication_year=2020&amp;author=Chiang%2CMC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Allen, W. E. et al. Thirst-associated preoptic neurons encode an aversive motivational drive. <i>Science</i> <b>357</b>, 1149–1155 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aan6747" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aan6747" aria-label="Article reference 31" data-doi="10.1126/science.aan6747">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXhsVOitbbF" aria-label="CAS reference 31">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28912243" aria-label="PubMed reference 31">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5723384" aria-label="PubMed Central reference 31">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Thirst-associated%20preoptic%20neurons%20encode%20an%20aversive%20motivational%20drive&amp;journal=Science&amp;doi=10.1126%2Fscience.aan6747&amp;volume=357&amp;pages=1149-1155&amp;publication_year=2017&amp;author=Allen%2CWE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Allen, W. E. et al. Thirst regulates motivated behavior through modulation of brainwide neural population dynamics. <i>Science</i> <b>364</b>, 253 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aav3932" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aav3932" aria-label="Article reference 32" data-doi="10.1126/science.aav3932">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30948440" aria-label="PubMed reference 32">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6711472" aria-label="PubMed Central reference 32">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Thirst%20regulates%20motivated%20behavior%20through%20modulation%20of%20brainwide%20neural%20population%20dynamics&amp;journal=Science&amp;doi=10.1126%2Fscience.aav3932&amp;volume=364&amp;publication_year=2019&amp;author=Allen%2CWE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Pool, A.-H. et al. The cellular basis of distinct thirst modalities. <i>Nature</i> <b>588</b>, 112–117 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-020-2821-8" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-020-2821-8" aria-label="Article reference 33" data-doi="10.1038/s41586-020-2821-8">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33057193" aria-label="PubMed reference 33">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7718410" aria-label="PubMed Central reference 33">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20cellular%20basis%20of%20distinct%20thirst%20modalities&amp;journal=Nature&amp;doi=10.1038%2Fs41586-020-2821-8&amp;volume=588&amp;pages=112-117&amp;publication_year=2020&amp;author=Pool%2CA-H">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">McIntosh, A. R. &amp; Lobaugh, N. J. Partial least squares analysis of neuroimaging data: applications and advances. <i>Neuroimage</i> <b>23</b>, 250–263 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2004.07.020" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2004.07.020" aria-label="Article reference 34" data-doi="10.1016/j.neuroimage.2004.07.020">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Partial%20least%20squares%20analysis%20of%20neuroimaging%20data%3A%20applications%20and%20advances&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2004.07.020&amp;volume=23&amp;pages=250-263&amp;publication_year=2004&amp;author=McIntosh%2CAR&amp;author=Lobaugh%2CNJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Wold, S., Sjöström, M. &amp; Eriksson, L. PLS-regression: a basic tool of chemometrics. <i>Chemom. Intell. Lab. Syst.</i> <b>58</b>, 109–130 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0169-7439(01)00155-1" data-track-action="article reference" href="https://doi.org/10.1016%2FS0169-7439%2801%2900155-1" aria-label="Article reference 35" data-doi="10.1016/S0169-7439(01)00155-1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXotF2mtLw%3D" aria-label="CAS reference 35">CAS</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=PLS-regression%3A%20a%20basic%20tool%20of%20chemometrics&amp;journal=Chemom.%20Intell.%20Lab.%20Syst.&amp;doi=10.1016%2FS0169-7439%2801%2900155-1&amp;volume=58&amp;pages=109-130&amp;publication_year=2001&amp;author=Wold%2CS&amp;author=Sj%C3%B6str%C3%B6m%2CM&amp;author=Eriksson%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Woo, C.-W., Chang, L. J., Lindquist, M. A. &amp; Wager, T. D. Building better biomarkers: brain models in translational neuroimaging. <i>Nat. Neurosci.</i> <b>20</b>, 365–377 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4478" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4478" aria-label="Article reference 36" data-doi="10.1038/nn.4478">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXjsVSmsr8%3D" aria-label="CAS reference 36">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28230847" aria-label="PubMed reference 36">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5988350" aria-label="PubMed Central reference 36">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Building%20better%20biomarkers%3A%20brain%20models%20in%20translational%20neuroimaging&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4478&amp;volume=20&amp;pages=365-377&amp;publication_year=2017&amp;author=Woo%2CC-W&amp;author=Chang%2CLJ&amp;author=Lindquist%2CMA&amp;author=Wager%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Poldrack, R. A., Huckins, G. &amp; Varoquaux, G. Establishment of best practices for evidence for prediction: a review. <i>JAMA Psychiatry</i> <b>77</b>, 534–540 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/jamapsychiatry.2019.3671" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamapsychiatry.2019.3671" aria-label="Article reference 37" data-doi="10.1001/jamapsychiatry.2019.3671">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31774490" aria-label="PubMed reference 37">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7250718" aria-label="PubMed Central reference 37">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Establishment%20of%20best%20practices%20for%20evidence%20for%20prediction%3A%20a%20review&amp;journal=JAMA%20Psychiatry&amp;doi=10.1001%2Fjamapsychiatry.2019.3671&amp;volume=77&amp;pages=534-540&amp;publication_year=2020&amp;author=Poldrack%2CRA&amp;author=Huckins%2CG&amp;author=Varoquaux%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Nimon, K., Lewis, M., Kane, R. &amp; Haynes, R. M. An R package to compute commonality coefficients in the multiple regression case: an introduction to the package and a practical example. <i>Behav. Res. Methods</i> <b>40</b>, 457–466 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/BRM.40.2.457" data-track-action="article reference" href="https://doi.org/10.3758%2FBRM.40.2.457" aria-label="Article reference 38" data-doi="10.3758/BRM.40.2.457">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18522056" aria-label="PubMed reference 38">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20R%20package%20to%20compute%20commonality%20coefficients%20in%20the%20multiple%20regression%20case%3A%20an%20introduction%20to%20the%20package%20and%20a%20practical%20example&amp;journal=Behav.%20Res.%20Methods&amp;doi=10.3758%2FBRM.40.2.457&amp;volume=40&amp;pages=457-466&amp;publication_year=2008&amp;author=Nimon%2CK&amp;author=Lewis%2CM&amp;author=Kane%2CR&amp;author=Haynes%2CRM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Haufe, S. et al. On the interpretation of weight vectors of linear models in multivariate neuroimaging. <i>Neuroimage</i> <b>87</b>, 96–110 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2013.10.067" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2013.10.067" aria-label="Article reference 39" data-doi="10.1016/j.neuroimage.2013.10.067">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24239590" aria-label="PubMed reference 39">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20interpretation%20of%20weight%20vectors%20of%20linear%20models%20in%20multivariate%20neuroimaging&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2013.10.067&amp;volume=87&amp;pages=96-110&amp;publication_year=2014&amp;author=Haufe%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Hayes, D. J. &amp; Northoff, G. Identifying a network of brain regions involved in aversion-related processing: a cross-species translational investigation. <i>Front. Integr. Neurosci.</i> <b>5</b>, 49 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fnint.2011.00049" data-track-action="article reference" href="https://doi.org/10.3389%2Ffnint.2011.00049" aria-label="Article reference 40" data-doi="10.3389/fnint.2011.00049">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22102836" aria-label="PubMed reference 40">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3215229" aria-label="PubMed Central reference 40">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Identifying%20a%20network%20of%20brain%20regions%20involved%20in%20aversion-related%20processing%3A%20a%20cross-species%20translational%20investigation&amp;journal=Front.%20Integr.%20Neurosci.&amp;doi=10.3389%2Ffnint.2011.00049&amp;volume=5&amp;publication_year=2011&amp;author=Hayes%2CDJ&amp;author=Northoff%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Lindquist, K. A., Satpute, A. B., Wager, T. D., Weber, J. &amp; Barrett, L. F. The brain basis of positive and negative affect: evidence from a meta-analysis of the human neuroimaging literature. <i>Cereb. Cortex</i> <b>26</b>, 1910–1922 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhv001" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhv001" aria-label="Article reference 41" data-doi="10.1093/cercor/bhv001">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25631056" aria-label="PubMed reference 41">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20brain%20basis%20of%20positive%20and%20negative%20affect%3A%20evidence%20from%20a%20meta-analysis%20of%20the%20human%20neuroimaging%20literature&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhv001&amp;volume=26&amp;pages=1910-1922&amp;publication_year=2016&amp;author=Lindquist%2CKA&amp;author=Satpute%2CAB&amp;author=Wager%2CTD&amp;author=Weber%2CJ&amp;author=Barrett%2CLF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Panzeri, S., Macke, J. H., Gross, J. &amp; Kayser, C. Neural population coding: combining insights from microscopic and mass signals. <i>Trends Cogn. Sci.</i> <b>19</b>, 162–172 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2015.01.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2015.01.002" aria-label="Article reference 42" data-doi="10.1016/j.tics.2015.01.002">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25670005" aria-label="PubMed reference 42">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4379382" aria-label="PubMed Central reference 42">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20population%20coding%3A%20combining%20insights%20from%20microscopic%20and%20mass%20signals&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2015.01.002&amp;volume=19&amp;pages=162-172&amp;publication_year=2015&amp;author=Panzeri%2CS&amp;author=Macke%2CJH&amp;author=Gross%2CJ&amp;author=Kayser%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Mouraux, A., Diukova, A., Lee, M. C., Wise, R. G. &amp; Iannetti, G. D. A multisensory investigation of the functional significance of the ‘pain matrix’. <i>Neuroimage</i> <b>54</b>, 2237–2249 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.09.084" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.09.084" aria-label="Article reference 43" data-doi="10.1016/j.neuroimage.2010.09.084">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20932917" aria-label="PubMed reference 43">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20multisensory%20investigation%20of%20the%20functional%20significance%20of%20the%20%E2%80%98pain%20matrix%E2%80%99&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.09.084&amp;volume=54&amp;pages=2237-2249&amp;publication_year=2011&amp;author=Mouraux%2CA&amp;author=Diukova%2CA&amp;author=Lee%2CMC&amp;author=Wise%2CRG&amp;author=Iannetti%2CGD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Liang, M., Mouraux, A., Hu, L. &amp; Iannetti, G. D. Primary sensory cortices contain distinguishable spatial patterns of activity for each sense. <i>Nat. Commun.</i> <b>4</b>, 1979 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/ncomms2979" data-track-action="article reference" href="https://doi.org/10.1038%2Fncomms2979" aria-label="Article reference 44" data-doi="10.1038/ncomms2979">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3sjgslygsA%3D%3D" aria-label="CAS reference 44">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23752667" aria-label="PubMed reference 44">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Primary%20sensory%20cortices%20contain%20distinguishable%20spatial%20patterns%20of%20activity%20for%20each%20sense&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fncomms2979&amp;volume=4&amp;publication_year=2013&amp;author=Liang%2CM&amp;author=Mouraux%2CA&amp;author=Hu%2CL&amp;author=Iannetti%2CGD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">Shuler, M. G. &amp; Bear, M. F. Reward timing in the primary visual cortex. <i>Science</i> <b>311</b>, 1606–1609 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1123513" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1123513" aria-label="Article reference 45" data-doi="10.1126/science.1123513">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD28XitlSnsLg%3D" aria-label="CAS reference 45">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16543459" aria-label="PubMed reference 45">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Reward%20timing%20in%20the%20primary%20visual%20cortex&amp;journal=Science&amp;doi=10.1126%2Fscience.1123513&amp;volume=311&amp;pages=1606-1609&amp;publication_year=2006&amp;author=Shuler%2CMG&amp;author=Bear%2CMF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Kragel, P. A. et al. A human colliculus-pulvinar-amygdala pathway encodes negative emotion. <i>Neuron</i> <a href="https://doi.org/10.1016/j.neuron.2021.06.001" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.neuron.2021.06.001">https://doi.org/10.1016/j.neuron.2021.06.001</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Pessoa, L. &amp; Adolphs, R. Emotion processing and the amygdala: from a ‘low road’ to ‘many roads’ of evaluating biological significance. <i>Nat. Rev. Neurosci.</i> <b>11</b>, 773–783 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn2920" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2920" aria-label="Article reference 47" data-doi="10.1038/nrn2920">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXhtlWmu7bJ" aria-label="CAS reference 47">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20959860" aria-label="PubMed reference 47">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025529" aria-label="PubMed Central reference 47">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotion%20processing%20and%20the%20amygdala%3A%20from%20a%20%E2%80%98low%20road%E2%80%99%20to%20%E2%80%98many%20roads%E2%80%99%20of%20evaluating%20biological%20significance&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2920&amp;volume=11&amp;pages=773-783&amp;publication_year=2010&amp;author=Pessoa%2CL&amp;author=Adolphs%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Chen, C., Cheng, M., Ito, T. &amp; Song, S. Neuronal organization in the inferior colliculus revisited with cell-type-dependent monosynaptic tracing. <i>J. Neurosci.</i> <b>38</b>, 3318–3332 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2173-17.2018" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2173-17.2018" aria-label="Article reference 48" data-doi="10.1523/JNEUROSCI.2173-17.2018">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXhslWmt7zK" aria-label="CAS reference 48">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29483283" aria-label="PubMed reference 48">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6596054" aria-label="PubMed Central reference 48">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuronal%20organization%20in%20the%20inferior%20colliculus%20revisited%20with%20cell-type-dependent%20monosynaptic%20tracing&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2173-17.2018&amp;volume=38&amp;pages=3318-3332&amp;publication_year=2018&amp;author=Chen%2CC&amp;author=Cheng%2CM&amp;author=Ito%2CT&amp;author=Song%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Tan, L. L. &amp; Kuner, R. Neocortical circuits in pain and pain relief. <i>Nat. Rev. Neurosci.</i> <b>22</b>, 458–471 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41583-021-00468-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41583-021-00468-2" aria-label="Article reference 49" data-doi="10.1038/s41583-021-00468-2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXhtlaitrnM" aria-label="CAS reference 49">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34127843" aria-label="PubMed reference 49">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Neocortical%20circuits%20in%20pain%20and%20pain%20relief&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fs41583-021-00468-2&amp;volume=22&amp;pages=458-471&amp;publication_year=2021&amp;author=Tan%2CLL&amp;author=Kuner%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">Mogil, J. S. The genetic mediation of individual differences in sensitivity to pain and its inhibition. <i>Proc. Natl Acad. Sci. USA</i> <b>96</b>, 7744–7751 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.96.14.7744" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.96.14.7744" aria-label="Article reference 50" data-doi="10.1073/pnas.96.14.7744">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXltVOktrc%3D" aria-label="CAS reference 50">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10393892" aria-label="PubMed reference 50">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC33613" aria-label="PubMed Central reference 50">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20genetic%20mediation%20of%20individual%20differences%20in%20sensitivity%20to%20pain%20and%20its%20inhibition&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.96.14.7744&amp;volume=96&amp;pages=7744-7751&amp;publication_year=1999&amp;author=Mogil%2CJS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Baron, R. et al. Peripheral neuropathic pain: a mechanism-related organizing principle based on sensory profiles. <i>Pain</i> <b>158</b>, 261–272 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/j.pain.0000000000000753" data-track-action="article reference" href="https://doi.org/10.1097%2Fj.pain.0000000000000753" aria-label="Article reference 51" data-doi="10.1097/j.pain.0000000000000753">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27893485" aria-label="PubMed reference 51">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Peripheral%20neuropathic%20pain%3A%20a%20mechanism-related%20organizing%20principle%20based%20on%20sensory%20profiles&amp;journal=Pain&amp;doi=10.1097%2Fj.pain.0000000000000753&amp;volume=158&amp;pages=261-272&amp;publication_year=2017&amp;author=Baron%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Price, D. D. Psychological and neural mechanisms of the affective dimension of pain. <i>Science</i> <b>288</b>, 1769–1772 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.288.5472.1769" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.288.5472.1769" aria-label="Article reference 52" data-doi="10.1126/science.288.5472.1769">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3cXjvFCisrw%3D" aria-label="CAS reference 52">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10846154" aria-label="PubMed reference 52">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Psychological%20and%20neural%20mechanisms%20of%20the%20affective%20dimension%20of%20pain&amp;journal=Science&amp;doi=10.1126%2Fscience.288.5472.1769&amp;volume=288&amp;pages=1769-1772&amp;publication_year=2000&amp;author=Price%2CDD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Satpute, A. B. et al. Identification of discrete functional subregions of the human periaqueductal gray. <i>Proc. Natl Acad. Sci. USA</i> <b>110</b>, 17101–17106 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1306095110" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1306095110" aria-label="Article reference 53" data-doi="10.1073/pnas.1306095110">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhslejsbbJ" aria-label="CAS reference 53">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24082116" aria-label="PubMed reference 53">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3801046" aria-label="PubMed Central reference 53">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=Identification%20of%20discrete%20functional%20subregions%20of%20the%20human%20periaqueductal%20gray&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1306095110&amp;volume=110&amp;pages=17101-17106&amp;publication_year=2013&amp;author=Satpute%2CAB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54."><p class="c-article-references__text" id="ref-CR54">Craig, A. D., Bushnell, M. C., Zhang, E. T. &amp; Blomqvist, A. A thalamic nucleus specific for pain and temperature sensation. <i>Nature</i> <b>372</b>, 770–773 (1994).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/372770a0" data-track-action="article reference" href="https://doi.org/10.1038%2F372770a0" aria-label="Article reference 54" data-doi="10.1038/372770a0">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK2MXivVSjsr8%3D" aria-label="CAS reference 54">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7695716" aria-label="PubMed reference 54">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20thalamic%20nucleus%20specific%20for%20pain%20and%20temperature%20sensation&amp;journal=Nature&amp;doi=10.1038%2F372770a0&amp;volume=372&amp;pages=770-773&amp;publication_year=1994&amp;author=Craig%2CAD&amp;author=Bushnell%2CMC&amp;author=Zhang%2CET&amp;author=Blomqvist%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55."><p class="c-article-references__text" id="ref-CR55">Woo, C.-W. et al. Quantifying cerebral contributions to pain beyond nociception. <i>Nat. Commun.</i> <b>8</b>, 14211 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/ncomms14211" data-track-action="article reference" href="https://doi.org/10.1038%2Fncomms14211" aria-label="Article reference 55" data-doi="10.1038/ncomms14211">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXislOhsbw%3D" aria-label="CAS reference 55">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28195170" aria-label="PubMed reference 55">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5316889" aria-label="PubMed Central reference 55">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantifying%20cerebral%20contributions%20to%20pain%20beyond%20nociception&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fncomms14211&amp;volume=8&amp;publication_year=2017&amp;author=Woo%2CC-W">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56."><p class="c-article-references__text" id="ref-CR56">Anderson, A. K. &amp; Sobel, N. Dissociating intensity from valence as sensory inputs to emotion. <i>Neuron</i> <b>39</b>, 581–583 (2003).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(03)00504-X" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2803%2900504-X" aria-label="Article reference 56" data-doi="10.1016/S0896-6273(03)00504-X">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3sXmslOmurs%3D" aria-label="CAS reference 56">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12925272" aria-label="PubMed reference 56">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Dissociating%20intensity%20from%20valence%20as%20sensory%20inputs%20to%20emotion&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2803%2900504-X&amp;volume=39&amp;pages=581-583&amp;publication_year=2003&amp;author=Anderson%2CAK&amp;author=Sobel%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57."><p class="c-article-references__text" id="ref-CR57">Wehrum, S. et al. Gender commonalities and differences in the neural processing of visual sexual stimuli. <i>J. Sex. Med.</i> <b>10</b>, 1328–1342 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/jsm.12096" data-track-action="article reference" href="https://doi.org/10.1111%2Fjsm.12096" aria-label="Article reference 57" data-doi="10.1111/jsm.12096">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23421466" aria-label="PubMed reference 57">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 57" href="http://scholar.google.com/scholar_lookup?&amp;title=Gender%20commonalities%20and%20differences%20in%20the%20neural%20processing%20of%20visual%20sexual%20stimuli&amp;journal=J.%20Sex.%20Med.&amp;doi=10.1111%2Fjsm.12096&amp;volume=10&amp;pages=1328-1342&amp;publication_year=2013&amp;author=Wehrum%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58."><p class="c-article-references__text" id="ref-CR58">Neugebauer, V. Amygdala pain mechanisms. <i>Handb. Exp. Pharmacol.</i> <b>227</b>, 261–284 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1007/978-3-662-46450-2_13" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/978-3-662-46450-2_13" aria-label="Article reference 58" data-doi="10.1007/978-3-662-46450-2_13">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28XnsFaqtrw%3D" aria-label="CAS reference 58">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25846623" aria-label="PubMed reference 58">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4701385" aria-label="PubMed Central reference 58">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Amygdala%20pain%20mechanisms&amp;journal=Handb.%20Exp.%20Pharmacol.&amp;doi=10.1007%2F978-3-662-46450-2_13&amp;volume=227&amp;pages=261-284&amp;publication_year=2015&amp;author=Neugebauer%2CV">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59."><p class="c-article-references__text" id="ref-CR59">Kim, J., Shinkareva, S. V. &amp; Wedell, D. H. Representations of modality-general valence for videos and music derived from fMRI data. <i>Neuroimage</i> <b>148</b>, 42–54 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2017.01.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2017.01.002" aria-label="Article reference 59" data-doi="10.1016/j.neuroimage.2017.01.002">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28057489" aria-label="PubMed reference 59">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 59" href="http://scholar.google.com/scholar_lookup?&amp;title=Representations%20of%20modality-general%20valence%20for%20videos%20and%20music%20derived%20from%20fMRI%20data&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2017.01.002&amp;volume=148&amp;pages=42-54&amp;publication_year=2017&amp;author=Kim%2CJ&amp;author=Shinkareva%2CSV&amp;author=Wedell%2CDH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60."><p class="c-article-references__text" id="ref-CR60">Li, J., Schiller, D., Schoenbaum, G., Phelps, E. A. &amp; Daw, N. D. Differential roles of human striatum and amygdala in associative learning. <i>Nat. Neurosci.</i> <b>14</b>, 1250–1252 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.2904" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.2904" aria-label="Article reference 60" data-doi="10.1038/nn.2904">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhtFGnur%2FP" aria-label="CAS reference 60">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21909088" aria-label="PubMed reference 60">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3268261" aria-label="PubMed Central reference 60">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 60" href="http://scholar.google.com/scholar_lookup?&amp;title=Differential%20roles%20of%20human%20striatum%20and%20amygdala%20in%20associative%20learning&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.2904&amp;volume=14&amp;pages=1250-1252&amp;publication_year=2011&amp;author=Li%2CJ&amp;author=Schiller%2CD&amp;author=Schoenbaum%2CG&amp;author=Phelps%2CEA&amp;author=Daw%2CND">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61."><p class="c-article-references__text" id="ref-CR61">Belova, M. A., Paton, J. J. &amp; Salzman, C. D. Moment-to-moment tracking of state value in the amygdala. <i>J. Neurosci.</i> <b>28</b>, 10023–10030 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1400-08.2008" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1400-08.2008" aria-label="Article reference 61" data-doi="10.1523/JNEUROSCI.1400-08.2008">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXht1ChsLnE" aria-label="CAS reference 61">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18829960" aria-label="PubMed reference 61">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2610542" aria-label="PubMed Central reference 61">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 61" href="http://scholar.google.com/scholar_lookup?&amp;title=Moment-to-moment%20tracking%20of%20state%20value%20in%20the%20amygdala&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1400-08.2008&amp;volume=28&amp;pages=10023-10030&amp;publication_year=2008&amp;author=Belova%2CMA&amp;author=Paton%2CJJ&amp;author=Salzman%2CCD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62."><p class="c-article-references__text" id="ref-CR62">Hayes, D. J. &amp; Northoff, G. Common brain activations for painful and non-painful aversive stimuli. <i>BMC Neurosci.</i> <b>13</b>, 60 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="noopener" data-track-label="10.1186/1471-2202-13-60" data-track-action="article reference" href="https://link.springer.com/doi/10.1186/1471-2202-13-60" aria-label="Article reference 62" data-doi="10.1186/1471-2202-13-60">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22676259" aria-label="PubMed reference 62">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3464596" aria-label="PubMed Central reference 62">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Common%20brain%20activations%20for%20painful%20and%20non-painful%20aversive%20stimuli&amp;journal=BMC%20Neurosci.&amp;doi=10.1186%2F1471-2202-13-60&amp;volume=13&amp;publication_year=2012&amp;author=Hayes%2CDJ&amp;author=Northoff%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63."><p class="c-article-references__text" id="ref-CR63">Villemure, C. &amp; Bushnell, M. C. Mood influences supraspinal pain processing separately from attention. <i>J. Neurosci.</i> <b>29</b>, 705–715 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.3822-08.2009" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.3822-08.2009" aria-label="Article reference 63" data-doi="10.1523/JNEUROSCI.3822-08.2009">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhsVCnt7o%3D" aria-label="CAS reference 63">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19158297" aria-label="PubMed reference 63">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2768393" aria-label="PubMed Central reference 63">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="http://scholar.google.com/scholar_lookup?&amp;title=Mood%20influences%20supraspinal%20pain%20processing%20separately%20from%20attention&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.3822-08.2009&amp;volume=29&amp;pages=705-715&amp;publication_year=2009&amp;author=Villemure%2CC&amp;author=Bushnell%2CMC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="64."><p class="c-article-references__text" id="ref-CR64">Roy, M., Piché, M., Chen, J.-I., Peretz, I. &amp; Rainville, P. Cerebral and spinal modulation of pain by emotions. <i>Proc. Natl Acad. Sci. USA</i> <b>106</b>, 20900–20905 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.0904706106" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.0904706106" aria-label="Article reference 64" data-doi="10.1073/pnas.0904706106">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXksFyjug%3D%3D" aria-label="CAS reference 64">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19926861" aria-label="PubMed reference 64">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2779826" aria-label="PubMed Central reference 64">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=Cerebral%20and%20spinal%20modulation%20of%20pain%20by%20emotions&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.0904706106&amp;volume=106&amp;pages=20900-20905&amp;publication_year=2009&amp;author=Roy%2CM&amp;author=Pich%C3%A9%2CM&amp;author=Chen%2CJ-I&amp;author=Peretz%2CI&amp;author=Rainville%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="65."><p class="c-article-references__text" id="ref-CR65">Anders, S., Eippert, F., Weiskopf, N. &amp; Veit, R. The human amygdala is sensitive to the valence of pictures and sounds irrespective of arousal: an fMRI study. <i>Soc. Cogn. Affect. Neurosci.</i> <b>3</b>, 233–243 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/scan/nsn017" data-track-action="article reference" href="https://doi.org/10.1093%2Fscan%2Fnsn017" aria-label="Article reference 65" data-doi="10.1093/scan/nsn017">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19015115" aria-label="PubMed reference 65">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2566767" aria-label="PubMed Central reference 65">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20human%20amygdala%20is%20sensitive%20to%20the%20valence%20of%20pictures%20and%20sounds%20irrespective%20of%20arousal%3A%20an%20fMRI%20study&amp;journal=Soc.%20Cogn.%20Affect.%20Neurosci.&amp;doi=10.1093%2Fscan%2Fnsn017&amp;volume=3&amp;pages=233-243&amp;publication_year=2008&amp;author=Anders%2CS&amp;author=Eippert%2CF&amp;author=Weiskopf%2CN&amp;author=Veit%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="66."><p class="c-article-references__text" id="ref-CR66">Woo, C.-W. et al. Separate neural representations for physical pain and social rejection. <i>Nat. Commun.</i> <b>5</b>, 5380 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/ncomms6380" data-track-action="article reference" href="https://doi.org/10.1038%2Fncomms6380" aria-label="Article reference 66" data-doi="10.1038/ncomms6380">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25400102" aria-label="PubMed reference 66">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="http://scholar.google.com/scholar_lookup?&amp;title=Separate%20neural%20representations%20for%20physical%20pain%20and%20social%20rejection&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fncomms6380&amp;volume=5&amp;publication_year=2014&amp;author=Woo%2CC-W">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="67."><p class="c-article-references__text" id="ref-CR67">Peelen, M. V. &amp; Downing, P. E. Using multi-voxel pattern analysis of fMRI data to interpret overlapping functional activations. <i>Trends Cogn. Sci.</i> <b>11</b>, 4–5 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2006.10.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2006.10.009" aria-label="Article reference 67" data-doi="10.1016/j.tics.2006.10.009">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17129747" aria-label="PubMed reference 67">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20multi-voxel%20pattern%20analysis%20of%20fMRI%20data%20to%20interpret%20overlapping%20functional%20activations&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2006.10.009&amp;volume=11&amp;pages=4-5&amp;publication_year=2007&amp;author=Peelen%2CMV&amp;author=Downing%2CPE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="68."><p class="c-article-references__text" id="ref-CR68">Tomova, L. et al. Acute social isolation evokes midbrain craving responses similar to hunger. <i>Nat. Neurosci.</i> <b>23</b>, 1597–1605 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-020-00742-z" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-020-00742-z" aria-label="Article reference 68" data-doi="10.1038/s41593-020-00742-z">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXisVSlu7bJ" aria-label="CAS reference 68">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33230328" aria-label="PubMed reference 68">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8580014" aria-label="PubMed Central reference 68">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=Acute%20social%20isolation%20evokes%20midbrain%20craving%20responses%20similar%20to%20hunger&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-020-00742-z&amp;volume=23&amp;pages=1597-1605&amp;publication_year=2020&amp;author=Tomova%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="69."><p class="c-article-references__text" id="ref-CR69">Woolf, C. J. Central sensitization: implications for the diagnosis and treatment of pain. <i>Pain</i> <b>152</b>, S2–S15 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.pain.2010.09.030" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.pain.2010.09.030" aria-label="Article reference 69" data-doi="10.1016/j.pain.2010.09.030">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20961685" aria-label="PubMed reference 69">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 69" href="http://scholar.google.com/scholar_lookup?&amp;title=Central%20sensitization%3A%20implications%20for%20the%20diagnosis%20and%20treatment%20of%20pain&amp;journal=Pain&amp;doi=10.1016%2Fj.pain.2010.09.030&amp;volume=152&amp;pages=S2-S15&amp;publication_year=2011&amp;author=Woolf%2CCJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="70."><p class="c-article-references__text" id="ref-CR70">Ceko, M., Bushnell, M. C., Fitzcharles, M.-A. &amp; Schweinhardt, P. Fibromyalgia interacts with age to change the brain. <i>Neuroimage Clin.</i> <b>3</b>, 249–260 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.nicl.2013.08.015" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.nicl.2013.08.015" aria-label="Article reference 70" data-doi="10.1016/j.nicl.2013.08.015">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24273710" aria-label="PubMed reference 70">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3814958" aria-label="PubMed Central reference 70">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 70" href="http://scholar.google.com/scholar_lookup?&amp;title=Fibromyalgia%20interacts%20with%20age%20to%20change%20the%20brain&amp;journal=Neuroimage%20Clin.&amp;doi=10.1016%2Fj.nicl.2013.08.015&amp;volume=3&amp;pages=249-260&amp;publication_year=2013&amp;author=Ceko%2CM&amp;author=Bushnell%2CMC&amp;author=Fitzcharles%2CM-A&amp;author=Schweinhardt%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="71."><p class="c-article-references__text" id="ref-CR71">López-Solà, M. et al. Towards a neurophysiological signature for fibromyalgia. <i>Pain</i> <b>158</b>, 34–47 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/j.pain.0000000000000707" data-track-action="article reference" href="https://doi.org/10.1097%2Fj.pain.0000000000000707" aria-label="Article reference 71" data-doi="10.1097/j.pain.0000000000000707">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27583567" aria-label="PubMed reference 71">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5161739" aria-label="PubMed Central reference 71">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 71" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20a%20neurophysiological%20signature%20for%20fibromyalgia&amp;journal=Pain&amp;doi=10.1097%2Fj.pain.0000000000000707&amp;volume=158&amp;pages=34-47&amp;publication_year=2017&amp;author=L%C3%B3pez-Sol%C3%A0%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="72."><p class="c-article-references__text" id="ref-CR72">Grothusen, J. R., Alexander, G., Erwin, K. &amp; Schwartzman, R. Thermal pain in complex regional pain syndrome type I. <i>Pain Physician</i> <b>17</b>, 71–79 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.36076/ppj.2014/17/71" data-track-action="article reference" href="https://doi.org/10.36076%2Fppj.2014%2F17%2F71" aria-label="Article reference 72" data-doi="10.36076/ppj.2014/17/71">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24452647" aria-label="PubMed reference 72">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 72" href="http://scholar.google.com/scholar_lookup?&amp;title=Thermal%20pain%20in%20complex%20regional%20pain%20syndrome%20type%20I&amp;journal=Pain%20Physician&amp;doi=10.36076%2Fppj.2014%2F17%2F71&amp;volume=17&amp;pages=71-79&amp;publication_year=2014&amp;author=Grothusen%2CJR&amp;author=Alexander%2CG&amp;author=Erwin%2CK&amp;author=Schwartzman%2CR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="73."><p class="c-article-references__text" id="ref-CR73">Eippert, F. et al. Activation of the opioidergic descending pain control system underlies placebo analgesia. <i>Neuron</i> <b>63</b>, 533–543 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2009.07.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2009.07.014" aria-label="Article reference 73" data-doi="10.1016/j.neuron.2009.07.014">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhsVCjsr7N" aria-label="CAS reference 73">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19709634" aria-label="PubMed reference 73">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 73" href="http://scholar.google.com/scholar_lookup?&amp;title=Activation%20of%20the%20opioidergic%20descending%20pain%20control%20system%20underlies%20placebo%20analgesia&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2009.07.014&amp;volume=63&amp;pages=533-543&amp;publication_year=2009&amp;author=Eippert%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="74."><p class="c-article-references__text" id="ref-CR74">Wager, T. D. et al. An fMRI-based neurologic signature of physical pain. <i>N. Engl. J. Med.</i> <b>368</b>, 1388–1397 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1056/NEJMoa1204471" data-track-action="article reference" href="https://doi.org/10.1056%2FNEJMoa1204471" aria-label="Article reference 74" data-doi="10.1056/NEJMoa1204471">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXmt1yhu7w%3D" aria-label="CAS reference 74">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23574118" aria-label="PubMed reference 74">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3691100" aria-label="PubMed Central reference 74">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 74" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20fMRI-based%20neurologic%20signature%20of%20physical%20pain&amp;journal=N.%20Engl.%20J.%20Med.&amp;doi=10.1056%2FNEJMoa1204471&amp;volume=368&amp;pages=1388-1397&amp;publication_year=2013&amp;author=Wager%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="75."><p class="c-article-references__text" id="ref-CR75">Bartoshuk, L. M. et al. Valid across-group comparisons with labeled scales: the gLMS versus magnitude matching. <i>Physiol. Behav.</i> <b>82</b>, 109–114 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.physbeh.2004.02.033" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.physbeh.2004.02.033" aria-label="Article reference 75" data-doi="10.1016/j.physbeh.2004.02.033">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2cXlsVWisrg%3D" aria-label="CAS reference 75">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15234598" aria-label="PubMed reference 75">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="http://scholar.google.com/scholar_lookup?&amp;title=Valid%20across-group%20comparisons%20with%20labeled%20scales%3A%20the%20gLMS%20versus%20magnitude%20matching&amp;journal=Physiol.%20Behav.&amp;doi=10.1016%2Fj.physbeh.2004.02.033&amp;volume=82&amp;pages=109-114&amp;publication_year=2004&amp;author=Bartoshuk%2CLM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="76."><p class="c-article-references__text" id="ref-CR76">Hayes, J. E., Allen, A. L. &amp; Bennett, S. M. Direct comparison of the generalized visual analog scale and general labeled magnitude scale. <i>Food Qual. Prefer.</i> <b>28</b>, 36–44 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.foodqual.2012.07.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.foodqual.2012.07.012" aria-label="Article reference 76" data-doi="10.1016/j.foodqual.2012.07.012">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23175601" aria-label="PubMed reference 76">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 76" href="http://scholar.google.com/scholar_lookup?&amp;title=Direct%20comparison%20of%20the%20generalized%20visual%20analog%20scale%20and%20general%20labeled%20magnitude%20scale&amp;journal=Food%20Qual.%20Prefer.&amp;doi=10.1016%2Fj.foodqual.2012.07.012&amp;volume=28&amp;pages=36-44&amp;publication_year=2013&amp;author=Hayes%2CJE&amp;author=Allen%2CAL&amp;author=Bennett%2CSM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="77."><p class="c-article-references__text" id="ref-CR77">Kumar, S., Forster, H. M., Bailey, P. &amp; Griffiths, T. D. Mapping unpleasantness of sounds to their auditory representation. <i>J. Acoust. Soc. Am.</i> <b>124</b>, 3810–3817 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1121/1.3006380" data-track-action="article reference" href="https://doi.org/10.1121%2F1.3006380" aria-label="Article reference 77" data-doi="10.1121/1.3006380">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19206807" aria-label="PubMed reference 77">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 77" href="http://scholar.google.com/scholar_lookup?&amp;title=Mapping%20unpleasantness%20of%20sounds%20to%20their%20auditory%20representation&amp;journal=J.%20Acoust.%20Soc.%20Am.&amp;doi=10.1121%2F1.3006380&amp;volume=124&amp;pages=3810-3817&amp;publication_year=2008&amp;author=Kumar%2CS&amp;author=Forster%2CHM&amp;author=Bailey%2CP&amp;author=Griffiths%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="78."><p class="c-article-references__text" id="ref-CR78">Kumar, S., von Kriegstein, K., Friston, K. &amp; Griffiths, T. D. Features versus feelings: dissociable representations of the acoustic features and valence of aversive sounds. <i>J. Neurosci.</i> <b>32</b>, 14184–14192 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1759-12.2012" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1759-12.2012" aria-label="Article reference 78" data-doi="10.1523/JNEUROSCI.1759-12.2012">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XhsFGlsb7P" aria-label="CAS reference 78">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23055488" aria-label="PubMed reference 78">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3505833" aria-label="PubMed Central reference 78">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 78" href="http://scholar.google.com/scholar_lookup?&amp;title=Features%20versus%20feelings%3A%20dissociable%20representations%20of%20the%20acoustic%20features%20and%20valence%20of%20aversive%20sounds&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1759-12.2012&amp;volume=32&amp;pages=14184-14192&amp;publication_year=2012&amp;author=Kumar%2CS&amp;author=Kriegstein%2CK&amp;author=Friston%2CK&amp;author=Griffiths%2CTD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="79."><p class="c-article-references__text" id="ref-CR79">Lang, P. J., Bradley, M. M. &amp; Cuthbert, B. N. International affective picture system (IAPS): affective ratings of pictures and instruction manual. <i>Technical Report A-8</i>. <i>University of Florida</i>, <i>Gainesville</i> (2008).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="80."><p class="c-article-references__text" id="ref-CR80">Op de Beeck, H. P. Against hyperacuity in brain reading: spatial smoothing does not hurt multivariate fMRI analyses? <i>Neuroimage</i> <b>49</b>, 1943–1948 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2009.02.047" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2009.02.047" aria-label="Article reference 80" data-doi="10.1016/j.neuroimage.2009.02.047">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19285144" aria-label="PubMed reference 80">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 80" href="http://scholar.google.com/scholar_lookup?&amp;title=Against%20hyperacuity%20in%20brain%20reading%3A%20spatial%20smoothing%20does%20not%20hurt%20multivariate%20fMRI%20analyses%3F&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2009.02.047&amp;volume=49&amp;pages=1943-1948&amp;publication_year=2010&amp;author=Op%20de%20Beeck%2CHP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="81."><p class="c-article-references__text" id="ref-CR81">Genovese, C. R., Lazar, N. A. &amp; Nichols, T. Thresholding of statistical maps in functional neuroimaging using the false discovery rate. <i>Neuroimage</i> <b>15</b>, 870–878 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1006/nimg.2001.1037" data-track-action="article reference" href="https://doi.org/10.1006%2Fnimg.2001.1037" aria-label="Article reference 81" data-doi="10.1006/nimg.2001.1037">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11906227" aria-label="PubMed reference 81">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 81" href="http://scholar.google.com/scholar_lookup?&amp;title=Thresholding%20of%20statistical%20maps%20in%20functional%20neuroimaging%20using%20the%20false%20discovery%20rate&amp;journal=Neuroimage&amp;doi=10.1006%2Fnimg.2001.1037&amp;volume=15&amp;pages=870-878&amp;publication_year=2002&amp;author=Genovese%2CCR&amp;author=Lazar%2CNA&amp;author=Nichols%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="82."><p class="c-article-references__text" id="ref-CR82">Thompson, B. &amp; Borrello, G. M. The importance of structure coefficients in regression research. <i>Educ. Psychol. Meas.</i> <b>45</b>, 203–209 (1985).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/001316448504500202" data-track-action="article reference" href="https://doi.org/10.1177%2F001316448504500202" aria-label="Article reference 82" data-doi="10.1177/001316448504500202">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 82" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20importance%20of%20structure%20coefficients%20in%20regression%20research&amp;journal=Educ.%20Psychol.%20Meas.&amp;doi=10.1177%2F001316448504500202&amp;volume=45&amp;pages=203-209&amp;publication_year=1985&amp;author=Thompson%2CB&amp;author=Borrello%2CGM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="83."><p class="c-article-references__text" id="ref-CR83">Parra, L. C., Spence, C. D., Gerson, A. D. &amp; Sajda, P. Recipes for the linear analysis of EEG. <i>Neuroimage</i> <b>28</b>, 326–341 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2005.05.032" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2005.05.032" aria-label="Article reference 83" data-doi="10.1016/j.neuroimage.2005.05.032">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16084117" aria-label="PubMed reference 83">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 83" href="http://scholar.google.com/scholar_lookup?&amp;title=Recipes%20for%20the%20linear%20analysis%20of%20EEG&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2005.05.032&amp;volume=28&amp;pages=326-341&amp;publication_year=2005&amp;author=Parra%2CLC&amp;author=Spence%2CCD&amp;author=Gerson%2CAD&amp;author=Sajda%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="84."><p class="c-article-references__text" id="ref-CR84">Kohoutová, L. et al. Toward a unified framework for interpreting machine-learning models in neuroimaging. <i>Nat. Protoc</i>. <a href="https://doi.org/10.1038/s41596-019-0289-5" data-track="click" data-track-action="external reference" data-track-label="10.1038/s41596-019-0289-5">https://doi.org/10.1038/s41596-019-0289-5</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="85."><p class="c-article-references__text" id="ref-CR85">Mumford, J. A. &amp; Nichols, T. Simple group fMRI modeling and inference. <i>Neuroimage</i> <b>47</b>, 1469–1475 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2009.05.034" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2009.05.034" aria-label="Article reference 85" data-doi="10.1016/j.neuroimage.2009.05.034">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19463958" aria-label="PubMed reference 85">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 85" href="http://scholar.google.com/scholar_lookup?&amp;title=Simple%20group%20fMRI%20modeling%20and%20inference&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2009.05.034&amp;volume=47&amp;pages=1469-1475&amp;publication_year=2009&amp;author=Mumford%2CJA&amp;author=Nichols%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="86."><p class="c-article-references__text" id="ref-CR86">Bota, M. &amp; Swanson, L. W. BAMS Neuroanatomical Ontology: design and implementation. <i>Front. Neuroinformatics</i> <b>2</b>, 2 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/neuro.11.002.2008" data-track-action="article reference" href="https://doi.org/10.3389%2Fneuro.11.002.2008" aria-label="Article reference 86" data-doi="10.3389/neuro.11.002.2008">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2525975" aria-label="PubMed Central reference 86">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 86" href="http://scholar.google.com/scholar_lookup?&amp;title=BAMS%20Neuroanatomical%20Ontology%3A%20design%20and%20implementation&amp;journal=Front.%20Neuroinformatics&amp;doi=10.3389%2Fneuro.11.002.2008&amp;volume=2&amp;publication_year=2008&amp;author=Bota%2CM&amp;author=Swanson%2CLW">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-022-01082-w?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We thank D. Ott, J. Griffin, E. Biringen and T. Wilkes for assistance with data collection; P. Gianaros for sharing data included in study 4 and R. Stark for sharing data included in study 6; and R. Botvinik-Nezer, K. Zorina-Lichtenwalter and B. Petre for helpful comments on earlier versions of the manuscript. This work was funded by NIH R01DA035484 (to T.D.W.). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Institute of Cognitive Science, University of Colorado, Boulder, CO, USA</p><p class="c-article-author-affiliation__authors-list">Marta Čeko, Philip A. Kragel &amp; Tor D. Wager</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Psychology, Emory University, Atlanta, GA, USA</p><p class="c-article-author-affiliation__authors-list">Philip A. Kragel</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Center for Neuroscience Imaging Research, Institute for Basic Science, Suwon, South Korea</p><p class="c-article-author-affiliation__authors-list">Choong-Wan Woo</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Department of Biomedical Engineering, Sungkyunkwan University, Suwon, South Korea</p><p class="c-article-author-affiliation__authors-list">Choong-Wan Woo</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">Department of Intelligent Precision Healthcare Convergence, Sungkyunkwan University, Suwon, South Korea</p><p class="c-article-author-affiliation__authors-list">Choong-Wan Woo</p></li><li id="Aff6"><p class="c-article-author-affiliation__address">Serra Hunter Programme, Department of Medicine, School of Medicine and Health Sciences, University of Barcelona, Barcelona, Spain</p><p class="c-article-author-affiliation__authors-list">Marina López-Solà</p></li><li id="Aff7"><p class="c-article-author-affiliation__address">Department of Psychological and Brain Sciences, Dartmouth College, Hanover, NH, USA</p><p class="c-article-author-affiliation__authors-list">Tor D. Wager</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Marta-_eko-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Marta Čeko</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Marta%20%C4%8Ceko" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Marta%20%C4%8Ceko" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Marta%20%C4%8Ceko%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Philip_A_-Kragel-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Philip A. Kragel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Philip%20A.%20Kragel" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Philip%20A.%20Kragel" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Philip%20A.%20Kragel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Choong_Wan-Woo-Aff3-Aff4-Aff5"><span class="c-article-authors-search__title u-h3 js-search-name">Choong-Wan Woo</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Choong-Wan%20Woo" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Choong-Wan%20Woo" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Choong-Wan%20Woo%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Marina-L_pez_Sol_-Aff6"><span class="c-article-authors-search__title u-h3 js-search-name">Marina López-Solà</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Marina%20L%C3%B3pez-Sol%C3%A0" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Marina%20L%C3%B3pez-Sol%C3%A0" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Marina%20L%C3%B3pez-Sol%C3%A0%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Tor_D_-Wager-Aff1-Aff7"><span class="c-article-authors-search__title u-h3 js-search-name">Tor D. Wager</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Tor%20D.%20Wager" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Tor%20D.%20Wager" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Tor%20D.%20Wager%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>M.C., C.-W.W., M.L.-S. and T.D.W. conceived and designed the experiment for studies 1 and 2, and P.A.K. and T.D.W. conceived and designed the experiment for study 3. M.C. and C.-W.W. collected and preprocessed the data for studies 1 and 2, and P.A.K. collected and preprocessed the data for study 3. M.C., P.A.K. and T.D.W. analyzed the data and interpreted the results. M.C. created the figures, with intellectual input from all other authors. M.C. and T.D.W. wrote the manuscript. All authors edited the manuscript.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:marta.ceko@colorado.edu">Marta Čeko</a> or <a id="corresp-c2" href="mailto:tor.d.wager@dartmouth.edu">Tor D. Wager</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar4">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div class="c-article-section" id="peer-review-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="peer-review">Peer review</h2><div class="c-article-section__content" id="peer-review-content">
              
              
                <h3 class="c-article__sub-heading" id="FPar3">Peer review information</h3>
                <p><i>Nature Neuroscience</i> thanks Junichi Chikazoe and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Extended data"><div class="c-article-section" id="Sec44-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec44">Extended data</h2><div class="c-article-section__content" id="Sec44-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig7"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 1 pls-r models trained to predi" href="/articles/s41593-022-01082-w/figures/7" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_Fig7_ESM.jpg">Extended Data Fig. 1 PLS-R models trained to predict normative ratings to negative (aversive) and positive (pleasant) IAPS images.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>(a)</b> PLS-R procedure to estimate brain patterns for ‘arousal’ (common across stimuli) and for stimulus type-specific outcomes (IAPS norm ratings) simultaneously <b>(b)</b> <i>Behavior plots</i>. <b>Left:</b> normative ratings shown for each individual stimulus (that is, IAPS image); original IAPS scales (1–9 scales for Valence (higher score = less negative / more positive; 0 is neutral) and Arousal (higher score = more arousing). <b>Right</b>: norm ratings averaged per bin (‘stimulus intensity level’, used for PLS-R training) and shown on a 0–4 split scale (higher score = more negative / more positive; 0 is neutral); <i>Pattern response plots</i>. Relationship between observed and predicted ratings. Circles reflect mean values across participants for each stimulus type, error bars reflect within-participant SEM. ‘Arousal’ model (panel 1), trained on all stimuli, significantly predicted ratings across stimulus types. Stimulus type-specific models (panels 2–3) significantly predicted ratings to target (color-matched), but not off-target stimulus type. <i>r</i>, mean within-participant Pearson correlation between predicted and observed ratings; two-sided P-values based on a 10,000 samples bootstrap test of within-participant <i>r</i> values<b>. (c) Left</b>: PLS-R model weight maps showing which brain areas make a reliable contribution to each model’s prediction (based on bootstrapping with 10,000 samples and displayed here at t &gt; 3, retaining positive values). <b>Right</b>: Model encoding maps showing where in the brain voxel-wise activity correlates with PLS model outcomes, corrected for multiple comparisons using q &lt; 0.05 FDR and thresholded at t &gt; 3, retaining positive values. <b>(d)</b> Violin plots showing average BOLD response per stimulus intensity (x-axis) in bilateral ventral striatum (vStr) and amygdala ROIs (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01082-w#MOESM1">7</a>), * p = 0.047, ** p = 0.002, * p &lt; 0.001 (left panels); Mean structure coefficient values for each model, averaged across in-ROI voxels across both hemispheres, * p &lt; 0.001, only p-values associated with positive t-values are marked and interpreted, each dot is a participant (right panels); one-sample t-test on n = 55 participants, treating participant as random effect, bars reflect mean values across participants for each stimulus type, error bars reflect within-participant SEM.<b>(e)</b> 3D surface maps of vStr and amy are displaying FDR-corrected model encoding maps for PLS ‘norm’ models of positive and negative images, and for the PLS model trained on participants’ ratings of negative images (Analysis 1).</p></div></div></div></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec45-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec45">Supplementary information</h2><div class="c-article-section__content" id="Sec45-content"><div data-test="supplementary-info"><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary information" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_MOESM1_ESM.pdf" data-supp-info-image="">Supplementary Information</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Supplementary Methods, Figs. 1–4 and Tables 1–10</p></div></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM2"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="reporting summary" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-022-01082-w/MediaObjects/41593_2022_1082_MOESM2_ESM.pdf" data-supp-info-image="">Reporting Summary</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Common%20and%20stimulus-type-specific%20brain%20representations%20of%20negative%20affect&amp;author=Marta%20%C4%8Ceko%20et%20al&amp;contentID=10.1038%2Fs41593-022-01082-w&amp;copyright=The%20Author%28s%29%2C%20under%20exclusive%20licence%20to%20Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2022-05-30&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41593-022-01082-w" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41593-022-01082-w" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Čeko, M., Kragel, P.A., Woo, CW. <i>et al.</i> Common and stimulus-type-specific brain representations of negative affect.
                    <i>Nat Neurosci</i> <b>25</b>, 760–770 (2022). https://doi.org/10.1038/s41593-022-01082-w</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-022-01082-w?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-09-24">24 September 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-04-25">25 April 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-05-30">30 May 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-06">June 2022</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41593-022-01082-w</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:A neural signature for the subjective experience of threat anticipation under uncertainty" href="https://doi.org/10.1038/s41467-024-45433-6">
                                        A neural signature for the subjective experience of threat anticipation under uncertainty
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Xiqin Liu</li><li>Guojuan Jiao</li><li>Benjamin Becker</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Communications</i> (2024)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:A systems identification approach using Bayes factors to deconstruct the brain bases of emotion regulation" href="https://doi.org/10.1038/s41593-024-01605-7">
                                        A systems identification approach using Bayes factors to deconstruct the brain bases of emotion regulation
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Ke Bo</li><li>Thomas E. Kraynak</li><li>Tor D. Wager</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Neuroscience</i> (2024)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:First-in-human prediction of chronic pain state using intracranial neural biomarkers" href="https://doi.org/10.1038/s41593-023-01338-z">
                                        First-in-human prediction of chronic pain state using intracranial neural biomarkers
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Prasad Shirvalkar</li><li>Jordan Prosky</li><li>Edward F. Chang</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Neuroscience</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Prefrontal circuits encode both general danger and specific threat representations" href="https://doi.org/10.1038/s41593-023-01472-8">
                                        Prefrontal circuits encode both general danger and specific threat representations
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Mario Martin-Fernandez</li><li>Ana Paula Menegolla</li><li>Cyril Herry</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Neuroscience</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:A mesocorticolimbic signature of pleasure in the human brain" href="https://doi.org/10.1038/s41562-023-01639-0">
                                        A mesocorticolimbic signature of pleasure in the human brain
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Philip A. Kragel</li><li>Michael T. Treadway</li><li>Emma C. Hahn</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Human Behaviour</i> (2023)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01082-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01082-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    
        <div class="c-article-associated-content__container">
            <section>
                <h2 class="c-article-associated-content__title u-mb-24">Associated content</h2>
                
                    
                    
                        <div class="u-full-height u-mb-24">
                            
    <article class="u-full-height c-card c-card--flush">
        <div class="c-card__layout u-full-height">
            <div class="c-card__body">
                <h3 class="c-card__title">
                    <a href="https://www.nature.com/articles/s41593-022-01077-7"
                       class="c-card__link u-link-inherit"
                       data-track="click"
                       data-track-action="view article"
                       data-track-category="associated content"
                       
                       data-track-label="news_and_views">Refining the negative into general and specific</a>
                </h3>
                
<ul data-test="author-list" class="c-author-list c-author-list--compact">
    <li>Junichi Chikazoe</li>
</ul>

                
    <div class="c-card__section c-meta">
        
            <span class="c-meta__item">Nature Neuroscience</span>
        
        <span class="c-meta__item" data-test="article.type"><span class="c-meta__type">News &amp; Views</span></span>
        
        
            <time class="c-meta__item" datetime="2022-05-30">30 May 2022</time>
        
    </div>

            </div>
        </div>
    </article>


                        </div>
                    
                
            </section>
        </div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer[0] = window.dataLayer[0] || {};
            window.dataLayer[0].content = window.dataLayer[0].content || {};
            window.dataLayer[0].content.associatedContentTypes = "news_and_views";
        </script>
    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41593-022-01082-w;doi=10.1038/s41593-022-01082-w;techmeta=36,59;subjmeta=116,1457,2394,378,3917,631;kwrd=Emotion,Neural+decoding,Sensory+processing">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=2079106321&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-022-01082-w%26doi%3D10.1038/s41593-022-01082-w%26techmeta%3D36,59%26subjmeta%3D116,1457,2394,378,3917,631%26kwrd%3DEmotion,Neural+decoding,Sensory+processing">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=2079106321&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-022-01082-w%26doi%3D10.1038/s41593-022-01082-w%26techmeta%3D36,59%26subjmeta%3D116,1457,2394,378,3917,631%26kwrd%3DEmotion,Neural+decoding,Sensory+processing"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/s41593-022-01082-w&amp;format=js&amp;last_modified=2022-05-30" async></script>
<img src="/d25i7yp0/article/s41593-022-01082-w" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>