<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise | Nature Neuroscience</title>
    
        
    
        
        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://push-content.springernature.io" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"commentary","legacy":{"webtrendsPrimaryArticleType":"comments & opinion","webtrendsSubjectTerms":null,"webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Commentary"}},"article":{"doi":"10.1038/77666"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Michael J. Tarr","Isabel Gauthier"],"publishedAt":965088000,"publishedAtString":"2000-08-01","title":"FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"3","issue":"8"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":false,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.c-card__title-recommendation,.c-reading-companion__figure-title,.u-h3,.u-h4,h3,h4,h5,h6{line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}main{display:block}h1{font-size:2em}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-card--major .c-card__title,.u-h1,.u-h2,h1,h2{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700}h1{font-size:2rem;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,h2{font-size:1.5rem;letter-spacing:-.0117156rem;line-height:1.6rem}.u-h3{letter-spacing:-.0117156rem;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:1.25rem;font-weight:700}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{letter-spacing:-.0117156rem;line-height:1.4rem}.c-card__title,.u-h4{line-height:1.4rem}.c-card__title-recommendation,.c-reading-companion__figure-title,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;font-weight:700;letter-spacing:-.0117156rem}.c-reading-companion__figure-title{line-height:1.4rem}input+label{padding-left:.5em}h1,h2,h3{margin:0}nav ol,nav ul{list-style:none none}p:empty{display:none}h2+*{margin-block-start:1rem}h1+*{margin-block-start:3rem}[style*="display: none"]:first-child+*{margin-block-start:0}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;margin-top:0;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-editorial-summary__container .c-article-editorial-summary__button:focus{outline:3px solid #fece3e;will-change:transform}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px!important}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;margin-bottom:16px;padding-bottom:16px}.c-recommendations-header{border-bottom:1px solid #d5d5d5}.c-recommendations-title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.24;margin:0;padding-bottom:16px}.c-recommendations-close{background-color:transparent;border:0;cursor:pointer;height:2em;margin-right:-10px;margin-top:-5px;width:2em}.c-recommendations-authors{line-height:1.24;margin-bottom:0}.c-recommendations-list-container{margin-top:0;position:relative}.c-recommendations-list{display:flex;flex-wrap:nowrap;justify-content:space-between;margin:0 auto;overflow-x:hidden;padding:16px 0;scroll-behavior:smooth;scroll-snap-type:x mandatory;width:calc(100% - 146px)}@media only screen and (max-width:539px){.c-recommendations-list{display:block;height:40vh;overflow-y:auto;width:100%}}.c-recommendations-list__item{display:flex;flex:0 0 calc(33.3333% - 16px);margin:0 8px;scroll-snap-align:center}@media only screen and (max-width:539px){.c-recommendations-list__item{margin:0;padding:0 0 16px}}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 16px 0 0;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #d5d5d5;height:auto;min-height:0;position:relative;transform:translateY(0)}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;line-height:1.4rem;margin-bottom:0;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit;font-size:1.125rem;text-decoration:none}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}@media only screen and (max-width:539px){.c-recommendations-column-switch{display:flex;flex-direction:column-reverse}}.js-greyout-page-background{background-color:rgba(34,34,34,.75);bottom:0;left:0;position:fixed;right:0;top:0}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a{color:inherit}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px;padding:0 16px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px;padding:0}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:540px){.u-hide-at-sm{display:none;visibility:hidden}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-mbs-0{margin-block-start:0!important}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-display-flex{display:flex;width:100%}.u-flex-direction-column{flex-direction:column}.u-justify-content-space-between{justify-content:space-between}.u-flex-static{flex:0 0 auto}.u-mt-32{margin-top:32px}.u-mb-0{margin-bottom:0}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px} }</style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-c15543fc61.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-c15543fc61.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                e.src = 'https://cmp-static.nature.com/production_live/consent-bundle-8-16.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-2b0f06c1e4.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>

<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        var polyfillsUrl = function() {
            var features = {
                'IntersectionObserver': window.IntersectionObserver,
                'Promise': window.Promise,
                'URLSearchParams': window.URLSearchParams,
                'Symbol.iterator': window.Symbol && Symbol.iterator,
                'Array.from': Array.from,
                'Array.prototype.includes': Array.prototype.includes,
                'Array.prototype.find': Array.prototype.find,
                'Array.prototype.forEach': Array.prototype.forEach,
                'NodeList.prototype.forEach': NodeList.prototype.forEach,
                'Element.prototype.closest': Element.prototype.closest,
                'Element.prototype.prepend': Element.prototype.prepend,
                'Element.prototype.remove': Element.prototype.remove,
                'Object.assign': Object.assign
            };
            var req = [];
            for (var feature in features) {
                if (Object.prototype.hasOwnProperty.call(features, feature) && !features[feature]) {
                    req.push(feature);
                }
            }
            if (req.length) {
                return 'https://polyfill.io/v3/polyfill.min.js?features=' + req.join('%2C') + '&flags=always';
            }
            return null;
        };

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    {src: polyfillsUrl(), test: 'polyfills-js', noinit: true},
                    
                        {src: '/static/js/global-article-es6-bundle-01ba63a93a.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-24733ecc67.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-4a19668d96.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-eeebedc844.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-c634a291c7.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        
                            var conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-885b4d4cd7.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-6a76e92cf3.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-49a6cda65c.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-c21db8dda6.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>






<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise","description":"Much evidence suggests that the fusiform face area is involved in face processing. In contrast to the accompanying article by Kanwisher, we conclude that the apparent face selectivity of this area reflects a more generalized form of processing not intrinsically specific to faces.","datePublished":"","dateModified":"","pageStart":"764","pageEnd":"769","sameAs":"https://doi.org/10.1038/77666","keywords":"Biomedicine,general,Neurosciences,Behavioral Sciences,Biological Techniques,Neurobiology,Animal Genetics and Genomics","image":"https://static-content.springer.com/image/art%3A10.1038%2F77666/MediaObjects/41593_2000_Article_BFnn0800_764_Fig1_HTML.gif","isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"3","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Michael J. Tarr","affiliation":[{"name":"Brown University","address":{"name":"Department of Cognitive and Linguistic Sciences, Brown University, Rhode Island, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Isabel Gauthier","affiliation":[{"name":"Vanderbilt University","address":{"name":"Department of Psychology, Vanderbilt University, Nashville , USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/nn0800_764">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise"/>
    <meta name="dc.source" content="Nature Neuroscience 2000 3:8"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.type" content="BriefCommunication"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2000 Nature America Inc."/>
    <meta name="dc.rights" content="2000 Nature America Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Much evidence suggests that the fusiform face area is involved in face processing. In contrast to the accompanying article by Kanwisher, we conclude that the apparent face selectivity of this area reflects a more generalized form of processing not intrinsically specific to faces."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.volume" content="3"/>
    <meta name="prism.number" content="8"/>
    <meta name="prism.section" content="BriefCommunication"/>
    <meta name="prism.startingPage" content="764"/>
    <meta name="prism.endingPage" content="769"/>
    <meta name="prism.copyright" content="2000 Nature America Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/nn0800_764"/>
    <meta name="prism.doi" content="doi:10.1038/77666"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/nn0800_764.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/nn0800_764"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise"/>
    <meta name="citation_volume" content="3"/>
    <meta name="citation_issue" content="8"/>
    <meta name="citation_publication_date" content="2000/08"/>
    <meta name="citation_firstpage" content="764"/>
    <meta name="citation_lastpage" content="769"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/77666"/>
    <meta name="DOI" content="10.1038/77666"/>
    <meta name="size" content="122743"/>
    <meta name="citation_doi" content="10.1038/77666"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/77666&amp;api_key="/>
    <meta name="description" content="Much evidence suggests that the fusiform face area is involved in face processing. In contrast to the accompanying article by Kanwisher, we conclude that the apparent face selectivity of this area reflects a more generalized form of processing not intrinsically specific to faces."/>
    <meta name="dc.creator" content="Tarr, Michael J."/>
    <meta name="dc.creator" content="Gauthier, Isabel"/>
    <meta name="dc.subject" content="Biomedicine, general"/>
    <meta name="dc.subject" content="Neurosciences"/>
    <meta name="dc.subject" content="Behavioral Sciences"/>
    <meta name="dc.subject" content="Biological Techniques"/>
    <meta name="dc.subject" content="Neurobiology"/>
    <meta name="dc.subject" content="Animal Genetics and Genomics"/>
    <meta name="citation_reference" content="citation_journal_title=Cognition; citation_title=The effect of face inversion on the human fusiform face area; citation_author=N Kanwisher, F  Tong,  K Nakayama; citation_volume=68; citation_publication_date=1998; citation_pages=B1- 11; citation_doi=10.1016/S0010-0277(98)00035-3; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroreport; citation_title=Selective visual streaming in face recognition: evidence from developmental prosopagnosia; citation_author=S Bentin, LY  Deouell,  N Soroker; citation_volume=10; citation_publication_date=1999; citation_pages= 823-827; citation_doi=10.1097/00001756-199903170-00029; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title= Cereb. Cortex; citation_title=Electrophysiological studies of human face perception. III: Effects of top-down processing on face-specific potentials; citation_author=A Puce, T  Allison,  G McCarthy; citation_volume=9; citation_publication_date=1999; citation_pages=445-458; citation_doi=10.1093/cercor/9.5.445; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=The fusiform face area: A module in human extrastriate cortex specialized for face perception; citation_author=N Kanwisher, J  McDermott,  MM Chun; citation_volume= 17; citation_publication_date=1997; citation_pages=4302-4311; citation_doi=10.1523/JNEUROSCI.17-11-04302.1997; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroreport; citation_title=The fusiform face area is selective for faces not animals ; citation_author=N Kanwisher, D  Stanley,  A Harris; citation_volume=10; citation_publication_date=1999; citation_pages=183-187 ; citation_doi=10.1097/00001756-199901180-00035; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=An area within human ventral cortex sensitive to &#8220;building&#8221; stimuli: Evidence and implications; citation_author=GK Aguirre, E  Zarahn,  M D&#39;Esposito; citation_volume=21; citation_publication_date=1998; citation_pages= 373-383; citation_doi=10.1016/S0896-6273(00)80546-2; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=The effect of face inversion on activity in human neural systems for face and object perception; citation_author=JV Haxby; citation_volume=22; citation_publication_date=1999; citation_pages= 189-199; citation_doi=10.1016/S0896-6273(00)80690-X; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Gen.; citation_title=Looking at upside-down faces; citation_author=RK Yin; citation_volume= 81; citation_publication_date=1969; citation_pages=141-145; citation_doi=10.1037/h0027474; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Activation of the middle fusiform &#8216;face area&#8217; increases with expertise in recognizing novel objects ; citation_author=I Gauthier, MJ  Tarr, A W Anderson, P Skudlarski, JC  Gore; citation_volume=2; citation_publication_date=1999; citation_pages=568- 573; citation_doi=10.1038/9224; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cognit. Neurosci.; citation_title=Electrophysiological studies of face perception in humans ; citation_author=S Bentin, T  Allison, A Puce, E  Perez,  G McCarthy; citation_volume=8; citation_publication_date=1996; citation_pages=551- 565; citation_doi=10.1162/jocn.1996.8.6.551; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=Exp. Brain Res.; citation_title=A face-responsive potential recorded from the human scalp; citation_author=DA Jeffreys; citation_volume=78; citation_publication_date=1989; citation_pages=193-202; citation_doi=10.1007/BF00230699; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroreport; citation_title=The selectivity of the occipitotemporal M170 for faces; citation_author=J Liu, M  Higuchi, A Marantz, N Kanwisher; citation_volume= 7; citation_publication_date=2000; citation_pages=337-341; citation_doi=10.1097/00001756-200002070-00023; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroreport; citation_title=The N170 occipito-temporal component is delayed and enhanced to inverted faces but not to inverted objects: An electrophysiological account of face-specific processes in the human brain; citation_author=B Rossion; citation_volume= 11; citation_publication_date=2000; citation_pages=69-74; citation_doi=10.1097/00001756-200001170-00014; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex ; citation_title=Electrophysiological studies of human face perception. II: Response properties of face-specific potentials generated in occipitotemporal cortex; citation_author=G McCarthy, A  Puce, A Belger, T Allison; citation_volume=5; citation_publication_date=1999; citation_pages=431-444; citation_doi=10.1093/cercor/9.5.431; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects; citation_author=LL Chao, JV  Haxby,  A Martin; citation_volume= 2; citation_publication_date=1999; citation_pages=913-919; citation_doi=10.1038/13217; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA ; citation_title=Distributed representation of objects in the human ventral visual pathway; citation_author=A Ishai, LG  Ungerleider,  A Martin, JL Schouten, J  Haxby; citation_volume=96; citation_publication_date=1999; citation_pages=9379-9384; citation_doi=10.1073/pnas.96.16.9379; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Neurosci.; citation_title=Inferotemporal cortex and object vision; citation_author=K Tanaka; citation_volume= 19; citation_publication_date=1996; citation_pages=109-139; citation_doi=10.1146/annurev.ne.19.030196.000545; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Differential sensitivity of human visual cortex to faces, letterstrings, and textures: A functional magnetic resonance imaging study ; citation_author=A Puce, T  Allison, M Asgari, JC  Gore,  G McCarthy; citation_volume=16; citation_publication_date=1996; citation_pages=5205- 5215; citation_doi=10.1523/JNEUROSCI.16-16-05205.1996; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title= Trends Cogn. Sci.; citation_title=What constrains the organization of the ventral temporal cortex?; citation_author=I Gauthier; citation_volume=4; citation_publication_date=2000; citation_pages=1-2; citation_doi=10.1016/S1364-6613(99)01416-3; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Neurology; citation_title=Prosopagnosia: Anatomical basis and behavioral mechanisms ; citation_author=AR Damasio, H  Damasio,  GW Van Hoesen; citation_volume=32; citation_publication_date=1982; citation_pages=331-341 ; citation_doi=10.1212/WNL.32.4.331; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Gen.; citation_title=Why faces are and are not special: An effect of expertise; citation_author=R Diamond, S  Carey; citation_volume=115; citation_publication_date=1986; citation_pages= 107-117; citation_doi=10.1037/0096-3445.115.2.107; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_title=Mechanisms of Perceptual Learning ; citation_publication_date=1997; citation_id=CR22; citation_author=JW Tanaka; citation_author=I  Gauthier"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Dissociation of object and spatial visual processing pathways in human extrastriate cortex; citation_author=JV Haxby; citation_volume= 88; citation_publication_date=1991; citation_pages=1621-1625; citation_doi=10.1073/pnas.88.5.1621; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Brain; citation_title=Functional neuroanatomy of face and object processing: A positron emission tomography study; citation_author=J Sergent, S  Ohta,  B MacDonald; citation_volume=115; citation_publication_date=1992; citation_pages= 15-36; citation_doi=10.1093/brain/115.1.15; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Expertise for cars and birds recruits brain areas involved in face recognition ; citation_author=I Gauthier, P  Skudlarski, JC  Gore, AW Anderson; citation_volume=3; citation_publication_date=2000; citation_pages=191- 197; citation_doi=10.1038/72140; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Biol.; citation_title=Levels of categorization in visual object studied with functional MRI; citation_author=I Gauthier, AW  Anderson, M J Tarr, P Skudlarski, JC  Gore; citation_volume=7; citation_publication_date=1997; citation_pages= 645-651; citation_doi=10.1016/S0960-9822(06)00291-0; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=Cognit. Neuropsychol.; citation_title=Does visual subordinate-level categorisation engage the functionally defined Fusiform Face Area?; citation_author=I Gauthier; citation_volume=17 ; citation_publication_date=2000; citation_pages=143-163; citation_doi=10.1080/026432900380544; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroreport; citation_title=Are face-responsive regions selective only for faces? ; citation_author=LL Chao, A  Martin, J V Haxby; citation_volume=10; citation_publication_date=1999; citation_pages=2945-2950 ; citation_doi=10.1097/00001756-199909290-00013; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title= J. Cogn. Neurosci.; citation_title=A spurious category-specific agnosia for living things in normal human and nonhuman primates; citation_author=D Gaffan, CA  Heywood; citation_volume=5; citation_publication_date=1994; citation_pages=118-128; citation_doi=10.1162/jocn.1993.5.1.118; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Hum. Brain Mapp.; citation_title=Location of human face-selective cortex with respect to retinotopic areas; citation_author=E Halgren; citation_volume=7; citation_publication_date=1999; citation_pages=29- 37; citation_doi=10.1002/(SICI)1097-0193(1999)7:1&lt;29::AID-HBM3&gt;3.0.CO;2-R; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci. ; citation_title=The fusiform &#8220;face area&#8221; is part of a network that processes faces at the individual level; citation_author=I Gauthier; citation_volume=12; citation_publication_date=2000; citation_pages=495-504; citation_doi=10.1162/089892900562165; citation_id=CR31"/>
    <meta name="citation_reference" content="Rossion, B.  et al. Hemispheric asymmetries for whole-based and part-based face processing in the human brain. J. Cogn. Neurosci. (in press)."/>
    <meta name="citation_reference" content="Tanaka, J. W. &amp; Curran, T. A neural basis for expert object recognition. Psychol. Sci. (in press)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Distinct representations of eye gaze and identity in the distributed human neural system for face perception ; citation_author=EA Hoffman, JV Haxby; citation_volume=3; citation_publication_date=2000; citation_pages=80- 84; citation_doi=10.1038/71152; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Neurology ; citation_title=Intact recognition of facial expression, gender and age in patients with impaired recognition of face identity; citation_author=D Tranel, AR  Damasio,  H Damasio; citation_volume=38; citation_publication_date=1998; citation_pages=690-696; citation_doi=10.1212/WNL.38.5.690; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=Can face recognition really be dissociated from object recognition?; citation_author=I Gauthier, M  Behrmann,  MJ Tarr; citation_volume=11; citation_publication_date=1999; citation_pages=349- 370; citation_doi=10.1162/089892999563472; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Arch. Gen. Psychiatry; citation_title=Abnormal ventral temporal cortical activity during face discrimination among individuals with autism and asperger syndrome; citation_author=RT Schultz; citation_volume=57; citation_publication_date=2000; citation_pages=331-340; citation_doi=10.1001/archpsyc.57.4.331; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=What is special about face recognition? Nineteen experiments on a person with visual object agnosia and dyslexia but normal face recognition ; citation_author=M Moscovitch, G  Winocur,  M Behrmann; citation_volume=9; citation_publication_date=1997; citation_pages=555- 604; citation_doi=10.1162/jocn.1997.9.5.555; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Vision Res.; citation_title=Becoming a &#8220;Greeble&#8221; expert: Exploring the face recognition mechanism; citation_author=I Gauthier, MJ  Tarr; citation_volume= 37; citation_publication_date=1997; citation_pages=1673-1682; citation_doi=10.1016/S0042-6989(96)00286-6; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Face perception and within-category discrimination in prosopagnosia; citation_author=MJ Farah, KL  Levinson,  KL Klein; citation_volume=33; citation_publication_date=1995; citation_pages=661 -674; citation_doi=10.1016/0028-3932(95)00002-K; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=Face-specific processing in the human fusiform gyrus; citation_author=G McCarthy, A  Puce, JC Gore, T Allison; citation_volume= 9; citation_publication_date=1997; citation_pages=605-610; citation_doi=10.1162/jocn.1997.9.5.605; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title= Cognit. Psychol.; citation_title=Pictures and names: Making the connection; citation_author=P Jolicoeur, M  Gluck,  SM Kosslyn; citation_volume=16; citation_publication_date=1984; citation_pages=243-275; citation_doi=10.1016/0010-0285(84)90009-4; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Vision Res.; citation_title=Training &#8220;Greeble&#8221; experts: A framework for studying expert object recognition processes; citation_author=I Gauthier, P  Williams, MJ  Tarr, J Tanaka; citation_volume=38; citation_publication_date=1998; citation_pages=2401 -2428; citation_doi=10.1016/S0042-6989(97)00442-2; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Cognit. Neuropsychol.; citation_title=Response properties of the human fusiform face area; citation_author=F Tong, K  Nakayama,  M Moscovitch, O Weinrib, N  Kanwisher; citation_volume=17; citation_publication_date=2000; citation_pages= 257-279; citation_doi=10.1080/026432900380607; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=Exp. Brain Res.; citation_title=Visual neurones responsive to faces in the monkey temporal cortex; citation_author=DI Perrett, ET  Rolls,  W Caan; citation_volume=47; citation_publication_date=1982; citation_pages=329- 342; citation_doi=10.1007/BF00239352; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Effects of shape-discrimination training on the selectivity of inferotemporal cells in adult monkeys; citation_author=E Kobatake, G  Wang, K  Tanaka; citation_volume= 80; citation_publication_date=1998; citation_pages=324-330; citation_doi=10.1152/jn.1998.80.1.324; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Psychophysical and physiological evidence for viewer-centered object representation in the primate ; citation_author=NK Logothetis, J Pauls; citation_volume=3; citation_publication_date=1995; citation_pages=270- 288; citation_doi=10.1093/cercor/5.3.270; citation_id=CR47"/>
    <meta name="citation_reference" content="Kanwisher, N., Downing, P., Epstein, R. &amp; Kourtzi, Z. in Handbook of Functional Neuroimaging of Cognition (eds. Cabeza, R. &amp; Kingstone, A.) (MIT Press, Cambridge, MA, in press)."/>
    <meta name="citation_reference" content="citation_title=Perceptual Learning; citation_publication_date=2000; citation_id=CR49; citation_author=DL Sheinberg; citation_author=NK Logothetis"/>
    <meta name="citation_author" content="Tarr, Michael J."/>
    <meta name="citation_author_institution" content="Department of Cognitive and Linguistic Sciences, Brown University, Rhode Island, USA"/>
    <meta name="citation_author" content="Gauthier, Isabel"/>
    <meta name="citation_author_institution" content="Department of Psychology, Vanderbilt University, Nashville , USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise"/>
    <meta name="twitter:description" content="Nature Neuroscience - Much evidence suggests that the fusiform face area is involved in face processing. In contrast to the accompanying article by Kanwisher, we conclude that the apparent face..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2F77666/MediaObjects/41593_2000_Article_BFnn0800_764_Fig1_HTML.gif"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/nn0800_764"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise - Nature Neuroscience"/>
    <meta property="og:description" content="Much evidence suggests that the fusiform face area is involved in face processing. In contrast to the accompanying article by Kanwisher, we conclude that the apparent face selectivity of this area reflects a more generalized form of processing not intrinsically specific to faces."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2F77666/MediaObjects/41593_2000_Article_BFnn0800_764_Fig1_HTML.gif"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=nn0800_764;doi=10.1038/77666;kwrd=Biomedicine%2C+general,Neurosciences,Behavioral+Sciences,Biological+Techniques,Neurobiology,Animal+Genetics+and+Genomics">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=159309728&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn0800_764%26doi%3D10.1038/77666%26kwrd%3DBiomedicine%2C+general,Neurosciences,Behavioral+Sciences,Biological+Techniques,Neurobiology,Animal+Genetics+and+Genomics">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=159309728&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn0800_764%26doi%3D10.1038/77666%26kwrd%3DBiomedicine%2C+general,Neurosciences,Behavioral+Sciences,Biological+Techniques,Neurobiology,Animal+Genetics+and+Genomics"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="//media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="//media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link"
                               href="#search-menu"
                               data-header-expander
                               data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <span>Search</span><svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding">
                            
                                <a class="c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/nn0800_764'>Log in</a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;commentary" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:commentary"><span itemprop="name">commentary</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn0800_764.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
                
    <div class="c-recommendations__container u-container u-display-none" data-component-recommendations>
        <aside class="c-status-message c-status-message--success u-display-none" data-component-status-msg>
            <svg class="c-status-message__icon" width="24" height="24" role="img" aria-label="success:" focusable="false">
                <use xlink:href="#icon-success"></use>
            </svg>
            <div class="c-status-message__message" tabindex="-1" id="success-message">
                Your article has downloaded
            </div>
        </aside>

        <div class="c-recommendations-header u-display-flex u-justify-content-space-between">
            <h2 class="c-recommendations-title" id="recommendation-heading">Similar articles being viewed by others</h2>
            <button class="c-recommendations-close u-flex-static" type="button" aria-label="Close" data-track="click" data-track-action="close recommendations">
                <svg class="u-icon" width="16" height="16" aria-hidden="true" focusable="false"><use xlink:href="#icon-close"></use></svg>
            </button>
        </div>

        <section aria-roledescription="carousel" aria-labelledby="recommendation-heading">
            <p class="u-visually-hidden">Slider with three articles shown per slide. Use the Previous and Next buttons to navigate the slides or the slide controller buttons at the end to navigate through each slide.</p>
            <div class="c-recommendations-list-container">
                <div class="c-recommendations-list">
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 1 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41467-021-24806-1/MediaObjects/41467_2021_24806_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41467-021-24806-1" data-track="click" data-track-action="click recommendations - 1" data-track-label="10.1038/s41467-021-24806-1">Holistic face recognition is an emergent phenomenon of spatial processing in face-selective regions</a></h3>
                                        <p class="u-sans-serif u-mb-0">06 August 2021</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Sonia Poltoratski, Kendrick Kay,  Kalanit Grill-Spector</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 2 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41467-020-18325-8/MediaObjects/41467_2020_18325_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41467-020-18325-8" data-track="click" data-track-action="click recommendations - 2" data-track-label="10.1038/s41467-020-18325-8">Rapid and dynamic processing of face pareidolia in the human brain</a></h3>
                                        <p class="u-sans-serif u-mb-0">09 September 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Susan G. Wardle, Jessica Taubert,  Chris I. Baker</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 3 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41583-020-00393-w/MediaObjects/41583_2020_393_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41583-020-00393-w" data-track="click" data-track-action="click recommendations - 3" data-track-label="10.1038/s41583-020-00393-w">The macaque face patch system: a turtles underbelly for the brain</a></h3>
                                        <p class="u-sans-serif u-mb-0">03 November 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Janis K. Hesse &amp; Doris Y. Tsao</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 4 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41467-021-22524-2/MediaObjects/41467_2021_22524_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41467-021-22524-2" data-track="click" data-track-action="click recommendations - 4" data-track-label="10.1038/s41467-021-22524-2">Differential spatial computations in ventral and lateral face-selective regions are scaffolded by structural connections</a></h3>
                                        <p class="u-sans-serif u-mb-0">15 April 2021</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Dawn Finzi, Jesse Gomez,  Kalanit Grill-Spector</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 5 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41598-023-29583-z/MediaObjects/41598_2023_29583_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41598-023-29583-z" data-track="click" data-track-action="click recommendations - 5" data-track-label="10.1038/s41598-023-29583-z">Looking at the upper facial half enlarges the range of holistic face processing</a></h3>
                                        <p class="u-sans-serif u-mb-0">10 February 2023</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Zhe Wang, Hao Ni,  Haiyang Jin</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 6 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41467-020-14432-8/MediaObjects/41467_2020_14432_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41467-020-14432-8" data-track="click" data-track-action="click recommendations - 6" data-track-label="10.1038/s41467-020-14432-8">Fast temporal dynamics and causal relevance of face processing in the human temporal cortex</a></h3>
                                        <p class="u-sans-serif u-mb-0">31 January 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Jessica Schrouff, Omri Raccah,  Josef Parvizi</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 7 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41467-019-09239-1/MediaObjects/41467_2019_9239_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41467-019-09239-1" data-track="click" data-track-action="click recommendations - 7" data-track-label="10.1038/s41467-019-09239-1">How face perception unfolds over time</a></h3>
                                        <p class="u-sans-serif u-mb-0">19 March 2019</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Katharina Dobs, Leyla Isik,  Nancy Kanwisher</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 8 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41598-021-86842-7/MediaObjects/41598_2021_86842_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41598-021-86842-7" data-track="click" data-track-action="click recommendations - 8" data-track-label="10.1038/s41598-021-86842-7">View-tuned and view-invariant face encoding in IT cortex is explained by selected natural image fragments</a></h3>
                                        <p class="u-sans-serif u-mb-0">09 April 2021</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Yunjun Nam, Takayuki Sato,  Manabu Tanifuji</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 9 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1038%2Fs41598-018-28144-z/MediaObjects/41598_2018_28144_Fig1_HTML.jpg" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                    <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1038/s41598-018-28144-z" data-track="click" data-track-action="click recommendations - 9" data-track-label="10.1038/s41598-018-28144-z">The impact of stimulus size and orientation on individual face coding in monkey face-selective cortex</a></h3>
                                        <p class="u-sans-serif u-mb-0">09 July 2018</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Jessica Taubert, Goedele Van Belle,  Bruno Rossion</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                </div>
            </div>
        </section>
    </div>
    <div class="js-greyout-page-background" style="display:none" data-component-grey-background></div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer.push({
                recommendations: {
                    recommender: 'semantic',
                    model: 'specter',
                    policy_id: 'BootstrappedUCB',
                    timestamp: 1686148424,
                    embedded_user: null
                }
            });
        </script>
    

            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
    
    
    

                        <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2000-08">August 2000</time></a></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Michael_J_-Tarr" data-author-popup="auth-Michael_J_-Tarr">Michael J. Tarr</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Isabel-Gauthier" data-author-popup="auth-Isabel-Gauthier">Isabel Gauthier</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup></li></ul>

                    
                        
                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>3</b>,<span class="u-visually-hidden">pages </span>764769 (<span data-test="article-publication-year">2000</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">4993 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">434 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">11 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/nn0800_764/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
                
    

    

                
            </div>

        <div class="c-article-body">
            <div class="c-article-section__content c-article-section__content--standfirst u-text-bold" lang="en"><p>Much evidence suggests that the fusiform face area is involved in face processing. In contrast to the accompanying article by Kanwisher, we conclude that the apparent face selectivity of this area reflects a more generalized form of processing not intrinsically specific to faces.</p></div>
            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn0800_764.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

    
</div>

                
            </noscript>

                
                    <div class="js-context-bar-sticky-point-mobile">
                        
                            <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn0800_764.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                        
                    </div>
                
            
                <div class="main-content">
                <div class="c-article-section__content"><p>How does the primate visual system process and identify objects? Central to this question is that visual recognition can occur at many levels, from coarse categories, for example a car, to highly specific individuals, my dad's 1960 TR3 convertible (subordinate-level processing). The processing demands exerted by these two tasks seem to require separable visual recognition systems, one dedicated to determining category membership and one dedicated to individuation. The most conspicuous version of this argument is one in which there is a functional and neuroanatomical division between the mechanisms supporting object at the basic level and face recognition at the individual level. Here we evaluate this claim and ask whether putatively face-specific mechanisms in a region of the visual cortex known as the Fusiform Face Area (FFA) are selective specifically to the geometry of faces or whether, through the operation of other factors, they extend to non-face stimuli.</p></div><div class="c-article-section__content"><p>The comparison between faces and non-face objects is critical for evaluating three competing models. First, Kanwisher (this issue) suggests that face selectivity in the FFA as revealed by functional magnetic resonance imaging (fMRI) reflects a special-purpose, innate mechanism for detecting the geometry of faces, that is, a mechanism that determines only that a face is a face, but not the individual identity of the face<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Kanwisher, N., Tong, F. &amp; Nakayama, K. The effect of face inversion on the human fusiform face area. Cognition 68, B1 11 (1998)." href="/articles/nn0800_764#ref-CR1" id="ref-link-section-d27747789e305">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Bentin, S., Deouell, L. Y. &amp; Soroker, N. Selective visual streaming in face recognition: evidence from developmental prosopagnosia. Neuroreport 10, 823827 (1999)." href="/articles/nn0800_764#ref-CR2" id="ref-link-section-d27747789e308">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Puce, A., Allison, T. &amp; McCarthy, G. Electrophysiological studies of human face perception. III: Effects of top-down processing on face-specific potentials.  Cereb. Cortex 9, 445458 (1999)." href="/articles/nn0800_764#ref-CR3" id="ref-link-section-d27747789e311">3</a></sup>. Evidence for this detection model comes from studies in which selectivity for faces in FFA has been established over a wide variety of conditions, including line drawings, two-tone, gray-scale or colored imagesstimulus manipulations that affect face-recognition performance but have little impact on activation in FFA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Kanwisher, N., Tong, F. &amp; Nakayama, K. The effect of face inversion on the human fusiform face area. Cognition 68, B1 11 (1998)." href="/articles/nn0800_764#ref-CR1" id="ref-link-section-d27747789e315">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e318">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Kanwisher, N., Stanley, D. &amp; Harris, A. The fusiform face area is selective for faces not animals . Neuroreport 10, 183187 (1999)." href="/articles/nn0800_764#ref-CR5" id="ref-link-section-d27747789e321">5</a></sup>.</p></div><div class="c-article-section__content"><p>For example, face inversion seems to only minimally influence activity in the FFA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Kanwisher, N., Tong, F. &amp; Nakayama, K. The effect of face inversion on the human fusiform face area. Cognition 68, B1 11 (1998)." href="/articles/nn0800_764#ref-CR1" id="ref-link-section-d27747789e328">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Aguirre, G. K., Zarahn, E. &amp; D'Esposito, M. An area within human ventral cortex sensitive to building stimuli: Evidence and implications. Neuron 21, 373383 (1998)." href="/articles/nn0800_764#ref-CR6" id="ref-link-section-d27747789e331">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Haxby, J. V.  et al. The effect of face inversion on activity in human neural systems for face and object perception. Neuron 22, 189199 (1999)." href="/articles/nn0800_764#ref-CR7" id="ref-link-section-d27747789e334">7</a></sup>. This result appears at odds with the strong effect of inversion on face recognition performance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Yin, R. K. Looking at upside-down faces. J. Exp. Psychol. Gen.  81, 141145 (1969)." href="/articles/nn0800_764#ref-CR8" id="ref-link-section-d27747789e338">8</a></sup>. However, inversion only impairs, but does not abolish, the perception of identity. Inverted faces are typically recognized well above chance level, which is consistent with the small but significant fMRI face inversion effects reported in some studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Kanwisher, N., Tong, F. &amp; Nakayama, K. The effect of face inversion on the human fusiform face area. Cognition 68, B1 11 (1998)." href="/articles/nn0800_764#ref-CR1" id="ref-link-section-d27747789e342">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e345">9</a></sup>. Moreover, this same small inversion effect has been replicated with non-face objects in expert subjects<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e349">9</a></sup>. The absence or relatively small inversion effect in the FFA may also mean that activity as measured by fMRI simply is not sufficiently fine-grained to pick up certain effects. As a case in point, fMRI cannot detect the robust and early effect of face inversion reported in ERPs: a ten-millisecond delay in the N170 face-sensitive potential<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Bentin, S., Allison, T., Puce, A., Perez, E. &amp; McCarthy, G. Electrophysiological studies of face perception in humans . J. Cognit. Neurosci. 8, 551 565 (1996)." href="/articles/nn0800_764#ref-CR10" id="ref-link-section-d27747789e353">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Jeffreys, D. A. A face-responsive potential recorded from the human scalp. Exp. Brain Res. 78, 193202 ( 1989)." href="/articles/nn0800_764#ref-CR11" id="ref-link-section-d27747789e356">11</a></sup> that is recorded at temporo-occipital electrodes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Liu, J., Higuchi, M., Marantz, A. &amp; Kanwisher, N. The selectivity of the occipitotemporal M170 for faces. Neuroreport  7, 337341 (2000)." href="/articles/nn0800_764#ref-CR12" id="ref-link-section-d27747789e361">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Rossion, B.  et al. The N170 occipito-temporal component is delayed and enhanced to inverted faces but not to inverted objects: An electrophysiological account of face-specific processes in the human brain. Neuroreport  11, 6974 (2000)." href="/articles/nn0800_764#ref-CR13" id="ref-link-section-d27747789e364">13</a></sup> or a similar inversion effect in intracranial recordings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="McCarthy, G., Puce, A., Belger, A. &amp; Allison, T. Electrophysiological studies of human face perception. II: Response properties of face-specific potentials generated in occipitotemporal cortex. Cereb. Cortex  5, 431444 ( 1999)." href="/articles/nn0800_764#ref-CR14" id="ref-link-section-d27747789e368">14</a></sup>.</p></div><div class="c-article-section__content"><p>A second model holds that category selectivity reflects the presence of a geometrically defined feature map in ventral temporal cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Chao, L. L., Haxby, J. V. &amp; Martin, A. Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects. Nat. Neurosci.  2, 913919 (1999)." href="/articles/nn0800_764#ref-CR15" id="ref-link-section-d27747789e375">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Ishai, A., Ungerleider, L. G., Martin, A., Schouten, J. L. &amp; Haxby, J. Distributed representation of objects in the human ventral visual pathway. Proc. Natl. Acad. Sci. USA  96, 93799384 ( 1999)." href="/articles/nn0800_764#ref-CR16" id="ref-link-section-d27747789e378">16</a></sup>. The hypothesis is that small, localized brain regions are activated by objects, generally from a single category, with similar shape and image features. Evidence for feature maps comes from monkey neurophysiology<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Tanaka, K. Inferotemporal cortex and object vision. Annu. Rev. Neurosci.  19, 109139 (1996)." href="/articles/nn0800_764#ref-CR17" id="ref-link-section-d27747789e382">17</a></sup> suggesting a topography of features in inferior temporal cortex (IT) and from human fMRI studies indicating that across a single task, different stimuli selectively activate different regions of the ventral temporal cortex. For instance, distinct brain areas respond preferentially to letter strings, chairs, buildings or faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e386">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Aguirre, G. K., Zarahn, E. &amp; D'Esposito, M. An area within human ventral cortex sensitive to building stimuli: Evidence and implications. Neuron 21, 373383 (1998)." href="/articles/nn0800_764#ref-CR6" id="ref-link-section-d27747789e389">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Ishai, A., Ungerleider, L. G., Martin, A., Schouten, J. L. &amp; Haxby, J. Distributed representation of objects in the human ventral visual pathway. Proc. Natl. Acad. Sci. USA  96, 93799384 ( 1999)." href="/articles/nn0800_764#ref-CR16" id="ref-link-section-d27747789e392">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Puce, A., Allison, T., Asgari, M., Gore, J. C. &amp; McCarthy, G. Differential sensitivity of human visual cortex to faces, letterstrings, and textures: A functional magnetic resonance imaging study . J. Neurosci. 16, 5205 5215 (1996)." href="/articles/nn0800_764#ref-CR18" id="ref-link-section-d27747789e395">18</a></sup>. However, geometric similarity alone seems unlikely to account for category selectivity, in that task manipulations independent of image geometry can lead to activation maps indistinguishable from those produced by manipulating geometry.</p></div><div class="c-article-section__content"><p>Third, our preferred model, the flexible process map<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Gauthier, I. What constrains the organization of the ventral temporal cortex?  Trends Cogn. Sci. 4, 12 (2000)." href="/articles/nn0800_764#ref-CR19" id="ref-link-section-d27747789e402">19</a></sup>, holds that an assortment of extrastriate areas support separable components of visual object processing and recognition. This model is distinguished from the detection and feature-map models in that specialization of large extrastriate areas (that is, those detectable with fMRI) is not <i>a priori</i> a function of stimulus geometry. Rather, through experience, observers associate particular geometrieswhich define object categorieswith task-appropriate recognition strategies that automatically recruit components of the process map. In contrast to other accounts, the process-map model provides a general explanation for category selectivity, as well as why the FFA responds to a wide range of stimuli, including faces and non-face objects.</p></div><div class="c-article-section__content"><p>
              <b>Factors affecting FFA processing</b>
            </p></div><div class="c-article-section__content"><p>Given that face selectivity may not be intrinsically related to the specific geometry of faces, what else might account for the strong activation for faces in the FFA? Behavioral work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Damasio, A. R., Damasio, H. &amp; Van Hoesen, G. W. Prosopagnosia: Anatomical basis and behavioral mechanisms . Neurology 32, 331341 (1982)." href="/articles/nn0800_764#ref-CR20" id="ref-link-section-d27747789e419">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Diamond, R. &amp; Carey, S. Why faces are and are not special: An effect of expertise. J. Exp. Psychol. Gen. 115, 107117 (1986)." href="/articles/nn0800_764#ref-CR21" id="ref-link-section-d27747789e422">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Tanaka, J. W. &amp; Gauthier, I. in Mechanisms of Perceptual Learning  (eds. Goldstone, R. L., Medin, D. L. &amp; Schyns, P. G.) 83 125 (Academic, San Diego, California, 1997)." href="/articles/nn0800_764#ref-CR22" id="ref-link-section-d27747789e425">22</a></sup> suggests two critical factors associated with face recognition because of our particular experience with faces. First, the level of categorization at which objects are recognized is differentfaces generally being recognized at the individual level, but objects such as chairs or birds being recognized at a more categorical level. Second, we have far greater expertise with faces as compared to almost any other visual category. Expertise with faces may automatize face processing at the individual level, thereby rendering task manipulations less effective for faces, for example, the rapid presentation rates used in some studies (such as 300 ms with a 500 ms ISI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Kanwisher, N., Stanley, D. &amp; Harris, A. The fusiform face area is selective for faces not animals . Neuroreport 10, 183187 (1999)." href="/articles/nn0800_764#ref-CR5" id="ref-link-section-d27747789e429">5</a></sup>) may not affect face processing nearly as much as object processing.</p></div><div class="c-article-section__content"><p>Because extreme values for these two dimensions are typically associated with face recognition, any comparison between faces and non-face objects confounds these factors unless they are independently manipulated. When we do such manipulations, it is the level of categorization and the level of expertise, not the stimulus geometry, that are critical in determining selectivity in the FFA. Given such domain-general processes, we argue that the FFA may be better thought of as a flexible fusiform areaa mechanism for visual recognition that exhibits a great deal of plasticity in response to both task demands and experience.</p></div><div class="c-article-section__content"><p>
              <b>Evidence from fMRI</b>
            </p></div><div class="c-article-section__content"><p>Functional MRI provides an ideal tool for evaluating these models because brain areas can be identified in a functional manner. In comparison to cytoarchitectonic criteria (like Brodmann areas) or gross anatomical landmarks (such as the Talairach system), a region performing the same function in different individuals can be defined, allowing for variability in the mapping of function to anatomy. Building on a long history of neuropsychological findings indicating specialization in the primate visual system for face processing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Damasio, A. R., Damasio, H. &amp; Van Hoesen, G. W. Prosopagnosia: Anatomical basis and behavioral mechanisms . Neurology 32, 331341 (1982)." href="/articles/nn0800_764#ref-CR20" id="ref-link-section-d27747789e445">20</a></sup>, both PET and fMRI studies have localized face-selective regions in the ventral temporal lobe<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e449">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Puce, A., Allison, T., Asgari, M., Gore, J. C. &amp; McCarthy, G. Differential sensitivity of human visual cortex to faces, letterstrings, and textures: A functional magnetic resonance imaging study . J. Neurosci. 16, 5205 5215 (1996)." href="/articles/nn0800_764#ref-CR18" id="ref-link-section-d27747789e452">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Haxby, J. V.  et al. Dissociation of object and spatial visual processing pathways in human extrastriate cortex. Proc. Natl. Acad. Sci. USA  88, 16211625 (1991)." href="/articles/nn0800_764#ref-CR23" id="ref-link-section-d27747789e455">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Sergent, J., Ohta, S. &amp; MacDonald, B. Functional neuroanatomy of face and object processing: A positron emission tomography study. Brain 115, 1536 (1992)." href="/articles/nn0800_764#ref-CR24" id="ref-link-section-d27747789e458">24</a></sup>. Functional MRI has been used to identify a small number of face-selective voxelsthe FFAthrough a comparison of faces and non-face objects in a common task<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e462">4</a></sup>. Importantly, this neural pattern replicates within the same study and generalizes across experimental conditions. That is, candidate face-selective voxels are recruited more for faces than for non-face objects even when the task and stimuli are varied. These results from imaging seem to support earlier accounts of face selectivity in the brain (and provide a method of localizing it). Different interpretations are possible, however, when categorization level and experience are taken into account.</p></div><div class="c-article-section__content"><p>To specifically address the roles of these two factors, several studies have manipulated the level of categorization and the level of expertise for non-face objects. These studies find that the response of FFA to non-face objects is affected by these manipulations independent of particular stimulus geometries<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e469">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Gauthier, I., Anderson, A. W., Tarr, M. J., Skudlarski, P. &amp; Gore, J. C. Levels of categorization in visual object studied with functional MRI. Curr. Biol. 7, 645651 (1997)." href="/articles/nn0800_764#ref-CR26" id="ref-link-section-d27747789e472">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Gauthier, I.  et al. Does visual subordinate-level categorisation engage the functionally defined Fusiform Face Area? Cognit. Neuropsychol. 17 , 143163 (2000)." href="/articles/nn0800_764#ref-CR27" id="ref-link-section-d27747789e475">27</a></sup>. Logically then, these others factors can account for most of the strong face selectivity in FFA activity.</p></div><div class="c-article-section__content"><p>
              <b>Manipulating categorization-level</b>
            </p></div><div class="c-article-section__content"><p>The FFA bilaterally shows an increased response when familiar artifactual and natural kind objects are seen in the context of visually similar stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e489">25</a></sup>. The FFA shows a similar response for animals, even when their faces are obscured<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Chao, L. L., Martin, A. &amp; Haxby, J. V. Are face-responsive regions selective only for faces? Neuroreport 10, 29452950 (1999)." href="/articles/nn0800_764#ref-CR28" id="ref-link-section-d27747789e493">28</a></sup> (but see ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Kanwisher, N., Stanley, D. &amp; Harris, A. The fusiform face area is selective for faces not animals . Neuroreport 10, 183187 (1999)." href="/articles/nn0800_764#ref-CR5" id="ref-link-section-d27747789e496">5</a>). Moreover, when the level of categorization is manipulated by different labels that subjects match to the same image (for example, TR3 versus car for the same picture of a TR3), the FFA is more active for judgments requiring classification at a subordinate level compared to more categorical judgments for a large variety of objects, living or artifactual<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Gauthier, I., Anderson, A. W., Tarr, M. J., Skudlarski, P. &amp; Gore, J. C. Levels of categorization in visual object studied with functional MRI. Curr. Biol. 7, 645651 (1997)." href="/articles/nn0800_764#ref-CR26" id="ref-link-section-d27747789e500">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Gauthier, I.  et al. Does visual subordinate-level categorisation engage the functionally defined Fusiform Face Area? Cognit. Neuropsychol. 17 , 143163 (2000)." href="/articles/nn0800_764#ref-CR27" id="ref-link-section-d27747789e503">27</a></sup>. Thus, living things, including animals and animals with hidden faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Chao, L. L., Haxby, J. V. &amp; Martin, A. Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects. Nat. Neurosci.  2, 913919 (1999)." href="/articles/nn0800_764#ref-CR15" id="ref-link-section-d27747789e507">15</a></sup>, may recruit the FFA because of their visual homogeneity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Gaffan, D. &amp; Heywood, C. A. A spurious category-specific agnosia for living things in normal human and nonhuman primates.  J. Cogn. Neurosci. 5, 118128 (1994)." href="/articles/nn0800_764#ref-CR29" id="ref-link-section-d27747789e512">29</a></sup> and the level of visual discrimination that is most often applied to them (such as distinguishing a cow from a horse by default).</p></div><div class="c-article-section__content"><p>
              <b>Manipulating level of expertise</b>
            </p></div><div class="c-article-section__content"><p>The second factor influencing FFA activity for a wide range of objects is subject expertise. The FFA and a similarly selective occipital area (OFA) in the right hemisphere<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e525">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Haxby, J. V.  et al. The effect of face inversion on activity in human neural systems for face and object perception. Neuron 22, 189199 (1999)." href="/articles/nn0800_764#ref-CR7" id="ref-link-section-d27747789e528">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Halgren, E.  et al. Location of human face-selective cortex with respect to retinotopic areas. Hum. Brain Mapp. 7, 29 37 (1999)." href="/articles/nn0800_764#ref-CR30" id="ref-link-section-d27747789e531">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gauthier, I.  et al. The fusiform face area is part of a network that processes faces at the individual level. J. Cogn. Neurosci.  12, 495504 ( 2000)." href="/articles/nn0800_764#ref-CR31" id="ref-link-section-d27747789e534">31</a></sup> are both recruited when observers become experts in discriminating objects from a visually homogeneous category (objects that share a common geometric structure). As detailed below, this occurs in subjects trained in the laboratory to be experts with novel objects called Greebles, as well as bird and car experts with 20 years of experience<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e538">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e541">25</a></sup>. Expertise here means more than practice or priming with specific instances of a class because the FFA exhibits an equivalent response for new Greebles never shown during training. Such expertise effects indicate a high degree of flexibility with regard to acceptable image geometries in the neural network mediating object recognition. Moreover, this flexibility does not have a critical period and can be harnessed for relatively novel learning experiences (such as learning to read brain scans or individuate nonsense objects such as Greebles).</p></div><div class="c-article-section__content"><p>
              <b>Automatization by expertise</b>
            </p></div><div class="c-article-section__content"><p>Object processing in the FFA can be automatized by expertise. Consider that Greeble experts show FFA activation in response to Greebles even under passive viewing instructions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e554">9</a></sup>. Moreover, whereas novices can easily focus on the top half of a composite Greeble (made out of the top of one and the bottom of another), Greeble experts cannot ignore the bottom distractor part. The behavioral changes measured by this composite effect show a significant correlation across subjects and training sessions with activity in the right FFA of Greeble experts (I.G. and M.J.T., unpublished data). Thus, neural changes with expertise, at least in the right FFA, seem to be tied strongly to holistic processing strategies. This is consistent with a PET study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Rossion, B.  et al. Hemispheric asymmetries for whole-based and part-based face processing in the human brain. J. Cogn. Neurosci. (in press)." href="/articles/nn0800_764#ref-CR32" id="ref-link-section-d27747789e558">32</a></sup> reporting that the right FFA is more active when observers attend to whole faces than face parts, whereas the opposite pattern is found in the left FFA.</p></div><div class="c-article-section__content"><p>An fMRI study of bird and car experts further supports the idea that expertise automatizes processing in the right FFA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e566">25</a></sup>. In novices, the homogeneous classes of birds and cars elicit more activity in the FFA than a set of various familiar objects, and this effect is more pronounced when subjects attend to the identity of the objects than when they attend to their location. In contrast, experts show more activity in the right FFA for their category of expertise, birds or cars, regardless of whether they attend to the identity or location of the objects. In addition, a behavioral test of relative performance in matching birds or cars is highly correlated (<i>r</i> <span class="stix"></span> 0.8) with activity in the right FFA for another set of birds or cars during the location judgments. Similarly, an ERP study of bird and dog experts found an enhanced N170the negative potential typically associated with face-specific processing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Bentin, S., Allison, T., Puce, A., Perez, E. &amp; McCarthy, G. Electrophysiological studies of face perception in humans . J. Cognit. Neurosci. 8, 551 565 (1996)." href="/articles/nn0800_764#ref-CR10" id="ref-link-section-d27747789e573">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Jeffreys, D. A. A face-responsive potential recorded from the human scalp. Exp. Brain Res. 78, 193202 ( 1989)." href="/articles/nn0800_764#ref-CR11" id="ref-link-section-d27747789e576">11</a></sup>for categorizing objects within their respective domains of expertise<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Tanaka, J. W. &amp; Curran, T. A neural basis for expert object recognition. Psychol. Sci. (in press)." href="/articles/nn0800_764#ref-CR33" id="ref-link-section-d27747789e580">33</a></sup>. Thus, both fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e584">25</a></sup> and ERP<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Tanaka, J. W. &amp; Curran, T. A neural basis for expert object recognition. Psychol. Sci. (in press)." href="/articles/nn0800_764#ref-CR33" id="ref-link-section-d27747789e589">33</a></sup> studies of experts provide evidence that the neural basis of face recognition extends to other domains of expertise.</p></div><div class="c-article-section__content"><p>Although these findings would already seem sufficient to reject the hypothesis of the FFA as a face detector<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Kanwisher, N., Tong, F. &amp; Nakayama, K. The effect of face inversion on the human fusiform face area. Cognition 68, B1 11 (1998)." href="/articles/nn0800_764#ref-CR1" id="ref-link-section-d27747789e596">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Bentin, S., Deouell, L. Y. &amp; Soroker, N. Selective visual streaming in face recognition: evidence from developmental prosopagnosia. Neuroreport 10, 823827 (1999)." href="/articles/nn0800_764#ref-CR2" id="ref-link-section-d27747789e599">2</a></sup>, additional evidence is provided by fMRI habituation procedures assessing the nature of automatized processing for faces in the FFA. A task in which subjects attended to the location of a face revealed that FFA and OFA activity habituates more to the repeated presentation of a single face than to different faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gauthier, I.  et al. The fusiform face area is part of a network that processes faces at the individual level. J. Cogn. Neurosci.  12, 495504 ( 2000)." href="/articles/nn0800_764#ref-CR31" id="ref-link-section-d27747789e603">31</a></sup>. Thus, this activity seems to reflect more than generic face detection. Also supporting the hypothesis that the FFA is involved in individuation of faces, attention to face identity (rather than to eye gaze) increases activity in the vicinity of the FFA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Hoffman, E. A. &amp; Haxby, J. V. Distinct representations of eye gaze and identity in the distributed human neural system for face perception . Nat. Neurosci. 3, 80 84 (2000)." href="/articles/nn0800_764#ref-CR34" id="ref-link-section-d27747789e607">34</a></sup>. It does not follow, however, that this area is not involved in individual face processing when subjects attend to dimensions other than identity. Indeed, several studies find that the FFA activity level in response to faces, as well as to other categories of expertise, is relatively immune to whether the task is recognition or not<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e611">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Ishai, A., Ungerleider, L. G., Martin, A., Schouten, J. L. &amp; Haxby, J. Distributed representation of objects in the human ventral visual pathway. Proc. Natl. Acad. Sci. USA  96, 93799384 ( 1999)." href="/articles/nn0800_764#ref-CR16" id="ref-link-section-d27747789e614">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e617">25</a></sup>. Thus, it seems that the FFA automatically processes objects for which observers are experts at the subordinate level, but, as with most visual processes, the efficacy of the system may be further modulated by attention.</p></div><div class="c-article-section__content"><p>
              <b>Evidence from neuropsychology</b>
            </p></div><div class="c-article-section__content"><p>The most salient neuropsychological example of impaired visual object recognition with brain injury is that of prosopagnosia. Patients with this disorder usually have suffered injury in the lingual and fusiform gyri, which typically encompass the FFA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Tranel, D., Damasio, A. R. &amp; Damasio, H. Intact recognition of facial expression, gender and age in patients with impaired recognition of face identity. Neurology  38, 690696 ( 1998)." href="/articles/nn0800_764#ref-CR35" id="ref-link-section-d27747789e630">35</a></sup>. The pattern of sparing and loss is strikingalthough they can recognize a face as a face, these patients are remarkably impaired at face recognition at the individual level, but sometimes seem to be able to recognize non-face objects. Although this deficit is often cited as evidence for a face-specific neural substrate, such as the FFA, it actually says little about the origins of face selectivity. Thus, prosopagnosia as a face-specific deficit does not distinguish among the detection, feature-map and process-map modelsall three of which acknowledge the existence of and, indeed, attempt to explain category-selective neural substrates. To the extent that prosopagnosia speaks to these models at all, it is because of an intact ability. Even though the FFA is typically lesioned in prosopagnosia, face detection is spared when tested<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Tranel, D., Damasio, A. R. &amp; Damasio, H. Intact recognition of facial expression, gender and age in patients with impaired recognition of face identity. Neurology  38, 690696 ( 1998)." href="/articles/nn0800_764#ref-CR35" id="ref-link-section-d27747789e634">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Gauthier, I., Behrmann, M. &amp; Tarr, M. J. Can face recognition really be dissociated from object recognition? J. Cogn. Neurosci. 11, 349 370 (1999)." href="/articles/nn0800_764#ref-CR36" id="ref-link-section-d27747789e637">36</a></sup>; thus, the detection model cannot account for face-selective activity in the FFA. Interestingly, autistic individuals do not show normal FFA activity when viewing faces and also have few problems with face detection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Schultz, R. T.  et al. Abnormal ventral temporal cortical activity during face discrimination among individuals with autism and asperger syndrome. Arch. Gen. Psychiatry 57, 331340 ( 2000)." href="/articles/nn0800_764#ref-CR37" id="ref-link-section-d27747789e641">37</a></sup>.</p></div><div class="c-article-section__content"><p>At the same time, a patient (CK) with the complementary pattern of sparing and losspreserved face recognition with impaired object recognitionis widely held as the other side of a double dissociation demonstrating distinct face and object recognition mechanisms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Moscovitch, M., Winocur, G. &amp; Behrmann, M. What is special about face recognition? Nineteen experiments on a person with visual object agnosia and dyslexia but normal face recognition . J. Cogn. Neurosci. 9, 555 604 (1997)." href="/articles/nn0800_764#ref-CR38" id="ref-link-section-d27747789e648">38</a></sup>. As with prosopagnosia, at issue is not whether there exist category-selective brain regions, but rather, whether these regions are domain-general or domain-specific. That is, all three models predict that a patient such as CK could occur; the question is simply why. Unfortunately, testing the domain-specificity of CK's spared recognition abilities would be difficult in that it is his holistic processing mechanisms that remain intact (given that it is generally agreed that the FFA is involved in holistic processing for faces and possibly other objects<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e652">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e655">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Gauthier, I.  et al. Does visual subordinate-level categorisation engage the functionally defined Fusiform Face Area? Cognit. Neuropsychol. 17 , 143163 (2000)." href="/articles/nn0800_764#ref-CR27" id="ref-link-section-d27747789e658">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gauthier, I.  et al. The fusiform face area is part of a network that processes faces at the individual level. J. Cogn. Neurosci.  12, 495504 ( 2000)." href="/articles/nn0800_764#ref-CR31" id="ref-link-section-d27747789e661">31</a></sup>). Within the framework of the process-map model, the recruitment of these holistic mechanisms results from the interaction between subordinate-level recognition and expertise training. CK, however, seems to have lost the ability to recognize objects in a non-holistic manner and, in particular, the ability to move from a novice to an expert for any new object class. Thus, unlike normal subjects<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e665">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Gauthier, I. &amp; Tarr, M. J. Becoming a Greeble expert: Exploring the face recognition mechanism. Vision Res.  37, 16731682 (1997)." href="/articles/nn0800_764#ref-CR39" id="ref-link-section-d27747789e668">39</a></sup>, CK cannot be bootstrapped into applying the intact components of his visual recognition system to new, non-face objects.</p></div><div class="c-article-section__content"><p>Beyond its specific inconsistency with the detection model, the syndrome of prosopagnosia reinforces the point that processing in the FFA is domain-general. In particular, patients with prosopagnosia are impaired with more than faces. Although this was raised as a possibility some time ago<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Damasio, A. R., Damasio, H. &amp; Van Hoesen, G. W. Prosopagnosia: Anatomical basis and behavioral mechanisms . Neurology 32, 331341 (1982)." href="/articles/nn0800_764#ref-CR20" id="ref-link-section-d27747789e675">20</a></sup>, it was rejected by some researchers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Farah, M. J., Levinson, K. L. &amp; Klein, K. L. Face perception and within-category discrimination in prosopagnosia. Neuropsychologia 33, 661 674 (1995)." href="/articles/nn0800_764#ref-CR40" id="ref-link-section-d27747789e679">40</a></sup> based on a study in which a prosopagnosic patient was differentially impaired at recognizing previously studied faces as compared to recognizing previously studied homogeneous non-face objects (such as eyeglasses). This experiment, however, did not consider potential response biases, for instance, the frequency with which the patient responded old to individual items actually shown during study relative to those items not shown during study, and the amount of time and effort expended by the patient for faces as compared to objects. Indeed, if the patient believed (perhaps incorrectly) that he was more impaired with faces relative to other objects, he may spend less time and allocate fewer attentional resources in encoding and recalling faces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Gauthier, I., Behrmann, M. &amp; Tarr, M. J. Can face recognition really be dissociated from object recognition? J. Cogn. Neurosci. 11, 349 370 (1999)." href="/articles/nn0800_764#ref-CR36" id="ref-link-section-d27747789e683">36</a></sup>. These concerns were addressed in a study that measured recognition response times in conjunction with a bias-free (d) measure of recognition accuracy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Gauthier, I., Behrmann, M. &amp; Tarr, M. J. Can face recognition really be dissociated from object recognition? J. Cogn. Neurosci. 11, 349 370 (1999)." href="/articles/nn0800_764#ref-CR36" id="ref-link-section-d27747789e687">36</a></sup>. Data from two patients with prosopagnosia were collected for their recognition of faces, visually similar non-face objects and Greebles. Although the patients did about as well as control subjects in recognizing objects and Greebles, they showed a speedaccuracy tradeoff to achieve this level of performance. That is, the patients spent far more time than the controls to achieve the same level of recognition accuracy. Moreover, when patients were forced to spend the same amount of time for each stimulus category, accuracy as measured by da statistic capturing a subject's ability to discriminate or remember items independent of response biasrevealed that patients with prosopagnosia are most impaired whenever visually similar stimuli must be discriminated, regardless of category. Thus, prosopagnosia may actually be a domain-general deficit when assessed using a complete picture of performance. </p></div><div class="c-article-section__content"><p>
              <b>Critiques of the process map</b>
            </p></div><div class="c-article-section__content"><p>It is our contention that behavioral, neuroimaging, and neuropsychological results provide strong evidence in support of a domain-general modelthe process-map modelfor face processing and recognition. In particular, manipulations of the factors of level of categorization and level of expertise are able to account for nearly all of the apparent differences between face and object recognition. There are, however, skeptics. Next we review and address some critiques of a domain-general account.</p></div><div class="c-article-section__content"><p>Several groups have attempted to refute the hypothesis that the reason that FFA seems face selective is because faces are recognized at the individual level, whereas other objects are recognized at a coarser level. One study compared passive viewing of faces and visually similar flowers appearing on a continuously changing background of nonsense patterns or non-face objects. When compared to a baseline of non-face objects, faces, but not flowers, produced activation in right fusiform gyrus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="McCarthy, G., Puce, A., Gore, J. C. &amp; Allison, T. Face-specific processing in the human fusiform gyrus. J. Cogn. Neurosci.  9, 605610 (1997)." href="/articles/nn0800_764#ref-CR41" id="ref-link-section-d27747789e704">41</a></sup>. Similarly, another study compared identity judgments for faces and hands and found higher activation for faces than hands as compared to a fixation baseline<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e708">4</a></sup>.</p></div><div class="c-article-section__content"><p>How can these results be reconciled with other studies indicating a role for subordinate-level processing in the FFA? First, consider that the first study used passive viewing and did not require subjects to process flowers at the subordinate level. The second study showed faces and hands for 500 ms each. As reviewed above, subordinate-level judgments not automatized by expertise typically require additional processing time<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Jolicoeur, P., Gluck, M. &amp; Kosslyn, S. M. Pictures and names: Making the connection.  Cognit. Psychol. 16, 243275 (1984)." href="/articles/nn0800_764#ref-CR42" id="ref-link-section-d27747789e715">42</a></sup>. Second, these experiments only indicate that categorization level is not sufficient to account for all the specificity in the FFA. Note that this is already assumed by our model, in which the interaction of multiple factors (such as homogeneity, categorization level and expertise) constrain face-recognition performance. </p></div><div class="c-article-section__content"><p>In sum, experiments using non-face objects can provide some evidence that a given factor influences FFA response. However, the exact contribution of a factor to the combination that leads to the maximum FFA response cannot be inferred based on the same experiment (unless it can be precisely equated for faces and objects and we know how it interacts with other factors). This also means that we cannot refute the possibility that image geometry is one of several factors that contribute to maximum selectivityat least not until maximum selectivity is obtained with non-face objects.</p></div><div class="c-article-section__content"><p>Even accepting that the FFA is involved in subordinate-level recognition, it remains possible that this area is preferentially selective for a specific geometrythat defining what sort of an image counts as a face. Refuting this argument is complexalthough we know that the FFA can become selective for other domains of expertise, for example, Greebles, birds and cars<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e725">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e728">25</a></sup>, it is often stated that Greebles look like faces and that experts can learn to apply face-selective mechanisms to other categories. These two claims seem reasonablea mechanism efficient for face processing might gain some of its efficiency by making assumptions regarding stimulus geometry. However, it is crucial that we be clear about what such claims imply, given that we have already established selectivity of the FFA in response to non-face stimuli.</p></div><div class="c-article-section__content"><p>As a specific and oft cited example, consider FFA selectivity for Greebles. Several findings indicate that Greebles are not treated as face-like in terms of their geometry. First, Greeble novices do not show Greeble-specific activation in FFA, but Greeble experts do show such activation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e736">9</a></sup>. Second, Greeble novices do not show face-like behavioral effects, but Greeble experts do show such effects<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Gauthier, I. &amp; Tarr, M. J. Becoming a Greeble expert: Exploring the face recognition mechanism. Vision Res.  37, 16731682 (1997)." href="/articles/nn0800_764#ref-CR39" id="ref-link-section-d27747789e740">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Gauthier, I., Williams, P., Tarr, M. J. &amp; Tanaka, J. Training Greeble experts: A framework for studying expert object recognition processes. Vision Res. 38, 2401 2428 (1998)." href="/articles/nn0800_764#ref-CR43" id="ref-link-section-d27747789e743">43</a></sup>. Third, CK, the agnosic patient who shows intact face recognition, but is dramatically impaired in non-face object recognition<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Moscovitch, M., Winocur, G. &amp; Behrmann, M. What is special about face recognition? Nineteen experiments on a person with visual object agnosia and dyslexia but normal face recognition . J. Cogn. Neurosci. 9, 555 604 (1997)." href="/articles/nn0800_764#ref-CR38" id="ref-link-section-d27747789e747">38</a></sup> cannot recognize Greebles any better than other objectseven when he is told to think of Greebles as faces or little people (M. Behrmann, I. G. &amp; M. J. T., unpublished observation). At most, subjects can only learn to treat Greebles like faces following an intensive training process that takes about 10 hours.</p></div><div class="c-article-section__content"><p>A second point is that subjects can see objects as face-like without recruiting those processes thought to be face-specific. For example, inverted faces are not recognized using the same configural processes as upright faces, yet anybody, including prosopagnosics, can identify inverted faces as faces. Likewise, schematic faces (made out of small geometric shapes) clearly look like faces but elicit about half as much activity as shaded faces do (equal to the activation obtained with the back of heads in a different experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Tong, F., Nakayama, K., Moscovitch, M., Weinrib, O. &amp; Kanwisher, N. Response properties of the human fusiform face area. Cognit. Neuropsychol. 17, 257279 (2000)." href="/articles/nn0800_764#ref-CR44" id="ref-link-section-d27747789e754">44</a></sup>). Finally, perhaps the best example comes from patients with prosopagnosia, who can identify faces as such, but have severe problems perceiving and recognizing them as individuals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Tranel, D., Damasio, A. R. &amp; Damasio, H. Intact recognition of facial expression, gender and age in patients with impaired recognition of face identity. Neurology  38, 690696 ( 1998)." href="/articles/nn0800_764#ref-CR35" id="ref-link-section-d27747789e758">35</a></sup>. This is consistent with our experience training Greeble experts. Neither behavioral nor neural effects of expertise with Greebles are found even when subjects are well advanced in the training but before they meet our criterion for expertise (to recognize Greebles as quickly at the individual as at the family level).</p></div><div class="c-article-section__content"><p>Thus, seeing Greebles as face-like (which any novice can do easily) does not predict expertise effects, including recruitment of the FFA. In contrast, a specific measure of holistic processing (the composite effect) with Greebles correlates with the recruitment of the FFA for Greebles in a different task (I.G. &amp; M.J.T., unpublished data). This method, combining precise psychophysics and fMRI measurements of expertise acquisition, indicates that the FFA is recruited by Greebles because experts acquire a more efficient strategy for discriminating Greebles, not because subjects learn to see Greebles as face-like. Reinforcing this point, even when Greeble experts successfully transfer their expert abilities to the recognition of new Greeble exemplars, their expertise may not apply to new Greebles that are more homogeneous than the original training set, even though the new Greebles clearly look equivalently face-like (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn0800_764#Fig1">Fig. 1</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Examples of Greebles."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1: Examples of Greebles.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn0800_764/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2F77666/MediaObjects/41593_2000_Article_BFnn0800_764_Fig1_HTML.gif?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2F77666/MediaObjects/41593_2000_Article_BFnn0800_764_Fig1_HTML.gif" alt="figure 1" loading="lazy" width="560" height="308"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>(<b>a</b>) Greebles from a set that Greeble experts could learn to recognize faster than novices. (<b>b</b>) Another set of Greebles, which the same experts could not learn faster than novices, presumably because they are more visually homogeneous than Greebles in the training set. Filled squares denote data from novices, and open circles denote data from experts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Gauthier, I., Williams, P., Tarr, M. J. &amp; Tanaka, J. Training Greeble experts: A framework for studying expert object recognition processes. Vision Res. 38, 2401 2428 (1998)." href="/articles/nn0800_764#ref-CR43" id="ref-link-section-d27747789e786">43</a></sup>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn0800_764/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div></div><div class="c-article-section__content"><p>The evidence for selectivity on a purely geometric level in the FFA is not strong, although it is possible that the FFA tends to respond to objects that are face-like because our perceptual expertise with faces makes this geometry a cue that the computations executed in the FFA are required. However, our results indicate experience recognizing Greebles, cars or birds at the individual level can make the geometries of these objects equally valid cues. Selectivity for particular image geometry is learneda point driven home because objects of acceptable geometry do not activate the FFA by default. Thus, selectivity at a purely geometric level does not provide an adequate account of FFA specialization. In contrast, as already reviewed, we have established that level of categorization and expertise in a given object domain do affect the response of FFA independent of stimulus geometry. We argue that it is the manipulation of these factors, not stimulus geometry, that leads to recruitment of the FFA.</p></div><div class="c-article-section__content"><p>Could different interpretations for the function of the FFA depend on how we define this area? One method consists of defining a face-selective area in a group of subjects and measuring its behavior in other conditions (in the same or another group). This averaging method is not optimal, but it may be useful when individual localizers are not available. A study comparing group-averaged with individual functional definitions revealed that even though a FFA can be found in the large majority of subjects, it is small enough and variable enough in its location that the former approach may be inadequate<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Gauthier, I.  et al. Does visual subordinate-level categorisation engage the functionally defined Fusiform Face Area? Cognit. Neuropsychol. 17 , 143163 (2000)." href="/articles/nn0800_764#ref-CR27" id="ref-link-section-d27747789e804">27</a></sup>. Specifically, if the defined region is large enough to encompass the FFA for all subjects, it also includes many non-face-selective voxels, and if it is small enough to contain only face-selective voxels, it may not include the FFA of many subjects.</p></div><div class="c-article-section__content"><p>Given these problems, many researchers have chosen to rely on individual localizers, leading to very small and highly selective FFAs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e811">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . Nat. Neurosci. 2, 568 573 (1999)." href="/articles/nn0800_764#ref-CR9" id="ref-link-section-d27747789e814">9</a></sup>. This approach sustains a certain illusion: that of a sharply defined area that is stable across conditions. Typically, a localizer is used to define a FFA at the outset of the study, and all further analyses reflect the response of only these voxels. Little consideration is given to the potential variability of the FFA. For instance, both the peaks of face selectivity and the extent of the FFA as defined using a faces-minus-objects comparison can differ substantially within subjects during passive viewing as compared to an active identification task<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . Nat. Neurosci. 3, 191 197 (2000)." href="/articles/nn0800_764#ref-CR25" id="ref-link-section-d27747789e818">25</a></sup>. This issue is highly relevant to the nature of the selectivity in the FFA, as differences between faces and non-face objects must be weighed against the variability of face selectivity itself. To the extent the microstructure of this variability can be assessed with current techniques, there is no indication that the face-selective part of cortex is in any sense mutually exclusive with the rest of the object-recognition system. In a fMRI study of bird and car experts, several criteria for the definition of the FFA were compared (see <a href="http://www.nature.com/neuro/web_specials">http://www.nature.com/neuro/web_specials</a>). The criterion most stringent in terms of size and face selectivity (face to object activity ratio, 12.8) led to a right FFA region of interest with an average size of 3 voxels (each voxel was 3.125 mm<sup>2</sup> in plane) but could be found in all 19 subjects. In comparison, the criterion used in many prior studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. J. Neurosci.  17, 43024311 (1997)." href="/articles/nn0800_764#ref-CR4" id="ref-link-section-d27747789e831">4</a></sup> led to a larger area (average size of 6 voxels), which displayed more moderate face selectivity (face to object activity ratio, 5.2) but was less inclusive subject-wise (a right FFA only found in 7 of 19 subjects). Crucially, regardless of criterion, the FFA showed sensitivity to the level of categorization and expertise manipulations. This and several other analyses, such as center of mass comparisons and inspection of the peaks in unsmoothed activation maps, indicate that face expertise cannot be dissociated from object expertise at the spatial resolution of fMRI.</p></div><div class="c-article-section__content"><p>The existence of face cells in IT<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Perrett, D. I., Rolls, E. T. &amp; Caan, W. Visual neurones responsive to faces in the monkey temporal cortex. Exp. Brain Res. 47, 329 342 (1982)." href="/articles/nn0800_764#ref-CR45" id="ref-link-section-d27747789e839">45</a></sup> is often cited as evidence for a distinct recognition mechanism for faces. On the other hand, studies in which monkeys learn to recognize novel objects have revealed a remarkable similarity between properties of cells tuned to these trained objects and face cells<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Kobatake, E., Wang, G. &amp; Tanaka, K. Effects of shape-discrimination training on the selectivity of inferotemporal cells in adult monkeys. J. Neurophysiol.  80, 324330 (1998)." href="/articles/nn0800_764#ref-CR46" id="ref-link-section-d27747789e843">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Logothetis, N. K. &amp; Pauls, J. Psychophysical and physiological evidence for viewer-centered object representation in the primate . Cereb. Cortex 3, 270 288 (1995)." href="/articles/nn0800_764#ref-CR47" id="ref-link-section-d27747789e846">47</a></sup>. One interpretation is that it would be surprising if neurons exist that respond strongly to both faces and cars (but not other complex objects) in car experts (for example)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Kanwisher, N., Downing, P., Epstein, R. &amp; Kourtzi, Z. in Handbook of Functional Neuroimaging of Cognition (eds. Cabeza, R. &amp; Kingstone, A.) (MIT Press, Cambridge, MA, in press)." href="/articles/nn0800_764#ref-CR48" id="ref-link-section-d27747789e850">48</a></sup>. The implication is that faces and objects would selectively activate independent populations of neurons, interspersed within the same fMRI voxel. Even if this were the case, the intermingling of at least two populations of neurons in a relatively small region of IT would suggest that these neurons serve similar functional roles, but with somewhat different tuning (for instance, adjacent cortical columns are tuned to specific orientations, but the functional role of the entire area is a coding of orientation spacearguing that faces are special in this context is equivalent to suggesting that vertical lines are special, too).</p></div><div class="c-article-section__content"><p>Moreover, the finding that a given neuron responds most strongly to a specific stimulus does not imply that this same neuron is not functionally implicated in the processing of other stimuli. For example, neurophysiologists often rely on a reduction method<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Tanaka, K. Inferotemporal cortex and object vision. Annu. Rev. Neurosci.  19, 109139 (1996)." href="/articles/nn0800_764#ref-CR17" id="ref-link-section-d27747789e857">17</a></sup> in which, beginning with an image from a restricted basis set, they incrementally simplify the test stimulus while attempting to maintain the same level of cell response. Thus, the reduction method is bound to produce a single preferred feature set per cell. In contrast, IT cells can have responses that defy simple explanations in terms of singular preferred features (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn0800_764#Fig2">Fig. 2</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Complex selectivity of IT cells."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2: Complex selectivity of IT cells.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn0800_764/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2F77666/MediaObjects/41593_2000_Article_BFnn0800_764_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2F77666/MediaObjects/41593_2000_Article_BFnn0800_764_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="560" height="536"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Adapted from ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Sheinberg, D. L. &amp; Logothetis, N. K. in Perceptual Learning (ed. Fahle, M.) (MIT Press, Cambridge, Massachusetts, 2000)." href="/articles/nn0800_764#ref-CR49" id="ref-link-section-d27747789e875">49</a>. (<b>a</b>) This cell responded most to the picture of a teacup, and also responded more to the picture of a balloon than all other images tested. Although the selectivity of this cell may be based on color, this set of responses illustrates that any hypothesis about the selectivity of a neuron is highly dependent upon the stimulus set used in an experiment. (<b>b</b>) A cell that responds to a subset of animals, with no obvious measure of similarity separating the effective from ineffective stimuli. The authors<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Sheinberg, D. L. &amp; Logothetis, N. K. in Perceptual Learning (ed. Fahle, M.) (MIT Press, Cambridge, Massachusetts, 2000)." href="/articles/nn0800_764#ref-CR49" id="ref-link-section-d27747789e885">49</a></sup> argue that selectivity emerges from experience and that images that activate IT neurons need not be especially similar to one another.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn0800_764/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-chevron-right"></use></svg></a></div></figure></div></div><div class="c-article-section__content"><p>
              <b>Conclusions</b>
            </p></div><div class="c-article-section__content"><p>From grandmothers to scientists (and the two are not mutually exclusive), there is a certain fondness for the idea that the difficulty of face recognition combined with its social importance has exerted unique adaptive pressures. Thus, it is often argued, it would not be particularly surprising if there were a distinct neural and functional module for face recognition. Although the adaptive pressures may be real, this implies only that the primate visual system should be capable of efficiently performing this task, not that whatever perceptual mechanisms represent the present end-state of evolution must be exclusive to faces. Put another way, speculating on the evolutionary reasons for why a particular neural system might have arisen does not define the limits of this system. In an effort to explore these limits, we have collected evidence that FFA processing is domain-general. Specifically, it is involved in processing subordinate-level information for all objects, including faces. This processing is not restricted to objects of a certain geometry (that is, faces), as this factor cannot account for the majority of responses in the FFA to non-face objects. On the other hand, manipulations of the level of categorization and the level of expertise are able to predict when and if FFA activity will be found in a given task. Thus, even if stimulus geometry is somehow involved in FFA selectivity, it is likely to remain only one of several factors that contribute to the specialization of this brain area. That faces generally elicit the maximum response in the FFA is interesting, but only as an effect that is inherently confounded with the processing biases that, through experience, are automatically engaged when we see a face.</p></div>
                </div>
            

            <div data-enable-entitlement-checks>
            <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1"><p class="c-article-references__text" id="ref-CR1">Kanwisher, N., Tong, F. &amp; Nakayama, K. The effect of face inversion on the human fusiform face area. <i>Cognition</i> <b>68</b>, B1 11 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0010-0277(98)00035-3" data-track-action="article reference" href="https://doi.org/10.1016%2FS0010-0277%2898%2900035-3" aria-label="Article reference 1" data-doi="10.1016/S0010-0277(98)00035-3">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1cvkvVKmtQ%3D%3D" aria-label="CAS reference 1">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20face%20inversion%20on%20the%20human%20fusiform%20face%20area&amp;journal=Cognition&amp;doi=10.1016%2FS0010-0277%2898%2900035-3&amp;volume=68&amp;pages=B1-11&amp;publication_year=1998&amp;author=Kanwisher%2CN&amp;author=Tong%2CF&amp;author=Nakayama%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2"><p class="c-article-references__text" id="ref-CR2">Bentin, S., Deouell, L. Y. &amp; Soroker, N. Selective visual streaming in face recognition: evidence from developmental prosopagnosia. <i>Neuroreport</i> <b>10</b>, 823827 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/00001756-199903170-00029" data-track-action="article reference" href="https://doi.org/10.1097%2F00001756-199903170-00029" aria-label="Article reference 2" data-doi="10.1097/00001756-199903170-00029">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M3itlamtg%3D%3D" aria-label="CAS reference 2">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Selective%20visual%20streaming%20in%20face%20recognition%3A%20evidence%20from%20developmental%20prosopagnosia&amp;journal=Neuroreport&amp;doi=10.1097%2F00001756-199903170-00029&amp;volume=10&amp;pages=823-827&amp;publication_year=1999&amp;author=Bentin%2CS&amp;author=Deouell%2CLY&amp;author=Soroker%2CN">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3"><p class="c-article-references__text" id="ref-CR3">Puce, A., Allison, T. &amp; McCarthy, G. Electrophysiological studies of human face perception. III: Effects of top-down processing on face-specific potentials. <i> Cereb. Cortex</i> <b>9</b>, 445458 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/9.5.445" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F9.5.445" aria-label="Article reference 3" data-doi="10.1093/cercor/9.5.445">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1MznvVSquw%3D%3D" aria-label="CAS reference 3">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrophysiological%20studies%20of%20human%20face%20perception.%20III%3A%20Effects%20of%20top-down%20processing%20on%20face-specific%20potentials&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F9.5.445&amp;volume=9&amp;pages=445-458&amp;publication_year=1999&amp;author=Puce%2CA&amp;author=Allison%2CT&amp;author=McCarthy%2CG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4"><p class="c-article-references__text" id="ref-CR4">Kanwisher, N., McDermott, J. &amp; Chun, M. M. The fusiform face area: A module in human extrastriate cortex specialized for face perception. <i>J. Neurosci.</i> <b> 17</b>, 43024311 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.17-11-04302.1997" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.17-11-04302.1997" aria-label="Article reference 4" data-doi="10.1523/JNEUROSCI.17-11-04302.1997">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK2sXjtl2mur0%3D" aria-label="CAS reference 4">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20fusiform%20face%20area%3A%20A%20module%20in%20human%20extrastriate%20cortex%20specialized%20for%20face%20perception&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.17-11-04302.1997&amp;volume=17&amp;pages=4302-4311&amp;publication_year=1997&amp;author=Kanwisher%2CN&amp;author=McDermott%2CJ&amp;author=Chun%2CMM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5"><p class="c-article-references__text" id="ref-CR5">Kanwisher, N., Stanley, D. &amp; Harris, A. The fusiform face area is selective for faces not animals . <i>Neuroreport</i> <b>10</b>, 183187 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/00001756-199901180-00035" data-track-action="article reference" href="https://doi.org/10.1097%2F00001756-199901180-00035" aria-label="Article reference 5" data-doi="10.1097/00001756-199901180-00035">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M7ptF2ntQ%3D%3D" aria-label="CAS reference 5">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20fusiform%20face%20area%20is%20selective%20for%20faces%20not%20animals&amp;journal=Neuroreport&amp;doi=10.1097%2F00001756-199901180-00035&amp;volume=10&amp;pages=183-187&amp;publication_year=1999&amp;author=Kanwisher%2CN&amp;author=Stanley%2CD&amp;author=Harris%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6"><p class="c-article-references__text" id="ref-CR6">Aguirre, G. K., Zarahn, E. &amp; D'Esposito, M. An area within human ventral cortex sensitive to building stimuli: Evidence and implications. <i>Neuron</i> <b>21</b>, 373383 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(00)80546-2" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2800%2980546-2" aria-label="Article reference 6" data-doi="10.1016/S0896-6273(00)80546-2">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1cXlslKnsr0%3D" aria-label="CAS reference 6">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20area%20within%20human%20ventral%20cortex%20sensitive%20to%20%E2%80%9Cbuilding%E2%80%9D%20stimuli%3A%20Evidence%20and%20implications&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2800%2980546-2&amp;volume=21&amp;pages=373-383&amp;publication_year=1998&amp;author=Aguirre%2CGK&amp;author=Zarahn%2CE&amp;author=D%27Esposito%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7"><p class="c-article-references__text" id="ref-CR7">Haxby, J. V. <i> et al</i>. The effect of face inversion on activity in human neural systems for face and object perception. <i>Neuron</i> <b>22</b>, 189199 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(00)80690-X" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2800%2980690-X" aria-label="Article reference 7" data-doi="10.1016/S0896-6273(00)80690-X">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXhtVGhsrs%3D" aria-label="CAS reference 7">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20face%20inversion%20on%20activity%20in%20human%20neural%20systems%20for%20face%20and%20object%20perception&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2800%2980690-X&amp;volume=22&amp;pages=189-199&amp;publication_year=1999&amp;author=Haxby%2CJV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8"><p class="c-article-references__text" id="ref-CR8">Yin, R. K. Looking at upside-down faces. <i>J. Exp. Psychol. Gen.</i> <b> 81</b>, 141145 (1969).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/h0027474" data-track-action="article reference" href="https://doi.org/10.1037%2Fh0027474" aria-label="Article reference 8" data-doi="10.1037/h0027474">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Looking%20at%20upside-down%20faces&amp;journal=J.%20Exp.%20Psychol.%20Gen.&amp;doi=10.1037%2Fh0027474&amp;volume=81&amp;pages=141-145&amp;publication_year=1969&amp;author=Yin%2CRK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9"><p class="c-article-references__text" id="ref-CR9">Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P. &amp; Gore, J. C. Activation of the middle fusiform face area increases with expertise in recognizing novel objects . <i>Nat. Neurosci.</i> <b>2</b>, 568 573 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/9224" data-track-action="article reference" href="https://doi.org/10.1038%2F9224" aria-label="Article reference 9" data-doi="10.1038/9224">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXjsFSis7s%3D" aria-label="CAS reference 9">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Activation%20of%20the%20middle%20fusiform%20%E2%80%98face%20area%E2%80%99%20increases%20with%20expertise%20in%20recognizing%20novel%20objects&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F9224&amp;volume=2&amp;pages=568-573&amp;publication_year=1999&amp;author=Gauthier%2CI&amp;author=Tarr%2CMJ&amp;author=Anderson%2CA%20W&amp;author=Skudlarski%2CP&amp;author=Gore%2CJC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10"><p class="c-article-references__text" id="ref-CR10">Bentin, S., Allison, T., Puce, A., Perez, E. &amp; McCarthy, G. Electrophysiological studies of face perception in humans . <i>J. Cognit. Neurosci.</i> <b>8</b>, 551 565 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn.1996.8.6.551" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn.1996.8.6.551" aria-label="Article reference 10" data-doi="10.1162/jocn.1996.8.6.551">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrophysiological%20studies%20of%20face%20perception%20in%20humans&amp;journal=J.%20Cognit.%20Neurosci.&amp;doi=10.1162%2Fjocn.1996.8.6.551&amp;volume=8&amp;pages=551-565&amp;publication_year=1996&amp;author=Bentin%2CS&amp;author=Allison%2CT&amp;author=Puce%2CA&amp;author=Perez%2CE&amp;author=McCarthy%2CG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11"><p class="c-article-references__text" id="ref-CR11">Jeffreys, D. A. A face-responsive potential recorded from the human scalp. <i>Exp. Brain Res.</i> <b>78</b>, 193202 ( 1989).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/BF00230699" data-track-action="article reference" href="https://doi.org/10.1007%2FBF00230699" aria-label="Article reference 11" data-doi="10.1007/BF00230699">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK3c%2Fns1Cntg%3D%3D" aria-label="CAS reference 11">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20face-responsive%20potential%20recorded%20from%20the%20human%20scalp&amp;journal=Exp.%20Brain%20Res.&amp;doi=10.1007%2FBF00230699&amp;volume=78&amp;pages=193-202&amp;publication_year=1989&amp;author=Jeffreys%2CDA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12"><p class="c-article-references__text" id="ref-CR12">Liu, J., Higuchi, M., Marantz, A. &amp; Kanwisher, N. The selectivity of the occipitotemporal M170 for faces. <i>Neuroreport</i> <b> 7</b>, 337341 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/00001756-200002070-00023" data-track-action="article reference" href="https://doi.org/10.1097%2F00001756-200002070-00023" aria-label="Article reference 12" data-doi="10.1097/00001756-200002070-00023">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20selectivity%20of%20the%20occipitotemporal%20M170%20for%20faces&amp;journal=Neuroreport&amp;doi=10.1097%2F00001756-200002070-00023&amp;volume=7&amp;pages=337-341&amp;publication_year=2000&amp;author=Liu%2CJ&amp;author=Higuchi%2CM&amp;author=Marantz%2CA&amp;author=Kanwisher%2CN">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13"><p class="c-article-references__text" id="ref-CR13">Rossion, B. <i> et al</i>. The N170 occipito-temporal component is delayed and enhanced to inverted faces but not to inverted objects: An electrophysiological account of face-specific processes in the human brain. <i>Neuroreport</i> <b> 11</b>, 6974 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/00001756-200001170-00014" data-track-action="article reference" href="https://doi.org/10.1097%2F00001756-200001170-00014" aria-label="Article reference 13" data-doi="10.1097/00001756-200001170-00014">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3c7kslCmtA%3D%3D" aria-label="CAS reference 13">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20N170%20occipito-temporal%20component%20is%20delayed%20and%20enhanced%20to%20inverted%20faces%20but%20not%20to%20inverted%20objects%3A%20An%20electrophysiological%20account%20of%20face-specific%20processes%20in%20the%20human%20brain&amp;journal=Neuroreport&amp;doi=10.1097%2F00001756-200001170-00014&amp;volume=11&amp;pages=69-74&amp;publication_year=2000&amp;author=Rossion%2CB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14"><p class="c-article-references__text" id="ref-CR14">McCarthy, G., Puce, A., Belger, A. &amp; Allison, T. Electrophysiological studies of human face perception. II: Response properties of face-specific potentials generated in occipitotemporal cortex. <i>Cereb. Cortex </i> <b>5</b>, 431444 ( 1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/9.5.431" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F9.5.431" aria-label="Article reference 14" data-doi="10.1093/cercor/9.5.431">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Electrophysiological%20studies%20of%20human%20face%20perception.%20II%3A%20Response%20properties%20of%20face-specific%20potentials%20generated%20in%20occipitotemporal%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F9.5.431&amp;volume=5&amp;pages=431-444&amp;publication_year=1999&amp;author=McCarthy%2CG&amp;author=Puce%2CA&amp;author=Belger%2CA&amp;author=Allison%2CT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15"><p class="c-article-references__text" id="ref-CR15">Chao, L. L., Haxby, J. V. &amp; Martin, A. Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects. <i>Nat. Neurosci.</i> <b> 2</b>, 913919 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/13217" data-track-action="article reference" href="https://doi.org/10.1038%2F13217" aria-label="Article reference 15" data-doi="10.1038/13217">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXmsVyjsrs%3D" aria-label="CAS reference 15">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Attribute-based%20neural%20substrates%20in%20temporal%20cortex%20for%20perceiving%20and%20knowing%20about%20objects&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F13217&amp;volume=2&amp;pages=913-919&amp;publication_year=1999&amp;author=Chao%2CLL&amp;author=Haxby%2CJV&amp;author=Martin%2CA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16"><p class="c-article-references__text" id="ref-CR16">Ishai, A., Ungerleider, L. G., Martin, A., Schouten, J. L. &amp; Haxby, J. Distributed representation of objects in the human ventral visual pathway. <i>Proc. Natl. Acad. Sci. USA </i> <b>96</b>, 93799384 ( 1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.96.16.9379" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.96.16.9379" aria-label="Article reference 16" data-doi="10.1073/pnas.96.16.9379">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXltVCjs70%3D" aria-label="CAS reference 16">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20representation%20of%20objects%20in%20the%20human%20ventral%20visual%20pathway&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.96.16.9379&amp;volume=96&amp;pages=9379-9384&amp;publication_year=1999&amp;author=Ishai%2CA&amp;author=Ungerleider%2CLG&amp;author=Martin%2CA&amp;author=Schouten%2CJL&amp;author=Haxby%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17"><p class="c-article-references__text" id="ref-CR17">Tanaka, K. Inferotemporal cortex and object vision. <i>Annu. Rev. Neurosci.</i> <b> 19</b>, 109139 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.ne.19.030196.000545" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.ne.19.030196.000545" aria-label="Article reference 17" data-doi="10.1146/annurev.ne.19.030196.000545">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK28XhsVClu7s%3D" aria-label="CAS reference 17">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Inferotemporal%20cortex%20and%20object%20vision&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.ne.19.030196.000545&amp;volume=19&amp;pages=109-139&amp;publication_year=1996&amp;author=Tanaka%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18"><p class="c-article-references__text" id="ref-CR18">Puce, A., Allison, T., Asgari, M., Gore, J. C. &amp; McCarthy, G. Differential sensitivity of human visual cortex to faces, letterstrings, and textures: A functional magnetic resonance imaging study . <i>J. Neurosci.</i> <b>16</b>, 5205 5215 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.16-16-05205.1996" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.16-16-05205.1996" aria-label="Article reference 18" data-doi="10.1523/JNEUROSCI.16-16-05205.1996">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK28XkvFahtLg%3D" aria-label="CAS reference 18">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Differential%20sensitivity%20of%20human%20visual%20cortex%20to%20faces%2C%20letterstrings%2C%20and%20textures%3A%20A%20functional%20magnetic%20resonance%20imaging%20study&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.16-16-05205.1996&amp;volume=16&amp;pages=5205-5215&amp;publication_year=1996&amp;author=Puce%2CA&amp;author=Allison%2CT&amp;author=Asgari%2CM&amp;author=Gore%2CJC&amp;author=McCarthy%2CG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19"><p class="c-article-references__text" id="ref-CR19">Gauthier, I. What constrains the organization of the ventral temporal cortex? <i> Trends Cogn. Sci.</i> <b>4</b>, 12 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S1364-6613(99)01416-3" data-track-action="article reference" href="https://doi.org/10.1016%2FS1364-6613%2899%2901416-3" aria-label="Article reference 19" data-doi="10.1016/S1364-6613(99)01416-3">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC2sbhtlertw%3D%3D" aria-label="CAS reference 19">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20constrains%20the%20organization%20of%20the%20ventral%20temporal%20cortex%3F&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2FS1364-6613%2899%2901416-3&amp;volume=4&amp;pages=1-2&amp;publication_year=2000&amp;author=Gauthier%2CI">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20"><p class="c-article-references__text" id="ref-CR20">Damasio, A. R., Damasio, H. &amp; Van Hoesen, G. W. Prosopagnosia: Anatomical basis and behavioral mechanisms . <i>Neurology</i> <b>32</b>, 331341 (1982).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1212/WNL.32.4.331" data-track-action="article reference" href="https://doi.org/10.1212%2FWNL.32.4.331" aria-label="Article reference 20" data-doi="10.1212/WNL.32.4.331">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL387kvV2hsA%3D%3D" aria-label="CAS reference 20">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Prosopagnosia%3A%20Anatomical%20basis%20and%20behavioral%20mechanisms&amp;journal=Neurology&amp;doi=10.1212%2FWNL.32.4.331&amp;volume=32&amp;pages=331-341&amp;publication_year=1982&amp;author=Damasio%2CAR&amp;author=Damasio%2CH&amp;author=Van%20Hoesen%2CGW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21"><p class="c-article-references__text" id="ref-CR21">Diamond, R. &amp; Carey, S. Why faces are and are not special: An effect of expertise. <i>J. Exp. Psychol. Gen.</i> <b>115</b>, 107117 (1986).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0096-3445.115.2.107" data-track-action="article reference" href="https://doi.org/10.1037%2F0096-3445.115.2.107" aria-label="Article reference 21" data-doi="10.1037/0096-3445.115.2.107">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL283is1Sisg%3D%3D" aria-label="CAS reference 21">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20faces%20are%20and%20are%20not%20special%3A%20An%20effect%20of%20expertise&amp;journal=J.%20Exp.%20Psychol.%20Gen.&amp;doi=10.1037%2F0096-3445.115.2.107&amp;volume=115&amp;pages=107-117&amp;publication_year=1986&amp;author=Diamond%2CR&amp;author=Carey%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22"><p class="c-article-references__text" id="ref-CR22">Tanaka, J. W. &amp; Gauthier, I. in <i>Mechanisms of Perceptual Learning </i> (eds. Goldstone, R. L., Medin, D. L. &amp; Schyns, P. G.) 83 125 (Academic, San Diego, California, 1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Mechanisms%20of%20Perceptual%20Learning&amp;pages=83-125&amp;publication_year=1997&amp;author=Tanaka%2CJW&amp;author=Gauthier%2CI">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23"><p class="c-article-references__text" id="ref-CR23">Haxby, J. V. <i> et al</i>. Dissociation of object and spatial visual processing pathways in human extrastriate cortex. <i>Proc. Natl. Acad. Sci. USA</i> <b> 88</b>, 16211625 (1991).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.88.5.1621" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.88.5.1621" aria-label="Article reference 23" data-doi="10.1073/pnas.88.5.1621">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK3M7ls1Klsg%3D%3D" aria-label="CAS reference 23">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Dissociation%20of%20object%20and%20spatial%20visual%20processing%20pathways%20in%20human%20extrastriate%20cortex&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.88.5.1621&amp;volume=88&amp;pages=1621-1625&amp;publication_year=1991&amp;author=Haxby%2CJV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24"><p class="c-article-references__text" id="ref-CR24">Sergent, J., Ohta, S. &amp; MacDonald, B. Functional neuroanatomy of face and object processing: A positron emission tomography study. <i>Brain</i> <b>115</b>, 1536 (1992).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/brain/115.1.15" data-track-action="article reference" href="https://doi.org/10.1093%2Fbrain%2F115.1.15" aria-label="Article reference 24" data-doi="10.1093/brain/115.1.15">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20neuroanatomy%20of%20face%20and%20object%20processing%3A%20A%20positron%20emission%20tomography%20study&amp;journal=Brain&amp;doi=10.1093%2Fbrain%2F115.1.15&amp;volume=115&amp;pages=15-36&amp;publication_year=1992&amp;author=Sergent%2CJ&amp;author=Ohta%2CS&amp;author=MacDonald%2CB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25"><p class="c-article-references__text" id="ref-CR25">Gauthier, I., Skudlarski, P., Gore, J. C. &amp; Anderson, A. W. Expertise for cars and birds recruits brain areas involved in face recognition . <i>Nat. Neurosci.</i> <b>3</b>, 191 197 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/72140" data-track-action="article reference" href="https://doi.org/10.1038%2F72140" aria-label="Article reference 25" data-doi="10.1038/72140">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3cXhslKls7g%3D" aria-label="CAS reference 25">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Expertise%20for%20cars%20and%20birds%20recruits%20brain%20areas%20involved%20in%20face%20recognition&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F72140&amp;volume=3&amp;pages=191-197&amp;publication_year=2000&amp;author=Gauthier%2CI&amp;author=Skudlarski%2CP&amp;author=Gore%2CJC&amp;author=Anderson%2CAW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26"><p class="c-article-references__text" id="ref-CR26">Gauthier, I., Anderson, A. W., Tarr, M. J., Skudlarski, P. &amp; Gore, J. C. Levels of categorization in visual object studied with functional MRI. <i>Curr. Biol.</i> <b>7</b>, 645651 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0960-9822(06)00291-0" data-track-action="article reference" href="https://doi.org/10.1016%2FS0960-9822%2806%2900291-0" aria-label="Article reference 26" data-doi="10.1016/S0960-9822(06)00291-0">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK2sXmsVSis7w%3D" aria-label="CAS reference 26">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Levels%20of%20categorization%20in%20visual%20object%20studied%20with%20functional%20MRI&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2FS0960-9822%2806%2900291-0&amp;volume=7&amp;pages=645-651&amp;publication_year=1997&amp;author=Gauthier%2CI&amp;author=Anderson%2CAW&amp;author=Tarr%2CM%20J&amp;author=Skudlarski%2CP&amp;author=Gore%2CJC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27"><p class="c-article-references__text" id="ref-CR27">Gauthier, I. <i> et al</i>. Does visual subordinate-level categorisation engage the functionally defined Fusiform Face Area? <i>Cognit. Neuropsychol.</i> <b>17 </b>, 143163 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/026432900380544" data-track-action="article reference" href="https://doi.org/10.1080%2F026432900380544" aria-label="Article reference 27" data-doi="10.1080/026432900380544">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3cfptlGksA%3D%3D" aria-label="CAS reference 27">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Does%20visual%20subordinate-level%20categorisation%20engage%20the%20functionally%20defined%20Fusiform%20Face%20Area%3F&amp;journal=Cognit.%20Neuropsychol.&amp;doi=10.1080%2F026432900380544&amp;volume=17&amp;pages=143-163&amp;publication_year=2000&amp;author=Gauthier%2CI">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28"><p class="c-article-references__text" id="ref-CR28">Chao, L. L., Martin, A. &amp; Haxby, J. V. Are face-responsive regions selective only for faces? <i>Neuroreport</i> <b>10</b>, 29452950 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/00001756-199909290-00013" data-track-action="article reference" href="https://doi.org/10.1097%2F00001756-199909290-00013" aria-label="Article reference 28" data-doi="10.1097/00001756-199909290-00013">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3c%2FhsF2qtw%3D%3D" aria-label="CAS reference 28">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Are%20face-responsive%20regions%20selective%20only%20for%20faces%3F&amp;journal=Neuroreport&amp;doi=10.1097%2F00001756-199909290-00013&amp;volume=10&amp;pages=2945-2950&amp;publication_year=1999&amp;author=Chao%2CLL&amp;author=Martin%2CA&amp;author=Haxby%2CJ%20V">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29"><p class="c-article-references__text" id="ref-CR29">Gaffan, D. &amp; Heywood, C. A. A spurious category-specific agnosia for living things in normal human and nonhuman primates. <i> J. Cogn. Neurosci.</i> <b>5</b>, 118128 (1994).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn.1993.5.1.118" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn.1993.5.1.118" aria-label="Article reference 29" data-doi="10.1162/jocn.1993.5.1.118">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20spurious%20category-specific%20agnosia%20for%20living%20things%20in%20normal%20human%20and%20nonhuman%20primates&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn.1993.5.1.118&amp;volume=5&amp;pages=118-128&amp;publication_year=1994&amp;author=Gaffan%2CD&amp;author=Heywood%2CCA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30"><p class="c-article-references__text" id="ref-CR30">Halgren, E. <i> et al</i>. Location of human face-selective cortex with respect to retinotopic areas. <i>Hum. Brain Mapp.</i> <b>7</b>, 29 37 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/(SICI)1097-0193(1999)7:1<29::AID-HBM3&gt;3.0.CO;2-R" data-track-action="article reference" href="https://doi.org/10.1002%2F%28SICI%291097-0193%281999%297%3A1%3C29%3A%3AAID-HBM3%3E3.0.CO%3B2-R" aria-label="Article reference 30" data-doi="10.1002/(SICI)1097-0193(1999)7:1<29::AID-HBM3&gt;3.0.CO;2-R">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M%2Fps1Citw%3D%3D" aria-label="CAS reference 30">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Location%20of%20human%20face-selective%20cortex%20with%20respect%20to%20retinotopic%20areas&amp;journal=Hum.%20Brain%20Mapp.&amp;doi=10.1002%2F%28SICI%291097-0193%281999%297%3A1%3C29%3A%3AAID-HBM3%3E3.0.CO%3B2-R&amp;volume=7&amp;pages=29-37&amp;publication_year=1999&amp;author=Halgren%2CE">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31"><p class="c-article-references__text" id="ref-CR31">Gauthier, I. <i> et al</i>. The fusiform face area is part of a network that processes faces at the individual level. <i>J. Cogn. Neurosci. </i> <b>12</b>, 495504 ( 2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/089892900562165" data-track-action="article reference" href="https://doi.org/10.1162%2F089892900562165" aria-label="Article reference 31" data-doi="10.1162/089892900562165">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3cvjsVKgsw%3D%3D" aria-label="CAS reference 31">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20fusiform%20%E2%80%9Cface%20area%E2%80%9D%20is%20part%20of%20a%20network%20that%20processes%20faces%20at%20the%20individual%20level&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2F089892900562165&amp;volume=12&amp;pages=495-504&amp;publication_year=2000&amp;author=Gauthier%2CI">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32"><p class="c-article-references__text" id="ref-CR32">Rossion, B. <i> et al</i>. Hemispheric asymmetries for whole-based and part-based face processing in the human brain. <i>J. Cogn. Neurosci.</i> (in press).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33"><p class="c-article-references__text" id="ref-CR33">Tanaka, J. W. &amp; Curran, T. A neural basis for expert object recognition. <i>Psychol. Sci.</i> (in press).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34"><p class="c-article-references__text" id="ref-CR34">Hoffman, E. A. &amp; Haxby, J. V. Distinct representations of eye gaze and identity in the distributed human neural system for face perception . <i>Nat. Neurosci.</i> <b>3</b>, 80 84 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/71152" data-track-action="article reference" href="https://doi.org/10.1038%2F71152" aria-label="Article reference 34" data-doi="10.1038/71152">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3cXht1ymtrs%3D" aria-label="CAS reference 34">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Distinct%20representations%20of%20eye%20gaze%20and%20identity%20in%20the%20distributed%20human%20neural%20system%20for%20face%20perception&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F71152&amp;volume=3&amp;pages=80-84&amp;publication_year=2000&amp;author=Hoffman%2CEA&amp;author=Haxby%2CJV">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35"><p class="c-article-references__text" id="ref-CR35">Tranel, D., Damasio, A. R. &amp; Damasio, H. Intact recognition of facial expression, gender and age in patients with impaired recognition of face identity. <i>Neurology </i> <b>38</b>, 690696 ( 1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1212/WNL.38.5.690" data-track-action="article reference" href="https://doi.org/10.1212%2FWNL.38.5.690" aria-label="Article reference 35" data-doi="10.1212/WNL.38.5.690">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Intact%20recognition%20of%20facial%20expression%2C%20gender%20and%20age%20in%20patients%20with%20impaired%20recognition%20of%20face%20identity&amp;journal=Neurology&amp;doi=10.1212%2FWNL.38.5.690&amp;volume=38&amp;pages=690-696&amp;publication_year=1998&amp;author=Tranel%2CD&amp;author=Damasio%2CAR&amp;author=Damasio%2CH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36"><p class="c-article-references__text" id="ref-CR36">Gauthier, I., Behrmann, M. &amp; Tarr, M. J. Can face recognition really be dissociated from object recognition? <i>J. Cogn. Neurosci.</i> <b>11</b>, 349 370 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/089892999563472" data-track-action="article reference" href="https://doi.org/10.1162%2F089892999563472" aria-label="Article reference 36" data-doi="10.1162/089892999563472">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1Mvgtlelsg%3D%3D" aria-label="CAS reference 36">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Can%20face%20recognition%20really%20be%20dissociated%20from%20object%20recognition%3F&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2F089892999563472&amp;volume=11&amp;pages=349-370&amp;publication_year=1999&amp;author=Gauthier%2CI&amp;author=Behrmann%2CM&amp;author=Tarr%2CMJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37"><p class="c-article-references__text" id="ref-CR37">Schultz, R. T. <i> et al</i>. Abnormal ventral temporal cortical activity during face discrimination among individuals with autism and asperger syndrome. <i>Arch. Gen. Psychiatry</i> <b>57</b>, 331340 ( 2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/archpsyc.57.4.331" data-track-action="article reference" href="https://doi.org/10.1001%2Farchpsyc.57.4.331" aria-label="Article reference 37" data-doi="10.1001/archpsyc.57.4.331">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3c3ivFWrsw%3D%3D" aria-label="CAS reference 37">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Abnormal%20ventral%20temporal%20cortical%20activity%20during%20face%20discrimination%20among%20individuals%20with%20autism%20and%20asperger%20syndrome&amp;journal=Arch.%20Gen.%20Psychiatry&amp;doi=10.1001%2Farchpsyc.57.4.331&amp;volume=57&amp;pages=331-340&amp;publication_year=2000&amp;author=Schultz%2CRT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38"><p class="c-article-references__text" id="ref-CR38">Moscovitch, M., Winocur, G. &amp; Behrmann, M. What is special about face recognition? Nineteen experiments on a person with visual object agnosia and dyslexia but normal face recognition . <i>J. Cogn. Neurosci.</i> <b>9</b>, 555 604 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn.1997.9.5.555" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn.1997.9.5.555" aria-label="Article reference 38" data-doi="10.1162/jocn.1997.9.5.555">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3sbhs1GqsA%3D%3D" aria-label="CAS reference 38">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20is%20special%20about%20face%20recognition%3F%20Nineteen%20experiments%20on%20a%20person%20with%20visual%20object%20agnosia%20and%20dyslexia%20but%20normal%20face%20recognition&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn.1997.9.5.555&amp;volume=9&amp;pages=555-604&amp;publication_year=1997&amp;author=Moscovitch%2CM&amp;author=Winocur%2CG&amp;author=Behrmann%2CM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39"><p class="c-article-references__text" id="ref-CR39">Gauthier, I. &amp; Tarr, M. J. Becoming a Greeble expert: Exploring the face recognition mechanism. <i>Vision Res.</i> <b> 37</b>, 16731682 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0042-6989(96)00286-6" data-track-action="article reference" href="https://doi.org/10.1016%2FS0042-6989%2896%2900286-6" aria-label="Article reference 39" data-doi="10.1016/S0042-6989(96)00286-6">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK2sznsVOrsQ%3D%3D" aria-label="CAS reference 39">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Becoming%20a%20%E2%80%9CGreeble%E2%80%9D%20expert%3A%20Exploring%20the%20face%20recognition%20mechanism&amp;journal=Vision%20Res.&amp;doi=10.1016%2FS0042-6989%2896%2900286-6&amp;volume=37&amp;pages=1673-1682&amp;publication_year=1997&amp;author=Gauthier%2CI&amp;author=Tarr%2CMJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40"><p class="c-article-references__text" id="ref-CR40">Farah, M. J., Levinson, K. L. &amp; Klein, K. L. Face perception and within-category discrimination in prosopagnosia. <i>Neuropsychologia</i> <b>33</b>, 661 674 (1995).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0028-3932(95)00002-K" data-track-action="article reference" href="https://doi.org/10.1016%2F0028-3932%2895%2900002-K" aria-label="Article reference 40" data-doi="10.1016/0028-3932(95)00002-K">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK2MvgsFGnuw%3D%3D" aria-label="CAS reference 40">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Face%20perception%20and%20within-category%20discrimination%20in%20prosopagnosia&amp;journal=Neuropsychologia&amp;doi=10.1016%2F0028-3932%2895%2900002-K&amp;volume=33&amp;pages=661-674&amp;publication_year=1995&amp;author=Farah%2CMJ&amp;author=Levinson%2CKL&amp;author=Klein%2CKL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41"><p class="c-article-references__text" id="ref-CR41">McCarthy, G., Puce, A., Gore, J. C. &amp; Allison, T. Face-specific processing in the human fusiform gyrus. <i>J. Cogn. Neurosci.</i> <b> 9</b>, 605610 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn.1997.9.5.605" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn.1997.9.5.605" aria-label="Article reference 41" data-doi="10.1162/jocn.1997.9.5.605">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3sbhs1GqsQ%3D%3D" aria-label="CAS reference 41">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Face-specific%20processing%20in%20the%20human%20fusiform%20gyrus&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn.1997.9.5.605&amp;volume=9&amp;pages=605-610&amp;publication_year=1997&amp;author=McCarthy%2CG&amp;author=Puce%2CA&amp;author=Gore%2CJC&amp;author=Allison%2CT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42"><p class="c-article-references__text" id="ref-CR42">Jolicoeur, P., Gluck, M. &amp; Kosslyn, S. M. Pictures and names: Making the connection. <i> Cognit. Psychol.</i> <b>16</b>, 243275 (1984).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0010-0285(84)90009-4" data-track-action="article reference" href="https://doi.org/10.1016%2F0010-0285%2884%2990009-4" aria-label="Article reference 42" data-doi="10.1016/0010-0285(84)90009-4">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL2c3jsVyjsw%3D%3D" aria-label="CAS reference 42">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Pictures%20and%20names%3A%20Making%20the%20connection&amp;journal=Cognit.%20Psychol.&amp;doi=10.1016%2F0010-0285%2884%2990009-4&amp;volume=16&amp;pages=243-275&amp;publication_year=1984&amp;author=Jolicoeur%2CP&amp;author=Gluck%2CM&amp;author=Kosslyn%2CSM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43"><p class="c-article-references__text" id="ref-CR43">Gauthier, I., Williams, P., Tarr, M. J. &amp; Tanaka, J. Training Greeble experts: A framework for studying expert object recognition processes. <i>Vision Res.</i> <b>38</b>, 2401 2428 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0042-6989(97)00442-2" data-track-action="article reference" href="https://doi.org/10.1016%2FS0042-6989%2897%2900442-2" aria-label="Article reference 43" data-doi="10.1016/S0042-6989(97)00442-2">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M%2FhsVOnsw%3D%3D" aria-label="CAS reference 43">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20%E2%80%9CGreeble%E2%80%9D%20experts%3A%20A%20framework%20for%20studying%20expert%20object%20recognition%20processes&amp;journal=Vision%20Res.&amp;doi=10.1016%2FS0042-6989%2897%2900442-2&amp;volume=38&amp;pages=2401-2428&amp;publication_year=1998&amp;author=Gauthier%2CI&amp;author=Williams%2CP&amp;author=Tarr%2CMJ&amp;author=Tanaka%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44"><p class="c-article-references__text" id="ref-CR44">Tong, F., Nakayama, K., Moscovitch, M., Weinrib, O. &amp; Kanwisher, N. Response properties of the human fusiform face area. <i>Cognit. Neuropsychol.</i> <b>17</b>, 257279 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/026432900380607" data-track-action="article reference" href="https://doi.org/10.1080%2F026432900380607" aria-label="Article reference 44" data-doi="10.1080/026432900380607">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3cfptlGkug%3D%3D" aria-label="CAS reference 44">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Response%20properties%20of%20the%20human%20fusiform%20face%20area&amp;journal=Cognit.%20Neuropsychol.&amp;doi=10.1080%2F026432900380607&amp;volume=17&amp;pages=257-279&amp;publication_year=2000&amp;author=Tong%2CF&amp;author=Nakayama%2CK&amp;author=Moscovitch%2CM&amp;author=Weinrib%2CO&amp;author=Kanwisher%2CN">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45"><p class="c-article-references__text" id="ref-CR45">Perrett, D. I., Rolls, E. T. &amp; Caan, W. Visual neurones responsive to faces in the monkey temporal cortex. <i>Exp. Brain Res.</i> <b>47</b>, 329 342 (1982).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/BF00239352" data-track-action="article reference" href="https://doi.org/10.1007%2FBF00239352" aria-label="Article reference 45" data-doi="10.1007/BF00239352">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaL3s%2FislKitA%3D%3D" aria-label="CAS reference 45">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20neurones%20responsive%20to%20faces%20in%20the%20monkey%20temporal%20cortex&amp;journal=Exp.%20Brain%20Res.&amp;doi=10.1007%2FBF00239352&amp;volume=47&amp;pages=329-342&amp;publication_year=1982&amp;author=Perrett%2CDI&amp;author=Rolls%2CET&amp;author=Caan%2CW">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46"><p class="c-article-references__text" id="ref-CR46">Kobatake, E., Wang, G. &amp; Tanaka, K. Effects of shape-discrimination training on the selectivity of inferotemporal cells in adult monkeys. <i>J. Neurophysiol.</i> <b> 80</b>, 324330 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.1998.80.1.324" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.1998.80.1.324" aria-label="Article reference 46" data-doi="10.1152/jn.1998.80.1.324">Article</a>
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1czisFWhtw%3D%3D" aria-label="CAS reference 46">CAS</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20shape-discrimination%20training%20on%20the%20selectivity%20of%20inferotemporal%20cells%20in%20adult%20monkeys&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.1998.80.1.324&amp;volume=80&amp;pages=324-330&amp;publication_year=1998&amp;author=Kobatake%2CE&amp;author=Wang%2CG&amp;author=Tanaka%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47"><p class="c-article-references__text" id="ref-CR47">Logothetis, N. K. &amp; Pauls, J. Psychophysical and physiological evidence for viewer-centered object representation in the primate . <i>Cereb. Cortex</i> <b>3</b>, 270 288 (1995).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/5.3.270" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F5.3.270" aria-label="Article reference 47" data-doi="10.1093/cercor/5.3.270">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Psychophysical%20and%20physiological%20evidence%20for%20viewer-centered%20object%20representation%20in%20the%20primate&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F5.3.270&amp;volume=3&amp;pages=270-288&amp;publication_year=1995&amp;author=Logothetis%2CNK&amp;author=Pauls%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48"><p class="c-article-references__text" id="ref-CR48">Kanwisher, N., Downing, P., Epstein, R. &amp; Kourtzi, Z. in <i>Handbook of Functional Neuroimaging of Cognition</i> (eds. Cabeza, R. &amp; Kingstone, A.) (MIT Press, Cambridge, MA, in press).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49"><p class="c-article-references__text" id="ref-CR49">Sheinberg, D. L. &amp; Logothetis, N. K. in <i>Perceptual Learning</i> (ed. Fahle, M.) (MIT Press, Cambridge, Massachusetts, 2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Perceptual%20Learning&amp;publication_year=2000&amp;author=Sheinberg%2CDL&amp;author=Logothetis%2CNK">
                    Google Scholar</a>
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/77666?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>This work was a collaborative effort, and the order of authorship is arbitrary. We thank D. Sheinberg for his careful reading of this review. M.J.T. thanks S. Pinker for a challenging discussion on some of the issues raised here; I.G. thanks N. Kanwisher for many stimulating discussions on our diverging opinions. This work was supported by NSF Award SBR-9615819.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Cognitive and Linguistic Sciences, Brown University, Box 1978, Providence, Rhode Island, 02912, USA</p><p class="c-article-author-affiliation__authors-list">Michael J. Tarr</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Psychology, Vanderbilt University, 301 Wilson Hall, Nashville , 37240, Tennessee, USA</p><p class="c-article-author-affiliation__authors-list">Isabel Gauthier</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Michael_J_-Tarr"><span class="c-article-authors-search__title u-h3 js-search-name">Michael J. Tarr</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Michael%20J.%20Tarr" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Michael%20J.%20Tarr" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Michael%20J.%20Tarr%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Isabel-Gauthier"><span class="c-article-authors-search__title u-h3 js-search-name">Isabel Gauthier</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Isabel%20Gauthier" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Isabel%20Gauthier" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Isabel%20Gauthier%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=FFA%3A%20a%20flexible%20fusiform%20area%20for%20subordinate-level%20visual%20processing%20automatized%20by%20expertise&amp;author=Michael%20J.%20Tarr%20et%20al&amp;contentID=10.1038%2F77666&amp;copyright=Nature%20America%20Inc.&amp;publication=1097-6256&amp;publicationDate=2000-08&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Tarr, M., Gauthier, I. FFA: a flexible fusiform area for subordinate-level visual processing automatized by expertise.
                    <i>Nat Neurosci</i> <b>3</b>, 764769 (2000). https://doi.org/10.1038/77666</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/77666?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2000-04-04">04 April 2000</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2000-06-20">20 June 2000</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2000-08">August 2000</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/77666</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Selectivity for food in human ventral visual cortex" href="https://doi.org/10.1038/s42003-023-04546-2">
                                        Selectivity for food in human ventral visual cortex
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Nidhi Jain</li><li>Aria Wang</li><li>Leila Wehbe</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Communications Biology</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Association between fractional amplitude of low-frequency fluctuation (fALFF) and facial emotion recognition ability in first-episode schizophrenia patients: a fMRI study" href="https://doi.org/10.1038/s41598-022-24258-7">
                                        Association between fractional amplitude of low-frequency fluctuation (fALFF) and facial emotion recognition ability in first-episode schizophrenia patients: a fMRI study
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Qijie Kuang</li><li>Sumiao Zhou</li><li>Shenglin She</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2022)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Face detection in untrained deep neural networks" href="https://doi.org/10.1038/s41467-021-27606-9">
                                        Face detection in untrained deep neural networks
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Seungdae Baek</li><li>Min Song</li><li>Se-Bum Paik</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Communications</i> (2021)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Stable habituation deficits in the early stage of psychosis: a 2-year follow-up study" href="https://doi.org/10.1038/s41398-020-01167-9">
                                        Stable habituation deficits in the early stage of psychosis: a 2-year follow-up study
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Suzanne N. Avery</li><li>Maureen McHugo</li><li>Stephan Heckers</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Translational Psychiatry</i> (2021)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Unsupervised deep learning identifies semantic disentanglement in single inferotemporal face patch neurons" href="https://doi.org/10.1038/s41467-021-26751-5">
                                        Unsupervised deep learning identifies semantic disentanglement in single inferotemporal face patch neurons
                                    </a>
                                </h3>
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Irina Higgins</li><li>Le Chang</li><li>Matthew Botvinick</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Communications</i> (2021)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
</div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn0800_764.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn0800_764.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    

    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=nn0800_764;doi=10.1038/77666;kwrd=Biomedicine%2C+general,Neurosciences,Behavioral+Sciences,Biological+Techniques,Neurobiology,Animal+Genetics+and+Genomics">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=1786827835&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn0800_764%26doi%3D10.1038/77666%26kwrd%3DBiomedicine%2C+general,Neurosciences,Behavioral+Sciences,Biological+Techniques,Neurobiology,Animal+Genetics+and+Genomics">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=1786827835&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn0800_764%26doi%3D10.1038/77666%26kwrd%3DBiomedicine%2C+general,Neurosciences,Behavioral+Sciences,Biological+Techniques,Neurobiology,Animal+Genetics+and+Genomics"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects/"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://nano.nature.com/"
                                                  data-track="click" data-track-action="nano" data-track-label="link">Nano</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies/"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints/"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://masterclasses.nature.com/live-expert-trainer-led/23649702"
                                                  data-track="click" data-track-action="live expert trainer-led workshops"
                                                  data-track-label="link">Live Expert Trainer-led workshops</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions/"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Career development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natureevents/"
                                                  data-track="click" data-track-action="nature events"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        events</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp/"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr/"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast/"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2023 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-account" viewBox="0 0 24 24"><path fill-rule="nonzero" d="M12 12c5.498 0 10 4.001 10 9a1 1 0 0 1-2 0c0-3.838-3.557-7-8-7s-8 3.162-8 7a1 1 0 0 1-2 0c0-4.999 4.502-9 10-9Zm0-11a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm0 2a3 3 0 1 1 0 6 3 3 0 0 1 0-6Z"/></symbol><symbol id="icon-eds-search" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z" fill-rule="nonzero"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-menu" viewBox="0 0 24 24"><path d="M21.09 5c.503 0 .91.448.91 1s-.407 1-.91 1H2.91C2.406 7 2 6.552 2 6s.407-1 .91-1h18.18Zm-3.817 6c.401 0 .727.448.727 1s-.326 1-.727 1H2.727C2.326 13 2 12.552 2 12s.326-1 .727-1h14.546Zm3.818 6c.502 0 .909.448.909 1s-.407 1-.91 1H2.91c-.503 0-.91-.448-.91-1s.407-1 .91-1h18.18Z" fill-rule="nonzero"/></symbol><symbol id="icon-search-filter" viewBox="0 0 29 29"><path d="M28 9H11a1 1 0 0 1 0-2h17a1 1 0 0 1 0 2ZM7 9H4a1 1 0 0 1 0-2h3a1 1 0 0 1 0 2Zm14 8H4a1 1 0 0 1 0-2h17a1 1 0 0 1 0 2Zm-10 8H4a1 1 0 0 1 0-2h7a1 1 0 0 1 0 2Z"/><path d="M9 11a3 3 0 1 1 3-3 3 3 0 0 1-3 3Zm0-4a1 1 0 1 0 1 1 1 1 0 0 0-1-1Zm14 12a3 3 0 1 1 3-3 3 3 0 0 1-3 3Zm0-4a1 1 0 1 0 1 1 1 1 0 0 0-1-1ZM13 27a3 3 0 1 1 3-3 3 3 0 0 1-3 3Zm0-4a1 1 0 1 0 1 1 1 1 0 0 0-1-1Z"/><path d="M28 17h-3a1 1 0 0 1 0-2h3a1 1 0 0 1 0 2Zm0 8H15a1 1 0 0 1 0-2h13a1 1 0 0 1 0 2Z"/><path d="M0 0h32v32H0z" style="fill:none"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    
        

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter  what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="/briefing/signup/formfeedback" method="post" data-location="banner" data-track="submit" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="DirectEmailBannerRedesign2020">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">
                        <label class="nature-briefing-banner__email-label" for="banner-EmailAddressInput">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="banner-EmailAddressInput" name="email" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="1" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="/briefing/signup/">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>

    




<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/77666&amp;format=js&amp;last_modified=2000-08-01" async></script>
<img src="/y9azf9f5/article/nn0800_764" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>