<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Decoding the content of visual short-term memory under distraction in occipital and parietal areas | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"cognitive-neuroscience;psychology","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/nn.4174"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Katherine C Bettencourt","Yaoda Xu"],"publishedAt":1448236800,"publishedAtString":"2015-11-23","title":"Decoding the content of visual short-term memory under distraction in occipital and parietal areas","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"19","issue":"1"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Decoding the content of visual short-term memory under distraction in occipital and parietal areas","description":"Using fMRI multi-voxel pattern decoding, human superior IPS, but not occipital cortex, was found to closely track behavioral measures of information storage in visual short-term memory (VSTM) across distractor presence and predictability. This suggests that superior IPS, and not occipital cortex, has a central role in VSTM storage in the human brain. Recent studies have provided conflicting accounts regarding where in the human brain visual short-term memory (VSTM) content is stored, with strong univariate fMRI responses being reported in superior intraparietal sulcus (IPS), but robust multivariate decoding being reported in occipital cortex. Given the continuous influx of information in everyday vision, VSTM storage under distraction is often required. We found that neither distractor presence nor predictability during the memory delay affected behavioral performance. Similarly, superior IPS exhibited consistent decoding of VSTM content across all distractor manipulations and had multivariate responses that closely tracked behavioral VSTM performance. However, occipital decoding of VSTM content was substantially modulated by distractor presence and predictability. Furthermore, we found no effect of targetâ€“distractor similarity on VSTM behavioral performance, further challenging the role of sensory regions in VSTM storage. Overall, consistent with previous univariate findings, our results indicate that superior IPS, but not occipital cortex, has a central role in VSTM storage.","datePublished":"2015-11-23T00:00:00Z","dateModified":"2015-11-23T00:00:00Z","pageStart":"150","pageEnd":"157","sameAs":"https://doi.org/10.1038/nn.4174","keywords":["Cognitive neuroscience","Psychology","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig1_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig2_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig3_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig4_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig5_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig6_HTML.jpg","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig7_HTML.jpg"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"19","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Katherine C Bettencourt","affiliation":[{"name":"Harvard University","address":{"name":"Department of Psychology, Harvard University, Cambridge, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Yaoda Xu","affiliation":[{"name":"Harvard University","address":{"name":"Department of Psychology, Harvard University, Cambridge, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"yaodaxu@fas.harvard.edu","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/nn.4174">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="Decoding the content of visual short-term memory under distraction in occipital and parietal areas"/>
    <meta name="dc.source" content="Nature Neuroscience 2016 19:1"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2015-11-23"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2016 Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2016 Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Using fMRI multi-voxel pattern decoding, human superior IPS, but not occipital cortex, was found to closely track behavioral measures of information storage in visual short-term memory (VSTM) across distractor presence and predictability. This suggests that superior IPS, and not occipital cortex, has a central role in VSTM storage in the human brain. Recent studies have provided conflicting accounts regarding where in the human brain visual short-term memory (VSTM) content is stored, with strong univariate fMRI responses being reported in superior intraparietal sulcus (IPS), but robust multivariate decoding being reported in occipital cortex. Given the continuous influx of information in everyday vision, VSTM storage under distraction is often required. We found that neither distractor presence nor predictability during the memory delay affected behavioral performance. Similarly, superior IPS exhibited consistent decoding of VSTM content across all distractor manipulations and had multivariate responses that closely tracked behavioral VSTM performance. However, occipital decoding of VSTM content was substantially modulated by distractor presence and predictability. Furthermore, we found no effect of target&#8211;distractor similarity on VSTM behavioral performance, further challenging the role of sensory regions in VSTM storage. Overall, consistent with previous univariate findings, our results indicate that superior IPS, but not occipital cortex, has a central role in VSTM storage."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2015-11-23"/>
    <meta name="prism.volume" content="19"/>
    <meta name="prism.number" content="1"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="150"/>
    <meta name="prism.endingPage" content="157"/>
    <meta name="prism.copyright" content="2016 Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/nn.4174"/>
    <meta name="prism.doi" content="doi:10.1038/nn.4174"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/nn.4174.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/nn.4174"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="Decoding the content of visual short-term memory under distraction in occipital and parietal areas"/>
    <meta name="citation_volume" content="19"/>
    <meta name="citation_issue" content="1"/>
    <meta name="citation_publication_date" content="2016/01"/>
    <meta name="citation_online_date" content="2015/11/23"/>
    <meta name="citation_firstpage" content="150"/>
    <meta name="citation_lastpage" content="157"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/nn.4174"/>
    <meta name="DOI" content="10.1038/nn.4174"/>
    <meta name="size" content="220126"/>
    <meta name="citation_doi" content="10.1038/nn.4174"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/nn.4174&amp;api_key="/>
    <meta name="description" content="Using fMRI multi-voxel pattern decoding, human superior IPS, but not occipital cortex, was found to closely track behavioral measures of information storage in visual short-term memory (VSTM) across distractor presence and predictability. This suggests that superior IPS, and not occipital cortex, has a central role in VSTM storage in the human brain. Recent studies have provided conflicting accounts regarding where in the human brain visual short-term memory (VSTM) content is stored, with strong univariate fMRI responses being reported in superior intraparietal sulcus (IPS), but robust multivariate decoding being reported in occipital cortex. Given the continuous influx of information in everyday vision, VSTM storage under distraction is often required. We found that neither distractor presence nor predictability during the memory delay affected behavioral performance. Similarly, superior IPS exhibited consistent decoding of VSTM content across all distractor manipulations and had multivariate responses that closely tracked behavioral VSTM performance. However, occipital decoding of VSTM content was substantially modulated by distractor presence and predictability. Furthermore, we found no effect of target&#8211;distractor similarity on VSTM behavioral performance, further challenging the role of sensory regions in VSTM storage. Overall, consistent with previous univariate findings, our results indicate that superior IPS, but not occipital cortex, has a central role in VSTM storage."/>
    <meta name="dc.creator" content="Bettencourt, Katherine C"/>
    <meta name="dc.creator" content="Xu, Yaoda"/>
    <meta name="dc.subject" content="Cognitive neuroscience"/>
    <meta name="dc.subject" content="Psychology"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Working memory in primate sensory systems; citation_author=T Pasternak, MW Greenlee; citation_volume=6; citation_publication_date=2005; citation_pages=97-107; citation_doi=10.1038/nrn1603; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Capacity limit of visual short-term memory in human posterior parietal cortex; citation_author=JJ Todd, R Marois; citation_volume=428; citation_publication_date=2004; citation_pages=751-754; citation_doi=10.1038/nature02466; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=Distinctive neural mechanisms supporting visual object individuation and identification; citation_author=Y Xu; citation_volume=21; citation_publication_date=2009; citation_pages=511-518; citation_doi=10.1162/jocn.2008.21024; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Dissociable neural mechanisms supporting visual short-term memory for objects; citation_author=Y Xu, MM Chun; citation_volume=440; citation_publication_date=2006; citation_pages=91-95; citation_doi=10.1038/nature04262; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=Neural representation of targets and distractors during object individuation and identification; citation_author=SK Jeong, Y Xu; citation_volume=25; citation_publication_date=2013; citation_pages=117-126; citation_doi=10.1162/jocn_a_00298; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=The neural fate of task-irrelevant features in object-based processing; citation_author=Y Xu; citation_volume=30; citation_publication_date=2010; citation_pages=14020-14028; citation_doi=10.1523/JNEUROSCI.3011-10.2010; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Cogn. Affect. Behav. Neurosci.; citation_title=Posterior parietal cortex activity predicts individual differences in visual short-term memory capacity; citation_author=JJ Todd, R Marois; citation_volume=5; citation_publication_date=2005; citation_pages=144-155; citation_doi=10.3758/CABN.5.2.144; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Right parietal cortex plays a critical role in change blindness; citation_author=DM Beck, N Muggleton, V Walsh, N Lavie; citation_volume=16; citation_publication_date=2006; citation_pages=712-717; citation_doi=10.1093/cercor/bhj017; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Posterior parietal cortex mediates encoding and maintenance processes in change blindness; citation_author=P Tseng; citation_volume=48; citation_publication_date=2010; citation_pages=1063-1070; citation_doi=10.1016/j.neuropsychologia.2009.12.005; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory; citation_author=EF Ester, TC Sprague, JT Serences; citation_volume=87; citation_publication_date=2015; citation_pages=893-905; citation_doi=10.1016/j.neuron.2015.07.013; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory; citation_author=SM Emrich, AC Riggall, JJ LaRocque, BR Postle; citation_volume=33; citation_publication_date=2013; citation_pages=6516-6523; citation_doi=10.1523/JNEUROSCI.5732-12.2013; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Spatially global representations in human primary visual cortex during working memory maintenance; citation_author=EF Ester, JT Serences, E Awh; citation_volume=29; citation_publication_date=2009; citation_pages=15258-15265; citation_doi=10.1523/JNEUROSCI.4388-09.2009; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Decoding reveals the contents of visual working memory in early visual areas; citation_author=SA Harrison, F Tong; citation_volume=458; citation_publication_date=2009; citation_pages=632-635; citation_doi=10.1038/nature07832; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Goal-dependent dissociation of visual and prefrontal cortices during working memory; citation_author=SH Lee, DJ Kravitz, CI Baker; citation_volume=16; citation_publication_date=2013; citation_pages=997-999; citation_doi=10.1038/nn.3452; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Mapping brain activation and information during category-specific visual working memory; citation_author=DE Linden, NN Oosterhof, C Klein, PE Downing; citation_volume=107; citation_publication_date=2012; citation_pages=628-639; citation_doi=10.1152/jn.00105.2011; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging; citation_author=AC Riggall, BR Postle; citation_volume=32; citation_publication_date=2012; citation_pages=12990-12998; citation_doi=10.1523/JNEUROSCI.1892-12.2012; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Sci.; citation_title=Stimulus-specific delay activity in human primary visual cortex; citation_author=JT Serences, EF Ester, EK Vogel, E Awh; citation_volume=20; citation_publication_date=2009; citation_pages=207-214; citation_doi=10.1111/j.1467-9280.2009.02276.x; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Visual short-term memory: activity supporting encoding and maintenance in retinotopic visual cortex; citation_author=MH Sneve, D Alnaes, T Endestad, MW Greenlee, S Magnussen; citation_volume=63; citation_publication_date=2012; citation_pages=166-178; citation_doi=10.1016/j.neuroimage.2012.06.053; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Biol.; citation_title=Reconstructions of information in visual spatial working memory degrade with memory load; citation_author=TC Sprague, EF Ester, JT Serences; citation_volume=24; citation_publication_date=2014; citation_pages=2174-2180; citation_doi=10.1016/j.cub.2014.07.066; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Neuropsychologia; citation_title=Neural correlates of object-based attentional selection in human cortex; citation_author=Y Hou, T Liu; citation_volume=50; citation_publication_date=2012; citation_pages=2916-2925; citation_doi=10.1016/j.neuropsychologia.2012.08.022; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Feature-specific attentional priority signals in human cortex; citation_author=T Liu, L Hospadaruk, DC Zhu, JL Gardner; citation_volume=31; citation_publication_date=2011; citation_pages=4484-4495; citation_doi=10.1523/JNEUROSCI.5745-10.2011; citation_id=CR21"/>
    <meta name="citation_reference" content="Xu, Y. &amp; Jeong, S.K. The contribution of human superior intraparietal sulcus to visual short-term memory and perception. in Mechanisms of Sensory Working Memory: Attention and Perfomance XXV (eds. Jolicoeur, P., Lefebrve, C. &amp; Martinez-Trujillo, J.) 33 (Academic Press, 2015)."/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Decoding the contents of visual short-term memory from human visual and parietal cortex; citation_author=TB Christophel, MN Hebart, J-D Haynes; citation_volume=32; citation_publication_date=2012; citation_pages=12983-12989; citation_doi=10.1523/JNEUROSCI.0184-12.2012; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Frontal and parietal cortical interactions with distributed visual representations during selective attention and action selection; citation_author=N Nelissen, M Stokes, AC Nobre, MF Rushworth; citation_volume=33; citation_publication_date=2013; citation_pages=16443-16458; citation_doi=10.1523/JNEUROSCI.2625-13.2013; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Complementary roles for primate frontal and parietal cortex in guarding working memory from distractor stimuli; citation_author=SN Jacob, A Nieder; citation_volume=83; citation_publication_date=2014; citation_pages=226-237; citation_doi=10.1016/j.neuron.2014.05.009; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Distinct neural mechanisms of distractor suppression in the frontal and parietal lobe; citation_author=M Suzuki, J Gottlieb; citation_volume=16; citation_publication_date=2013; citation_pages=98-104; citation_doi=10.1038/nn.3282; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Representation of remembered stimuli and task information in the monkey dorsolateral prefrontal and posterior parietal cortex; citation_author=XL Qi, AC Elworthy, BC Lambert, C Constantinidis; citation_volume=113; citation_publication_date=2015; citation_pages=44-57; citation_doi=10.1152/jn.00413.2014; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Biol.; citation_title=Shared representations for working memory and mental imagery in early visual cortex; citation_author=AM Albers, P Kok, I Toni, HC Dijkerman, FP de Lange; citation_volume=23; citation_publication_date=2013; citation_pages=1427-1431; citation_doi=10.1016/j.cub.2013.05.065; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Matching categorical object representations in inferior temporal cortex of man and monkey; citation_author=N Kriegeskorte; citation_volume=60; citation_publication_date=2008; citation_pages=1126-1141; citation_doi=10.1016/j.neuron.2008.10.043; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Representational geometry: integrating cognition, computation, and the brain; citation_author=N Kriegeskorte, RA Kievit; citation_volume=17; citation_publication_date=2013; citation_pages=401-412; citation_doi=10.1016/j.tics.2013.06.007; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Hum. Percept. Perform.; citation_title=The time course of consolidation in visual working memory; citation_author=EK Vogel, GF Woodman, SJ Luck; citation_volume=32; citation_publication_date=2006; citation_pages=1436-1451; citation_doi=10.1037/0096-1523.32.6.1436; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Sharp emergence of feature-selective sustained activity along the dorsal visual pathway; citation_author=D Mendoza-Halliday, S Torres, JC Martinez-Trujillo; citation_volume=17; citation_publication_date=2014; citation_pages=1255-1262; citation_doi=10.1038/nn.3785; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Neurophysiological investigation of the basis of the fMRI signal; citation_author=NK Logothetis, J Pauls, M Augath, T Trinath, A Oeltermann; citation_volume=412; citation_publication_date=2001; citation_pages=150-157; citation_doi=10.1038/35084005; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Neural foundations of imagery; citation_author=SM Kosslyn, G Ganis, WL Thompson; citation_volume=2; citation_publication_date=2001; citation_pages=635-642; citation_doi=10.1038/35090055; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Visual mental imagery induces retinotopically organized activation of early visual areas; citation_author=SD Slotnick, WL Thompson, SM Kosslyn; citation_volume=15; citation_publication_date=2005; citation_pages=1570-1583; citation_doi=10.1093/cercor/bhi035; citation_id=CR35"/>
    <meta name="citation_reference" content="Keogh, R. &amp; Pearson, J. Mental imagery and visual working memory. PloS One 6, e29221 (2011)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=The generality of parietal involvement in visual attention; citation_author=E Wojciulik, N Kanwisher; citation_volume=23; citation_publication_date=1999; citation_pages=747-764; citation_doi=10.1016/S0896-6273(01)80033-7; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Transient neural activity in human parietal cortex during spatial attention shifts; citation_author=S Yantis; citation_volume=5; citation_publication_date=2002; citation_pages=995-1002; citation_doi=10.1038/nn921; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Neurobiol.; citation_title=Parietal cortex and attention; citation_author=M Behrmann, JJ Geng, S Shomstein; citation_volume=14; citation_publication_date=2004; citation_pages=212-217; citation_doi=10.1016/j.conb.2004.03.012; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Neurosci.; citation_title=Space and attention in parietal cortex; citation_author=CL Colby, ME Goldberg; citation_volume=22; citation_publication_date=1999; citation_pages=319-349; citation_doi=10.1146/annurev.neuro.22.1.319; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Neurobiol.; citation_title=Neuroimaging of cognitive functions in human parietal cortex; citation_author=JC Culham, NG Kanwisher; citation_volume=11; citation_publication_date=2001; citation_pages=157-163; citation_doi=10.1016/S0959-4388(00)00191-4; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl. Acad. Sci. USA; citation_title=Mapping striate and extrastriate visual areas in human cerebral cortex; citation_author=EA DeYoe; citation_volume=93; citation_publication_date=1996; citation_pages=2382-2386; citation_doi=10.1073/pnas.93.6.2382; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=fMRI of human visual cortex; citation_author=SA Engel; citation_volume=369; citation_publication_date=1994; citation_pages=6481; citation_doi=10.1038/369525a0; citation_id=CR43"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging; citation_author=MI Sereno; citation_volume=268; citation_publication_date=1995; citation_pages=889-893; citation_doi=10.1126/science.7754376; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Visual topography of human intraparietal sulcus; citation_author=JD Swisher, MA Halko, LB Merabet, SA McMains, DC Somers; citation_volume=27; citation_publication_date=2007; citation_pages=5326-5337; citation_doi=10.1523/JNEUROSCI.0991-07.2007; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Spatial attention improves reliability of fMRI retinotopic mapping signals in occipital and parietal cortex; citation_author=DW Bressler, MA Silver; citation_volume=53; citation_publication_date=2010; citation_pages=526-533; citation_doi=10.1016/j.neuroimage.2010.06.063; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Selecting and perceiving multiple visual objects; citation_author=Y Xu, MM Chun; citation_volume=13; citation_publication_date=2009; citation_pages=167-174; citation_doi=10.1016/j.tics.2009.01.008; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=Front. Neuroinform.; citation_title=Vision egg: an open-source library for realtime visual stimulus generation; citation_author=AD Straw; citation_volume=2; citation_publication_date=2008; citation_pages=4; citation_doi=10.3389/neuro.11.004.2008; citation_id=CR48"/>
    <meta name="citation_reference" content="citation_journal_title=Spat. Vis.; citation_title=The psychophysics toolbox; citation_author=DH Brainard; citation_volume=10; citation_publication_date=1997; citation_pages=433-436; citation_doi=10.1163/156856897X00357; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Cortical surface-based analysis. I. Segmentation and surface reconstruction; citation_author=AM Dale, B Fischl, MI Sereno; citation_volume=9; citation_publication_date=1999; citation_pages=179-194; citation_doi=10.1006/nimg.1998.0395; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Trans. Med. Imaging; citation_title=Automated manifold surgery: constructing geometrically accurate and topologically correct models of the human cerebral cortex; citation_author=B Fischl, A Liu, AM Dale; citation_volume=20; citation_publication_date=2001; citation_pages=70-80; citation_doi=10.1109/42.906426; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Cortical surface-based analysis. II. Inflation, flattening, and a surface-based coordinate system; citation_author=B Fischl, MI Sereno, AM Dale; citation_volume=9; citation_publication_date=1999; citation_pages=195-207; citation_doi=10.1006/nimg.1998.0396; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Highly accurate inverse consistent registration: a robust approach; citation_author=M Reuter, HD Rosas, B Fischl; citation_volume=53; citation_publication_date=2010; citation_pages=1181-1196; citation_doi=10.1016/j.neuroimage.2010.07.020; citation_id=CR53"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain; citation_author=B Fischl; citation_volume=33; citation_publication_date=2002; citation_pages=341-355; citation_doi=10.1016/S0896-6273(02)00569-X; citation_id=CR54"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Sequence-independent segmentation of magnetic resonance images; citation_author=B Fischl; citation_volume=23; citation_issue=suppl. 1; citation_publication_date=2004; citation_pages=S69-S84; citation_doi=10.1016/j.neuroimage.2004.07.016; citation_id=CR55"/>
    <meta name="citation_reference" content="citation_journal_title=Behav. Brain Sci.; citation_title=The magical number 4 in short-term memory: a reconsideration of mental storage capacity; citation_author=N Cowan; citation_volume=24; citation_publication_date=2001; citation_pages=87-114; citation_doi=10.1017/S0140525X01003922; citation_id=CR56"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature; citation_author=C Destrieux, B Fischl, A Dale, E Halgren; citation_volume=53; citation_publication_date=2010; citation_pages=1-15; citation_doi=10.1016/j.neuroimage.2010.06.010; citation_id=CR57"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Predicting the orientation of invisible stimuli from activity in human primary visual cortex; citation_author=J-D Haynes, G Rees; citation_volume=8; citation_publication_date=2005; citation_pages=686-691; citation_doi=10.1038/nn1445; citation_id=CR58"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Decoding the visual and subjective contents of the human brain; citation_author=Y Kamitani, F Tong; citation_volume=8; citation_publication_date=2005; citation_pages=679-685; citation_doi=10.1038/nn1444; citation_id=CR59"/>
    <meta name="citation_author" content="Bettencourt, Katherine C"/>
    <meta name="citation_author_institution" content="Department of Psychology, Harvard University, Cambridge, USA"/>
    <meta name="citation_author" content="Xu, Yaoda"/>
    <meta name="citation_author_institution" content="Department of Psychology, Harvard University, Cambridge, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Decoding the content of visual short-term memory under distraction in occipital and parietal areas"/>
    <meta name="twitter:description" content="Nature Neuroscience - Using fMRI multi-voxel pattern decoding, human superior IPS, but not occipital cortex, was found to closely track behavioral measures of information storage in visual..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig1_HTML.jpg"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/nn.4174"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Decoding the content of visual short-term memory under distraction in occipital and parietal areas - Nature Neuroscience"/>
    <meta property="og:description" content="Using fMRI multi-voxel pattern decoding, human superior IPS, but not occipital cortex, was found to closely track behavioral measures of information storage in visual short-term memory (VSTM) across distractor presence and predictability. This suggests that superior IPS, and not occipital cortex, has a central role in VSTM storage in the human brain."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig1_HTML.jpg"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=nn.4174;doi=10.1038/nn.4174;techmeta=36,59;subjmeta=2649,378,477,631;kwrd=Cognitive+neuroscience,Psychology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=515792179&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.4174%26doi%3D10.1038/nn.4174%26techmeta%3D36,59%26subjmeta%3D2649,378,477,631%26kwrd%3DCognitive+neuroscience,Psychology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=515792179&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Dnn.4174%26doi%3D10.1038/nn.4174%26techmeta%3D36,59%26subjmeta%3D2649,378,477,631%26kwrd%3DCognitive+neuroscience,Psychology"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/nn.4174'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Decoding the content of visual short-term memory under distraction in occipital and parietal areas
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4174.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2015-11-23">23 November 2015</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Decoding the content of visual short-term memory under distraction in occipital and parietal areas</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Katherine_C-Bettencourt-Aff1" data-author-popup="auth-Katherine_C-Bettencourt-Aff1" data-author-search="Bettencourt, Katherine C">Katherine C Bettencourt</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Yaoda-Xu-Aff1" data-author-popup="auth-Yaoda-Xu-Aff1" data-author-search="Xu, Yaoda" data-corresp-id="c1">Yaoda Xu<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>Â </li></ul>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>Â 19</b>,Â <span class="u-visually-hidden">pages </span>150â€“157 (<span data-test="article-publication-year">2016</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">7799 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">188 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">14 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/nn.4174/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/cognitive-neuroscience" data-track="click" data-track-action="view subject" data-track-label="link">Cognitive neuroscience</a></li><li class="c-article-subject-list__subject"><a href="/subjects/psychology" data-track="click" data-track-action="view subject" data-track-label="link">Psychology</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs2" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs2">Abstract</h2><div class="c-article-section__content" id="Abs2-content"><p>Recent studies have provided conflicting accounts regarding where in the human brain visual short-term memory (VSTM) content is stored, with strong univariate fMRI responses being reported in superior intraparietal sulcus (IPS), but robust multivariate decoding being reported in occipital cortex. Given the continuous influx of information in everyday vision, VSTM storage under distraction is often required. We found that neither distractor presence nor predictability during the memory delay affected behavioral performance. Similarly, superior IPS exhibited consistent decoding of VSTM content across all distractor manipulations and had multivariate responses that closely tracked behavioral VSTM performance. However, occipital decoding of VSTM content was substantially modulated by distractor presence and predictability. Furthermore, we found no effect of targetâ€“distractor similarity on VSTM behavioral performance, further challenging the role of sensory regions in VSTM storage. Overall, consistent with previous univariate findings, our results indicate that superior IPS, but not occipital cortex, has a central role in VSTM storage.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4174.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4174.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41583-024-00796-z/MediaObjects/41583_2024_796_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41583-024-00796-z?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41583-024-00796-z">Preparatory activity and the expansive null-space
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">05 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Mark M. Churchland &amp; Krishna V. Shenoy</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41562-024-01838-3/MediaObjects/41562_2024_1838_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41562-024-01838-3?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41562-024-01838-3">The direction of theta and alpha travelling waves modulates human memory processing
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">08 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Uma R. Mohan, Honghui Zhang, â€¦ Joshua Jacobs</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41562-024-01826-7/MediaObjects/41562_2024_1826_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41562-024-01826-7?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41562-024-01826-7">Orthogonal neural encoding of targets and distractors supports multivariate cognitive control
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">08 March 2024</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Harrison Ritz &amp; Amitai Shenhav</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'topic',
                        model: 'visits_v2',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711582612,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>VSTM is a short-term memory buffer that has a vital role in temporarily maintaining visual information that is critical to guiding our thoughts and actions. It is an important gateway to information integration and high-level cognition. Research in non-human primates has consistently shown evidence for VSTM maintenance in parietal and prefrontal cortices<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Pasternak, T. &amp; Greenlee, M.W. Working memory in primate sensory systems. Nat. Rev. Neurosci. 6, 97â€“107 (2005)." href="/articles/nn.4174#ref-CR1" id="ref-link-section-d22723532e398">1</a></sup>. Similarly, in humans, strong univariate functional magnetic resonance imaging (fMRI) responses during the memory delay period in parietal cortex have highlighted the importance of this region in VSTM information storage. A region expanding across the superior IPS (referred to as superior IPS for simplicity), in particular, has been shown to track the amount of task-relevant information stored in VSTM<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Todd, J.J. &amp; Marois, R. Capacity limit of visual short-term memory in human posterior parietal cortex. Nature 428, 751â€“754 (2004)." href="/articles/nn.4174#ref-CR2" id="ref-link-section-d22723532e402">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Xu, Y. Distinctive neural mechanisms supporting visual object individuation and identification. J. Cogn. Neurosci. 21, 511â€“518 (2009)." href="/articles/nn.4174#ref-CR3" id="ref-link-section-d22723532e405">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e408">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Jeong, S.K. &amp; Xu, Y. Neural representation of targets and distractors during object individuation and identification. J. Cogn. Neurosci. 25, 117â€“126 (2013)." href="/articles/nn.4174#ref-CR5" id="ref-link-section-d22723532e411">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Xu, Y. The neural fate of task-irrelevant features in object-based processing. J. Neurosci. 30, 14020â€“14028 (2010)." href="/articles/nn.4174#ref-CR6" id="ref-link-section-d22723532e414">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Todd, J.J. &amp; Marois, R. Posterior parietal cortex activity predicts individual differences in visual short-term memory capacity. Cogn. Affect. Behav. Neurosci. 5, 144â€“155 (2005)." href="/articles/nn.4174#ref-CR7" id="ref-link-section-d22723532e417">7</a></sup>. Consistent with fMRI findings, transcranial magnetic stimulation (TMS) to parietal regions has also been shown to affect VSTM processing and maintenance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Beck, D.M., Muggleton, N., Walsh, V. &amp; Lavie, N. Right parietal cortex plays a critical role in change blindness. Cereb. Cortex 16, 712â€“717 (2006)." href="/articles/nn.4174#ref-CR8" id="ref-link-section-d22723532e421">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Tseng, P. et al. Posterior parietal cortex mediates encoding and maintenance processes in change blindness. Neuropsychologia 48, 1063â€“1070 (2010)." href="/articles/nn.4174#ref-CR9" id="ref-link-section-d22723532e424">9</a></sup>.</p><p>In more recent studies using fMRI multivariate pattern analysis (MVPA), however, human occipital cortex has been shown to exhibit strong and consistent decoding of VSTM contents<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Ester, E.F., Sprague, T.C. &amp; Serences, J.T. Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory. Neuron 87, 893â€“905 (2015)." href="/articles/nn.4174#ref-CR10" id="ref-link-section-d22723532e431">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Emrich, S.M., Riggall, A.C., LaRocque, J.J. &amp; Postle, B.R. Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory. J. Neurosci. 33, 6516â€“6523 (2013)." href="/articles/nn.4174#ref-CR11" id="ref-link-section-d22723532e434">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Ester, E.F., Serences, J.T. &amp; Awh, E. Spatially global representations in human primary visual cortex during working memory maintenance. J. Neurosci. 29, 15258â€“15265 (2009)." href="/articles/nn.4174#ref-CR12" id="ref-link-section-d22723532e437">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e440">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Lee, S.H., Kravitz, D.J. &amp; Baker, C.I. Goal-dependent dissociation of visual and prefrontal cortices during working memory. Nat. Neurosci. 16, 997â€“999 (2013)." href="/articles/nn.4174#ref-CR14" id="ref-link-section-d22723532e443">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Linden, D.E., Oosterhof, N.N., Klein, C. &amp; Downing, P.E. Mapping brain activation and information during category-specific visual working memory. J. Neurophysiol. 107, 628â€“639 (2012)." href="/articles/nn.4174#ref-CR15" id="ref-link-section-d22723532e446">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Riggall, A.C. &amp; Postle, B.R. The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging. J. Neurosci. 32, 12990â€“12998 (2012)." href="/articles/nn.4174#ref-CR16" id="ref-link-section-d22723532e450">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Serences, J.T., Ester, E.F., Vogel, E.K. &amp; Awh, E. Stimulus-specific delay activity in human primary visual cortex. Psychol. Sci. 20, 207â€“214 (2009)." href="/articles/nn.4174#ref-CR17" id="ref-link-section-d22723532e453">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Sneve, M.H., Alnaes, D., Endestad, T., Greenlee, M.W. &amp; Magnussen, S. Visual short-term memory: activity supporting encoding and maintenance in retinotopic visual cortex. Neuroimage 63, 166â€“178 (2012)." href="/articles/nn.4174#ref-CR18" id="ref-link-section-d22723532e456">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Sprague, T.C., Ester, E.F. &amp; Serences, J.T. Reconstructions of information in visual spatial working memory degrade with memory load. Curr. Biol. 24, 2174â€“2180 (2014)." href="/articles/nn.4174#ref-CR19" id="ref-link-section-d22723532e459">19</a></sup>. Despite the presence of strong univariate VSTM responses in human parietal cortex and its ability to represent task-relevant visual features<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Hou, Y. &amp; Liu, T. Neural correlates of object-based attentional selection in human cortex. Neuropsychologia 50, 2916â€“2925 (2012)." href="/articles/nn.4174#ref-CR20" id="ref-link-section-d22723532e463">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Liu, T., Hospadaruk, L., Zhu, D.C. &amp; Gardner, J.L. Feature-specific attentional priority signals in human cortex. J. Neurosci. 31, 4484â€“4495 (2011)." href="/articles/nn.4174#ref-CR21" id="ref-link-section-d22723532e466">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Xu, Y. &amp; Jeong, S.K. The contribution of human superior intraparietal sulcus to visual short-term memory and perception. in Mechanisms of Sensory Working Memory: Attention and Perfomance XXV (eds. Jolicoeur, P., Lefebrve, C. &amp; Martinez-Trujillo, J.) 33 (Academic Press, 2015)." href="/articles/nn.4174#ref-CR22" id="ref-link-section-d22723532e469">22</a></sup>, MVPA studies have produced mixed decoding results regarding the role of this brain region in VSTM information representation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Emrich, S.M., Riggall, A.C., LaRocque, J.J. &amp; Postle, B.R. Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory. J. Neurosci. 33, 6516â€“6523 (2013)." href="/articles/nn.4174#ref-CR11" id="ref-link-section-d22723532e473">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Linden, D.E., Oosterhof, N.N., Klein, C. &amp; Downing, P.E. Mapping brain activation and information during category-specific visual working memory. J. Neurophysiol. 107, 628â€“639 (2012)." href="/articles/nn.4174#ref-CR15" id="ref-link-section-d22723532e476">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Riggall, A.C. &amp; Postle, B.R. The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging. J. Neurosci. 32, 12990â€“12998 (2012)." href="/articles/nn.4174#ref-CR16" id="ref-link-section-d22723532e479">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Christophel, T.B., Hebart, M.N. &amp; Haynes, J.-D. Decoding the contents of visual short-term memory from human visual and parietal cortex. J. Neurosci. 32, 12983â€“12989 (2012)." href="/articles/nn.4174#ref-CR23" id="ref-link-section-d22723532e482">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Nelissen, N., Stokes, M., Nobre, A.C. &amp; Rushworth, M.F. Frontal and parietal cortical interactions with distributed visual representations during selective attention and action selection. J. Neurosci. 33, 16443â€“16458 (2013)." href="/articles/nn.4174#ref-CR24" id="ref-link-section-d22723532e485">24</a></sup>. Together, these results have been used to argue that occipital cortex, rather than parietal cortex, has a central role in the storage of VSTM in the human brain.</p><p>Although findings from occipital cortex are robust, they are also puzzling. First, given the almost unlimited representational capacity of the primary visual cortex in sensory processing, it is unclear how this brain region would give rise to a highly capacity-limited VSTM system. Second, why would a brain region that is primarily involved in perception be recruited for VSTM storage? Given the continuous influx of visual information in everyday visual perception, it is often necessary to hold information in VSTM while concurrently processing incoming visual stimuli. How can VSTM representations be maintained in the face of such distraction? Previous psychophysical work has shown that distractors that are similar to targets can interfere with VSTM performance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Pasternak, T. &amp; Greenlee, M.W. Working memory in primate sensory systems. Nat. Rev. Neurosci. 6, 97â€“107 (2005)." href="/articles/nn.4174#ref-CR1" id="ref-link-section-d22723532e492">1</a></sup>. Although this has been taken as evidence supporting the sensory nature of VSTM representation, it also highlights the need to separate memory and incoming sensory representations to reduce interference. Furthermore, as both distractor and VSTM processing engage other brain regions such as parietal and prefrontal cortices, distractor interference could occur in any of these regions. Thus, the behavioral interference results alone do not pinpoint occipital cortex as the primary VSTM storage site.</p><p>Although previous MVPA studies have produced mixed results regarding the role of the parietal cortex in VSTM information representation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Emrich, S.M., Riggall, A.C., LaRocque, J.J. &amp; Postle, B.R. Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory. J. Neurosci. 33, 6516â€“6523 (2013)." href="/articles/nn.4174#ref-CR11" id="ref-link-section-d22723532e499">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Linden, D.E., Oosterhof, N.N., Klein, C. &amp; Downing, P.E. Mapping brain activation and information during category-specific visual working memory. J. Neurophysiol. 107, 628â€“639 (2012)." href="/articles/nn.4174#ref-CR15" id="ref-link-section-d22723532e502">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Riggall, A.C. &amp; Postle, B.R. The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging. J. Neurosci. 32, 12990â€“12998 (2012)." href="/articles/nn.4174#ref-CR16" id="ref-link-section-d22723532e505">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Christophel, T.B., Hebart, M.N. &amp; Haynes, J.-D. Decoding the contents of visual short-term memory from human visual and parietal cortex. J. Neurosci. 32, 12983â€“12989 (2012)." href="/articles/nn.4174#ref-CR23" id="ref-link-section-d22723532e508">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Nelissen, N., Stokes, M., Nobre, A.C. &amp; Rushworth, M.F. Frontal and parietal cortical interactions with distributed visual representations during selective attention and action selection. J. Neurosci. 33, 16443â€“16458 (2013)." href="/articles/nn.4174#ref-CR24" id="ref-link-section-d22723532e511">24</a></sup>, none of them specifically targeted superior IPS, a key parietal region whose activity tracks VSTM storage<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Todd, J.J. &amp; Marois, R. Capacity limit of visual short-term memory in human posterior parietal cortex. Nature 428, 751â€“754 (2004)." href="/articles/nn.4174#ref-CR2" id="ref-link-section-d22723532e515">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Xu, Y. Distinctive neural mechanisms supporting visual object individuation and identification. J. Cogn. Neurosci. 21, 511â€“518 (2009)." href="/articles/nn.4174#ref-CR3" id="ref-link-section-d22723532e518">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e521">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Jeong, S.K. &amp; Xu, Y. Neural representation of targets and distractors during object individuation and identification. J. Cogn. Neurosci. 25, 117â€“126 (2013)." href="/articles/nn.4174#ref-CR5" id="ref-link-section-d22723532e524">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Xu, Y. The neural fate of task-irrelevant features in object-based processing. J. Neurosci. 30, 14020â€“14028 (2010)." href="/articles/nn.4174#ref-CR6" id="ref-link-section-d22723532e527">6</a></sup>. Thus, the role of the human parietal cortex in VSTM representation has not been adequately evaluated with MVPA.</p><p>In non-human primates, conflicting results have implicated both parietal and prefrontal regions in the representation of VSTM information under distraction<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Jacob, S.N. &amp; Nieder, A. Complementary roles for primate frontal and parietal cortex in guarding working memory from distractor stimuli. Neuron 83, 226â€“237 (2014)." href="/articles/nn.4174#ref-CR25" id="ref-link-section-d22723532e535">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Suzuki, M. &amp; Gottlieb, J. Distinct neural mechanisms of distractor suppression in the frontal and parietal lobe. Nat. Neurosci. 16, 98â€“104 (2013)." href="/articles/nn.4174#ref-CR26" id="ref-link-section-d22723532e538">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Qi, X.L., Elworthy, A.C., Lambert, B.C. &amp; Constantinidis, C. Representation of remembered stimuli and task information in the monkey dorsolateral prefrontal and posterior parietal cortex. J. Neurophysiol. 113, 44â€“57 (2015)." href="/articles/nn.4174#ref-CR27" id="ref-link-section-d22723532e541">27</a></sup>. However, to our knowledge, in humans, no brain region has been shown to represent VSTM information during the delay regardless of distraction, and it therefore remains unclear whether or how occipital and parietal cortices would contribute to real-world VSTM processing, where distraction is constant.</p><p>Thus, despite substantial research on the neural basis of VSTM, the fundamental question of where in the brain the content of VSTM is stored has not been answered. We found that MVPA decoding in superior IPS, but not occipital cortex, closely tracked behavioral measures of information storage in VSTM across distractor presence and predictability. This suggests that superior IPS, but not occipital cortex, has a central role in VSTM storage in the human brain.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Decoding VSTM content with predictable distractors</h3><p>To assess the role of both occipital and parietal cortices in VSTM storage under visual distraction (experiment 1), we adapted an oriented grating VSTM task used previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e560">13</a></sup>, which was shown to elicit robust VSTM decoding in occipital cortex, and manipulated whether or not distractors were present during the delay period (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig1">Fig. 1</a>). Ten participants were shown two gratings (<span class="stix">âˆ¼</span>25Â° or <span class="stix">âˆ¼</span>115Â°) sequentially at fixation and then retroactively cued as to which orientation to remember. After an extended delay (11 s), a third grating appeared at fixation and participants reported whether this grating was jittered clockwise or counterclockwise from the remembered grating. During the delay, either a blank screen (trials without distractors) or a series of face or gazebo stimuli (trials with distractors) were presented. In an effort to replicate the previous study's findings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e567">13</a></sup> and to minimize any changes in VSTM strategy brought on by the distractors, we had all participants complete all eight blocks of trials without distractors before switching to trials with distractors. Participants were thus able to anticipate, with 100% accuracy, whether a given block of trials would contain distractors.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Main experimental task from experiments 1 and 3."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 1: Main experimental task from experiments 1 and 3.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4174/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig1_HTML.jpg?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig1_HTML.jpg" alt="figure 1" loading="lazy" width="685" height="319"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Participants were shown two orientated gratings and then cued as to which to remember. The cue presented here is enlarged for clarity. After a long delay, a third grating appeared and participants were asked to judge whether this grating was jittered clockwise or counterclockwise to the remembered grating. During the delay, participants either saw a blank screen with a fixation dot (trials without distractors) or a sequential presentation of task irrelevant faces or gazebos (trials with distractors). In experiment 1, trials without distractors were presented in the first half of the experiment while those with distractors were presented in the second half, making distractor presence/absence predictable. In experiment 3, the two types of trials were randomly intermixed within a run, making distractor presence/absence unpredictable.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4174/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Behaviorally, we obtained very similar performance accuracy to seen previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e593">13</a></sup>, with an average of 76.3% correct across all trials. Notably, there were no differences in performance (<i>t</i>(9) = 0.8, <i>P</i> = 0.43) between trials with distractors (77.3%) and trials without (75.3%). Moreover, there was no difference between the first and second half of each trial type (trials without distractors: <i>t</i>(9) = 1.3, <i>P</i> = 0.23; trials with distractors: <i>t</i>(9) = 0.4, <i>P</i> = 0.68), and no difference between the two trial types when we only examined the first half of trials in each (<i>t</i>(9) = 0.9, <i>P</i> = 0.4). This suggests that trials with distractors were never more difficult than trials without distractors and that VSTM storage is resistant to the kind of visual distraction introduced here.</p><p>MVPA decoding accuracy for the remembered stimulus during the delay period was then examined in our occipital and parietal regions of interest (ROIs; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig2">Fig. 2</a> and Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.4174#Sec10">Methods</a>) after responses were z-scored in a given ROI to remove any response amplitude differences among the different brain regions. In occipital cortex, when decoding performance was examined in areas V1 through V4 individually, we found no significant interaction between ROI and trial type (<i>F</i>(3,9) = 0.8, <i>P</i> = 0.48). As such, following what was done previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e637">13</a></sup>, we combined these regions into a single ROI, V1â€“V4. Replicating the previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e642">13</a></sup>, decoding accuracy for the average delay period in V1â€“V4 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig3">Fig. 3a</a>) in trials without distractors was significantly above chance (<i>t</i>(9) = 7.1, <i>P</i> &lt; 0.0001). However, for trials with distractors, decoding accuracy dropped significantly compared with trials without distractors (<i>t</i>(9) = 5.6, <i>P</i> = 0.0004) and no longer differed from chance performance (<i>t</i>(9) = 0.8, <i>P</i> = 0.44), even though there was no significant behavioral difference between the two trial types. Although chance level decoding does not necessarily imply the absence of VSTM representation, as limitations of fMRI MVPA could have prevented the readout of weak VSTM representations, the significant drop in the decoding performance, however, unambiguously shows that distractor presence significantly modulated the strength of VSTM representation in occipital cortex.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="ROIs and the localizer tasks."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 2: ROIs and the localizer tasks.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4174/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="685" height="556"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>(<b>a</b>â€“<b>d</b>) A moving, flashing, colored checkerboard wedge (<b>a</b>) and an object-based VSTM task (<b>b</b>) were used to define occipital and parietal topographic regions (<b>c</b>) and superior IPS (<b>d</b>), respectively. In the VSTM task, participants were shown a sequential presentation of either 1, 2, 3, 4 or 6 real-world objects at fixation and, after a brief delay, reported whether the test object shown at fixation matched or did not match one of the remembered objects. Superior IPS was defined as a region that tracked the behavioral VSTM capacity measures in this task. (<b>e</b>) IPL and SPL were anatomically defined. Each ROI was further refined to select voxels that respond to the task stimuli. All ROIs are shown here on the inflated left hemisphere of an example participant.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4174/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="MVPA decoding accuracy for experiments 1 and 3."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 3: MVPA decoding accuracy for experiments 1 and 3.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4174/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig3_HTML.jpg?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig3_HTML.jpg" alt="figure 3" loading="lazy" width="685" height="451"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>(<b>a</b>,<b>b</b>) MVPA decoding accuracy for the average VSTM delay period activity in V1â€“V4 (<b>a</b>) and superior IPS (<b>b</b>) in experiments 1 (with predictable distractors) and 3 (with unpredictable distractors). The same ten participants took part in both experiments. Although the presence and predictability of distractors did not affect behavioral performance, V1â€“V4 showed successful VSTM decoding when distractors were absent and the presence of distractors was predictable (experiment 1), but showed a significant drop to chance-level decoding when distractors were present. However, when the presence of distractors was unpredictable (experiment 3), V1â€“V4 showed weaker, but significant and comparable, VSTM decoding for both distractor present and absent conditions. Unlike V1â€“V4, superior IPS mirrored behavioral performance and showed consistent and significant VSTM decoding irrespective of distractor presence and predictability. Error bars indicate s.e.m. *<i>P</i> &lt; 0.05, **<i>P</i> &lt; 0.01, ***<i>P</i> &lt; 0.001; ns, non-significant; No dist., trials without distractors; Dist., trials with distractors.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4174/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>In superior IPS, decoding accuracy across the delay period was above chance for both trials without distractors (<i>t</i>(9) = 3.0, <i>P</i> = 0.02) and those with distractors (<i>t</i>(9) = 4.6, <i>P</i> = 0.001), with no difference between these two trial types (<i>t</i>(9) = 1.7, <i>P</i> = 0.13) (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig3">Fig. 3b</a>). Although the overall decoding accuracy was lower in this region than in V1â€“V4 in trials without distractors, this was likely a result of differences in ROI size and signal-to-noise ratios that are unrelated to the actual strength of the memory representations. Notably, the interaction between trial type and ROI was significant (<i>F</i>(1,9) = 9.5 <i>P</i> = 0.01), indicating that the effect of distractors on VSTM decoding differed between occipital and parietal regions, with distractors affecting VSTM representation in occipital cortex, but not superior IPS.</p><p>Although the face and the gazebo distractors were task irrelevant, they could nevertheless be decoded with high accuracy in both V1â€“V4 (accuracy = 0.98, <i>t</i>(9) = 39.0, <i>P</i> &lt; 0.0001) and superior IPS (accuracy = 0.92, <i>t</i>(9) = 18.3, <i>P</i> &lt; 0.0001). This suggests that parietal cortex is capable of maintaining the memory item while concurrently processing incoming visual stimuli. Occipital cortex, on the other hand, was significantly affected by the presence of additional visual stimuli, and appeared to favor incoming visual stimuli over memory representations.</p><h3 class="c-article__sub-heading" id="Sec4">Decoding overlapping visual stimuli in occipital cortex</h3><p>It is possible that distractor processing obscured our ability to decode the memory representation in occipital cortex resulting from limitations of fMRI MVPA. Although decoding in superior IPS argues against the idea of such limitations, given the greater distractor-induced response amplitude change in occipital cortex than in superior IPS (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig8">Supplementary Fig. 1</a>), it is important to directly assess whether overlapping visual stimuli can be successfully decoded in occipital cortex.</p><p>Previous fMRI MVPA studies have shown that VSTM representations in occipital cortex are highly similar in pattern to those produced by perceptual stimulation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e813">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Riggall, A.C. &amp; Postle, B.R. The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging. J. Neurosci. 32, 12990â€“12998 (2012)." href="/articles/nn.4174#ref-CR16" id="ref-link-section-d22723532e816">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Albers, A.M., Kok, P., Toni, I., Dijkerman, H.C. &amp; de Lange, F.P. Shared representations for working memory and mental imagery in early visual cortex. Curr. Biol. 23, 1427â€“1431 (2013)." href="/articles/nn.4174#ref-CR28" id="ref-link-section-d22723532e819">28</a></sup>. We were able to replicate this finding in our VSTM experiment in the trials without distractors. Specifically, when we trained a classifier using the probe stimuli at test as our perceptual stimulus, we still found significant cross-decoding during the VSTM delay (accuracy = 0.62, <i>t</i>(9) = 3.1, <i>P</i> = 0.01). The sensory nature of VSTM representations in occipital cortex therefore allowed us to remove VSTM-related processing and directly test whether or not orientated gratings presented perceptually could be decoded in occipital cortex with and without overlapping distractors.</p><p>In experiment 2, eight of the ten participants who took part in experiment 1 were shown the same grating stimuli (<span class="stix">âˆ¼</span>25Â° or <span class="stix">âˆ¼</span>115Â°) as in experiment 1, but at a much lower contrast (25% opacity) to simulate the reduced strength of the VSTM representations (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig4">Fig. 4</a>). As shown in both the univariate (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig9">Supplementary Fig. 2</a>) and multivariate (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig5">Fig. 5</a>) results below, this level of contrast produced very comparable, if not weaker, representations in occipital cortex than the same memory representation in experiment 1 (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig3">Fig. 3a</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig8">Supplementary Fig. 1</a>). During the experiment, the grating was presented either alone (trials without distractors) or overlapped by the same face or gazebo distractor stimuli from experiment 1 (trials with distractors). The timing of the grating and distractor presentations mirrored that of the delay period in experiment 1 (Online <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/nn.4174#Sec10">Methods</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig4">Fig. 4</a>). To make decoding more challenging, instead of asking participants to attend the gratings, as they would do during the delay period of the VSTM task, we asked them to perform a one-back letter repetition detection task on a letter stream presented at fixation. This fixation task mirrors a perceptual task used previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e854">13</a></sup>, and, as it does not require participants to attend or encoding the grating stimulus in any way, it removes all VSTM processing related to the grating stimuli that may be automatically engaged when participants attend to a stimulus.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Stimuli and task for experiment 2."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 4: Stimuli and task for experiment 2.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4174/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig4_HTML.jpg?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig4_HTML.jpg" alt="figure 4" loading="lazy" width="685" height="263"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Participants were continuously shown a low contrast oriented grating that was either presented alone (trials without distractors) or overlaid with high-contrast distractor stimuli that flickered on and off following the distractor presentation timing during the delay period in experiment 1 (trials with distractors). Participants performed a one-back letter repetition detection task at fixation. Both the fixation dot and the letter have been enlarged in this figure for clarity.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4174/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="MVPA decoding results for experiment 2."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 5: MVPA decoding results for experiment 2.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4174/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig5_HTML.jpg?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig5_HTML.jpg" alt="figure 5" loading="lazy" width="675" height="954"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Eight of the ten participants from experiments 1 and 3 took part in this experiment. Decoding accuracy for the presented grating was significantly above chance in both trials with and without distractors, with no differences seen between trial types, suggesting that MVPA can decode two simultaneously represented stimuli in occipital cortex. Error bars indicate s.e.m. ns, non-significant; *<i>P</i> &lt; 0.05, **<i>P</i> &lt; 0.01; No dist., trials without distractors; Dist., trials with distractors.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4174/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Using the same ROI defined in experiment 1, we found that orientation decoding accuracy in V1â€“V4 was significantly above chance for the presented orientation (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig5">Fig. 5</a>) whether or not distractors were present (trials without distractors: <i>t</i>(7) = 3.5, <i>P</i> = 0.01; trials with distractors: <i>t</i>(7) = 4.2, <i>P</i> = 0.004), with no difference between the two trial types (<i>t</i>(7) = 0.4, <i>P</i> = 0.72). Decoding accuracy for the distractor category was also above chance (accuracy = 0.98, <i>t</i>(7) = 58.1, <i>P</i> &lt; 0.0001).</p><p>In this task, in trials with distractors, the grating was perceptually present throughout the entire delay, whereas distractors flickered on and off, creating some portion of the time in which only the grating was present during the delay. We modeled this task off the assumption that, in experiment 1, the VSTM representations during the delay were also constant, whereas the appearance of distractors was transient. Thus, any boost to decoding in this experiment created by the grating being presented 'alone' during a portion of the delay in trials with distractors would also exist in experiment 1. Moreover, as a result of adaptation, the prolonged presentation of the gratings during the perceptual task should have actually weakened the orientation representation compared to if we had flickered the grating with the distractors, as that type of stimulation would have more optimally driven responses in occipital cortex. Although this experiment might not provide a definitive answer to whether or not completely overlapping stimuli could both be successfully decoded in occipital cortex, it nevertheless created a comparable decoding situation to VSTM to help us better understand the nature of the decoding drop in experiment 1 when distractors were present.</p><p>Because the decoding accuracy for trials without distractors in the perceptual task was equivalent, if not lower, than that seen for the VSTM trials without distractors in experiment 1, our contrast manipulation replicated the strength of the memory representation fairly well. However, unlike in experiment 1, we saw no effect of distractors on decoding accuracy. Thus, occipital cortex was capable of simultaneously representing the contents of both gratings and distractors robustly, even though participants were never explicitly asked to encode either. These results indicate that the drop in VSTM decoding accuracy in occipital cortex in trials with distractors in experiment 1 was not a result of limitations in fMRI MVPA in decoding a weak memory stimulus among a much stronger distractor stimulus, but rather of a lack of robust VSTM representation when other visual stimuli had to be processed. Given the ubiquitous nature of distractors in our everyday visual environment, this vulnerability to distraction suggests that occipital cortex cannot be the primary storage region for VSTM.</p><h3 class="c-article__sub-heading" id="Sec5">Decoding of VSTM content with unpredictable distractors</h3><p>If occipital cortex is capable of representing perceptually presented grating information while processing additional incoming visual stimuli, as shown in experiment 2, then what causes the drop in VSTM representation in this brain region in the face of distraction? One possibility is that the processing of incoming visual stimuli automatically weakens any VSTM representation present in occipital cortex. However, as the presence of distractors was fully predictable in experiment 1, it is also possible that, when participants know distractors will be present during the delay period, they can strategically choose not to engage occipital cortex in VSTM representation.</p><p>To test this idea, in experiment 3, we brought back the participants from experiment 1 and had them complete the exact same task, but we removed their ability to anticipate the upcoming trial type by randomly intermixing trials with and without distractors in each run. If the representation of VSTM information in occipital cortex reflects a particular task strategy, we should no longer see a difference in VSTM decoding accuracy in this brain region for the two trial types. Depending on whether or not participants still choose to engage occipital cortex in VSTM representation, VSTM decoding in occipital cortex could be either above or at chance level for both trial types. On the other hand, if VSTM representation in occipital cortex is always negatively affected by the presence of distractors, then, as in experiment 1, we would expect to see a significant difference in decoding performance between the two trial types, with higher decoding accuracy seen in trials without distractors than in those with distractors.</p><p>Behavioral performance in this experiment was similar to that of experiment 1 (<i>t</i>(9) = 1.1, <i>P</i> = 0.34), with an average of 77.9% correct across all trials. As in experiment 1, there were no differences in performance (<i>t</i>(9) = 1.1, <i>P</i> = 0.29) between trials with (78.1%) and without distractors (77.7%).</p><p>However, unlike experiment 1, when we examined decoding accuracy for the remembered orientation during the delay period, we found above chance decoding in both V1â€“V4 and superior IPS for trials with (V1â€“V4: <i>t</i>(9) = 3.5, <i>P</i> = 0.007; superior IPS: <i>t</i>(9) = 2.5, <i>P</i> = 0.03) and without distractors (V1â€“V4: <i>t</i>(9) = 2.7, <i>P</i> = 0.02; superior IPS: <i>t</i>(9) = 3.4, <i>P</i> = 0.008) and no significant differences between trial types (V1â€“V4: <i>t</i>(9) = 0.7, <i>P</i> = 0.52; superior IPS: <i>t</i>(9) = 0.1, <i>P</i> = 0.94) (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig3">Fig. 3</a>). There was also no interaction between brain region and trial type (<i>F</i>(1,9) = 0.3, <i>P</i> = 0.52). As in experiment 1, decoding accuracy for the distractor category was significant in both V1â€“V4 (accuracy = 0.98, <i>t</i>(9) = 100.6, <i>P</i> &lt; 0.0001) and superior IPS (accuracy = 0.88, <i>t</i>(9) = 17.04, <i>P</i> &lt; 0.0001).</p><p>Our ability to decode VSTM contents in occipital cortex in trials with distractors here further supports our results from experiment 2. Combined together, these two experiments strongly suggest that the drop in decoding seen in trials with distractors in experiment 1 was not a result of a failure of fMRI MVPA to decode a memory stimulus amongst a stronger distractor stimulus, but rather a decrease in the memory representation.</p><p>A direct comparison between experiments 1 and 3 revealed an interaction between experiment, ROI and trial type (<i>F</i>(1,9) = 6.13, <i>P</i> = 0.02), indicating that, although VSTM decoding accuracy was consistently above chance in superior IPS across experiments and trial types, decoding accuracy in V1â€“V4 varied on the basis of the presence and predictability of distractors. This variability exists despite the fact that the task and trials were identical in the two experiments. Across the two experiments, as the presence of distractors became more predictable, VSTM decoding accuracy in V1â€“V4 decreased such that decoding accuracy of both trials types in experiment 3 were lower than that of trials without distractors in experiment 1 (experiment 3 trials without distractors: <i>t</i>(9) = 2.1, <i>P</i> = 0.07; experiment 3 trials with distractors: <i>t</i>(9) = 4.5, <i>P</i> = 0.002), but higher than that of trials with distractors in experiment 1 (experiment 3 trials without distractors: <i>t</i>(9) = 2.0, <i>P</i> = 0.07; experiment 3 trials with distractors: <i>t</i>(9) = 2.1, <i>P</i> = 0.06). These results suggest that the predictability of distractor presence governs whether or not participants choose to engage occipital cortex in VSTM representation. Given that behavioral VSTM performance in both experiments was unaffected by the presence and the predictability of distractors, these results suggest that superior IPS has a central role in VSTM storage, whereas VSTM representations seen in occipital cortex are unlikely to be essential.</p><h3 class="c-article__sub-heading" id="Sec6">VSTM decoding in other parietal regions</h3><p>Unlike in superior IPS, none of the topographic IPS regions or anatomically defined superior and inferior parietal lobules (SPL and IPL, respectively) showed consistent decoding of memory information across distractor presence, absence or level of predictability (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig10">Supplementary Figs. 3</a>,<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig11">4</a>,<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig12">5</a>,<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig13">6</a>). This suggests that VSTM storage may not be a general function of the parietal cortex, but rather may be specific to superior IPS. This also underscores the importance of appropriate ROI selection in understanding the role of parietal cortex in these types of higher order processes. If regions that are involved in VSTM, such as superior IPS, are combined with regions specialized for other processes, as in the large anatomically defined IPL and SPL regions, then our ability to detect VSTM representations in parietal cortex would be substantially hampered, resulting in an inaccurate depiction of the role of parietal cortex in VSTM.</p><h3 class="c-article__sub-heading" id="Sec7">Behavioral and neural VSTM correlations</h3><p>The results from experiment 1 clearly show that orientation representations in occipital cortex are unrelated to behavioral performance on the task, as a sharp decrease in decoding was seen in trials with distractors with no concurrent disruption of behavioral performance. However, although we have established a similar null distractor effect for both decoding in superior IPS and behavioral performance, it remains unclear whether orientation representations in this brain region are directly related to behavioral VSTM performance. In experiment 4, we brought back a subset of the original participants to more directly examine this relationship. Each participant completed two experimental sessions, an MRI session and a behavioral session outside the MRI scanner. In both sessions, participants were shown and asked to remember a single orientated grating, followed by a mask to disrupt any lingering perceptual representation. Target orientations were drawn from a set of six orientations (10Â°, 40Â°, 70Â°, 100Â°, 130Â° and 160Â°). In the MRI experiment, after a delay, participants were asked to report the direction of a small rotation in the test stimulus relative to the remembered orientation, similar to what was done in experiments 1 and 3. We obtained VSTM decoding accuracies during the delay period for each possible pair of orientations in both our V1â€“V4 and superior IPS ROIs, creating a neural orientation representation similarity matrix for each ROI. In the behavioral task, after a delay, participants were asked to report whether there was an orientation change, which occurred in half of the trials. The test orientation was drawn from the same set of six orientations as the target orientation and, in change trials, it came equally often from the five remaining orientations. The larger the angular difference between the remembered and the test orientations, the faster participants are able to respond. Using these reaction time measures, we constructed a behavioral orientation representation similarity matrix. We then calculated the correlation between the neural and behavioral representation similarity matrices<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Kriegeskorte, N. et al. Matching categorical object representations in inferior temporal cortex of man and monkey. Neuron 60, 1126â€“1141 (2008)." href="/articles/nn.4174#ref-CR29" id="ref-link-section-d22723532e1097">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Kriegeskorte, N. &amp; Kievit, R.A. Representational geometry: integrating cognition, computation, and the brain. Trends Cogn. Sci. 17, 401â€“412 (2013)." href="/articles/nn.4174#ref-CR30" id="ref-link-section-d22723532e1100">30</a></sup>. If VSTM representations in a brain region were directly related to VSTM behavioral performance, then the distinctiveness of a pair of orientation representations in that brain region should directly correlate with how fast participants could tell them apart in the behavioral change detection task, resulting in a negative correlation between the two measures (that is, the bigger the neural representational difference, the shorter the reaction time).</p><p>Indeed, we found strong negative correlations between decoding and behavioral performance for both V1â€“V4 and superior IPS (V1â€“V4: <i>r</i> = â€“0.7, <i>P</i> = 0.002; superior IPS: <i>r</i> = â€“0.59, <i>P</i> = 0.009, permutation tests for both; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig6">Fig. 6</a>). These results held even if we removed the first time point used for the average delay activity (V1â€“V4: <i>r</i> = â€“0.68, <i>P</i> = 0.004; superior IPS: <i>r</i> = â€“0.51, <i>P</i> = 0.03, permutation tests for both), suggesting that these results are not driven by any lingering encoding period activity. Thus, as the VSTM representations in superior IPS and V1â€“V4 become harder to distinguish, behavioral reaction time increases. Combined with the results of our other experiments, this strongly supports the idea that superior IPS has a central role in the storage of information into VSTM. Being a VSTM region, superior IPS is unlikely to be involved in the initial computation and representations of the orientation information. Rather, such information must be processed elsewhere (for example, V1â€“V4) and uploaded into superior IPS when it needs to be retained in VSTM. It is therefore not surprising that delay representations in V1â€“V4 also correlated with behavioral performance. However, experiment 1 clearly shows that such representations cannot reliably support successful information retention in VSTM.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Correlation of neural and behavioral VSTM representations from experiment 4."><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 6: Correlation of neural and behavioral VSTM representations from experiment 4.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4174/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig6_HTML.jpg?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig6_HTML.jpg" alt="figure 6" loading="lazy" width="685" height="334"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Six participants from experiment 1 took part in this experiment. (<b>a</b>,<b>b</b>) Both V1â€“V4 (<b>a</b>) and superior IPS (<b>b</b>) showed strong negative correlations between behavioral (RT) and neural (decoding accuracy) measures of VSTM representation similarity across the six orientations tested, showing that the more similar a pair of orientation representations are in these brain regions during the VSTM delay period, the harder it is to discriminate them behaviorally in a change-detection task. In V1â€“V4, two pairs of orientation representations (40â€“160Â° and 130â€“160Â°) had identical RTs and decoding accuracies, and so both points occupy the same place in the graph. These results establish a link between VSTM representations in both brain regions and behavioral VSTM performance when distractors were absent during the delay period.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4174/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec8">Target-distractor similarity and behavioral performance</h3><p>If delay period representations in occipital cortex are important in VSTM, then, because occipital cortex must also process incoming distractor information, the more similar the distractors are to the targets, the more they should share similar neural processing substrates and compete for representation. However, if delay period representations in occipital cortex are not a central component of neural VSTM representation, then the competition caused by target-distractor similarity would minimally affect VSTM performance. To test these predictions, in experiment 5, we asked six participants from experiments 1 and 3 to complete a behavioral version of the oriented grating VSTM task in experiment 3 and cued them to remember one of two sequentially presented grating stimuli (<span class="stix">âˆ¼</span>25Â° or <span class="stix">âˆ¼</span>115Â°). Following the parameters used in experiment 3, during the extended delay period (400 ms after the offset of the target stimulus), in addition to viewing a series of faces, a series of gazebos or simply a fixation dot (no distractor trials), the subjects also viewed a series of orientated gratings. Trials containing the different distractor conditions were randomly intermixed in a given run, just as in experiment 3. The oriented grating distractors differed from the to-be-remembered target gratings only in orientation and were drawn from a set of six orientations covering the entire visual field in 30Â° increments (0Â°, 30Â°, 60Â°, 90Â°, 120Â° and 150Â°). During the delay period, the entire set of grating distractors was presented roughly three times. The presentation of the grating distractors would therefore activate similar neural processing substrates as the target orientation, maximally masking the activation of the remembered orientation. Among the three types of distractors shown, the grating distractors imposed the greatest representation competition in occipital cortex. However, we found no significant differences in VSTM performance between any of the distractor conditions (no distractor versus grating distractor trials: <i>t</i>(5) = 0.3, <i>P</i> = 0.81; no distractor versus face distractor trials: <i>t</i>(5) = 2.0, <i>P</i> = 0.10; no distractor versus gazebo distractor trials: <i>t</i>(5) = 1.8, <i>P</i> = 0.14; <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig7">Fig. 7</a>). Thus, the type of distractors present during the delay did not affect behavioral VSTM performance. These behavioral results further suggest that delay period representations in occipital cortex cannot be a central component of neural VSTM representation, reaffirming our fMRI decoding results.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Accuracy results for experiment 5."><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Figure 7: Accuracy results for experiment 5.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/nn.4174/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig7_HTML.jpg?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig7_HTML.jpg" alt="figure 7" loading="lazy" width="675" height="746"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Six participants from experiment 1 took part in this experiment. In this behavioral experiment, the presence and absence of distractors during the VSTM delay period, as well as the similarity between the target and distractors, were varied. There was no difference in accuracy, as measured by percent correct for any distractor condition, nor did any distractor condition differ from the no distractor condition, indicating that neither distractor presence/absence nor target-distractor similarity affected performance. Error bars indicate s.e.m. No dist., trials without distractors; faces, trials with face distractors during the delay; gazebos, trials with gazebo distractors; gratings, trials with oriented grating distractors.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/nn.4174/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Although previous behavioral studies have reported that passive viewing of a distractor similar to the remembered target negatively affected VSTM performance, a close examination of these results reveal that distractor interference is mainly present during the early delay period, when sensory information is still being consolidated into VSTM, whereas late delay period activity seems to be resilient to distractor inference<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Pasternak, T. &amp; Greenlee, M.W. Working memory in primate sensory systems. Nat. Rev. Neurosci. 6, 97â€“107 (2005)." href="/articles/nn.4174#ref-CR1" id="ref-link-section-d22723532e1219">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Vogel, E.K., Woodman, G.F. &amp; Luck, S.J. The time course of consolidation in visual working memory. J. Exp. Psychol. Hum. Percept. Perform. 32, 1436â€“1451 (2006)." href="/articles/nn.4174#ref-CR31" id="ref-link-section-d22723532e1222">31</a></sup>. Thus, prior work actually argues against the idea that sensory areas are recruited and are necessary for VSTM maintenance. Instead, they suggest that once encoding is complete, stored information in VSTM is resilient to distraction. As our distractor stimuli were shown after the consolidation processing was completed<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Vogel, E.K., Woodman, G.F. &amp; Luck, S.J. The time course of consolidation in visual working memory. J. Exp. Psychol. Hum. Percept. Perform. 32, 1436â€“1451 (2006)." href="/articles/nn.4174#ref-CR31" id="ref-link-section-d22723532e1226">31</a></sup>, our results further argue that consolidated VSTM representations are protected against incoming perceptual interference. Given that distracting visual information is ubiquitous in the real world, this protection against interference is an essential feature of VSTM if it is to have any substantial role in real world vision.</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Discussion</h2><div class="c-article-section__content" id="Sec9-content"><p>Using fMRI response amplitude measures, previous reports have highlighted the role of superior IPS in maintaining VSTM representations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Todd, J.J. &amp; Marois, R. Capacity limit of visual short-term memory in human posterior parietal cortex. Nature 428, 751â€“754 (2004)." href="/articles/nn.4174#ref-CR2" id="ref-link-section-d22723532e1239">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Xu, Y. Distinctive neural mechanisms supporting visual object individuation and identification. J. Cogn. Neurosci. 21, 511â€“518 (2009)." href="/articles/nn.4174#ref-CR3" id="ref-link-section-d22723532e1242">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1245">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Jeong, S.K. &amp; Xu, Y. Neural representation of targets and distractors during object individuation and identification. J. Cogn. Neurosci. 25, 117â€“126 (2013)." href="/articles/nn.4174#ref-CR5" id="ref-link-section-d22723532e1248">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Xu, Y. The neural fate of task-irrelevant features in object-based processing. J. Neurosci. 30, 14020â€“14028 (2010)." href="/articles/nn.4174#ref-CR6" id="ref-link-section-d22723532e1251">6</a></sup>. In contrast, using fMRI MVPA measures, recent studies have revealed VSTM representations in occipital cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Ester, E.F., Sprague, T.C. &amp; Serences, J.T. Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory. Neuron 87, 893â€“905 (2015)." href="/articles/nn.4174#ref-CR10" id="ref-link-section-d22723532e1255">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Emrich, S.M., Riggall, A.C., LaRocque, J.J. &amp; Postle, B.R. Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory. J. Neurosci. 33, 6516â€“6523 (2013)." href="/articles/nn.4174#ref-CR11" id="ref-link-section-d22723532e1258">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1261">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Riggall, A.C. &amp; Postle, B.R. The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging. J. Neurosci. 32, 12990â€“12998 (2012)." href="/articles/nn.4174#ref-CR16" id="ref-link-section-d22723532e1264">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Serences, J.T., Ester, E.F., Vogel, E.K. &amp; Awh, E. Stimulus-specific delay activity in human primary visual cortex. Psychol. Sci. 20, 207â€“214 (2009)." href="/articles/nn.4174#ref-CR17" id="ref-link-section-d22723532e1267">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Sprague, T.C., Ester, E.F. &amp; Serences, J.T. Reconstructions of information in visual spatial working memory degrade with memory load. Curr. Biol. 24, 2174â€“2180 (2014)." href="/articles/nn.4174#ref-CR19" id="ref-link-section-d22723532e1270">19</a></sup>. In this set of fMRI MVPA studies, we critically evaluated the contribution of both occipital and parietal cortices to VSTM representation and storage by varying the presence and predictability of distractors during the delay period of an oriented grating VSTM task. Although distractor presence predictably did not affect behavioral performance, it significantly affected VSTM decoding in occipital cortex. Specifically, when the presence of distractors was predictable in experiment 1, we found strong VSTM decoding during the delay period in occipital cortex when distractors were absent, but we observed a significant drop, to chance level decoding, when distractors were present. This drop in VSTM decoding was not simply a failure of MVPA to resolve a weak VSTM pattern among a stronger distractor pattern, as distractor processing had no effect on the successful decoding of perceptually presented weak oriented gratings in occipital cortex in experiment 2. Moreover, when distractor presence was no longer predictable in experiment 3, equal VSTM decoding was seen in occipital cortex in trials with and without distractors. Decoding accuracy was lower in experiment 3 than the trials without distractors in experiment 1, but still significantly above chance. Thus, processing incoming task-irrelevant visual stimuli does not automatically degrade VSTM representations in occipital cortex. Rather, the predictability of distractor presence allows participants to strategically decide whether or not to engage occipital cortex in VSTM representation. In the decoding analyses for experiments 1 and 3, we only tested whether a brain region represented left-tilted gratings differently than right-tilted gratings; however, in our task, we required participants to perform the much harder classification of a 3Â° or 6Â° orientation change. Given the high level of precision required in VSTM representation to perform this task, if a region shows poor decoding for the gross left versus right orientation discrimination, as occipital cortex does in experiment 1 when distractor presence is predictable, then it would be unlikely for it to support robust behavioral performance on the much harder VSTM task we gave our participants. In contrast, superior IPS mirrored behavioral performance and showed equally strong VSTM decoding independent of distractor presence and predictability. These results indicate that superior IPS, and not occipital cortex, may have a central role in supporting VSTM storage.</p><p>Using fMRI representation similarity measures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Kriegeskorte, N. et al. Matching categorical object representations in inferior temporal cortex of man and monkey. Neuron 60, 1126â€“1141 (2008)." href="/articles/nn.4174#ref-CR29" id="ref-link-section-d22723532e1277">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Kriegeskorte, N. &amp; Kievit, R.A. Representational geometry: integrating cognition, computation, and the brain. Trends Cogn. Sci. 17, 401â€“412 (2013)." href="/articles/nn.4174#ref-CR30" id="ref-link-section-d22723532e1280">30</a></sup>, experiment 4 further showed that VSTM representation (in the absence of distraction) in superior IPS closely tracked behavioral performance on a VSTM task, thereby establishing a link between neural representation and behavior in this brain region. This neural-behavioral link is a necessary feature of any region that has a central role in VSTM information maintenance and this finding therefore underscores the importance of the role of superior IPS in VSTM storage. Delay period representations in occipital cortex also reflected behavioral VSTM measures in the absence of distractors, likely as a result of its role in the initial processing of the orientation information. However, as experiment 1 clearly revealed, such representations cannot reliably support successful information retention in VSTM.</p><p>By manipulating the similarity between the target and distractor stimuli in a behavioral study, we also found that the type of distractors present during the delay period did not affect behavioral VSTM performance. This is consistent with previous studies showing that consolidated VSTM representations, which were what we tested, are largely immune to incoming perceptual interference, regardless of the target-distractor similarity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Pasternak, T. &amp; Greenlee, M.W. Working memory in primate sensory systems. Nat. Rev. Neurosci. 6, 97â€“107 (2005)." href="/articles/nn.4174#ref-CR1" id="ref-link-section-d22723532e1287">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Vogel, E.K., Woodman, G.F. &amp; Luck, S.J. The time course of consolidation in visual working memory. J. Exp. Psychol. Hum. Percept. Perform. 32, 1436â€“1451 (2006)." href="/articles/nn.4174#ref-CR31" id="ref-link-section-d22723532e1290">31</a></sup>. This behavioral evidence further speaks against the role of occipital cortex in VSTM information representation, as occipital cortex is necessarily involved in the processing of incoming distractor information and the similarity between the target and distractor stimuli should negatively affect VSTM representation in this brain region. Overall, our findings reestablish the important contribution of superior IPS to VSTM representation and argue against the notion that occipital cortex has a central role in maintaining VSTM information.</p><p>Our findings echo a recent neurophysiological finding in macaques<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Mendoza-Halliday, D., Torres, S. &amp; Martinez-Trujillo, J.C. Sharp emergence of feature-selective sustained activity along the dorsal visual pathway. Nat. Neurosci. 17, 1255â€“1262 (2014)." href="/articles/nn.4174#ref-CR32" id="ref-link-section-d22723532e1297">32</a></sup>. Using a VSTM task with motion stimuli, the authors found that the spiking activity in direction-selective neurons in the middle temporal (MT) area did not reflect the memorized motion direction. Similar to V1â€“V4, MT is a primary sensory region. Instead, the authors found that VSTM information was only present in the spiking activity of higher order, multimodal areas. However, VSTM-related local field potential (LFP) activity was present in both MT and higher order areas. As previous work has linked fMRI activity primarily to LFPs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Logothetis, N.K., Pauls, J., Augath, M., Trinath, T. &amp; Oeltermann, A. Neurophysiological investigation of the basis of the fMRI signal. Nature 412, 150â€“157 (2001)." href="/articles/nn.4174#ref-CR33" id="ref-link-section-d22723532e1301">33</a></sup>, the authors<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Mendoza-Halliday, D., Torres, S. &amp; Martinez-Trujillo, J.C. Sharp emergence of feature-selective sustained activity along the dorsal visual pathway. Nat. Neurosci. 17, 1255â€“1262 (2014)." href="/articles/nn.4174#ref-CR32" id="ref-link-section-d22723532e1305">32</a></sup> reasoned that LPF activity was likely the source of VSTM decoding in occipital cortex in fMRI studies. However, given the lack of single-unit activity in these same regions, the authors argued that such LFP activity, and the fMRI decoding findings based on that activity, did not reflect VSTM storage, but instead reflected another process, which they suggested could be an attentional priority map. Despite the limitations in the types of neural activity fMRI can measure, our stimulus manipulation let us reach the same conclusions as those of the previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Mendoza-Halliday, D., Torres, S. &amp; Martinez-Trujillo, J.C. Sharp emergence of feature-selective sustained activity along the dorsal visual pathway. Nat. Neurosci. 17, 1255â€“1262 (2014)." href="/articles/nn.4174#ref-CR32" id="ref-link-section-d22723532e1309">32</a></sup>: that occipital VSTM representations do not reflect the primary storage of VSTM information. Thus, with appropriate stimulus manipulations and experimental design, fMRI is capable of revealing the nature of visual information processing in the human brain. In parietal cortex, both single-unit and LFP activity related to VSTM representation has been reported<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Pasternak, T. &amp; Greenlee, M.W. Working memory in primate sensory systems. Nat. Rev. Neurosci. 6, 97â€“107 (2005)." href="/articles/nn.4174#ref-CR1" id="ref-link-section-d22723532e1313">1</a></sup>, suggesting that this brain region is important for VSTM representation. This is again consistent with our results. Together, our fMRI findings and those from neurophysiological recording studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Mendoza-Halliday, D., Torres, S. &amp; Martinez-Trujillo, J.C. Sharp emergence of feature-selective sustained activity along the dorsal visual pathway. Nat. Neurosci. 17, 1255â€“1262 (2014)." href="/articles/nn.4174#ref-CR32" id="ref-link-section-d22723532e1318">32</a></sup> provide converging evidence indicating that higher order multimodal areas, and not primary sensory regions, are critical for the storage of VSTM information.</p><p>fMRI MVPA operates on the assumption that neurons selective for the different features are distributed differentially across different voxels. As such, an inappropriate fMRI voxel resolution may result in the lack of heterogeneity among the voxels and null results from a brain region that would be otherwise important in a neural process. Although this is an important limitation of fMRI MVPA, in each of our ROIs, we were able to obtain robust VSTM decoding in at least one condition across the experiments. Given that feature distribution in a brain region would not change rapidly enough with our experimental manipulations to create the differences that we observed, a change in decoding accuracy must then be a result of how the brain region participates in the task under the different experimental conditions. Thus, at least for the regions that we examined in the present study, the resolution of our MRI voxels does not appear to impede our ability to decode VSTM representations.</p><p>Previous work has shown that mental imagery activates occipital cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Kosslyn, S.M., Ganis, G. &amp; Thompson, W.L. Neural foundations of imagery. Nat. Rev. Neurosci. 2, 635â€“642 (2001)." href="/articles/nn.4174#ref-CR34" id="ref-link-section-d22723532e1329">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Slotnick, S.D., Thompson, W.L. &amp; Kosslyn, S.M. Visual mental imagery induces retinotopically organized activation of early visual areas. Cereb. Cortex 15, 1570â€“1583 (2005)." href="/articles/nn.4174#ref-CR35" id="ref-link-section-d22723532e1332">35</a></sup>, and that imagery, perception and VSTM all share similar representations in occipital cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Albers, A.M., Kok, P., Toni, I., Dijkerman, H.C. &amp; de Lange, F.P. Shared representations for working memory and mental imagery in early visual cortex. Curr. Biol. 23, 1427â€“1431 (2013)." href="/articles/nn.4174#ref-CR28" id="ref-link-section-d22723532e1336">28</a></sup>. Notably, individuals with poor mental imagery skills show lower VSTM decoding in occipital cortex than those who excel at imagery<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Albers, A.M., Kok, P., Toni, I., Dijkerman, H.C. &amp; de Lange, F.P. Shared representations for working memory and mental imagery in early visual cortex. Curr. Biol. 23, 1427â€“1431 (2013)." href="/articles/nn.4174#ref-CR28" id="ref-link-section-d22723532e1340">28</a></sup>. Thus, it has been argued that individuals with strong mental imagery may rely on imagery to support VSTM performance, whereas those with poor imagery may rely on different strategies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Keogh, R. &amp; Pearson, J. Mental imagery and visual working memory. PloS One 6, e29221 (2011)." href="/articles/nn.4174#ref-CR36" id="ref-link-section-d22723532e1344">36</a></sup>. In our VSTM tasks, it is likely that mental imageryâ€“based visual rehearsal was deployed in memory delay periods when distractors were known to be absent, less so when distractor presence was unpredictable, and minimally when distractors were known to be present. However, this strategy ultimately produced no noticeable behavioral benefit and therefore does not seem to be a necessary component of VSTM.</p><p>Although previous MVPA studies have produced mixed results regarding the role of the parietal cortex in VSTM information representation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Ester, E.F., Sprague, T.C. &amp; Serences, J.T. Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory. Neuron 87, 893â€“905 (2015)." href="/articles/nn.4174#ref-CR10" id="ref-link-section-d22723532e1351">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Emrich, S.M., Riggall, A.C., LaRocque, J.J. &amp; Postle, B.R. Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory. J. Neurosci. 33, 6516â€“6523 (2013)." href="/articles/nn.4174#ref-CR11" id="ref-link-section-d22723532e1354">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Linden, D.E., Oosterhof, N.N., Klein, C. &amp; Downing, P.E. Mapping brain activation and information during category-specific visual working memory. J. Neurophysiol. 107, 628â€“639 (2012)." href="/articles/nn.4174#ref-CR15" id="ref-link-section-d22723532e1357">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Riggall, A.C. &amp; Postle, B.R. The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging. J. Neurosci. 32, 12990â€“12998 (2012)." href="/articles/nn.4174#ref-CR16" id="ref-link-section-d22723532e1360">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Sprague, T.C., Ester, E.F. &amp; Serences, J.T. Reconstructions of information in visual spatial working memory degrade with memory load. Curr. Biol. 24, 2174â€“2180 (2014)." href="/articles/nn.4174#ref-CR19" id="ref-link-section-d22723532e1363">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Christophel, T.B., Hebart, M.N. &amp; Haynes, J.-D. Decoding the contents of visual short-term memory from human visual and parietal cortex. J. Neurosci. 32, 12983â€“12989 (2012)." href="/articles/nn.4174#ref-CR23" id="ref-link-section-d22723532e1366">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Nelissen, N., Stokes, M., Nobre, A.C. &amp; Rushworth, M.F. Frontal and parietal cortical interactions with distributed visual representations during selective attention and action selection. J. Neurosci. 33, 16443â€“16458 (2013)." href="/articles/nn.4174#ref-CR24" id="ref-link-section-d22723532e1370">24</a></sup>, none of them specifically targeted the superior IPS, a key parietal region whose response amplitude tracks VSTM storage<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Todd, J.J. &amp; Marois, R. Capacity limit of visual short-term memory in human posterior parietal cortex. Nature 428, 751â€“754 (2004)." href="/articles/nn.4174#ref-CR2" id="ref-link-section-d22723532e1374">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Xu, Y. Distinctive neural mechanisms supporting visual object individuation and identification. J. Cogn. Neurosci. 21, 511â€“518 (2009)." href="/articles/nn.4174#ref-CR3" id="ref-link-section-d22723532e1377">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1380">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Jeong, S.K. &amp; Xu, Y. Neural representation of targets and distractors during object individuation and identification. J. Cogn. Neurosci. 25, 117â€“126 (2013)." href="/articles/nn.4174#ref-CR5" id="ref-link-section-d22723532e1383">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Xu, Y. The neural fate of task-irrelevant features in object-based processing. J. Neurosci. 30, 14020â€“14028 (2010)." href="/articles/nn.4174#ref-CR6" id="ref-link-section-d22723532e1386">6</a></sup>. We found that, mirroring behavioral performance, VSTM representations could be consistently decoded from superior IPS regardless of the presence and the predictability of distractors. No other parietal regions showed such reliable VSTM decoding, including parietal topographic maps in IPS and anatomically defined IPL and SPL. This may explain why previous attempts have failed to reveal consistent VSTM decoding in parietal cortex when superior IPS was not targeted and highlights the importance of appropriate ROI selection in understanding the role of parietal cortex in visual cognition.</p><p>Parietal cortex has also long been associated with attention-related processing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Wojciulik, E. &amp; Kanwisher, N. The generality of parietal involvement in visual attention. Neuron 23, 747â€“764 (1999)." href="/articles/nn.4174#ref-CR37" id="ref-link-section-d22723532e1393">37</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Yantis, S. et al. Transient neural activity in human parietal cortex during spatial attention shifts. Nat. Neurosci. 5, 995â€“1002 (2002)." href="/articles/nn.4174#ref-CR38" id="ref-link-section-d22723532e1396">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Behrmann, M., Geng, J.J. &amp; Shomstein, S. Parietal cortex and attention. Curr. Opin. Neurobiol. 14, 212â€“217 (2004)." href="/articles/nn.4174#ref-CR39" id="ref-link-section-d22723532e1399">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Colby, C.L. &amp; Goldberg, M.E. Space and attention in parietal cortex. Annu. Rev. Neurosci. 22, 319â€“349 (1999)." href="/articles/nn.4174#ref-CR40" id="ref-link-section-d22723532e1402">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Culham, J.C. &amp; Kanwisher, N.G. Neuroimaging of cognitive functions in human parietal cortex. Curr. Opin. Neurobiol. 11, 157â€“163 (2001)." href="/articles/nn.4174#ref-CR41" id="ref-link-section-d22723532e1405">41</a></sup>. Our results suggest that one way parietal cortex may participate in attention-related information processing is by directly representing task-relevant VSTM information in superior IPS. One can argue that parietal cortex may simply contain an attentional template that tracks what is behaviorally relevant. However, as such an attentional template has to be distinct for the different orientation gratings shown and has to be maintained for a prolonged period in the absence of any visual stimulation, it is unclear how such an attentional template would differ fundamentally from a VSTM representation.</p><p>To conclude, we found that MVPA decoding in superior IPS, but not occipital cortex, closely tracked behavioral measures of information storage in VSTM across distractor presence and predictability. This suggests that superior IPS, and not occipital cortex, has a central role in VSTM storage in the human brain.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec10-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec10">Methods</h2><div class="c-article-section__content" id="Sec10-content"><h3 class="c-article__sub-heading" id="Sec11">Participants.</h3><p>Ten paid participants (seven female) from the Harvard University community were recruited to participate in experiments 1 and 3. Six (five female) of those also completed experiments 4 and 5. Finally, eight (six female) of the ten also completed experiment 2. All participants gave informed consent in accordance with the Institutional Review Board of Harvard University. Participants were between 23 and 36 years old (mean age = 29.5). All had normal or corrected-to-normal visual acuity, all were right-handed, and received payments for their participation.</p><h3 class="c-article__sub-heading" id="Sec12">VSTM experiments examining distractor presence and predictibility (experiments 1 and 3).</h3><p>The design of experiments 1 and 3 was adapted from the delayed orientation discrimination task (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig1">Fig. 1</a>) used previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1435">13</a></sup>. In each trial, participants saw a sequential presentation of two centrally presented sine-wave gratings one at <span class="stix">âˆ¼</span>25Â° and the other at <span class="stix">âˆ¼</span>115Â° (radius, 5Â° of visual angle; contrast, 20%; spatial frequency, 1 cycle per degree), followed by a numerical cue (1 or 2) that indicated which grating they were to remember, first or second. The presentation order of the two gratings and whether the first or second grating would be cued were counterbalanced within each run. After an extended delay, participants were asked to report the direction of rotation (Â±3Â° or Â± 6Â°) of a test grating relative to the cued grating. The grating was rotated equally often to the left or to the right, but the amount of rotation (3Â° or 6Â°) was random. The precise timing of each trial was as follows: first sample grating (200 ms), blank (400 ms), second sample grating (200 ms), blank (400 ms), cue (800 ms), delay (11 s), test grating (500 ms), response (2,000 ms), and feedback (500 ms). Feedback was given after every trial as either a happy face (for correct trials) or a sad face (for error trials). Each trial lasted 16 s and was followed by 16s of fixation to allow the hemodynamic response to return to baseline. To ensure proper fixation, a black fixation dot was present throughout the trial and the inter-trial fixation period (this applied to all the experiments reported here except where noted). To alert and prepare participants for the upcoming stimulus trial, during the last 500ms of the fixation period, the fixation dot turned from black to red (this design feature was implemented in all the experiments reported here). We used eye tracking to monitor the gaze of each participant to ensure that participants maintained fixation throughout the trial (this applied to all the fMRI experiments reported here). Each run (296 s) consisted of eight trials plus an initial practice trial that was excluded from later analyses.</p><p>Half of the trials were trials without distractors in which no stimuli were presented during the delay, identical to what was done previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1442">13</a></sup>. The other half of the trials were trials with distractors in which a sequential presentation of 17 faces or gazebos were shown throughout the entire delay. The delay began and ended with 400 ms of blank fixation. Each distractor was presented for 200 ms, followed by a 400-ms blank and subtended 6.9Â° Ã— 8.3Â° of visual angle. In experiment 1, trials with and without distractors were shown in separate runs with each participant first completing all eight runs of trials without distractors, followed by all eight runs of trials with distractors, with nine trials (one practice) in each run. This was done so that performance on trials without distractors would not be influenced by any strategy that participants might develop after completing trials with distractors, thus giving us the best chance to replicate previous work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1446">13</a></sup>. In trials with distractors, trials containing face distractors (50%) and those containing gazebo distractors (50%) were randomly intermixed. In experiment 3, trials with and without distractors were randomly intermixed in each run. The random nature prevented participants from being able to accurately anticipate whether a distractor would be present for any given trial. Half the trials (four) in each run had no distractors, and half had distractors (with two containing face distractors and two containing gazebo distractors). Thus, the total number of trials of each type was matched to that of experiment 1. Within each run the two grating orientations appeared equally often and, when distractors were present, appeared equally often with the two types of distractors. In both experiments 1 and 3, each participant completed a total of 16 runs, each lasting 4 min and 56 s.</p><h3 class="c-article__sub-heading" id="Sec13">Control experiment with overlapping perceptual stimuli (experiment 2).</h3><p>The goal of this experiment was to perceptually recreate the processing that would have occurred during the delay period of experiment 1, to examine whether or not MPVA can decode a weak perceptual stimulus superimposed by a strong perceptual stimulus. Using a block design, with each block lasting 12 s, we presented a semi-transparent (25% opacity) oriented grating (25Â° or 115Â°) for an entire block. This grating was either presented alone (trials without distractors) or overlaid with a sequential presentation of 20 faces or gazebos (75% opacity) timed to match the presentation of the distractor stimuli during the delay period of experiment 1 (on for 200 ms and off for 400 ms) (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig4">Fig. 4</a>). The opacity of the grating and distractor stimuli was intended to simulate the weaker representation of the stored grating in memory and any possible suppression of the distractor stimuli. To further challenge the decoding ability of MVPA, we diverted participants' attention away from the gratings and distractors by asking them to attend to a sequential presentation of letters at fovea, timed to match the presentation of the distractor stimuli in experiment 1. Thus, the presentation of the letters coincided with that of the distractors, although the presentation of the grating was kept visible and constant across the entire block to simulate the grating memory representation formed during the delay period of experiment 1. Participants performed a 1-back letter repetition detection task on the letter stream and responded with a button press. As in experiments 1 and 3, within each run the two grating orientations appeared equally often and, when distractors were present, appeared equally often with the two types of distractors. Each run lasted 3 min and 20 s, containing eight 12-s stimulus blocks alternating with eight 12-s fixation blocks in which only the fixation dot was present. In one session, participants completed ten runs of blocks with distractors and, in a separate session, completed ten runs of blocks without distractors.</p><h3 class="c-article__sub-heading" id="Sec14">Correlation between VSTM decoding and behavioral performance experiment (experiment 4).</h3><p>To examine whether VSTM representations formed in each brain region during the delay period are related to VSTM behavioral performance, we had participants complete two separate tasks, one fMRI experiment to measure the neural representation similarity, and one behavioral experiment outside the MRI to measure the behavioral representation similarity. In the fMRI experiment, participants completed a task very similar to what was done in experiments 1 and 3, but with only one grating stimulus presented in each trial, followed by a mask and no distractors during the delay. In each trial, participants saw a brief presentation of one grating in one of six orientations, 10Â°, 40Â°, 70Â°, 100Â°, 130Â° and 160Â°, followed by a briefly presented plaid mask containing two overlapping orientations, 0Â° and 90Â° for 200 ms. After a delay of 11.4 s, participants were asked to report the direction of rotation (Â±3Â° or Â±6Â°) of a test grating relative to the remembered grating. Feedback was provided after every trial. The precise timing of each trial was as follows: sample grating (200 ms), blank (200 ms), mask (200 ms), delay (11.4 s), test grating (500 ms), response (2,000 ms) and feedback (500 ms). Each trial lasted 15 s and was followed by 15 s of fixation to allow the hemodynamic response to return to baseline. Neural measures of similarity were calculated based on the decoding accuracy between each pair of orientations (see below).</p><p>In the behavioral experiment, participants were also shown a single oriented grating (drawn from the same six orientations, 10Â°, 40Â°, 70Â°, 100Â°, 130Â° and 160Â°), followed by the same plaid mask as in the fMRI experiment. After a short delay, participants performed a same-different judgment on a test grating drawn from the same set of orientations as the sample grating. Feedback was provided after each trial. The precise timing of each trial was as follows: sample grating (200 ms), blank (200 ms), mask (200 ms), delay (1,000 ms), test grating (500 ms), response (2,000 ms) and feedback (300ms). Each trial lasted 4.4 s and was followed by 1 s of fixation. Reaction time was recorded as a behavioral measure of the similarity between the sample and test orientations. Each run consisted of 60 trials, plus one practice trial at the beginning of the run. Participants completed a total of eight runs. In each run, there were an equal number of change and no change trials, and in the change trials each orientation was paired equally often with all the other orientations. Anytime participants made an incorrect response, a red unhappy face flickered on and off for 5 s and the trial was repeated at the end, until correct responses were obtained for all trials in the run. Reaction time measures were calculated from all the correct trials, and only reaction time, and not accuracy, was included in further analysis.</p><h3 class="c-article__sub-heading" id="Sec15">Behavioral control experiment using multiple different distractor types (experiment 5).</h3><p>The goal of this experiment was to examine how different types of distractors might affect behavioral performance in the main VSTM task. Trial structure and timing of this experiment was identical to experiments 1 and 3. Specifically, participants were shown sequential, brief presentations of two centrally presented sine-wave gratings at <span class="stix">âˆ¼</span>25Â° or <span class="stix">âˆ¼</span>115Â° (radius, 5Â° of visual angle; contrast, 20%; spatial frequency, 1 cycle per degree) in a randomized order, followed by a numerical cue that indicated which grating they were to remember, first or second. After an extended delay, participants were asked to report the direction of rotation (Â±3Â° or Â±6Â°) of a test grating relative to the cued grating. Feedback was provided after every trial. As in experiments 1 and 3, the precise timing of each trial was as follows: first sample grating (200 ms), blank (400 ms), second sample grating (200 ms), blank (400 ms), cue (800 ms), delay (11 s), test grating (500 ms), response (2,000 ms), and feedback (500 ms). Unlike in experiments 1 and 3, however, here the inter-trial interval was only 1 s, instead of 16 s, as we did not need to wait for the hemodynamic response to return to baseline in this behavioral experiment. During the delay, participants either saw a blank screen with a fixation dot (no distractor trials), or a sequential presentation of either 17 faces, 17 gazebos, or 17 oriented gratings. The face and gazebo stimuli were drawn from the same set as in experiments 1 and 3. The oriented distractor gratings differed from the to-be-remember target gratings only in orientation and they were drawn from a set of six covering the entire visual field in 30Â° increments (0Â°, 30Â°, 60Â°, 90Â°, 120Â° and 150Â°). As in experiments 1 and 3, each distractor was presented for 200 ms, followed by a 400-ms blank and subtended 6.9Â° Ã— 8.3Â° of visual angle. As in experiment 3, trials with and without distractors were randomly intermixed in each run. Each run contained a total of 33 trials, 8 for each trial type (no distractor, face distractor, gazebo distractor and grating distractor), plus one practice trial at the beginning of the run. Participants completed three runs each, each lasting 9 min and 23 s.</p><h3 class="c-article__sub-heading" id="Sec16">Localizer experiments.</h3><p>To identify topographic regions in occipital and parietal cortices, we mapped topographic visual field representations of polar angle for each participant with flashing checkerboard stimuli using standard techniques<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="DeYoe, E.A. et al. Mapping striate and extrastriate visual areas in human cerebral cortex. Proc. Natl. Acad. Sci. USA 93, 2382â€“2386 (1996)." href="/articles/nn.4174#ref-CR42" id="ref-link-section-d22723532e1489">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Engel, S.A. et al. fMRI of human visual cortex. Nature 369, 6481 (1994)." href="/articles/nn.4174#ref-CR43" id="ref-link-section-d22723532e1492">43</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Sereno, M.I. et al. Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging. Science 268, 889â€“893 (1995)." href="/articles/nn.4174#ref-CR44" id="ref-link-section-d22723532e1495">44</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Swisher, J.D., Halko, M.A., Merabet, L.B., McMains, S.A. &amp; Somers, D.C. Visual topography of human intraparietal sulcus. J. Neurosci. 27, 5326â€“5337 (2007)." href="/articles/nn.4174#ref-CR45" id="ref-link-section-d22723532e1498">45</a></sup>. To reveal maps in parietal cortex, we optimized our parameters following a previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Swisher, J.D., Halko, M.A., Merabet, L.B., McMains, S.A. &amp; Somers, D.C. Visual topography of human intraparietal sulcus. J. Neurosci. 27, 5326â€“5337 (2007)." href="/articles/nn.4174#ref-CR45" id="ref-link-section-d22723532e1502">45</a></sup>. Specifically, the colored polar angle wedge swept across the entire screen (23.4 Ã— 17.5Â° of visual angle), had an arc of 72Â°, a sweep period of 55.467 s, flashed at 4 Hz, and swept out 12 cycles per run (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig2">Fig. 2a</a>). Each participant completed 4â€“6 runs (each lasting 11 min 5.6 s). The task varied slightly across participants. All participants were asked to detect a dimming in the visual display, for some participants the dimming occurred only at fixation, for others it occurred only within the polar angle wedge, and for some it could occur in both locations, commiserate with the various methodologies used in the literature<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Swisher, J.D., Halko, M.A., Merabet, L.B., McMains, S.A. &amp; Somers, D.C. Visual topography of human intraparietal sulcus. J. Neurosci. 27, 5326â€“5337 (2007)." href="/articles/nn.4174#ref-CR45" id="ref-link-section-d22723532e1509">45</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Bressler, D.W. &amp; Silver, M.A. Spatial attention improves reliability of fMRI retinotopic mapping signals in occipital and parietal cortex. Neuroimage 53, 526â€“533 (2010)." href="/articles/nn.4174#ref-CR46" id="ref-link-section-d22723532e1512">46</a></sup>. No differences were seen in the maps obtained through each of these methods.</p><p>To identity the superior IPS region previously shown to be involved in VSTM storage<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Xu, Y. Distinctive neural mechanisms supporting visual object individuation and identification. J. Cogn. Neurosci. 21, 511â€“518 (2009)." href="/articles/nn.4174#ref-CR3" id="ref-link-section-d22723532e1519">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1522">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Jeong, S.K. &amp; Xu, Y. Neural representation of targets and distractors during object individuation and identification. J. Cogn. Neurosci. 25, 117â€“126 (2013)." href="/articles/nn.4174#ref-CR5" id="ref-link-section-d22723532e1525">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Xu, Y. &amp; Chun, M.M. Selecting and perceiving multiple visual objects. Trends Cogn. Sci. 13, 167â€“174 (2009)." href="/articles/nn.4174#ref-CR47" id="ref-link-section-d22723532e1528">47</a></sup>, we followed the procedures used previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1532">4</a></sup>. Participants completed a VSTM object experiment, similar to the sequential central presentation shape experiments used previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1536">4</a></sup>. In each trial, participants saw 1, 2, 3, 4 or 6 real world objects presented sequentially at central fixation, and after a short delay, judged whether a probe object shown at fixation was present in the original display (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig2">Fig. 2b</a>). Eight distinctive objects were used, each subtended 7.9Â° Ã— 7.5Â° of visual angle and presented on a light gray background. Each trial lasted 6 s and consisted of fixation (500 ms), a sample display period, consisting of eight possible stimulus presentation slots (100 ms each, followed by 50-ms blank, for a total of 1,150 ms), a blank delay period (1,000 ms), a test display and response period (2,000 ms), and response feedback (1,350 ms). Each run also contained blank fixation trials (6 s). Trial presentation order was pseudorandom and balanced for trial history in a run<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Todd, J.J. &amp; Marois, R. Capacity limit of visual short-term memory in human posterior parietal cortex. Nature 428, 751â€“754 (2004)." href="/articles/nn.4174#ref-CR2" id="ref-link-section-d22723532e1543">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1546">4</a></sup>. Participants completed 2â€“4 runs, with each run lasting 7 min and 42 s. Those completing four runs were those for whom superior IPS could not be localized reliably with two runs. The additional runs allowed us to obtain comparable number of voxels in superior IPS across all participants. Each run contained 76 trials, 12 per set size, plus 2 practice trials at the beginning of the run and 2 filler trials, one at the beginning and one at the end of the run, for trial history balancing purposes. Practice and filler trials were removed from further data analysis.</p><h3 class="c-article__sub-heading" id="Sec17">MRI methods.</h3><p>Stimuli were generated by a Macintosh MacBook Pro and back projected onto a screen mounted at the rear end of the scanner bore. Topographic mapping stimuli were presented using VisionEgg software<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Straw, A.D. Vision egg: an open-source library for realtime visual stimulus generation. Front. Neuroinform. 2, 4 (2008)." href="/articles/nn.4174#ref-CR48" id="ref-link-section-d22723532e1558">48</a></sup>, whereas all other stimuli were presented using Matlab with Psychtoolbox extensions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Brainard, D.H. The psychophysics toolbox. Spat. Vis. 10, 433â€“436 (1997)." href="/articles/nn.4174#ref-CR49" id="ref-link-section-d22723532e1562">49</a></sup>. All data were acquired on a Siemens Tim Trio 3T scanner with a 32-channel head coil at the Center for Brain Science at Harvard University. Participants took part in two or three sessions of MRI scanning. In one session, a high resolution (1.0 Ã— 1.0 Ã— 1.3 mm) anatomical image was collected for surface reconstruction. Before functional imaging in each session, T1-weighted echo-planar images were collected in the same slice prescription as the functional scans to allow each session to be registered to the participant's high-resolution anatomical scan. Functional data were acquired using T2*-weighted gradient-echo, echo-planar sequences. Each volume of the main experimental data, for all four fMRI experiments (experiments 1â€“4), contained 28 slices (3 mm thick, 3 Ã— 3 mm in plane, no skip) oriented just off parallel from the AC-PC line to ensure full occipital and parietal coverage (TR = 2 s, TE = 35 ms, flip angle = 80Â°). For the topographic IPS localizer, each volume of the topographic data contained 42 slices (3 mm thick, 3.125 Ã— 3.125 mm in plane, no skip) oriented just off parallel from the AC-PC line to cover the full brain (TR = 2.6 s, TE = 30 ms, flip angle = 90Â°). For the superior IPS localizer, each volume contained 24 slices (5 mm thick, 3.75 Ã— 3.75 mm in plane, no skip) parallel to the AC-PC line (TR = 1.5 s, TE = 30 ms, flip angle = 90Â°). fMRI data were analyzed using the Freesurfer software package<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Dale, A.M., Fischl, B. &amp; Sereno, M.I. Cortical surface-based analysis. I. Segmentation and surface reconstruction. Neuroimage 9, 179â€“194 (1999)." href="/articles/nn.4174#ref-CR50" id="ref-link-section-d22723532e1566">50</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Fischl, B., Liu, A. &amp; Dale, A.M. Automated manifold surgery: constructing geometrically accurate and topologically correct models of the human cerebral cortex. IEEE Trans. Med. Imaging 20, 70â€“80 (2001)." href="/articles/nn.4174#ref-CR51" id="ref-link-section-d22723532e1569">51</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Fischl, B., Sereno, M.I. &amp; Dale, A.M. Cortical surface-based analysis. II. Inflation, flattening, and a surface-based coordinate system. Neuroimage 9, 195â€“207 (1999)." href="/articles/nn.4174#ref-CR52" id="ref-link-section-d22723532e1572">52</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Reuter, M., Rosas, H.D. &amp; Fischl, B. Highly accurate inverse consistent registration: a robust approach. Neuroimage 53, 1181â€“1196 (2010)." href="/articles/nn.4174#ref-CR53" id="ref-link-section-d22723532e1575">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Fischl, B. et al. Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain. Neuron 33, 341â€“355 (2002)." href="/articles/nn.4174#ref-CR54" id="ref-link-section-d22723532e1578">54</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Fischl, B. et al. Sequence-independent segmentation of magnetic resonance images. Neuroimage 23 (suppl. 1), S69â€“S84 (2004)." href="/articles/nn.4174#ref-CR55" id="ref-link-section-d22723532e1581">55</a></sup>. Data preprocessing included motion correction, slice timing correction, linear drift correction and intensity normalization. Computer representations of each cortical hemispheric surface were unfolded and inflated. All data was analyzed in the native space of each participant.</p><h3 class="c-article__sub-heading" id="Sec18">ROI definitions.</h3><p>By following the procedures described previously<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Swisher, J.D., Halko, M.A., Merabet, L.B., McMains, S.A. &amp; Somers, D.C. Visual topography of human intraparietal sulcus. J. Neurosci. 27, 5326â€“5337 (2007)." href="/articles/nn.4174#ref-CR45" id="ref-link-section-d22723532e1593">45</a></sup> and by examining phase reversals in the polar angle maps, we were able to identify topographic areas in occipital and parietal cortices including V1, V2, V3, V4, V3A, V3B, IPS0, IPS1, IPS2, IPS3 and IPS4 in each participant (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig2">Fig. 2a,c</a>).</p><p>To identity superior IPS, which has previously been shown to track VSTM storage<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Xu, Y. Distinctive neural mechanisms supporting visual object individuation and identification. J. Cogn. Neurosci. 21, 511â€“518 (2009)." href="/articles/nn.4174#ref-CR3" id="ref-link-section-d22723532e1603">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1606">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Jeong, S.K. &amp; Xu, Y. Neural representation of targets and distractors during object individuation and identification. J. Cogn. Neurosci. 25, 117â€“126 (2013)." href="/articles/nn.4174#ref-CR5" id="ref-link-section-d22723532e1609">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Xu, Y. &amp; Chun, M.M. Selecting and perceiving multiple visual objects. Trends Cogn. Sci. 13, 167â€“174 (2009)." href="/articles/nn.4174#ref-CR47" id="ref-link-section-d22723532e1612">47</a></sup>, fMRI data from the superior IPS localizer was analyzed using a multiple regression analysis with the regression coefficient for each set size weighted by each participant's corresponding behavioral K score estimate for that set size calculated using Cowan's K (ref. <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Cowan, N. The magical number 4 in short-term memory: a reconsideration of mental storage capacity. Behav. Brain Sci. 24, 87â€“114, discussion 114â€“185 (2001)." href="/articles/nn.4174#ref-CR56" id="ref-link-section-d22723532e1615">56</a>). Superior IPS was defined as a region that showed significant activation in the regression analysis overlapping or near the region previously reported in Talairach coordinates<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Todd, J.J. &amp; Marois, R. Capacity limit of visual short-term memory in human posterior parietal cortex. Nature 428, 751â€“754 (2004)." href="/articles/nn.4174#ref-CR2" id="ref-link-section-d22723532e1619">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. Nature 440, 91â€“95 (2006)." href="/articles/nn.4174#ref-CR4" id="ref-link-section-d22723532e1622">4</a></sup>. Although we originally set the threshold for activation in this region to <i>P</i> &lt; 0.05, this created ROIs that, for some participants, contained too few voxels for the MVPA analysis (see below for more details), and so the threshold was relaxed to <i>P</i> &lt; 0.1 to create a larger ROI (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig2">Fig. 2d</a>). This ROI was localized individually in each participant.</p><p>Besides the above ROIs, we also created anatomically defined ROIs corresponding to the SPL and IPL (<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/nn.4174#Fig2">Fig. 2e</a>). These regions were defined using Freesurfer's automatic parcellation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Destrieux, C., Fischl, B., Dale, A. &amp; Halgren, E. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. Neuroimage 53, 1â€“15 (2010)." href="/articles/nn.4174#ref-CR57" id="ref-link-section-d22723532e1642">57</a></sup>.</p><p>Previously, occipital ROIs were further refined<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1649">13</a></sup> by using eccentricity data to select the region of each ROI that corresponded to the location of the stimuli to be remembered. As eccentricity data has been shown to be somewhat unreliable in parietal regions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Swisher, J.D., Halko, M.A., Merabet, L.B., McMains, S.A. &amp; Somers, D.C. Visual topography of human intraparietal sulcus. J. Neurosci. 27, 5326â€“5337 (2007)." href="/articles/nn.4174#ref-CR45" id="ref-link-section-d22723532e1653">45</a></sup>, in order to perform the same kind of refinement on our ROIs, we selected a subregion of each ROI (superior IPS, SPL, IPL and parietal and occipital topographic regions) that showed higher activation (<i>P</i> &lt; 0.05) during the encoding period relative to fixation in trials without distractors. This contrast allowed us to select voxels that were visually responsive to the location of the grating stimuli without any contamination from distractor stimuli. Separate ROIs were created for experiments 1, 3, and 4 based on the activity in the respective experiments. Experiment 2 used the V1â€“V4 ROI defined in experiment 1. For one participant, V3A showed no task related activity in experiment 3 in the left hemisphere and this participant was removed from both the univariate and MVPA analyses of V3A.</p><p>As is common in other studies using MVPA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1664">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Haynes, J.-D. &amp; Rees, G. Predicting the orientation of invisible stimuli from activity in human primary visual cortex. Nat. Neurosci. 8, 686â€“691 (2005)." href="/articles/nn.4174#ref-CR58" id="ref-link-section-d22723532e1667">58</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Kamitani, Y. &amp; Tong, F. Decoding the visual and subjective contents of the human brain. Nat. Neurosci. 8, 679â€“685 (2005)." href="/articles/nn.4174#ref-CR59" id="ref-link-section-d22723532e1670">59</a></sup>, feature selection was also applied to select the top 120 voxels in each ROI that were the most active during the encoding period in trials without distractors. For combined regions, this number was multiplied by the number of regions in the combined ROI (for example, V1â€“V4 consists of four regions so a total of 480 voxels were selected). Decoding results were very similar for feature selected subset of voxels and the whole ROI. Unlike occipital regions, superior IPS is a relatively small region. Initially, we defined superior IPS with a threshold for activation at <i>P</i> &lt; 0.05. However, for several participants, this produced an ROI that contained too few voxels for clear MVPA decoding, with an average of only 89 voxels across all participants, and a range (after feature selection) of 29â€“120 voxels. Therefore, we decreased the threshold for activation in the superior IPS localizer to <i>P</i> &lt; 0.1 and performed the same subregion selection and feature selection detailed above. This produced a ROI with an average of 106 voxels across all participants, and a range of 45-120 voxels. This larger superior IPS ROI was used for the results presented here. We performed the same analyses using the more stringent ROI threshold (at <i>P</i> &lt; 0.05) and saw a very similar pattern in this region. For individuals with less than 120 voxels in their superior IPS ROI, the entirety of the ROI was selected.</p><h3 class="c-article__sub-heading" id="Sec19">MVPA analysis.</h3><p>To assess whether a brain region was involved in VSTM storage (experiments 1 and 3), we used MVPA decoding methods to determine whether activity within each ROI reflected the orientation of the remembered grating for that trial. Similar to a previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1691">13</a></sup>, our methodology isolated memory specific activity by presenting both types of orientations in each trial and by using a cue based on stimulus order (that is, 1 or 2). This ensured that neither stimulus nor cue driven activity could contaminate the fMRI responses used to decode the orientation held in VSTM for any given trial. In addition to decoding the orientation of the remembered stimulus, in trials with distractors, we also performed separate analysis to decode the type of distractor presented in a given trial.</p><p>Decoding analysis was performed on the average delay period fMRI response (including time points 6â€“12 s or TRs 4â€“8) from each voxel in a given ROI, similar to a previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1698">13</a></sup>. These time points were selected because they accounted for hemodynamic response lag, but were uncontaminated by test stimulus presentations. This delay time period is one TR longer than that used previoulsy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1702">13</a></sup>, but is still early enough to be uncontaminated by the presentation of the test stimulus (which occurred at 13 s). We saw no reason to exclude the additional data point, as the inclusion of this data point would increase power in our analysis. fMRI responses across all the voxels in each ROI were then normalized using z-score transformation to remove any effects related to overall amplitude differences between ROIs (decoding performance was similar for normalized and non-normalized data). The resulting fMRI response pattern from each ROI was then used in the decoding analysis.</p><p>Using the leave-one-run-out cross validation procedure, we trained a linear support vector machine (SVM) to either discriminate the orientation of the remembered grating or the type of distractors shown during the delay period. Analysis was performed in MATLAB using the CLOP toolbox (Challenge Learning Object Package, <a href="http://clopinet.com/CLOP/">http://clopinet.com/CLOP/</a>). Decoding accuracy was expressed as the proportion of test patterns that were correctly classified, with chance level performance being 50%. Significance was assessed within an ROI using paired <i>t</i> tests, one tailed for comparisons to chance, two-tailed for comparisons between conditions.</p><h3 class="c-article__sub-heading" id="Sec20">Behavioral and neural representation similarity analysis.</h3><p>To construct neural representation similarity measures between orientations in experiment 4, we compared the decoding accuracy between all pairs of orientations. As in experiments 1 and 3, the decoding analysis was performed on the average delay period fMRI response (including time points 6â€“10 s or TRs 4â€“6) from each voxel in a given ROI. These time points were selected because they accounted for hemodynamic response lag but were far enough from encoding and test to be uncontaminated by stimulus presentations. Removing the earliest time point in this analysis produced similar results, suggesting that our results are driven by memory representations, not any lingering perceptual representations present during the encoding period which were unlikely given the masking procedure we used. fMRI responses across all the voxels within each ROI were then normalized using z-score transformation to remove any effects related to overall amplitude differences between ROIs. The resulting fMRI response pattern from each ROI was then used in the decoding analysis.</p><p>Using the leave-one-run-out cross validation procedure, we trained a linear support vector machine (SVM) to discriminate between each pair of orientations (for example, 10Â° and 40Â°, 10Â° and 70Â°, etc). As before, the analysis was performed in MATLAB using the CLOP toolbox. Decoding accuracy was expressed as the proportion of test patterns that were correctly classified, with chance level performance being 50%. This produced a neural representation similarity matrix, showing how dissociable each orientation was from the others. The decoding accuracies for each orientation pair was calculated separately for each participant and then averaged across all participants to create the group-level neural representation similarity matrix<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Kriegeskorte, N. et al. Matching categorical object representations in inferior temporal cortex of man and monkey. Neuron 60, 1126â€“1141 (2008)." href="/articles/nn.4174#ref-CR29" id="ref-link-section-d22723532e1730">29</a></sup>.</p><p>The behavioral representation similarity matrix was created by comparing the reaction time to detect a change for each orientation paired with each of the other five orientations. We then averaged all trials for each orientation pair, regardless of which orientation was the target and which was the test stimulus. Reaction time was calculated separately for each participant and then averaged across participants to form the group-level behavioral representation similarity matrix for each orientation pair.</p><p>We then directly correlated the behavioral and neural representation similarity matrices in each ROI. If the neural representation in a region reflects the storage of the item in VSTM, then we should see a strong correlation between the behavioral and neural measures of representation similarity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Kriegeskorte, N. et al. Matching categorical object representations in inferior temporal cortex of man and monkey. Neuron 60, 1126â€“1141 (2008)." href="/articles/nn.4174#ref-CR29" id="ref-link-section-d22723532e1740">29</a></sup>. The significance of each correlation was evaluated using a permutation test in which the values within the behavioral and neural measures of representation similarity were randomly shuffled and then correlated. We ran the permutation test over 10,000 iterations to derive the mean and s.d. of the baseline correlation value distribution.</p><h3 class="c-article__sub-heading" id="Sec21">Univariate response amplitude analysis.</h3><p>In addition to the MVPA analysis, we also examined the univariate fMRI response amplitudes to both trials with and without distractors in each ROI in experiments 1â€“3. fMRI response amplitudes for each stimulus condition were measured in percent signal change, calculated by taking the difference in average signal intensity between each trial type and the fixation trials, then dividing this difference by that of the fixation trials and multiplying it by 100. Differences in encoding period and delay period activity were analyzed by using, in each individual participant, the maximum signal change during the encoding period and either the maximum (when activity increased during the delay) or minimum (when activity decreased during the delay) signal change during the delay period.</p><h3 class="c-article__sub-heading" id="Sec22">Statistics.</h3><p>We used a within-subject design in all the experiments included here, as such, all participants received all the test conditions. Consequently, randomization and blinding were not required. Simple <i>t</i>-tests and analysis of variance (ANOVA) were used to assess the difference between conditions at the group level. Following previously published studies that made similar measurements<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1764">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Serences, J.T., Ester, E.F., Vogel, E.K. &amp; Awh, E. Stimulus-specific delay activity in human primary visual cortex. Psychol. Sci. 20, 207â€“214 (2009)." href="/articles/nn.4174#ref-CR17" id="ref-link-section-d22723532e1767">17</a></sup>, data distribution was assumed to be normal, but this was not formally tested. Although no statistical methods were used to pre-determine the sample sizes for each experiment, our sample sizes are similar to those reported in previous publications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. Nature 458, 632â€“635 (2009)." href="/articles/nn.4174#ref-CR13" id="ref-link-section-d22723532e1771">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Serences, J.T., Ester, E.F., Vogel, E.K. &amp; Awh, E. Stimulus-specific delay activity in human primary visual cortex. Psychol. Sci. 20, 207â€“214 (2009)." href="/articles/nn.4174#ref-CR17" id="ref-link-section-d22723532e1774">17</a></sup>.</p><p>A <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/nn.4174#MOESM8">Supplementary Methods Checklist</a> is available.</p></div></div></section>
                </div>
            

            <div>
                <div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1"><p class="c-article-references__text" id="ref-CR1">Pasternak, T. &amp; Greenlee, M.W. Working memory in primate sensory systems. <i>Nat. Rev. Neurosci.</i> <b>6</b>, 97â€“107 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn1603" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn1603" aria-label="Article reference 1" data-doi="10.1038/nrn1603">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXoslKqtA%3D%3D" aria-label="CAS reference 1">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15654324" aria-label="PubMed reference 1">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Working%20memory%20in%20primate%20sensory%20systems&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn1603&amp;volume=6&amp;pages=97-107&amp;publication_year=2005&amp;author=Pasternak%2CT&amp;author=Greenlee%2CMW">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2"><p class="c-article-references__text" id="ref-CR2">Todd, J.J. &amp; Marois, R. Capacity limit of visual short-term memory in human posterior parietal cortex. <i>Nature</i> <b>428</b>, 751â€“754 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature02466" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature02466" aria-label="Article reference 2" data-doi="10.1038/nature02466">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2cXjtV2mt7k%3D" aria-label="CAS reference 2">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15085133" aria-label="PubMed reference 2">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Capacity%20limit%20of%20visual%20short-term%20memory%20in%20human%20posterior%20parietal%20cortex&amp;journal=Nature&amp;doi=10.1038%2Fnature02466&amp;volume=428&amp;pages=751-754&amp;publication_year=2004&amp;author=Todd%2CJJ&amp;author=Marois%2CR">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3"><p class="c-article-references__text" id="ref-CR3">Xu, Y. Distinctive neural mechanisms supporting visual object individuation and identification. <i>J. Cogn. Neurosci.</i> <b>21</b>, 511â€“518 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn.2008.21024" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn.2008.21024" aria-label="Article reference 3" data-doi="10.1162/jocn.2008.21024">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18510449" aria-label="PubMed reference 3">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Distinctive%20neural%20mechanisms%20supporting%20visual%20object%20individuation%20and%20identification&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn.2008.21024&amp;volume=21&amp;pages=511-518&amp;publication_year=2009&amp;author=Xu%2CY">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4"><p class="c-article-references__text" id="ref-CR4">Xu, Y. &amp; Chun, M.M. Dissociable neural mechanisms supporting visual short-term memory for objects. <i>Nature</i> <b>440</b>, 91â€“95 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature04262" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature04262" aria-label="Article reference 4" data-doi="10.1038/nature04262">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD28XhvFajtrk%3D" aria-label="CAS reference 4">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16382240" aria-label="PubMed reference 4">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Dissociable%20neural%20mechanisms%20supporting%20visual%20short-term%20memory%20for%20objects&amp;journal=Nature&amp;doi=10.1038%2Fnature04262&amp;volume=440&amp;pages=91-95&amp;publication_year=2006&amp;author=Xu%2CY&amp;author=Chun%2CMM">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5"><p class="c-article-references__text" id="ref-CR5">Jeong, S.K. &amp; Xu, Y. Neural representation of targets and distractors during object individuation and identification. <i>J. Cogn. Neurosci.</i> <b>25</b>, 117â€“126 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn_a_00298" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn_a_00298" aria-label="Article reference 5" data-doi="10.1162/jocn_a_00298">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23198893" aria-label="PubMed reference 5">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3736830" aria-label="PubMed Central reference 5">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20representation%20of%20targets%20and%20distractors%20during%20object%20individuation%20and%20identification&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn_a_00298&amp;volume=25&amp;pages=117-126&amp;publication_year=2013&amp;author=Jeong%2CSK&amp;author=Xu%2CY">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6"><p class="c-article-references__text" id="ref-CR6">Xu, Y. The neural fate of task-irrelevant features in object-based processing. <i>J. Neurosci.</i> <b>30</b>, 14020â€“14028 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.3011-10.2010" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.3011-10.2010" aria-label="Article reference 6" data-doi="10.1523/JNEUROSCI.3011-10.2010">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXhtlyqtLvP" aria-label="CAS reference 6">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20962223" aria-label="PubMed reference 6">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6634783" aria-label="PubMed Central reference 6">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20neural%20fate%20of%20task-irrelevant%20features%20in%20object-based%20processing&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.3011-10.2010&amp;volume=30&amp;pages=14020-14028&amp;publication_year=2010&amp;author=Xu%2CY">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7"><p class="c-article-references__text" id="ref-CR7">Todd, J.J. &amp; Marois, R. Posterior parietal cortex activity predicts individual differences in visual short-term memory capacity. <i>Cogn. Affect. Behav. Neurosci.</i> <b>5</b>, 144â€“155 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/CABN.5.2.144" data-track-action="article reference" href="https://doi.org/10.3758%2FCABN.5.2.144" aria-label="Article reference 7" data-doi="10.3758/CABN.5.2.144">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16180621" aria-label="PubMed reference 7">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Posterior%20parietal%20cortex%20activity%20predicts%20individual%20differences%20in%20visual%20short-term%20memory%20capacity&amp;journal=Cogn.%20Affect.%20Behav.%20Neurosci.&amp;doi=10.3758%2FCABN.5.2.144&amp;volume=5&amp;pages=144-155&amp;publication_year=2005&amp;author=Todd%2CJJ&amp;author=Marois%2CR">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8"><p class="c-article-references__text" id="ref-CR8">Beck, D.M., Muggleton, N., Walsh, V. &amp; Lavie, N. Right parietal cortex plays a critical role in change blindness. <i>Cereb. Cortex</i> <b>16</b>, 712â€“717 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhj017" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhj017" aria-label="Article reference 8" data-doi="10.1093/cercor/bhj017">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16120797" aria-label="PubMed reference 8">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Right%20parietal%20cortex%20plays%20a%20critical%20role%20in%20change%20blindness&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhj017&amp;volume=16&amp;pages=712-717&amp;publication_year=2006&amp;author=Beck%2CDM&amp;author=Muggleton%2CN&amp;author=Walsh%2CV&amp;author=Lavie%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9"><p class="c-article-references__text" id="ref-CR9">Tseng, P. et al. Posterior parietal cortex mediates encoding and maintenance processes in change blindness. <i>Neuropsychologia</i> <b>48</b>, 1063â€“1070 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuropsychologia.2009.12.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuropsychologia.2009.12.005" aria-label="Article reference 9" data-doi="10.1016/j.neuropsychologia.2009.12.005">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20005882" aria-label="PubMed reference 9">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Posterior%20parietal%20cortex%20mediates%20encoding%20and%20maintenance%20processes%20in%20change%20blindness&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2009.12.005&amp;volume=48&amp;pages=1063-1070&amp;publication_year=2010&amp;author=Tseng%2CP">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10"><p class="c-article-references__text" id="ref-CR10">Ester, E.F., Sprague, T.C. &amp; Serences, J.T. Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory. <i>Neuron</i> <b>87</b>, 893â€“905 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2015.07.013" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2015.07.013" aria-label="Article reference 10" data-doi="10.1016/j.neuron.2015.07.013">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXht12rs7%2FL" aria-label="CAS reference 10">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26257053" aria-label="PubMed reference 10">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4545683" aria-label="PubMed Central reference 10">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Parietal%20and%20frontal%20cortex%20encode%20stimulus-specific%20mnemonic%20representations%20during%20visual%20working%20memory&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2015.07.013&amp;volume=87&amp;pages=893-905&amp;publication_year=2015&amp;author=Ester%2CEF&amp;author=Sprague%2CTC&amp;author=Serences%2CJT">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11"><p class="c-article-references__text" id="ref-CR11">Emrich, S.M., Riggall, A.C., LaRocque, J.J. &amp; Postle, B.R. Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory. <i>J. Neurosci.</i> <b>33</b>, 6516â€“6523 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.5732-12.2013" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.5732-12.2013" aria-label="Article reference 11" data-doi="10.1523/JNEUROSCI.5732-12.2013">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhtl2jtrnE" aria-label="CAS reference 11">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23575849" aria-label="PubMed reference 11">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3664518" aria-label="PubMed Central reference 11">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20patterns%20of%20activity%20in%20sensory%20cortex%20reflect%20the%20precision%20of%20multiple%20items%20maintained%20in%20visual%20short-term%20memory&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.5732-12.2013&amp;volume=33&amp;pages=6516-6523&amp;publication_year=2013&amp;author=Emrich%2CSM&amp;author=Riggall%2CAC&amp;author=LaRocque%2CJJ&amp;author=Postle%2CBR">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12"><p class="c-article-references__text" id="ref-CR12">Ester, E.F., Serences, J.T. &amp; Awh, E. Spatially global representations in human primary visual cortex during working memory maintenance. <i>J. Neurosci.</i> <b>29</b>, 15258â€“15265 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.4388-09.2009" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.4388-09.2009" aria-label="Article reference 12" data-doi="10.1523/JNEUROSCI.4388-09.2009">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhsFKltbjJ" aria-label="CAS reference 12">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19955378" aria-label="PubMed reference 12">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2830793" aria-label="PubMed Central reference 12">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatially%20global%20representations%20in%20human%20primary%20visual%20cortex%20during%20working%20memory%20maintenance&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.4388-09.2009&amp;volume=29&amp;pages=15258-15265&amp;publication_year=2009&amp;author=Ester%2CEF&amp;author=Serences%2CJT&amp;author=Awh%2CE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13"><p class="c-article-references__text" id="ref-CR13">Harrison, S.A. &amp; Tong, F. Decoding reveals the contents of visual working memory in early visual areas. <i>Nature</i> <b>458</b>, 632â€“635 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature07832" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature07832" aria-label="Article reference 13" data-doi="10.1038/nature07832">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXitFKmtb4%3D" aria-label="CAS reference 13">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19225460" aria-label="PubMed reference 13">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2709809" aria-label="PubMed Central reference 13">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Decoding%20reveals%20the%20contents%20of%20visual%20working%20memory%20in%20early%20visual%20areas&amp;journal=Nature&amp;doi=10.1038%2Fnature07832&amp;volume=458&amp;pages=632-635&amp;publication_year=2009&amp;author=Harrison%2CSA&amp;author=Tong%2CF">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14"><p class="c-article-references__text" id="ref-CR14">Lee, S.H., Kravitz, D.J. &amp; Baker, C.I. Goal-dependent dissociation of visual and prefrontal cortices during working memory. <i>Nat. Neurosci.</i> <b>16</b>, 997â€“999 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3452" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3452" aria-label="Article reference 14" data-doi="10.1038/nn.3452">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhtVaku7jO" aria-label="CAS reference 14">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23817547" aria-label="PubMed reference 14">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3781947" aria-label="PubMed Central reference 14">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Goal-dependent%20dissociation%20of%20visual%20and%20prefrontal%20cortices%20during%20working%20memory&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3452&amp;volume=16&amp;pages=997-999&amp;publication_year=2013&amp;author=Lee%2CSH&amp;author=Kravitz%2CDJ&amp;author=Baker%2CCI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15"><p class="c-article-references__text" id="ref-CR15">Linden, D.E., Oosterhof, N.N., Klein, C. &amp; Downing, P.E. Mapping brain activation and information during category-specific visual working memory. <i>J. Neurophysiol.</i> <b>107</b>, 628â€“639 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00105.2011" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00105.2011" aria-label="Article reference 15" data-doi="10.1152/jn.00105.2011">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22013235" aria-label="PubMed reference 15">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Mapping%20brain%20activation%20and%20information%20during%20category-specific%20visual%20working%20memory&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00105.2011&amp;volume=107&amp;pages=628-639&amp;publication_year=2012&amp;author=Linden%2CDE&amp;author=Oosterhof%2CNN&amp;author=Klein%2CC&amp;author=Downing%2CPE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16"><p class="c-article-references__text" id="ref-CR16">Riggall, A.C. &amp; Postle, B.R. The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging. <i>J. Neurosci.</i> <b>32</b>, 12990â€“12998 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1892-12.2012" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1892-12.2012" aria-label="Article reference 16" data-doi="10.1523/JNEUROSCI.1892-12.2012">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XhsVGitLrK" aria-label="CAS reference 16">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22993416" aria-label="PubMed reference 16">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3470886" aria-label="PubMed Central reference 16">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20relationship%20between%20working%20memory%20storage%20and%20elevated%20activity%20as%20measured%20with%20functional%20magnetic%20resonance%20imaging&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1892-12.2012&amp;volume=32&amp;pages=12990-12998&amp;publication_year=2012&amp;author=Riggall%2CAC&amp;author=Postle%2CBR">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17"><p class="c-article-references__text" id="ref-CR17">Serences, J.T., Ester, E.F., Vogel, E.K. &amp; Awh, E. Stimulus-specific delay activity in human primary visual cortex. <i>Psychol. Sci.</i> <b>20</b>, 207â€“214 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/j.1467-9280.2009.02276.x" data-track-action="article reference" href="https://doi.org/10.1111%2Fj.1467-9280.2009.02276.x" aria-label="Article reference 17" data-doi="10.1111/j.1467-9280.2009.02276.x">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19170936" aria-label="PubMed reference 17">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Stimulus-specific%20delay%20activity%20in%20human%20primary%20visual%20cortex&amp;journal=Psychol.%20Sci.&amp;doi=10.1111%2Fj.1467-9280.2009.02276.x&amp;volume=20&amp;pages=207-214&amp;publication_year=2009&amp;author=Serences%2CJT&amp;author=Ester%2CEF&amp;author=Vogel%2CEK&amp;author=Awh%2CE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18"><p class="c-article-references__text" id="ref-CR18">Sneve, M.H., Alnaes, D., Endestad, T., Greenlee, M.W. &amp; Magnussen, S. Visual short-term memory: activity supporting encoding and maintenance in retinotopic visual cortex. <i>Neuroimage</i> <b>63</b>, 166â€“178 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2012.06.053" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2012.06.053" aria-label="Article reference 18" data-doi="10.1016/j.neuroimage.2012.06.053">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22776452" aria-label="PubMed reference 18">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20short-term%20memory%3A%20activity%20supporting%20encoding%20and%20maintenance%20in%20retinotopic%20visual%20cortex&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2012.06.053&amp;volume=63&amp;pages=166-178&amp;publication_year=2012&amp;author=Sneve%2CMH&amp;author=Alnaes%2CD&amp;author=Endestad%2CT&amp;author=Greenlee%2CMW&amp;author=Magnussen%2CS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19"><p class="c-article-references__text" id="ref-CR19">Sprague, T.C., Ester, E.F. &amp; Serences, J.T. Reconstructions of information in visual spatial working memory degrade with memory load. <i>Curr. Biol.</i> <b>24</b>, 2174â€“2180 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cub.2014.07.066" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cub.2014.07.066" aria-label="Article reference 19" data-doi="10.1016/j.cub.2014.07.066">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhsFagsLfP" aria-label="CAS reference 19">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25201683" aria-label="PubMed reference 19">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4181677" aria-label="PubMed Central reference 19">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Reconstructions%20of%20information%20in%20visual%20spatial%20working%20memory%20degrade%20with%20memory%20load&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2014.07.066&amp;volume=24&amp;pages=2174-2180&amp;publication_year=2014&amp;author=Sprague%2CTC&amp;author=Ester%2CEF&amp;author=Serences%2CJT">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20"><p class="c-article-references__text" id="ref-CR20">Hou, Y. &amp; Liu, T. Neural correlates of object-based attentional selection in human cortex. <i>Neuropsychologia</i> <b>50</b>, 2916â€“2925 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuropsychologia.2012.08.022" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuropsychologia.2012.08.022" aria-label="Article reference 20" data-doi="10.1016/j.neuropsychologia.2012.08.022">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22963835" aria-label="PubMed reference 20">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3473105" aria-label="PubMed Central reference 20">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlates%20of%20object-based%20attentional%20selection%20in%20human%20cortex&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2012.08.022&amp;volume=50&amp;pages=2916-2925&amp;publication_year=2012&amp;author=Hou%2CY&amp;author=Liu%2CT">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21"><p class="c-article-references__text" id="ref-CR21">Liu, T., Hospadaruk, L., Zhu, D.C. &amp; Gardner, J.L. Feature-specific attentional priority signals in human cortex. <i>J. Neurosci.</i> <b>31</b>, 4484â€“4495 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.5745-10.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.5745-10.2011" aria-label="Article reference 21" data-doi="10.1523/JNEUROSCI.5745-10.2011">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXktVKrt7s%3D" aria-label="CAS reference 21">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21430149" aria-label="PubMed reference 21">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6622917" aria-label="PubMed Central reference 21">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Feature-specific%20attentional%20priority%20signals%20in%20human%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.5745-10.2011&amp;volume=31&amp;pages=4484-4495&amp;publication_year=2011&amp;author=Liu%2CT&amp;author=Hospadaruk%2CL&amp;author=Zhu%2CDC&amp;author=Gardner%2CJL">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22"><p class="c-article-references__text" id="ref-CR22">Xu, Y. &amp; Jeong, S.K. The contribution of human superior intraparietal sulcus to visual short-term memory and perception. in <i>Mechanisms of Sensory Working Memory: Attention and Perfomance XXV</i> (eds. Jolicoeur, P., Lefebrve, C. &amp; Martinez-Trujillo, J.) 33 (Academic Press, 2015).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23"><p class="c-article-references__text" id="ref-CR23">Christophel, T.B., Hebart, M.N. &amp; Haynes, J.-D. Decoding the contents of visual short-term memory from human visual and parietal cortex. <i>J. Neurosci.</i> <b>32</b>, 12983â€“12989 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.0184-12.2012" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.0184-12.2012" aria-label="Article reference 23" data-doi="10.1523/JNEUROSCI.0184-12.2012">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XhsVGitLrI" aria-label="CAS reference 23">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22993415" aria-label="PubMed reference 23">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6621473" aria-label="PubMed Central reference 23">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Decoding%20the%20contents%20of%20visual%20short-term%20memory%20from%20human%20visual%20and%20parietal%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.0184-12.2012&amp;volume=32&amp;pages=12983-12989&amp;publication_year=2012&amp;author=Christophel%2CTB&amp;author=Hebart%2CMN&amp;author=Haynes%2CJ-D">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24"><p class="c-article-references__text" id="ref-CR24">Nelissen, N., Stokes, M., Nobre, A.C. &amp; Rushworth, M.F. Frontal and parietal cortical interactions with distributed visual representations during selective attention and action selection. <i>J. Neurosci.</i> <b>33</b>, 16443â€“16458 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2625-13.2013" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2625-13.2013" aria-label="Article reference 24" data-doi="10.1523/JNEUROSCI.2625-13.2013">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhs1Ojsb7O" aria-label="CAS reference 24">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24133250" aria-label="PubMed reference 24">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3797369" aria-label="PubMed Central reference 24">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Frontal%20and%20parietal%20cortical%20interactions%20with%20distributed%20visual%20representations%20during%20selective%20attention%20and%20action%20selection&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2625-13.2013&amp;volume=33&amp;pages=16443-16458&amp;publication_year=2013&amp;author=Nelissen%2CN&amp;author=Stokes%2CM&amp;author=Nobre%2CAC&amp;author=Rushworth%2CMF">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25"><p class="c-article-references__text" id="ref-CR25">Jacob, S.N. &amp; Nieder, A. Complementary roles for primate frontal and parietal cortex in guarding working memory from distractor stimuli. <i>Neuron</i> <b>83</b>, 226â€“237 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2014.05.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2014.05.009" aria-label="Article reference 25" data-doi="10.1016/j.neuron.2014.05.009">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhtFWgt7bP" aria-label="CAS reference 25">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24991963" aria-label="PubMed reference 25">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Complementary%20roles%20for%20primate%20frontal%20and%20parietal%20cortex%20in%20guarding%20working%20memory%20from%20distractor%20stimuli&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2014.05.009&amp;volume=83&amp;pages=226-237&amp;publication_year=2014&amp;author=Jacob%2CSN&amp;author=Nieder%2CA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26"><p class="c-article-references__text" id="ref-CR26">Suzuki, M. &amp; Gottlieb, J. Distinct neural mechanisms of distractor suppression in the frontal and parietal lobe. <i>Nat. Neurosci.</i> <b>16</b>, 98â€“104 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3282" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3282" aria-label="Article reference 26" data-doi="10.1038/nn.3282">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XhvVersr%2FJ" aria-label="CAS reference 26">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23242309" aria-label="PubMed reference 26">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Distinct%20neural%20mechanisms%20of%20distractor%20suppression%20in%20the%20frontal%20and%20parietal%20lobe&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3282&amp;volume=16&amp;pages=98-104&amp;publication_year=2013&amp;author=Suzuki%2CM&amp;author=Gottlieb%2CJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27"><p class="c-article-references__text" id="ref-CR27">Qi, X.L., Elworthy, A.C., Lambert, B.C. &amp; Constantinidis, C. Representation of remembered stimuli and task information in the monkey dorsolateral prefrontal and posterior parietal cortex. <i>J. Neurophysiol.</i> <b>113</b>, 44â€“57 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00413.2014" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00413.2014" aria-label="Article reference 27" data-doi="10.1152/jn.00413.2014">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25298389" aria-label="PubMed reference 27">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Representation%20of%20remembered%20stimuli%20and%20task%20information%20in%20the%20monkey%20dorsolateral%20prefrontal%20and%20posterior%20parietal%20cortex&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00413.2014&amp;volume=113&amp;pages=44-57&amp;publication_year=2015&amp;author=Qi%2CXL&amp;author=Elworthy%2CAC&amp;author=Lambert%2CBC&amp;author=Constantinidis%2CC">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28"><p class="c-article-references__text" id="ref-CR28">Albers, A.M., Kok, P., Toni, I., Dijkerman, H.C. &amp; de Lange, F.P. Shared representations for working memory and mental imagery in early visual cortex. <i>Curr. Biol.</i> <b>23</b>, 1427â€“1431 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cub.2013.05.065" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cub.2013.05.065" aria-label="Article reference 28" data-doi="10.1016/j.cub.2013.05.065">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3sXhtFCgsrvE" aria-label="CAS reference 28">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23871239" aria-label="PubMed reference 28">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Shared%20representations%20for%20working%20memory%20and%20mental%20imagery%20in%20early%20visual%20cortex&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2013.05.065&amp;volume=23&amp;pages=1427-1431&amp;publication_year=2013&amp;author=Albers%2CAM&amp;author=Kok%2CP&amp;author=Toni%2CI&amp;author=Dijkerman%2CHC&amp;author=de%20Lange%2CFP">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29"><p class="c-article-references__text" id="ref-CR29">Kriegeskorte, N. et al. Matching categorical object representations in inferior temporal cortex of man and monkey. <i>Neuron</i> <b>60</b>, 1126â€“1141 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2008.10.043" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2008.10.043" aria-label="Article reference 29" data-doi="10.1016/j.neuron.2008.10.043">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXlsVKjtA%3D%3D" aria-label="CAS reference 29">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19109916" aria-label="PubMed reference 29">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3143574" aria-label="PubMed Central reference 29">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Matching%20categorical%20object%20representations%20in%20inferior%20temporal%20cortex%20of%20man%20and%20monkey&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2008.10.043&amp;volume=60&amp;pages=1126-1141&amp;publication_year=2008&amp;author=Kriegeskorte%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30"><p class="c-article-references__text" id="ref-CR30">Kriegeskorte, N. &amp; Kievit, R.A. Representational geometry: integrating cognition, computation, and the brain. <i>Trends Cogn. Sci.</i> <b>17</b>, 401â€“412 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2013.06.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2013.06.007" aria-label="Article reference 30" data-doi="10.1016/j.tics.2013.06.007">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23876494" aria-label="PubMed reference 30">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3730178" aria-label="PubMed Central reference 30">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Representational%20geometry%3A%20integrating%20cognition%2C%20computation%2C%20and%20the%20brain&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2013.06.007&amp;volume=17&amp;pages=401-412&amp;publication_year=2013&amp;author=Kriegeskorte%2CN&amp;author=Kievit%2CRA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31"><p class="c-article-references__text" id="ref-CR31">Vogel, E.K., Woodman, G.F. &amp; Luck, S.J. The time course of consolidation in visual working memory. <i>J. Exp. Psychol. Hum. Percept. Perform.</i> <b>32</b>, 1436â€“1451 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0096-1523.32.6.1436" data-track-action="article reference" href="https://doi.org/10.1037%2F0096-1523.32.6.1436" aria-label="Article reference 31" data-doi="10.1037/0096-1523.32.6.1436">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17154783" aria-label="PubMed reference 31">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20time%20course%20of%20consolidation%20in%20visual%20working%20memory&amp;journal=J.%20Exp.%20Psychol.%20Hum.%20Percept.%20Perform.&amp;doi=10.1037%2F0096-1523.32.6.1436&amp;volume=32&amp;pages=1436-1451&amp;publication_year=2006&amp;author=Vogel%2CEK&amp;author=Woodman%2CGF&amp;author=Luck%2CSJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32"><p class="c-article-references__text" id="ref-CR32">Mendoza-Halliday, D., Torres, S. &amp; Martinez-Trujillo, J.C. Sharp emergence of feature-selective sustained activity along the dorsal visual pathway. <i>Nat. Neurosci.</i> <b>17</b>, 1255â€“1262 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3785" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3785" aria-label="Article reference 32" data-doi="10.1038/nn.3785">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhtlahurvE" aria-label="CAS reference 32">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25108910" aria-label="PubMed reference 32">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4978542" aria-label="PubMed Central reference 32">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Sharp%20emergence%20of%20feature-selective%20sustained%20activity%20along%20the%20dorsal%20visual%20pathway&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3785&amp;volume=17&amp;pages=1255-1262&amp;publication_year=2014&amp;author=Mendoza-Halliday%2CD&amp;author=Torres%2CS&amp;author=Martinez-Trujillo%2CJC">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33"><p class="c-article-references__text" id="ref-CR33">Logothetis, N.K., Pauls, J., Augath, M., Trinath, T. &amp; Oeltermann, A. Neurophysiological investigation of the basis of the fMRI signal. <i>Nature</i> <b>412</b>, 150â€“157 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/35084005" data-track-action="article reference" href="https://doi.org/10.1038%2F35084005" aria-label="Article reference 33" data-doi="10.1038/35084005">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXlsFWnsLs%3D" aria-label="CAS reference 33">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11449264" aria-label="PubMed reference 33">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Neurophysiological%20investigation%20of%20the%20basis%20of%20the%20fMRI%20signal&amp;journal=Nature&amp;doi=10.1038%2F35084005&amp;volume=412&amp;pages=150-157&amp;publication_year=2001&amp;author=Logothetis%2CNK&amp;author=Pauls%2CJ&amp;author=Augath%2CM&amp;author=Trinath%2CT&amp;author=Oeltermann%2CA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34"><p class="c-article-references__text" id="ref-CR34">Kosslyn, S.M., Ganis, G. &amp; Thompson, W.L. Neural foundations of imagery. <i>Nat. Rev. Neurosci.</i> <b>2</b>, 635â€“642 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/35090055" data-track-action="article reference" href="https://doi.org/10.1038%2F35090055" aria-label="Article reference 34" data-doi="10.1038/35090055">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXmvVWqtrs%3D" aria-label="CAS reference 34">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11533731" aria-label="PubMed reference 34">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20foundations%20of%20imagery&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2F35090055&amp;volume=2&amp;pages=635-642&amp;publication_year=2001&amp;author=Kosslyn%2CSM&amp;author=Ganis%2CG&amp;author=Thompson%2CWL">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35"><p class="c-article-references__text" id="ref-CR35">Slotnick, S.D., Thompson, W.L. &amp; Kosslyn, S.M. Visual mental imagery induces retinotopically organized activation of early visual areas. <i>Cereb. Cortex</i> <b>15</b>, 1570â€“1583 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhi035" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhi035" aria-label="Article reference 35" data-doi="10.1093/cercor/bhi035">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15689519" aria-label="PubMed reference 35">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20mental%20imagery%20induces%20retinotopically%20organized%20activation%20of%20early%20visual%20areas&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhi035&amp;volume=15&amp;pages=1570-1583&amp;publication_year=2005&amp;author=Slotnick%2CSD&amp;author=Thompson%2CWL&amp;author=Kosslyn%2CSM">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36"><p class="c-article-references__text" id="ref-CR36">Keogh, R. &amp; Pearson, J. Mental imagery and visual working memory. <i>PloS One</i> <b>6</b>, e29221 (2011).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37"><p class="c-article-references__text" id="ref-CR37">Wojciulik, E. &amp; Kanwisher, N. The generality of parietal involvement in visual attention. <i>Neuron</i> <b>23</b>, 747â€“764 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(01)80033-7" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2801%2980033-7" aria-label="Article reference 37" data-doi="10.1016/S0896-6273(01)80033-7">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXmtVWqu7k%3D" aria-label="CAS reference 37">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10482241" aria-label="PubMed reference 37">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20generality%20of%20parietal%20involvement%20in%20visual%20attention&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2801%2980033-7&amp;volume=23&amp;pages=747-764&amp;publication_year=1999&amp;author=Wojciulik%2CE&amp;author=Kanwisher%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38"><p class="c-article-references__text" id="ref-CR38">Yantis, S. et al. Transient neural activity in human parietal cortex during spatial attention shifts. <i>Nat. Neurosci.</i> <b>5</b>, 995â€“1002 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn921" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn921" aria-label="Article reference 38" data-doi="10.1038/nn921">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38XnsVGrsr4%3D" aria-label="CAS reference 38">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12219097" aria-label="PubMed reference 38">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Transient%20neural%20activity%20in%20human%20parietal%20cortex%20during%20spatial%20attention%20shifts&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn921&amp;volume=5&amp;pages=995-1002&amp;publication_year=2002&amp;author=Yantis%2CS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39"><p class="c-article-references__text" id="ref-CR39">Behrmann, M., Geng, J.J. &amp; Shomstein, S. Parietal cortex and attention. <i>Curr. Opin. Neurobiol.</i> <b>14</b>, 212â€“217 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.conb.2004.03.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2004.03.012" aria-label="Article reference 39" data-doi="10.1016/j.conb.2004.03.012">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2cXjtV2nu7c%3D" aria-label="CAS reference 39">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15082327" aria-label="PubMed reference 39">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Parietal%20cortex%20and%20attention&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2004.03.012&amp;volume=14&amp;pages=212-217&amp;publication_year=2004&amp;author=Behrmann%2CM&amp;author=Geng%2CJJ&amp;author=Shomstein%2CS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40"><p class="c-article-references__text" id="ref-CR40">Colby, C.L. &amp; Goldberg, M.E. Space and attention in parietal cortex. <i>Annu. Rev. Neurosci.</i> <b>22</b>, 319â€“349 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.neuro.22.1.319" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.neuro.22.1.319" aria-label="Article reference 40" data-doi="10.1146/annurev.neuro.22.1.319">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1MXhvFems7w%3D" aria-label="CAS reference 40">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10202542" aria-label="PubMed reference 40">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Space%20and%20attention%20in%20parietal%20cortex&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.neuro.22.1.319&amp;volume=22&amp;pages=319-349&amp;publication_year=1999&amp;author=Colby%2CCL&amp;author=Goldberg%2CME">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41"><p class="c-article-references__text" id="ref-CR41">Culham, J.C. &amp; Kanwisher, N.G. Neuroimaging of cognitive functions in human parietal cortex. <i>Curr. Opin. Neurobiol.</i> <b>11</b>, 157â€“163 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0959-4388(00)00191-4" data-track-action="article reference" href="https://doi.org/10.1016%2FS0959-4388%2800%2900191-4" aria-label="Article reference 41" data-doi="10.1016/S0959-4388(00)00191-4">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXksFeksb4%3D" aria-label="CAS reference 41">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11301234" aria-label="PubMed reference 41">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuroimaging%20of%20cognitive%20functions%20in%20human%20parietal%20cortex&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2FS0959-4388%2800%2900191-4&amp;volume=11&amp;pages=157-163&amp;publication_year=2001&amp;author=Culham%2CJC&amp;author=Kanwisher%2CNG">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42"><p class="c-article-references__text" id="ref-CR42">DeYoe, E.A. et al. Mapping striate and extrastriate visual areas in human cerebral cortex. <i>Proc. Natl. Acad. Sci. USA</i> <b>93</b>, 2382â€“2386 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.93.6.2382" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.93.6.2382" aria-label="Article reference 42" data-doi="10.1073/pnas.93.6.2382">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK28XhvVSkt7s%3D" aria-label="CAS reference 42">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8637882" aria-label="PubMed reference 42">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC39805" aria-label="PubMed Central reference 42">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Mapping%20striate%20and%20extrastriate%20visual%20areas%20in%20human%20cerebral%20cortex&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.93.6.2382&amp;volume=93&amp;pages=2382-2386&amp;publication_year=1996&amp;author=DeYoe%2CEA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43"><p class="c-article-references__text" id="ref-CR43">Engel, S.A. et al. fMRI of human visual cortex. <i>Nature</i> <b>369</b>, 6481 (1994).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/369525a0" data-track-action="article reference" href="https://doi.org/10.1038%2F369525a0" aria-label="Article reference 43" data-doi="10.1038/369525a0">Article</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=fMRI%20of%20human%20visual%20cortex&amp;journal=Nature&amp;doi=10.1038%2F369525a0&amp;volume=369&amp;publication_year=1994&amp;author=Engel%2CSA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44"><p class="c-article-references__text" id="ref-CR44">Sereno, M.I. et al. Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging. <i>Science</i> <b>268</b>, 889â€“893 (1995).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.7754376" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.7754376" aria-label="Article reference 44" data-doi="10.1126/science.7754376">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK2MXls1SgsLs%3D" aria-label="CAS reference 44">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7754376" aria-label="PubMed reference 44">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Borders%20of%20multiple%20visual%20areas%20in%20humans%20revealed%20by%20functional%20magnetic%20resonance%20imaging&amp;journal=Science&amp;doi=10.1126%2Fscience.7754376&amp;volume=268&amp;pages=889-893&amp;publication_year=1995&amp;author=Sereno%2CMI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45"><p class="c-article-references__text" id="ref-CR45">Swisher, J.D., Halko, M.A., Merabet, L.B., McMains, S.A. &amp; Somers, D.C. Visual topography of human intraparietal sulcus. <i>J. Neurosci.</i> <b>27</b>, 5326â€“5337 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.0991-07.2007" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.0991-07.2007" aria-label="Article reference 45" data-doi="10.1523/JNEUROSCI.0991-07.2007">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXlvFGhsr8%3D" aria-label="CAS reference 45">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17507555" aria-label="PubMed reference 45">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6672354" aria-label="PubMed Central reference 45">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20topography%20of%20human%20intraparietal%20sulcus&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.0991-07.2007&amp;volume=27&amp;pages=5326-5337&amp;publication_year=2007&amp;author=Swisher%2CJD&amp;author=Halko%2CMA&amp;author=Merabet%2CLB&amp;author=McMains%2CSA&amp;author=Somers%2CDC">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46"><p class="c-article-references__text" id="ref-CR46">Bressler, D.W. &amp; Silver, M.A. Spatial attention improves reliability of fMRI retinotopic mapping signals in occipital and parietal cortex. <i>Neuroimage</i> <b>53</b>, 526â€“533 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.06.063" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.06.063" aria-label="Article reference 46" data-doi="10.1016/j.neuroimage.2010.06.063">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20600961" aria-label="PubMed reference 46">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20attention%20improves%20reliability%20of%20fMRI%20retinotopic%20mapping%20signals%20in%20occipital%20and%20parietal%20cortex&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.06.063&amp;volume=53&amp;pages=526-533&amp;publication_year=2010&amp;author=Bressler%2CDW&amp;author=Silver%2CMA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47"><p class="c-article-references__text" id="ref-CR47">Xu, Y. &amp; Chun, M.M. Selecting and perceiving multiple visual objects. <i>Trends Cogn. Sci.</i> <b>13</b>, 167â€“174 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2009.01.008" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2009.01.008" aria-label="Article reference 47" data-doi="10.1016/j.tics.2009.01.008">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19269882" aria-label="PubMed reference 47">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3213861" aria-label="PubMed Central reference 47">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Selecting%20and%20perceiving%20multiple%20visual%20objects&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2009.01.008&amp;volume=13&amp;pages=167-174&amp;publication_year=2009&amp;author=Xu%2CY&amp;author=Chun%2CMM">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48"><p class="c-article-references__text" id="ref-CR48">Straw, A.D. Vision egg: an open-source library for realtime visual stimulus generation. <i>Front. Neuroinform.</i> <b>2</b>, 4 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/neuro.11.004.2008" data-track-action="article reference" href="https://doi.org/10.3389%2Fneuro.11.004.2008" aria-label="Article reference 48" data-doi="10.3389/neuro.11.004.2008">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19050754" aria-label="PubMed reference 48">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2584775" aria-label="PubMed Central reference 48">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Vision%20egg%3A%20an%20open-source%20library%20for%20realtime%20visual%20stimulus%20generation&amp;journal=Front.%20Neuroinform.&amp;doi=10.3389%2Fneuro.11.004.2008&amp;volume=2&amp;publication_year=2008&amp;author=Straw%2CAD">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49"><p class="c-article-references__text" id="ref-CR49">Brainard, D.H. The psychophysics toolbox. <i>Spat. Vis.</i> <b>10</b>, 433â€“436 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1163/156856897X00357" data-track-action="article reference" href="https://doi.org/10.1163%2F156856897X00357" aria-label="Article reference 49" data-doi="10.1163/156856897X00357">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK2szitVSlug%3D%3D" aria-label="CAS reference 49">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9176952" aria-label="PubMed reference 49">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20psychophysics%20toolbox&amp;journal=Spat.%20Vis.&amp;doi=10.1163%2F156856897X00357&amp;volume=10&amp;pages=433-436&amp;publication_year=1997&amp;author=Brainard%2CDH">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50"><p class="c-article-references__text" id="ref-CR50">Dale, A.M., Fischl, B. &amp; Sereno, M.I. Cortical surface-based analysis. I. Segmentation and surface reconstruction. <i>Neuroimage</i> <b>9</b>, 179â€“194 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1006/nimg.1998.0395" data-track-action="article reference" href="https://doi.org/10.1006%2Fnimg.1998.0395" aria-label="Article reference 50" data-doi="10.1006/nimg.1998.0395">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M7jt1Gisg%3D%3D" aria-label="CAS reference 50">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9931268" aria-label="PubMed reference 50">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20surface-based%20analysis.%20I.%20Segmentation%20and%20surface%20reconstruction&amp;journal=Neuroimage&amp;doi=10.1006%2Fnimg.1998.0395&amp;volume=9&amp;pages=179-194&amp;publication_year=1999&amp;author=Dale%2CAM&amp;author=Fischl%2CB&amp;author=Sereno%2CMI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51"><p class="c-article-references__text" id="ref-CR51">Fischl, B., Liu, A. &amp; Dale, A.M. Automated manifold surgery: constructing geometrically accurate and topologically correct models of the human cerebral cortex. <i>IEEE Trans. Med. Imaging</i> <b>20</b>, 70â€“80 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/42.906426" data-track-action="article reference" href="https://doi.org/10.1109%2F42.906426" aria-label="Article reference 51" data-doi="10.1109/42.906426">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3MzjvV2ksw%3D%3D" aria-label="CAS reference 51">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11293693" aria-label="PubMed reference 51">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Automated%20manifold%20surgery%3A%20constructing%20geometrically%20accurate%20and%20topologically%20correct%20models%20of%20the%20human%20cerebral%20cortex&amp;journal=IEEE%20Trans.%20Med.%20Imaging&amp;doi=10.1109%2F42.906426&amp;volume=20&amp;pages=70-80&amp;publication_year=2001&amp;author=Fischl%2CB&amp;author=Liu%2CA&amp;author=Dale%2CAM">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52"><p class="c-article-references__text" id="ref-CR52">Fischl, B., Sereno, M.I. &amp; Dale, A.M. Cortical surface-based analysis. II. Inflation, flattening, and a surface-based coordinate system. <i>Neuroimage</i> <b>9</b>, 195â€“207 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1006/nimg.1998.0396" data-track-action="article reference" href="https://doi.org/10.1006%2Fnimg.1998.0396" aria-label="Article reference 52" data-doi="10.1006/nimg.1998.0396">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M7jt1Gisw%3D%3D" aria-label="CAS reference 52">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9931269" aria-label="PubMed reference 52">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20surface-based%20analysis.%20II.%20Inflation%2C%20flattening%2C%20and%20a%20surface-based%20coordinate%20system&amp;journal=Neuroimage&amp;doi=10.1006%2Fnimg.1998.0396&amp;volume=9&amp;pages=195-207&amp;publication_year=1999&amp;author=Fischl%2CB&amp;author=Sereno%2CMI&amp;author=Dale%2CAM">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53"><p class="c-article-references__text" id="ref-CR53">Reuter, M., Rosas, H.D. &amp; Fischl, B. Highly accurate inverse consistent registration: a robust approach. <i>Neuroimage</i> <b>53</b>, 1181â€“1196 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.07.020" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.07.020" aria-label="Article reference 53" data-doi="10.1016/j.neuroimage.2010.07.020">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20637289" aria-label="PubMed reference 53">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=Highly%20accurate%20inverse%20consistent%20registration%3A%20a%20robust%20approach&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.07.020&amp;volume=53&amp;pages=1181-1196&amp;publication_year=2010&amp;author=Reuter%2CM&amp;author=Rosas%2CHD&amp;author=Fischl%2CB">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54"><p class="c-article-references__text" id="ref-CR54">Fischl, B. et al. Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain. <i>Neuron</i> <b>33</b>, 341â€“355 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(02)00569-X" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2802%2900569-X" aria-label="Article reference 54" data-doi="10.1016/S0896-6273(02)00569-X">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38XjtlWnsbg%3D" aria-label="CAS reference 54">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11832223" aria-label="PubMed reference 54">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=Whole%20brain%20segmentation%3A%20automated%20labeling%20of%20neuroanatomical%20structures%20in%20the%20human%20brain&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2802%2900569-X&amp;volume=33&amp;pages=341-355&amp;publication_year=2002&amp;author=Fischl%2CB">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55"><p class="c-article-references__text" id="ref-CR55">Fischl, B. et al. Sequence-independent segmentation of magnetic resonance images. <i>Neuroimage</i> <b>23</b> (suppl. 1), S69â€“S84 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2004.07.016" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2004.07.016" aria-label="Article reference 55" data-doi="10.1016/j.neuroimage.2004.07.016">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15501102" aria-label="PubMed reference 55">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Sequence-independent%20segmentation%20of%20magnetic%20resonance%20images&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2004.07.016&amp;volume=23&amp;issue=suppl.%201&amp;pages=S69-S84&amp;publication_year=2004&amp;author=Fischl%2CB">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56"><p class="c-article-references__text" id="ref-CR56">Cowan, N. The magical number 4 in short-term memory: a reconsideration of mental storage capacity. <i>Behav. Brain Sci.</i> <b>24</b>, 87â€“114, discussion 114â€“185 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/S0140525X01003922" data-track-action="article reference" href="https://doi.org/10.1017%2FS0140525X01003922" aria-label="Article reference 56" data-doi="10.1017/S0140525X01003922">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3MvntFSitA%3D%3D" aria-label="CAS reference 56">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11515286" aria-label="PubMed reference 56">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20magical%20number%204%20in%20short-term%20memory%3A%20a%20reconsideration%20of%20mental%20storage%20capacity&amp;journal=Behav.%20Brain%20Sci.&amp;doi=10.1017%2FS0140525X01003922&amp;volume=24&amp;pages=87-114&amp;publication_year=2001&amp;author=Cowan%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57"><p class="c-article-references__text" id="ref-CR57">Destrieux, C., Fischl, B., Dale, A. &amp; Halgren, E. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. <i>Neuroimage</i> <b>53</b>, 1â€“15 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.06.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.06.010" aria-label="Article reference 57" data-doi="10.1016/j.neuroimage.2010.06.010">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20547229" aria-label="PubMed reference 57">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 57" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20parcellation%20of%20human%20cortical%20gyri%20and%20sulci%20using%20standard%20anatomical%20nomenclature&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.06.010&amp;volume=53&amp;pages=1-15&amp;publication_year=2010&amp;author=Destrieux%2CC&amp;author=Fischl%2CB&amp;author=Dale%2CA&amp;author=Halgren%2CE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58"><p class="c-article-references__text" id="ref-CR58">Haynes, J.-D. &amp; Rees, G. Predicting the orientation of invisible stimuli from activity in human primary visual cortex. <i>Nat. Neurosci.</i> <b>8</b>, 686â€“691 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1445" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1445" aria-label="Article reference 58" data-doi="10.1038/nn1445">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXjsFyktLs%3D" aria-label="CAS reference 58">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15852013" aria-label="PubMed reference 58">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Predicting%20the%20orientation%20of%20invisible%20stimuli%20from%20activity%20in%20human%20primary%20visual%20cortex&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1445&amp;volume=8&amp;pages=686-691&amp;publication_year=2005&amp;author=Haynes%2CJ-D&amp;author=Rees%2CG">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59"><p class="c-article-references__text" id="ref-CR59">Kamitani, Y. &amp; Tong, F. Decoding the visual and subjective contents of the human brain. <i>Nat. Neurosci.</i> <b>8</b>, 679â€“685 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn1444" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn1444" aria-label="Article reference 59" data-doi="10.1038/nn1444">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXjsFyktLo%3D" aria-label="CAS reference 59">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15852014" aria-label="PubMed reference 59">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1808230" aria-label="PubMed Central reference 59">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 59" href="http://scholar.google.com/scholar_lookup?&amp;title=Decoding%20the%20visual%20and%20subjective%20contents%20of%20the%20human%20brain&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn1444&amp;volume=8&amp;pages=679-685&amp;publication_year=2005&amp;author=Kamitani%2CY&amp;author=Tong%2CF">
                    Google Scholar</a>Â 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.4174?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We would like to thank J. Swisher for his retinotopy code and members of the Harvard Vision Lab for their valuable comments on this study. This research was supported by US National Institutes of Health (NIH) grant 1R01EY022355 to Y.X. and NIH grant F32-EY022874 to K.C.B.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Psychology, Harvard University, Cambridge, Massachusetts, USA</p><p class="c-article-author-affiliation__authors-list">Katherine C BettencourtÂ &amp;Â Yaoda Xu</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Katherine_C-Bettencourt-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Katherine C Bettencourt</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Katherine%20C%20Bettencourt" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Katherine%20C%20Bettencourt" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">Â </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Katherine%20C%20Bettencourt%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Yaoda-Xu-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Yaoda Xu</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Yaoda%20Xu" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yaoda%20Xu" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">Â </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yaoda%20Xu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>K.C.B. and Y.X. designed the experiments. K.C.B. conducted the experiments and analyzed the data. K.C.B. and Y.X. wrote the manuscript.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:yaodaxu@fas.harvard.edu">Yaoda Xu</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading">Competing interests</h3>
                <p>The authors declare no competing financial interests.</p>
              
            </div></div></section><section data-title="Integrated supplementary information"><div class="c-article-section" id="Sec23-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec23">Integrated supplementary information</h2><div class="c-article-section__content" id="Sec23-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 1 univariate fmri responses f" href="/articles/nn.4174/figures/8" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig8_ESM.jpg">Supplementary Figure 1 Univariate fMRI responses for V1-V4 (a) and superior IPS (b) in Experiment 1 (with predictable distractors) and Experiment 3 (with unpredictable distractors)</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The same ten participants took part in both experiments. In both experiments, V1-V4 showed a mostly bottom-up based response, showing strong activation whenever stimuli were present. Superior IPS was driven by both bottom-up and top-down input, showing activation during both stimulus presentation and the delay. In Experiment 1, activity in V1-V4 decreased following the encoding period in trials without distractors (t(9) = 5.3, p = 0.005), but increased in trials with distractors (t(9) = 9.1, p = 0.0001), with a significant difference between the two trial types during the delay period (t(9) = 9.8, p &lt; 0.0001). In superior IPS, while there was significantly more activation during the delay period for trials with distractors than without (t(9) = 2.9, p = 0.02), activity for both trial types decreased following the encoding period (trials without distractors: t(9) = 8.2, p = 0.0001; trials with distractors: t(9) = 3.4, p = 0.008). In a 2 (ROI) x 2 (trial type) x 2 (time period: encoding vs. delay) ANOVA, these differences resulted in a significant main effect of time period (F(1,9) = 7.2, p = 0.03), ROI (F(1,9) = 38.4, p = 0.0002), and trial type (F(1,9) = 40.5, p = 0.0001), and significant interactions between all three factors (F(1,9) = 88.1, p &lt; 0.0001). Thus, response amplitudes in occipital cortex track the encoding of incoming visual information, regardless of whether or not it is task relevant. In superior IPS, however, while we do see increased activation for trials with distractors, relative to trials without distractors, this activity is lower than the task relevant information presented at encoding, suggesting that response amplitude in superior IPS is significantly modulated by the task relevance of the information presented. In Experiment 3, activity in V1-V4 decreased following the encoding period in trials without distractors (t(9) = 6.6, p = 0.0001) and increased in trials with distractors (t(9) = 7.6, p = 0.0001), similar to what was seen in Experiment 1. The difference in activation between the two trial types during the delay period was significant (t(9) = 15.4, p &lt; 0.0001). Delay period activity for each trial type did not differ between Experiments 1 and 3 (trials without distractors: p = 0.3; trials with distractors: p = 0.8), suggesting that univariate response amplitude within this region was not affected by the predictability of distractor presence. In superior IPS, as in Experiment 1, we saw a decrease in activation following the encoding period for trials with (t(9) = 8.6, p = 0.0001) and without distractors (t(9) = 12.1, p = 0.0001). However, unlike in Experiment 1, there was no difference in delay period activity between the two trial types (p = 0.65). Comparisons between Experiments 1 and 3 revealed that, delay period activity in Experiment 3 was significantly higher than in Experiment 1 in trials without distractors (t(9) = 3.1, p = 0.01), but trending towards significantly lower than delay period activity in Experiment 1 in trials with distractors (t(9) = 2.1, p = 0.07). Previously, it has been suggested that univariate activity in this region reflects the amount of information stored. Here the presence and predictability of distractors appears to affect response amplitudes even though the amount of information stored in VSTM remains constant. Specifically, activity seems to be the highest when distractors are most likely to appear, and decreases as the likelihood of distraction decreases. This suggests that superior IPS not only maintains VSTM information across the delay, but that it may be able to dynamically modulate its activation to protect this information from distraction, either by increasing suppression or by strengthening and enhancing the stored information. Error bars indicate s.e.m. No distractors, trials without distractors; Distractors, trials with distractors.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig9"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 2 univariate fmri responses f" href="/articles/nn.4174/figures/9" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig9_ESM.jpg">Supplementary Figure 2 Univariate fMRI responses for Experiment 2.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Eight of the participants from Experiment 1 completed this experiment. Similar to what was seen during the delay period of Experiment 1, V1-V4 showed stronger activation for trials with distractors than those without distractors (t(7) = 6.0, p = 0.0006). When the weak grating was presented alone (trials without distractors), we saw little to no univariate response in this region (p = 0.4), similar to the delay period response for trials without distractor in Experiment 1. This suggests that the memory and perceptual representations were similar in strength across the two experiments. Error bars indicate s.e.m. No distractors, trials without distractors; Distractors, trials with distractors.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig10"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 3 mvpa decoding accuracy for " href="/articles/nn.4174/figures/10" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig10_ESM.jpg">Supplementary Figure 3 MVPA decoding accuracy for the average VSTM delay period in topographic IPS regions (V3A-IPS4) for when distractors were predictable (Experiment 1) and unpredictable (Experiment 3).</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The same ten participants took part in both experiments. While all regions showed significant, above chance decoding of VSTM contents in at least one of the experiments/trial types, none showed consistent decoding irrespective of distractor presence or predictability. Above chance decoding was seen in trials without distractors in Experiment 1 in areas V3A (t(9) = 3.9, p = 0.003), V3B (t(9) = 4.2, p = 0.002), IPS0 (t(9) = 3.5, p = 0.007), IPS3 (t(9) = 2.9, p = 0.02), IPS4 ((t(9) = 2.4, p = 0.04), with a trend towards above chance decoding in IPS2 (t(9) = 2.1, p = 0.06), and in Experiment 3 in areas IPS0 (t(9) = 3.5, p = 0.007), IPS1 (t(9) = 2.4, p = 0.04), IPS2 (t(9) = 6.2, p = 0.0001), and IPS4 (t(9) = 2.3, p = 0.05), with a trend towards above chance decoding in V3A (t(8) = 2.3, p = 0.05). Above chance decoding was seen in trials with distractors in Experiment 1 in all topographic regions (V3A: (t(9) = 3.1, p = 0.01), V3B: (t(9) = 2.6, p = 0.03), IPS0: (t(9) = 4.1, p = 0.003), IPS1: (t(9) = 3.6, p = 0.006), IPS3: (t(9) = 2.5, p = 0.04), IPS4: (t(9) = 2.4, p = 0.04)), except for IPS2 where it was trending (t(9) = 2.2, p = 0.05), but only in IPS1 (t(9) = 2.4, p = 0.04), and IPS2 (t(9) = 3.0, p = 0.01) in Experiment 3. Significant or trending towards significant differences between trial types were seen in IPS1 in Experiment 1 (t(9) = 2.1, p = 0.07) and in IPS2 in Experiment 3 (t(9) = 2.5, p = 0.03). Decoding accuracy was not improved by combining IPS1-4 into one larger ROI. In this combined IPS1-4 ROI, above chance decoding was seen in trials without distractors for both Experiment 1 (t(9) = 2.7, p = 0.03) and Experiment 3 (t(9) = 3.7, p = 0.005), but not in trials with distractors in either experiment (Exp. 1: p = 0.17; Exp. 3: p = 0.13). Additionally, decoding accuracy was higher in trials without distractors than with in Experiment 3 (t(9) = 2.4, p = 0.04), but not in Experiment 1 (p = 0.51). Error bars indicate s.e.m. â€  p &lt; 0.10; * p &lt; 0.05; ** p &lt; 0.01; *** p &lt; 0.001; ns non-significant; No distractors, trials without distractors; Distractors, trials with distractors.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig11"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 4 mvpa decoding accuracy for " href="/articles/nn.4174/figures/11" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig11_ESM.jpg">Supplementary Figure 4 MVPA decoding accuracy for the average VSTM delay period in IPL and SPL for when distractors were predictable (Experiment 1) and unpredictable (Experiment 3).</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The same ten participants took part in both experiments. Both IPL and SPL showed significant decoding of VSTM information in trials without distractors in both experiments, but neither showed consistent decoding of VSTM information across both experiments and trial types. Above chance VSTM decoding was seen in trials without distractors in IPL and SPL in both Experiments 1 and 3 (IPL, Exp. 1: t(9) = 3.0, p = 0.01; IPL, Exp. 3: t(9) = 2.3, p = 0.05; SPL, Exp. 1: t(9) = 4.4, p = 0.002; SPL, Exp. 3: t(9) = 4.2, p = 0.002). However, in trials with distractors, above chance decoding was only seen in Experiment 3 and only in SPL (t(9) = 3.4, p = 0.008). A trend towards a significant difference between trial types was also seen in SPL in Experiment 3 (t(9) = 2.2, p = 0.06). Across the two experiments, there was a main effect of distractor presence in SPL (F(1,9) = 7.1, p = 0.03) and a trend towards the same in IPL (F(1,9) = 4.4, p = 0.07), but no effect of distractor predictability (IPL: p = 0.93; SPL: p = 0.52) or an interaction between the two factors (IPL: p = 0.75; SPL: p = 0.97) in either region. Error bars indicate s.e.m. â€  p &lt; 0.10; * p &lt; 0.05; ns non-significant; No distractors, trials without distractors; Distractors, trials with distractors.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig12"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 5 univariate fmri responses f" href="/articles/nn.4174/figures/12" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig12_ESM.jpg">Supplementary Figure 5 Univariate fMRI responses from each of the topographic IPS regions (V3A-IPS0) for both when distractors were predictable (Experiment 1) and unpredictable (Experiment 3).</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The same ten participants took part in both experiments. Topographic regions show a clear progression from primarily bottom up based univariate activity in V3A/B to activity that reflected a mixture of bottom up and top down activity in higher topographic regions. In both Experiments 1 and 3, topographic regions showed a clear progression from primarily bottom up based univariate activity in V3A/B to activity that reflected a mixture of bottom up and top down activity in higher topographic regions. In trials without distractors, in both experiments, all topographic regions showed significantly decreased activity following the encoding period (Exp. 1: V3A: t(9) = 5.8, p = 0.0002; V3B: t(9) = 6.3, p = 0.0001; IPS0: t(9) = 6.7, p &lt; 0.0001; IPS1: t(9) = 5.0, p = 0.0007; IPS2: t(9) = 3.9, p = 0.003; IPS3: t(9) = 5.1, p = 0.0006; IPS4: t(9) = 5.5, p = 0.0004; Exp. 3: V3A: t(9) = 7.8, p &lt; 0.0001; V3B: t(9) = 10.2, p &lt; 0.0001; IPS0: t(9) = 9.7, p &lt; 0.0001; IPS1: t(9) = 6.2, p = 0.0002; IPS2: t(9) = 5.7, p = 0.0002; IPS3: t(9) = 6.6, p = 0.0001; IPS4: t(9) = 9.7, p &lt; 0.0001). In trials with distractors, in both experiments, activity increased following the encoding period in V3A (Exp. 1: t(9) = 5.2, p = 0.0006; Exp. 3: t(9) = 4.5, p = 0.001) and V3B (Exp. 1: t(9) = 6.9, p &lt; 0.0001; Exp. 3: t(9) = 4.8, p = 0.001) decreased in IPS1 (,Exp. 1: t(9) = 3.2, p = 0.01; Exp. 3: t(9) = 5.7, p = 0.0002), IPS2 (Exp. 1: t(9) = 4.8 p = 0.001; Exp. 3: t(9) = 6.2, p = 0.0002), IPS3 (Exp. 1: t(9) = 3.9, p = 0.003; Exp. 3: t(9) = 4.6, p = 0.001), and IPS4 (Exp. 1: t(9) = 4.5, p = 0.002; Exp. 3: t(9) = 7.7, p &lt; 0.0001), and showed a trend towards decreasing in IPS0 (Exp. 1: t(9) = 2.9, p = 0.08; Exp. 3: t(9) = 2.1, p = 0.07). In V3A-IPS0, there was significantly more activation in the delay period for trials with distractors than without in both Experiments 1 (V3A: t(9) = 7.1, p &lt; 0.0001; V3B: t(9) = 7.8, p &lt; 0.0001; IPS0: t(9) = 5.4, p = 0.0004) and 3 (V3A: t(9) = 11.3, p &lt; 0.0001; V3B: t(9) = 9.4, p &lt; 0.0001; IPS0: t(9) = 6.4, p = 0.0001). IPS2 showed no difference in activation between the trial types for both experiments (Exp. 1: p = 0.74; Exp. 3: p = 0.29). In IPS1, there was no significant difference between trials with distractors and those without in Experiment 1 (p = 0.26), but a trend towards a significant difference between trial types in Experiment 3 (t(9) = 2.0, p = 0.08). In IPS3-4, there were no significant differences between trial types in Experiment 1 (IPS3: p = 0.13; IPS4: p = 0.4), but significantly higher activation for trials with distractors than those without in Experiment 3 (IPS3: t(9) = 3.6, p = 0.006; IPS4: t(9) = 3.5, p = 0.007). Error bars indicate s.e.m. No distractors, trials without distractors; Distractors, trials with distractors.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig13"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary figure 6 univariate fmri responses f" href="/articles/nn.4174/figures/13" data-supp-info-image="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_Article_BFnn4174_Fig13_ESM.jpg">Supplementary Figure 6 Univariate fMRI responses from anatomically defined IPL and SPL regions for both when distractors were predictable (Experiment 1) and unpredictable (Experiment 3).</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>The same ten participants took part in both experiments. Both regions showed activity similar to that of superior IPS, showing a mixture of top-down and bottom-up processing. In IPL and SPL, we found a significant decrease in activity following encoding in both trials with and without distractors in both experiments (Exp. 1, trials without distractors: IPL: t(9) = 8.6, p &lt; 0.0001; SPL: t(9) = 6.3, p = 0.0001; trials with distractors: IPL: t(9) = 3.6, p = 0.006; SPL: t(9) = 4.1, p = 0.003; Exp. 3, trials without distractors: IPL: t(9) = 10.0, p &lt; 0.0001; SPL: t(9) = 8.8, p &lt; 0.0001; trials with distractors: IPL: t(9) = 3.1, p = 0.01; SPL: t(9) = 6.2, p = 0.0002). Activity in IPL was significantly higher during the delay period for trials with distractors than trials without in both Experiments 1 (t(9) = 4.0, p = 0.003) and 3 (t(9) = 5.0, p = 0.0007), but activity between trial types in SPL only differed in Experiment 3 (t(9) = 3.1, p = 0.01). Error bars indicate s.e.m. No distractors, trials without distractors; Distractors, trials with distractors.</p></div></div></div></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec24-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec24">Supplementary information</h2><div class="c-article-section__content" id="Sec24-content"><div data-test="supplementary-info"><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM7"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary text and figures" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_BFnn4174_MOESM7_ESM.pdf" data-supp-info-image="">Supplementary Text and Figures</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Supplementary Figures 1â€“6 (PDF 620 kb)</p></div></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary methods checklist (pdf 488 kb)" href="https://static-content.springer.com/esm/art%3A10.1038%2Fnn.4174/MediaObjects/41593_2016_BFnn4174_MOESM8_ESM.pdf" data-supp-info-image="">Supplementary Methods Checklist (PDF 488 kb)</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Decoding%20the%20content%20of%20visual%20short-term%20memory%20under%20distraction%20in%20occipital%20and%20parietal%20areas&amp;author=Katherine%20C%20Bettencourt%20et%20al&amp;contentID=10.1038%2Fnn.4174&amp;copyright=Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2015-11-23&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/nn.4174" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/nn.4174" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Bettencourt, K., Xu, Y. Decoding the content of visual short-term memory under distraction in occipital and parietal areas.
                    <i>Nat Neurosci</i> <b>19</b>, 150â€“157 (2016). https://doi.org/10.1038/nn.4174</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/nn.4174?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-07-17">17 July 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-10-26">26 October 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2015-11-23">23 November 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2016-01">January 2016</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/nn.4174</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Spectrotemporal content of human auditory working memory represented in functional connectivity patterns" href="https://doi.org/10.1038/s42003-023-04675-8">
                                        Spectrotemporal content of human auditory working memory represented in functional connectivity patterns
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Jyrki Ahveninen</li><li>IÅŸÄ±l UluÃ§</li><li>Fahimeh Mamashli</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Communications Biology</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Neural correlates of visual and tactile path integration and their task related modulation" href="https://doi.org/10.1038/s41598-023-36797-8">
                                        Neural correlates of visual and tactile path integration and their task related modulation
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Lisa Rosenblum</li><li>Alexander KreÃŸ</li><li>Frank Bremmer</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Neural Mechanisms of the Maintenance and Manipulation of Gustatory Working Memory in Orbitofrontal Cortex" href="https://doi.org/10.1007/s12559-022-10035-1">
                                        Neural Mechanisms of the Maintenance and Manipulation of Gustatory Working Memory in Orbitofrontal Cortex
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Layla Chadaporn Antaket</li><li>Yoshiki Kashimori</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Cognitive Computation</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:The effect of visual working memory load on attentional bias in social anxiety" href="https://doi.org/10.1007/s12144-023-05441-z">
                                        The effect of visual working memory load on attentional bias in social anxiety
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Yibo Jiang</li><li>Chengshi Li</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Current Psychology</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Dynamic Networks with Multi-scale Temporal Structure" href="https://doi.org/10.1007/s13171-021-00256-1">
                                        Dynamic Networks with Multi-scale Temporal Structure
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Xinyu Kang</li><li>Apratim Ganguly</li><li>Eric D. Kolaczyk</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Sankhya A</i> (2022)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4174.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/nn.4174.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=nn.4174;doi=10.1038/nn.4174;techmeta=36,59;subjmeta=2649,378,477,631;kwrd=Cognitive+neuroscience,Psychology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1284759582&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.4174%26doi%3D10.1038/nn.4174%26techmeta%3D36,59%26subjmeta%3D2649,378,477,631%26kwrd%3DCognitive+neuroscience,Psychology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1284759582&amp;t=pos%3Dright%26type%3Darticle%26artid%3Dnn.4174%26doi%3D10.1038/nn.4174%26techmeta%3D36,59%26subjmeta%3D2649,378,477,631%26kwrd%3DCognitive+neuroscience,Psychology"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter â€” what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/nn.4174&amp;format=js&amp;last_modified=2016-01-01" async></script>
<img src="/86vwhu4p/article/nn.4174" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>