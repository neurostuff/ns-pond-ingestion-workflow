<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>A retinotopic code structures the interaction between perception and memory systems | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"cognitive-neuroscience;learning-and-memory;neuroscience;visual-system","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/s41593-023-01512-3"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Adam Steel","Edward H. Silson","Brenda D. Garcia","Caroline E. Robertson"],"publishedAt":1704153600,"publishedAtString":"2024-01-02","title":"A retinotopic code structures the interaction between perception and memory systems","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"27","issue":"2"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-68c4876c28.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-68c4876c28.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-22e9088d18.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-be699ef0bc.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-4841faf3e2.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-f72f566c73.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-9389823142.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-cb0ea70df9.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"A retinotopic code structures the interaction between perception and memory systems","description":"Conventional views of brain organization suggest that regions at the top of the cortical hierarchy processes internally oriented information using an abstract amodal neural code. Despite this, recent reports have described the presence of retinotopic coding at the cortical apex, including the default mode network. What is the functional role of retinotopic coding atop the cortical hierarchy? Here we report that retinotopic coding structures interactions between internally oriented (mnemonic) and externally oriented (perceptual) brain areas. Using functional magnetic resonance imaging, we observed robust inverted (negative) retinotopic coding in category-selective memory areas at the cortical apex, which is functionally linked to the classic (positive) retinotopic coding in category-selective perceptual areas in high-level visual cortex. These functionally linked retinotopic populations in mnemonic and perceptual areas exhibit spatially specific opponent responses during both bottom-up perception and top-down recall, suggesting that these areas are interlocked in a mutually inhibitory dynamic. These results show that retinotopic coding structures interactions between perceptual and mnemonic neural systems, providing a scaffold for their dynamic interaction. The authors show that functionally paired visual and memory brain areas share a common neural code, which structures their communication. This code is visual in nature and uses a pushâ€“pull dynamic to translate information between vision and memory.","datePublished":"2024-01-02T00:00:00Z","dateModified":"2024-01-02T00:00:00Z","pageStart":"339","pageEnd":"347","sameAs":"https://doi.org/10.1038/s41593-023-01512-3","keywords":["Cognitive neuroscience","Learning and memory","Neuroscience","Visual system","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig3_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig4_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig5_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig6_HTML.png"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"27","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Adam Steel","url":"http://orcid.org/0000-0001-8876-933X","affiliation":[{"name":"Dartmouth College","address":{"name":"Department of Psychology and Brain Sciences, Dartmouth College, Hanover, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"adamdanielsteel@gmail.com","@type":"Person"},{"name":"Edward H. Silson","affiliation":[{"name":"University of Edinburgh","address":{"name":"Psychosophy, Psychology, and Language Sciences, University of Edinburgh, Edinburgh, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Brenda D. Garcia","affiliation":[{"name":"Dartmouth College","address":{"name":"Department of Psychology and Brain Sciences, Dartmouth College, Hanover, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Caroline E. Robertson","url":"http://orcid.org/0000-0002-1858-6594","affiliation":[{"name":"Dartmouth College","address":{"name":"Department of Psychology and Brain Sciences, Dartmouth College, Hanover, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"caroline.e.robertson@dartmouth.edu","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/s41593-023-01512-3">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="A retinotopic code structures the interaction between perception and memory systems"/>
    <meta name="dc.source" content="Nature Neuroscience 2024 27:2"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2024-01-02"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2024 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2024 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Conventional views of brain organization suggest that regions at the top of the cortical hierarchy processes internally oriented information using an abstract amodal neural code. Despite this, recent reports have described the presence of retinotopic coding at the cortical apex, including the default mode network. What is the functional role of retinotopic coding atop the cortical hierarchy? Here we report that retinotopic coding structures interactions between internally oriented (mnemonic) and externally oriented (perceptual) brain areas. Using functional magnetic resonance imaging, we observed robust inverted (negative) retinotopic coding in category-selective memory areas at the cortical apex, which is functionally linked to the classic (positive) retinotopic coding in category-selective perceptual areas in high-level visual cortex. These functionally linked retinotopic populations in mnemonic and perceptual areas exhibit spatially specific opponent responses during both bottom-up perception and top-down recall, suggesting that these areas are interlocked in a mutually inhibitory dynamic. These results show that retinotopic coding structures interactions between perceptual and mnemonic neural systems, providing a scaffold for their dynamic interaction. The authors show that functionally paired visual and memory brain areas share a common neural code, which structures their communication. This code is visual in nature and uses a push&#8211;pull dynamic to translate information between vision and memory."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2024-01-02"/>
    <meta name="prism.volume" content="27"/>
    <meta name="prism.number" content="2"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="339"/>
    <meta name="prism.endingPage" content="347"/>
    <meta name="prism.copyright" content="2024 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/s41593-023-01512-3"/>
    <meta name="prism.doi" content="doi:10.1038/s41593-023-01512-3"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41593-023-01512-3.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41593-023-01512-3"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="A retinotopic code structures the interaction between perception and memory systems"/>
    <meta name="citation_volume" content="27"/>
    <meta name="citation_issue" content="2"/>
    <meta name="citation_publication_date" content="2024/02"/>
    <meta name="citation_online_date" content="2024/01/02"/>
    <meta name="citation_firstpage" content="339"/>
    <meta name="citation_lastpage" content="347"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/s41593-023-01512-3"/>
    <meta name="DOI" content="10.1038/s41593-023-01512-3"/>
    <meta name="size" content="208234"/>
    <meta name="citation_doi" content="10.1038/s41593-023-01512-3"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/s41593-023-01512-3&amp;api_key="/>
    <meta name="description" content="Conventional views of brain organization suggest that regions at the top of the cortical hierarchy processes internally oriented information using an abstract amodal neural code. Despite this, recent reports have described the presence of retinotopic coding at the cortical apex, including the default mode network. What is the functional role of retinotopic coding atop the cortical hierarchy? Here we report that retinotopic coding structures interactions between internally oriented (mnemonic) and externally oriented (perceptual) brain areas. Using functional magnetic resonance imaging, we observed robust inverted (negative) retinotopic coding in category-selective memory areas at the cortical apex, which is functionally linked to the classic (positive) retinotopic coding in category-selective perceptual areas in high-level visual cortex. These functionally linked retinotopic populations in mnemonic and perceptual areas exhibit spatially specific opponent responses during both bottom-up perception and top-down recall, suggesting that these areas are interlocked in a mutually inhibitory dynamic. These results show that retinotopic coding structures interactions between perceptual and mnemonic neural systems, providing a scaffold for their dynamic interaction. The authors show that functionally paired visual and memory brain areas share a common neural code, which structures their communication. This code is visual in nature and uses a push&#8211;pull dynamic to translate information between vision and memory."/>
    <meta name="dc.creator" content="Steel, Adam"/>
    <meta name="dc.creator" content="Silson, Edward H."/>
    <meta name="dc.creator" content="Garcia, Brenda D."/>
    <meta name="dc.creator" content="Robertson, Caroline E."/>
    <meta name="dc.subject" content="Cognitive neuroscience"/>
    <meta name="dc.subject" content="Learning and memory"/>
    <meta name="dc.subject" content="Neuroscience"/>
    <meta name="dc.subject" content="Visual system"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Rotational dynamics reduce interference between sensory and memory representations; citation_author=A Libby, TJ Buschman; citation_volume=24; citation_publication_date=2021; citation_pages=715-726; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Serial dependence across perception, attention, and memory; citation_author=A Kiyonaga, JM Scimeca, DP Bliss, D Whitney; citation_volume=21; citation_publication_date=2017; citation_pages=493; citation_id=CR2"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Rev. Neurosci.; citation_title=Expectation in perceptual decision making: neural and computational mechanisms; citation_author=C Summerfield, FP Lange; citation_volume=15; citation_publication_date=2014; citation_pages=745-756; citation_id=CR3"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Coexisting representations of sensory and mnemonic information in human visual cortex; citation_author=RL Rademaker, C Chunharas, JT Serences; citation_volume=22; citation_publication_date=2019; citation_pages=1336-1344; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Neurosci.; citation_title=Transforming the concept of memory reactivation; citation_author=SE Favila, H Lee, BA Kuhl; citation_volume=43; citation_publication_date=2020; citation_pages=939-950; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Neurosci.; citation_title=Pattern separation in the hippocampus; citation_author=MA Yassa, CEL Stark; citation_volume=34; citation_publication_date=2011; citation_pages=515-525; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=Br. J. Ophthalmol.; citation_title=Disturbances of vision by cerebral lesions; citation_author=G Holmes; citation_volume=2; citation_publication_date=1918; citation_pages=353-384; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Visual field maps in human cortex; citation_author=BA Wandell, SO Dumoulin, AA Brewer; citation_volume=56; citation_publication_date=2007; citation_pages=366-383; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream; citation_author=U Guclu, MAJ Gerven; citation_volume=35; citation_publication_date=2015; citation_pages=10005-10014; citation_id=CR9"/>
    <meta name="citation_reference" content="Groen, I. I. A., Dekker, T. M., Knapen, T. &amp; Silson, E. H. Visuospatial coding as ubiquitous scaffolding for human cognition. Trends Cogn. Sci. 
                  https://doi.org/10.1016/j.tics.2021.10.011
                  
                 (2022)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Visual and linguistic semantic representations are aligned at the border of human visual cortex; citation_author=SF Popham; citation_volume=24; citation_publication_date=2021; citation_pages=1628-1636; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Large-scale gradients in human cortical organization; citation_author=JM Huntenburg, PL Bazin, DS Margulies; citation_volume=22; citation_publication_date=2018; citation_pages=21-31; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Situating the default-mode network along a principal gradient of macroscale cortical organization; citation_author=DS Margulies; citation_volume=113; citation_publication_date=2016; citation_pages=12574-12579; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Science (1979); citation_title=Navigating cognition: spatial codes for human thinking; citation_author=JLS Bellmund, P G&#228;rdenfors, EI Moser, CF Doeller; citation_volume=362; citation_publication_date=2018; citation_pages=eaat6766; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Visual organization of the default network; citation_author=M Szinte, T Knapen; citation_volume=30; citation_publication_date=2020; citation_pages=3518-3527; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=eLife; citation_title=Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex; citation_author=P Christiaan Klink, X Chen, W Vanduffel, PR Roelfsema; citation_volume=10; citation_publication_date=2021; citation_pages=e67304; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Population receptive field estimates in human visual cortex; citation_author=SO Dumoulin, BA Wandell; citation_volume=39; citation_publication_date=2008; citation_pages=647; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=A retinotopic basis for the division of high-level scene processing between lateral and ventral human occipitotemporal cortex; citation_author=EH Silson, AWY Chan, RC Reynolds, DJ Kravitz, CI Baker; citation_volume=35; citation_publication_date=2015; citation_pages=11921-11935; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI; citation_author=P Kundu, SJ Inati, JW Evans, WM Luh, PA Bandettini; citation_volume=60; citation_publication_date=2012; citation_pages=1759-1770; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Evaluating the efficacy of multi-echo ICA denoising on model-based fMRI; citation_author=A Steel, BD Garcia, EH Silson, CE Robertson; citation_volume=264; citation_publication_date=2022; citation_pages=119723; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Probabilistic maps of visual topography in human cortex; citation_author=L Wang, REB Mruczek, MJ Arcaro, S Kastner; citation_volume=25; citation_publication_date=2015; citation_pages=3911-3931; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=The organization of the human cerebral cortex estimated by intrinsic functional connectivity; citation_author=BT Thomas Yeo; citation_volume=106; citation_publication_date=2011; citation_pages=1125-1165; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Sustained negative BOLD, blood flow and oxygen consumption response and its coupling to the positive response in the human brain; citation_author=A Shmuel; citation_volume=36; citation_publication_date=2002; citation_pages=1195-1210; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=A network linking scene perception and spatial memory systems in posterior cerebral cortex; citation_author=A Steel, MM Billings, EH Silson, CE Robertson; citation_volume=12; citation_publication_date=2021; citation_pages=1-13; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Eccentricity bias as an organizing principle for human high-order object areas; citation_author=U Hasson, I Levy, M Behrmann, T Hendler, R Malach; citation_volume=34; citation_publication_date=2002; citation_pages=479-490; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=The occipital place area is causally and selectively involved in scene perception; citation_author=DD Dilks, JB Julian, AM Paunov, N Kanwisher; citation_volume=33; citation_publication_date=2013; citation_pages=1331-1336; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=A cortical representation the local visual environment; citation_author=R Epstein, N Kanwisher; citation_volume=392; citation_publication_date=1998; citation_pages=598-601; citation_id=CR27"/>
    <meta name="citation_reference" content="Breedlove, J. L., St-Yves, G., Olman, C. A. &amp; Naselaris, T. Generative feedback explains distinct brain activity codes for seen and mental images. Curr. Biol. 
                  https://doi.org/10.1016/j.cub.2020.04.014
                  
                 (2020)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Perception and memory have distinct spatial tuning properties in human visual cortex; citation_author=SE Favila, BA Kuhl, J Winawer; citation_volume=13; citation_publication_date=2022; citation_pages=5864; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Canonical microcircuits for predictive coding; citation_author=AM Bastos; citation_volume=76; citation_publication_date=2012; citation_pages=695-711; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain; citation_author=T Knapen; citation_volume=118; citation_publication_date=2021; citation_pages=e2017032118; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Representation of contralateral visual space in the human hippocampus; citation_author=EH Silson, P Zeidman, T Knapen, CI Baker; citation_volume=41; citation_publication_date=2021; citation_pages=2382-2392; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Opin. Neurobiol.; citation_title=Dynamic network interactions supporting internally-oriented cognition; citation_author=DL Zabelina, JR Andrews-Hanna; citation_volume=40; citation_publication_date=2016; citation_pages=86-93; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=Common blood flow changes across visual tasks: II. Decreases in cerebral cortex; citation_author=GL Shulman; citation_volume=9; citation_publication_date=1997; citation_pages=648-663; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=The human brain is intrinsically organized into dynamic, anticorrelated functional networks; citation_author=MD Fox; citation_volume=102; citation_publication_date=2005; citation_pages=9673-9678; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=Annu Rev. Neurosci.; citation_title=The brain&#8217;s default mode network; citation_author=ME Raichle; citation_volume=38; citation_publication_date=2015; citation_pages=433-447; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Biol.; citation_title=Neural representations integrate the current field of view with the remembered 360&#176; panorama in scene-selective cortex; citation_author=CE Robertson; citation_volume=26; citation_publication_date=2016; citation_pages=2463-2468; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Parallel interdigitated distributed networks within the individual estimated by intrinsic functional connectivity; citation_author=RM Braga, RL Buckner; citation_volume=95; citation_publication_date=2017; citation_pages=457-471.e5; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Parallel distributed networks dissociate episodic and social functions within the individual; citation_author=LM DiNicola, RM Braga, RL Buckner; citation_volume=123; citation_publication_date=2020; citation_pages=1144-1179; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Front Hum. Neurosci.; citation_title=Scene-selectivity and retinotopy in medial parietal cortex; citation_author=EH Silson, AD Steel, CI Baker; citation_volume=10; citation_publication_date=2016; citation_pages=412; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=eLife; citation_title=Distinct subdivisions of human medial parietal cortex support recollection of people and places; citation_author=EH Silson, A Steel, A Kidder, AW Gilmore, CI Baker; citation_volume=8; citation_publication_date=2019; citation_pages=e47391; citation_id=CR41"/>
    <meta name="citation_reference" content="Deen, B. &amp; Freiwald, W. A. Parallel systems for social and spatial reasoning within the cortical apex. Preprint at bioRxiv 
                  https://doi.org/10.1101/2021.09.23.461550
                  
                 (2021)."/>
    <meta name="citation_reference" content="Ranganath, C. &amp; Ritchey, M. Two cortical systems for memory-guided behaviour. Nat. Rev. Neurosci. 13, 713&#8211;726 (2012); 
                  https://doi.org/10.1038/nrn3338
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Multiple reference frames for saccadic planning in the human parietal cortex; citation_author=Y Pertzov, G Avidan, E Zohary; citation_volume=31; citation_publication_date=2011; citation_pages=1059; citation_id=CR44"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Maps of visual space in human occipital cortex are retinotopic, not spatiotopic; citation_author=JL Gardner, EP Merriam, JA Movshon, DJ Heeger; citation_volume=28; citation_publication_date=2008; citation_pages=3988; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Spatial reference frames of visual, vestibular, and multimodal heading signals in the dorsal subdivision of the medial superior temporal area; citation_author=CR Fetsch, S Wang, Y Gu, GC DeAngelis, DE Angelaki; citation_volume=27; citation_publication_date=2007; citation_pages=700-712; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Higher level visual cortex represents retinotopic, not spatiotopic, object location; citation_author=JD Golomb, N Kanwisher; citation_volume=22; citation_publication_date=2012; citation_pages=2794-2810; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=J. Vis.; citation_title=Evaluating the correspondence between face-, scene-, and object-selectivity and retinotopic organization within lateral occipitotemporal cortex; citation_author=EH Silson, IIA Groen, DJ Kravitz, CI Baker; citation_volume=16; citation_publication_date=2016; citation_pages=14-14; citation_id=CR48"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Visual topography of human intraparietal sulcus; citation_author=JD Swisher, MA Halko, LB Merabet, SA McMains, DC Somers; citation_volume=27; citation_publication_date=2007; citation_pages=5326-5337; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=The vertical occipital fasciculus: a century of controversy resolved by in vivo measurements; citation_author=JD Yeatman; citation_volume=111; citation_publication_date=2014; citation_pages=E5214-E5223; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci. Methods.; citation_title=PsychoPy&#8212;psychophysics software in Python; citation_author=JW Peirce; citation_volume=162; citation_publication_date=2007; citation_pages=8-13; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Defining the most probable location of the parahippocampal place area using cortex-based alignment and cross-validation; citation_author=KS Weiner; citation_volume=170; citation_publication_date=2018; citation_pages=373-384; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci. Methods.; citation_title=The first step for neuroimaging data analysis: DICOM to NIfTI conversion; citation_author=X Li, PS Morgan, J Ashburner, J Smith, C Rorden; citation_volume=264; citation_publication_date=2016; citation_pages=47-56; citation_id=CR53"/>
    <meta name="citation_reference" content="Fischl, B. FreeSurfer. NeuroImage 62, 774&#8211;781 (2012); 
                  https://doi.org/10.1016/j.neuroimage.2012.01.021
                  
                "/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain; citation_author=B Fischl; citation_volume=33; citation_publication_date=2002; citation_pages=341-355; citation_id=CR55"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Cortical surface-based analysis. I. Segmentation and surface reconstruction; citation_author=AM Dale, B Fischl, MI Sereno; citation_volume=9; citation_publication_date=1999; citation_pages=179-194; citation_id=CR56"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=SUMA; citation_author=ZS Saad, RC Reynolds; citation_volume=62; citation_publication_date=2012; citation_pages=768-773; citation_id=CR57"/>
    <meta name="citation_reference" content="citation_journal_title=Computers Biomed. Res.; citation_title=AFNI: software for analysis and visualization of functional magnetic resonance neuroimages; citation_author=RW Cox; citation_volume=29; citation_publication_date=1996; citation_pages=162-173; citation_id=CR58"/>
    <meta name="citation_reference" content="citation_journal_title=J. Appl. Math.; citation_title=Effective preprocessing procedures virtually eliminate distance-dependent motion artifacts in resting state FMRI; citation_author=HJ Jo; citation_volume=2013; citation_publication_date=2013; citation_pages=935154; citation_id=CR59"/>
    <meta name="citation_reference" content="citation_journal_title=J. Open Source Softw.; citation_title=TE-dependent analysis of multi-echo fMRI with *tedana*; citation_author=E DuPre; citation_volume=6; citation_publication_date=2021; citation_pages=3669; citation_id=CR60"/>
    <meta name="citation_reference" content="DuPre, E. et al. ME-ICA/tedana: 0.0.6. Zenodo 
                  https://doi.org/10.5281/ZENODO.2558498
                  
                 (2019)."/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Separating slow BOLD from non-BOLD baseline drifts using multi-echo fMRI; citation_author=JW Evans, P Kundu, SG Horovitz, PA Bandettini; citation_volume=105; citation_publication_date=2015; citation_pages=189-197; citation_id=CR62"/>
    <meta name="citation_reference" content="citation_journal_title=Hum. Brain Mapp.; citation_title=Simplified intersubject averaging on the cortical surface using SUMA; citation_author=BD Argall, ZS Saad, MS Beauchamp; citation_volume=27; citation_publication_date=2006; citation_pages=14-27; citation_id=CR63"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=An algorithmic method for functionally defining regions of interest in the ventral visual pathway; citation_author=JB Julian, E Fedorenko, J Webster, N Kanwisher; citation_volume=60; citation_publication_date=2012; citation_pages=2357-2364; citation_doi=10.1016/j.neuroimage.2012.02.055; citation_id=CR64"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Hum. Behav.; citation_title=Extensive childhood experience with Pok&#233;mon suggests eccentricity drives organization of visual cortex; citation_author=J Gomez, M Barnett, K Grill-Spector; citation_volume=3; citation_publication_date=2019; citation_pages=611-624; citation_doi=10.1038/s41562-019-0592-8; citation_id=CR65"/>
    <meta name="citation_reference" content="citation_journal_title=NeuroImage; citation_title=Development of population receptive fields in the lateral visual stream improves spatial coding amid stable structural-functional coupling; citation_author=J Gomez; citation_volume=188; citation_publication_date=2019; citation_pages=59-69; citation_id=CR66"/>
    <meta name="citation_reference" content="R Core Team. R: a language and environment for statistical computing (R Foundation for Statistical Computing, 2013); 
                  www.r-project.org/
                  
                "/>
    <meta name="citation_reference" content="Lawrence, M. A. ez: easy analysis and visualization of factorial experiments. R package version 4.0.2 (2016)."/>
    <meta name="citation_author" content="Steel, Adam"/>
    <meta name="citation_author_institution" content="Department of Psychology and Brain Sciences, Dartmouth College, Hanover, USA"/>
    <meta name="citation_author" content="Silson, Edward H."/>
    <meta name="citation_author_institution" content="Psychosophy, Psychology, and Language Sciences, University of Edinburgh, Edinburgh, UK"/>
    <meta name="citation_author" content="Garcia, Brenda D."/>
    <meta name="citation_author_institution" content="Department of Psychology and Brain Sciences, Dartmouth College, Hanover, USA"/>
    <meta name="citation_author" content="Robertson, Caroline E."/>
    <meta name="citation_author_institution" content="Department of Psychology and Brain Sciences, Dartmouth College, Hanover, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="A retinotopic code structures the interaction between perception and memory systems"/>
    <meta name="twitter:description" content="Nature Neuroscience - The authors show that functionally paired visual and memory brain areas share a common neural code, which structures their communication. This code is visual in nature and..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig1_HTML.png"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/s41593-023-01512-3"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="A retinotopic code structures the interaction between perception and memory systems - Nature Neuroscience"/>
    <meta property="og:description" content="The authors show that functionally paired visual and memory brain areas share a common neural code, which structures their communication. This code is visual in nature and uses a push&#8211;pull dynamic to translate information between vision and memory."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig1_HTML.png"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41593-023-01512-3;doi=10.1038/s41593-023-01512-3;subjmeta=1595,2613,2649,378,631;kwrd=Cognitive+neuroscience,Learning+and+memory,Neuroscience,Visual+system">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=-1503724313&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-023-01512-3%26doi%3D10.1038/s41593-023-01512-3%26subjmeta%3D1595,2613,2649,378,631%26kwrd%3DCognitive+neuroscience,Learning+and+memory,Neuroscience,Visual+system">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=-1503724313&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-023-01512-3%26doi%3D10.1038/s41593-023-01512-3%26subjmeta%3D1595,2613,2649,378,631%26kwrd%3DCognitive+neuroscience,Learning+and+memory,Neuroscience,Visual+system"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41593-023-01512-3'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6%26journal-link%3Dhttps%253A%252F%252Fwww.nature.com%252Fneuro%252F"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        A retinotopic code structures the interaction between perception and memory systems
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-023-01512-3.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2024-01-02">02 January 2024</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">A retinotopic code structures the interaction between perception and memory systems</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Adam-Steel-Aff1" data-author-popup="auth-Adam-Steel-Aff1" data-author-search="Steel, Adam" data-corresp-id="c1">Adam Steel<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide">Â 
            <a class="js-orcid" href="http://orcid.org/0000-0001-8876-933X"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0001-8876-933X</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup><sup class="u-js-hide">Â <a href="#na1">na1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Edward_H_-Silson-Aff2" data-author-popup="auth-Edward_H_-Silson-Aff2" data-author-search="Silson, Edward H.">Edward H. Silson</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup><sup class="u-js-hide">Â <a href="#na1">na1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Brenda_D_-Garcia-Aff1" data-author-popup="auth-Brenda_D_-Garcia-Aff1" data-author-search="Garcia, Brenda D.">Brenda D. Garcia</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 4 authors for this article" title="Show all 4 authors for this article">â€¦</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Caroline_E_-Robertson-Aff1" data-author-popup="auth-Caroline_E_-Robertson-Aff1" data-author-search="Robertson, Caroline E." data-corresp-id="c2">Caroline E. Robertson<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide">Â 
            <a class="js-orcid" href="http://orcid.org/0000-0002-1858-6594"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-1858-6594</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup>Â </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span>Â 27</b>,Â <span class="u-visually-hidden">pages </span>339â€“347 (<span data-test="article-publication-year">2024</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">6127 <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">270 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/s41593-023-01512-3/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/cognitive-neuroscience" data-track="click" data-track-action="view subject" data-track-label="link">Cognitive neuroscience</a></li><li class="c-article-subject-list__subject"><a href="/subjects/learning-and-memory" data-track="click" data-track-action="view subject" data-track-label="link">Learning and memory</a></li><li class="c-article-subject-list__subject"><a href="/subjects/neuroscience" data-track="click" data-track-action="view subject" data-track-label="link">Neuroscience</a></li><li class="c-article-subject-list__subject"><a href="/subjects/visual-system" data-track="click" data-track-action="view subject" data-track-label="link">Visual system</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Conventional views of brain organization suggest that regions at the top of the cortical hierarchy processes internally oriented information using an abstract amodal neural code. Despite this, recent reports have described the presence of retinotopic coding at the cortical apex, including the default mode network. What is the functional role of retinotopic coding atop the cortical hierarchy? Here we report that retinotopic coding structures interactions between internally oriented (mnemonic) and externally oriented (perceptual) brain areas. Using functional magnetic resonance imaging, we observed robust inverted (negative) retinotopic coding in category-selective memory areas at the cortical apex, which is functionally linked to the classic (positive) retinotopic coding in category-selective perceptual areas in high-level visual cortex. These functionally linked retinotopic populations in mnemonic and perceptual areas exhibit spatially specific opponent responses during both bottom-up perception and top-down recall, suggesting that these areas are interlocked in a mutually inhibitory dynamic. These results show that retinotopic coding structures interactions between perceptual and mnemonic neural systems, providing a scaffold for their dynamic interaction.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-023-01512-3.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-023-01512-3.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41586-024-07451-8/MediaObjects/41586_2024_7451_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41586-024-07451-8?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41586-024-07451-8">Mapping model units to visual neurons reveals population code for social behaviour
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">22 May 2024</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41586-024-07425-w/MediaObjects/41586_2024_7425_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41586-024-07425-w?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41586-024-07425-w">Volatile working memory representations crystallize with practice
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">15 May 2024</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41586-024-07349-5/MediaObjects/41586_2024_7349_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41586-024-07349-5?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41586-024-07349-5">Temporal multiplexing of perception and memory codes in IT cortex
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">15 May 2024</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'topic',
                        model: 'visits_v2',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1717184306,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>Understanding how mnemonic and sensory representations functionally interface in the brain while avoiding interference is a central puzzle in neuroscience<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Libby, A. &amp; Buschman, T. J. Rotational dynamics reduce interference between sensory and memory representations. Nat. Neurosci. 24, 715â€“726 (2021)." href="#ref-CR1" id="ref-link-section-d41748316e447">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kiyonaga, A., Scimeca, J. M., Bliss, D. P. &amp; Whitney, D. Serial dependence across perception, attention, and memory. Trends Cogn. Sci. 21, 493 (2017)." href="#ref-CR2" id="ref-link-section-d41748316e447_1">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Summerfield, C. &amp; de Lange, F. P. Expectation in perceptual decision making: neural and computational mechanisms. Nat. Rev. Neurosci. 15, 745â€“756 (2014)." href="#ref-CR3" id="ref-link-section-d41748316e447_2">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Rademaker, R. L., Chunharas, C. &amp; Serences, J. T. Coexisting representations of sensory and mnemonic information in human visual cortex. Nat. Neurosci. 22, 1336â€“1344 (2019)." href="#ref-CR4" id="ref-link-section-d41748316e447_3">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Favila, S. E., Lee, H. &amp; Kuhl, B. A. Transforming the concept of memory reactivation. Trends Neurosci. 43, 939â€“950 (2020)." href="/articles/s41593-023-01512-3#ref-CR5" id="ref-link-section-d41748316e450">5</a></sup>. Previous work has shown that representational interference can be reduced through operations including orthogonalization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Libby, A. &amp; Buschman, T. J. Rotational dynamics reduce interference between sensory and memory representations. Nat. Neurosci. 24, 715â€“726 (2021)." href="/articles/s41593-023-01512-3#ref-CR1" id="ref-link-section-d41748316e454">1</a></sup>, pattern separation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Yassa, M. A. &amp; Stark, C. E. L. Pattern separation in the hippocampus. Trends Neurosci. 34, 515â€“525 (2011)." href="/articles/s41593-023-01512-3#ref-CR6" id="ref-link-section-d41748316e458">6</a></sup> and areal segregation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Favila, S. E., Lee, H. &amp; Kuhl, B. A. Transforming the concept of memory reactivation. Trends Neurosci. 43, 939â€“950 (2020)." href="/articles/s41593-023-01512-3#ref-CR5" id="ref-link-section-d41748316e462">5</a></sup>. However, the principles that preserve interaction across mnemonic and perceptual populations are less clear.</p><p>This puzzle is particularly perplexing because classic models of brain organization assume that perceptual and mnemonic cortical areas do not share neural coding principles. For example, the neural code that structures visual information processing in the brain, retinotopy, is not thought to be shared by mnemonic cortex. Instead, it is thought that retinotopic coding is replaced by abstract amodal coding as information propagates through the visual hierarchy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Holmes, G. Disturbances of vision by cerebral lesions. Br. J. Ophthalmol. 2, 353â€“384 (1918)." href="#ref-CR7" id="ref-link-section-d41748316e469">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wandell, B. A., Dumoulin, S. O. &amp; Brewer, A. A. Visual field maps in human cortex. Neuron 56, 366â€“383 (2007)." href="#ref-CR8" id="ref-link-section-d41748316e469_1">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Guclu, U. &amp; van Gerven, M. A. J. Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream. J. Neurosci. 35, 10005â€“10014 (2015)." href="#ref-CR9" id="ref-link-section-d41748316e469_2">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Groen, I. I. A., Dekker, T. M., Knapen, T. &amp; Silson, E. H. Visuospatial coding as ubiquitous scaffolding for human cognition. Trends Cogn. Sci. &#xA;                  https://doi.org/10.1016/j.tics.2021.10.011&#xA;                  &#xA;                 (2022)." href="/articles/s41593-023-01512-3#ref-CR10" id="ref-link-section-d41748316e472">10</a></sup> toward memory structures at the cortical apex (for example, the default mode network (DMN))<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Popham, S. F. et al. Visual and linguistic semantic representations are aligned at the border of human visual cortex. Nat. Neurosci. 24, 1628â€“1636 (2021)." href="#ref-CR11" id="ref-link-section-d41748316e476">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Huntenburg, J. M., Bazin, P. L. &amp; Margulies, D. S. Large-scale gradients in human cortical organization. Trends Cogn. Sci. 22, 21â€“31 (2018)." href="#ref-CR12" id="ref-link-section-d41748316e476_1">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574â€“12579 (2016)." href="#ref-CR13" id="ref-link-section-d41748316e476_2">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Bellmund, J. L. S., GÃ¤rdenfors, P., Moser, E. I. &amp; Doeller, C. F. Navigating cognition: spatial codes for human thinking. Science (1979) 362, eaat6766 (2018)." href="/articles/s41593-023-01512-3#ref-CR14" id="ref-link-section-d41748316e479">14</a></sup>. How can visual and mnemonic information interact effectively in the brain if they are represented using fundamentally different neural codes?</p><p>Recent work has suggested that even high-level cortical areas, including the DMN, exhibit retinotopic coding: they contain visually evoked population receptive fields (pRFs) with inverted response amplitudes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e486">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e489">16</a></sup>. But the functional relevance of this retinotopic coding at the cortical apex remains unclear. Here we propose that the retinotopic code spanning levels of the cortical hierarchy links functionally coupled mnemonic and perceptual areas of the brain, structuring their interaction. We investigated this proposal in three functional magnetic resonance imaging (fMRI) experiments.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><p>We began by determining whether retinotopic coding was present in mnemonic and perceptual regions spanning levels of the cortical hierarchy. In Experiment (Exp.) 1, participants (<i>n</i>â€‰=â€‰17) underwent visual pRF mapping<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Dumoulin, S. O. &amp; Wandell, B. A. Population receptive field estimates in human visual cortex. Neuroimage 39, 647 (2008)." href="/articles/s41593-023-01512-3#ref-CR17" id="ref-link-section-d41748316e504">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Silson, E. H., Chan, A. W. Y., Reynolds, R. C., Kravitz, D. J. &amp; Baker, C. I. A retinotopic basis for the division of high-level scene processing between lateral and ventral human occipitotemporal cortex. J. Neurosci. 35, 11921â€“11935 (2015)." href="/articles/s41593-023-01512-3#ref-CR18" id="ref-link-section-d41748316e507">18</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig1">1a</a>) with advanced multi-echo fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Kundu, P., Inati, S. J., Evans, J. W., Luh, W. M. &amp; Bandettini, P. A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. Neuroimage 60, 1759â€“1770 (2012)." href="/articles/s41593-023-01512-3#ref-CR19" id="ref-link-section-d41748316e514">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Steel, A., Garcia, B. D., Silson, E. H. &amp; Robertson, C. E. Evaluating the efficacy of multi-echo ICA denoising on model-based fMRI. Neuroimage 264, 119723 (2022)." href="/articles/s41593-023-01512-3#ref-CR20" id="ref-link-section-d41748316e517">20</a></sup> to maximize signal-to-noise ratio and pRF model fitting in anterior regions of the temporal and parietal lobes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Steel, A., Garcia, B. D., Silson, E. H. &amp; Robertson, C. E. Evaluating the efficacy of multi-echo ICA denoising on model-based fMRI. Neuroimage 264, 119723 (2022)." href="/articles/s41593-023-01512-3#ref-CR20" id="ref-link-section-d41748316e521">20</a></sup>. As expected, an initial group-level whole-brain analysis revealed robust positive retinotopic responses extending from early- to high-level visual areas (positive visually evoked pRFs, +pRFs) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig1">1b</a>). We also observed robust and reliable pRFs beyond the anterior extent of known retinotopic maps<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Wang, L., Mruczek, R. E. B., Arcaro, M. J. &amp; Kastner, S. Probabilistic maps of visual topography in human cortex. Cereb. Cortex 25, 3911â€“3931 (2015)." href="/articles/s41593-023-01512-3#ref-CR21" id="ref-link-section-d41748316e529">21</a></sup> in the anterior ventral temporal and lateral parietal cortex, regions of the cortical apex historically considered amodal<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Huntenburg, J. M., Bazin, P. L. &amp; Margulies, D. S. Large-scale gradients in human cortical organization. Trends Cogn. Sci. 22, 21â€“31 (2018)." href="/articles/s41593-023-01512-3#ref-CR12" id="ref-link-section-d41748316e533">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574â€“12579 (2016)." href="/articles/s41593-023-01512-3#ref-CR13" id="ref-link-section-d41748316e536">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Thomas Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. J. Neurophysiol. 106, 1125â€“1165 (2011)." href="/articles/s41593-023-01512-3#ref-CR22" id="ref-link-section-d41748316e539">22</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig1">1b</a>). In striking contrast with classically defined visual areas, a large portion of these anterior voxels had pRFs with an inverted visual response (that is, negative visually evoked pRFs, âˆ’pRFs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e546">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e549">16</a></sup>). We will refer to voxels with positive or negative pRF response amplitudes as +/âˆ’pRFs, respectively. This agrees with prior studies that also observed âˆ’pRFs in the brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e553">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e556">16</a></sup>, but the functional relevance of this inverted retinotopic code is unknown<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Groen, I. I. A., Dekker, T. M., Knapen, T. &amp; Silson, E. H. Visuospatial coding as ubiquitous scaffolding for human cognition. Trends Cogn. Sci. &#xA;                  https://doi.org/10.1016/j.tics.2021.10.011&#xA;                  &#xA;                 (2022)." href="/articles/s41593-023-01512-3#ref-CR10" id="ref-link-section-d41748316e561">10</a></sup>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="pRF mapping reveals retinotopic coding throughout the posterior cortex, comprised of both positive- and negative-amplitude pRFs."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1: pRF mapping reveals retinotopic coding throughout the posterior cortex, comprised of both positive- and negative-amplitude pRFs.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="304"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p><b>a</b>, PRF paradigm and modeling. In Exp. 1, participants underwent pRF mapping. Participants viewed visual scenes through a bar aperture that gradually traversed the visual field. Each visual-field traversal lasted 36â€‰s (18â€‰Ã—â€‰2â€‰s positions), and the bar made eight traversals per run. The direction of motion varied between traversals. To estimate the pRF for each voxel, a synthetic time series is generated for 400 visual-field locations (200 <i>x</i> and <i>y</i> positions) and 100 sizes (sigma). This results in four million possible time series that are fit to each voxelâ€™s activity. The fit results in four parameters describing each receptive field: <i>x</i>, <i>y</i>, sigma and amplitude. <b>b</b>, Negative-amplitude pRFs fall anterior to the cortex typically considered visual (beyond known retinotopic maps). Group average (<i>n</i>â€‰=â€‰17) pRF amplitude map (threshold at explained variance <i>R</i>-squared (<i>R</i><sup>2</sup>) &gt;â€‰0.08) is shown on partially inflated representations of the left hemisphere, alongside ROIs: SPAs (OPA, PPA), PMAs (LPMA, VPMA) (localized in an independent group of participants<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e605">24</a></sup>) and the DMN<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Thomas Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. J. Neurophysiol. 106, 1125â€“1165 (2011)." href="/articles/s41593-023-01512-3#ref-CR22" id="ref-link-section-d41748316e609">22</a></sup>. The known retinotopic maps in the posterior cortex (black dotted outlines<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Wang, L., Mruczek, R. E. B., Arcaro, M. J. &amp; Kastner, S. Probabilistic maps of visual topography in human cortex. Cereb. Cortex 25, 3911â€“3931 (2015)." href="/articles/s41593-023-01512-3#ref-CR21" id="ref-link-section-d41748316e614">21</a></sup>) contain exclusively positive-amplitude pRFs (hot colors), as visual stimulation evokes positive retinotopically specific BOLD responses. Negative-amplitude pRFs (cool colors), where visual stimulation evokes a negative spatially specific BOLD response, arise anterior to these retinotopic maps in the PMAs and DMN (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig2">2a</a> for example time series from a representative subject).</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>At the group level, âˆ’pRFs only appeared beyond the anterior extent of known retinotopic maps<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Wang, L., Mruczek, R. E. B., Arcaro, M. J. &amp; Kastner, S. Probabilistic maps of visual topography in human cortex. Cereb. Cortex 25, 3911â€“3931 (2015)." href="/articles/s41593-023-01512-3#ref-CR21" id="ref-link-section-d41748316e632">21</a></sup>, in areas associated with the cortical apex, consistent with previous reports<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e636">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e639">16</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig1">1b</a>). This topographic profile of pRF amplitude was also evident at the single-participant level, with robust pRF responses present throughout posterior cerebral cortex and âˆ’pRFs emerging at the anterior edge of high-level visual cortex (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig7">1</a>). In general, these anterior pRFs were not arranged topographically on the cortical surface in a manner that recapitulates the layout of the retina (that is, did not constitute â€˜retinotopic mapsâ€™). However, these âˆ’pRFs were robust and reliable within individuals: a half-split analysis (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-023-01512-3#Sec4">Methods</a>) confirmed that, for all regions of interest (ROIs), more than 78% of pRFs had consistent signed amplitude (that is, positive or negative), and these pRF amplitudes (all <i>R</i>â€‰&gt;â€‰0.1, <i>P</i>â€‰&lt;â€‰0.001) and visual-field-coverage maps (all Dice coefficientsâ€‰&gt;â€‰0.12, <i>P</i>â€‰&lt;â€‰0.04, Cohenâ€™s <i>D</i>â€‰&gt;â€‰0.54) were all highly reproducible across splits. Importantly, these anterior âˆ’pRF populations on the ventral and lateral surfaces are distinct from the population of âˆ’pRFs observed on the medial wall in peripheral early visual areas, which arise from stimulation outside the pRF (that is, surround suppression)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e665">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Shmuel, A. et al. Sustained negative BOLD, blood flow and oxygen consumption response and its coupling to the positive response in the human brain. Neuron 36, 1195â€“1210 (2002)." href="/articles/s41593-023-01512-3#ref-CR23" id="ref-link-section-d41748316e668">23</a></sup>.</p><p>If the functional role of the inverted retinotopic code at the cortical apex is structuring interactions with perceptual areas, we hypothesized that âˆ’pRFs would concentrate in mnemonic, as compared with perceptual, functional areas. Consistent with this prediction, at the group level, we observed that âˆ’pRFs tended to fall within swaths of cortex that selectively responded during top-down recall of familiar places, place memory areas (PMAs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e675">24</a></sup>) on the lateral and ventral surfaces (LPMA and VPMA, respectively) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig1">1b</a>). These two mnemonic areas each lie immediately anterior to one of the scene perception areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Hasson, U., Levy, I., Behrmann, M., Hendler, T. &amp; Malach, R. Eccentricity bias as an organizing principle for human high-order object areas. Neuron 34, 479â€“490 (2002)." href="/articles/s41593-023-01512-3#ref-CR25" id="ref-link-section-d41748316e682">25</a></sup> (SPAs) of the human brain (occipital place area (OPA)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Hasson, U., Levy, I., Behrmann, M., Hendler, T. &amp; Malach, R. Eccentricity bias as an organizing principle for human high-order object areas. Neuron 34, 479â€“490 (2002)." href="/articles/s41593-023-01512-3#ref-CR25" id="ref-link-section-d41748316e686">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Dilks, D. D., Julian, J. B., Paunov, A. M. &amp; Kanwisher, N. The occipital place area is causally and selectively involved in scene perception. J. Neurosci. 33, 1331â€“1336 (2013)." href="/articles/s41593-023-01512-3#ref-CR26" id="ref-link-section-d41748316e689">26</a></sup> and parahippocampal place area (PPA)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Epstein, R. &amp; Kanwisher, N. A cortical representation the local visual environment. Nature 392, 598â€“601 (1998)." href="/articles/s41593-023-01512-3#ref-CR27" id="ref-link-section-d41748316e693">27</a></sup>). In contrast to the PMAs, the SPAs tended to contain +pRFs.</p><p>We confirmed this observation in individual participants by calculating the percentage of +/âˆ’pRFs within individually localized SPAs and PMAs (lateral: OPA, LPMA; ventral: PPA, VPMA) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig2">2a</a>, <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-023-01512-3#Sec4">Methods</a>) to better understand their nuanced functional topography<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e706">24</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig2">2a</a> and Extended Data Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig7">1</a>â€“<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig9">3</a>). This analysis confirmed that, unlike the perceptual SPAs, which almost exclusively contained +pRFs, the mnemonic PMAs contained a significant percentage of âˆ’pRFs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig2">2b</a>) (two-way repeated measures analysis of variance (rmANOVA), main effect of ROI (<i>F</i>(1,16)â€‰=â€‰85.83, <i>P</i>â€‰&lt;â€‰0.0001); ROI: hemisphere interaction (<i>F</i>(1,16)â€‰=â€‰11.24, <i>P</i>â€‰=â€‰0.004)); post hoc tests: left hemisphere: OPA versus LPMA <i>t</i>(16)â€‰=â€‰10.74, <i>P</i><sub>corrected</sub>â€‰(<i>P</i><sub>corr</sub>) =â€‰0.000002, <i>D</i>â€‰=â€‰3.43); right hemisphere: OPA versus LPMA <i>t</i>(16)â€‰=â€‰5.97, <i>P</i><sub>corr</sub>â€‰=â€‰0.00002, <i>D</i>â€‰=â€‰1.89)). On the ventral surface, the effect of greater âˆ’pRFs in the PMAs versus SPAs was generally stronger in the left compared to the right hemisphere (two-way rmANOVA, main effect of ROI (<i>F</i>(1,16)â€‰=â€‰10.01, <i>P</i>â€‰=â€‰0.006); no ROI: hemisphere interaction (<i>F</i>(1,16)â€‰=â€‰3.12, <i>P</i>â€‰=â€‰0.09); left hemisphere: PPA versus VPMA (<i>t</i>(16)â€‰=â€‰2.62, <i>P</i><sub>corr</sub>â€‰=â€‰0.02, <i>D</i>â€‰=â€‰0.94); right hemisphere: PPA versus VPMA (<i>t</i>(16)â€‰=â€‰2.57, <i>P</i><sub>corr</sub>â€‰=â€‰0.04, <i>D</i>â€‰=â€‰0.90)). It should be noted that in many subjects, the PMAs contained both âˆ’pRF and +pRF subpopulations. Both +/âˆ’pRFs within each memory area showed overall positive activation during a memory recall task (<i>t</i>-test versus zero: âˆ’LPMA versus +LPMA (<i>t</i>(16)â€‰=â€‰17.67, <i>P</i>â€‰=â€‰6.35â€“12, <i>D</i>â€‰=â€‰4.28); âˆ’VPMA versus +VPMA (<i>t</i>(11)â€‰=â€‰12.43, <i>P</i>â€‰=â€‰5.89â€“9, <i>D</i>â€‰=â€‰2.31); âˆ’LPMA versus +LPMA (<i>t</i>(16)â€‰=â€‰0.44, <i>P</i>â€‰=â€‰0.65, <i>D</i>â€‰=â€‰0.04); âˆ’VPMA versus +VPMA (<i>t</i>(11)â€‰=â€‰0.26, <i>P</i>â€‰=â€‰0.79, <i>D</i>â€‰=â€‰0.07) (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig10">4</a>)). This suggests the +/âˆ’pRF subpopulations in the PMAs are comparably engaged in memory recall, although they show opposite response profiles to visual stimulation. Importantly, these results of a higher proportion of âˆ’pRFs in the PMAs versus the SPAs held across a wide range of pRF <i>R</i><sup>2</sup> thresholds (<i>R</i><sup>2</sup>â€‰&gt;â€‰0.05 to <i>R</i><sup>2</sup>â€‰&gt;â€‰0.20). Taking these all together, these results show that âˆ’pRFs are disproportionately represented in category-selective mnemonic areas (PMAs), as compared with their perceptual counterparts (SPAs).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Transition to mnemonic cortex is marked by the appearance of negative pRFs."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2: Transition to mnemonic cortex is marked by the appearance of negative pRFs.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="240"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p><b>a</b>, PRF modeling reveals posteriorâ€“anterior inversion of pRF amplitude in individual participants. Left, PRF amplitude for a representative participant overlaid onto a lateral view of the left hemisphere (threshold at <i>R</i><sup>2</sup>â€‰&gt;â€‰0.15; see Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig7">1</a> for example ventral and lateral surface pRF amplitude maps from all participants and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig9">3</a> for amplitude maps with default mode parcellation overlaid). Posterior visual cortex is dominated by positive-amplitude pRFs (hot colors), while cortex anterior to regions classically considered visual exhibits a high concentration of negative-amplitude pRFs (cold colors). This individualâ€™s OPA and LPMA are shown in white. Both the SPAs and PMAs contain pRFs (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig8">2</a>). Right, time-series, model fits and reconstructed pRFs for two surface vertices in this subject. Top, example prototypical positive-amplitude pRF from the lateral SPA (OPA) in the left and right hemispheres (LH, RH). Bottom, example negative-amplitude population receptive field from the LPMA. <b>b</b>, Memory areas (PMAs) contain a larger percentage of negative pRFs compared to perceptual areas (SPAs) (repeated measures ANOVA, Bonferroni-corrected <i>t</i>-tests). Blue bars depict percentage of negative pRFs from individually localized SPAs and PMAs compared to total pRFs in the area (dotted outline). On the ventral and lateral surfaces, SPAs are dominated by positive pRFs, whereas a transition from positive to negative pRFs is evident within PMAs. Individual participant data points overlaid and connected in gray. *<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.05, ***<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.001. NS, not significant.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>It should be noted that both +pRFs and âˆ’pRFs in the PMAs tended to be smaller than +pRFs in the SPAs on both surfaces (lateral surface: main effect of ROI (<i>F</i>(2,32)â€‰=â€‰10.27, <i>P</i>â€‰=â€‰0.0003); (OPA versus +pRFs in LPMA: <i>t</i>(16)â€‰=â€‰5.61, <i>P</i><sub>corrâ€‰</sub>=â€‰0.0001, <i>D</i>â€‰=â€‰1.83); (OPA versus âˆ’pRFs in LPMA: <i>t</i>(16)â€‰=â€‰2.59, <i>P</i><sub>corr</sub>â€‰=â€‰0.01, <i>D</i>â€‰=â€‰1.31); (ventral surface (<i>F</i>(2,22)â€‰=â€‰15.46 <i>P</i>â€‰=â€‰0.000006); (PPA versus +VPMA: <i>t</i>(11)â€‰=â€‰2.83, <i>P</i><sub>corr</sub>â€‰=â€‰0.03, <i>D</i>â€‰=â€‰0.99); (PPA versus âˆ’VPMA: <i>t</i>(11)â€‰=â€‰5.43, <i>P</i><sub>corr</sub>â€‰=â€‰0.00006, <i>D</i>â€‰=â€‰1.85)). PRF sizes were not significantly different between +/âˆ’pRFs in LPMA (<i>t</i>(16)â€‰=â€‰1.52, <i>P</i><sub>corr</sub>â€‰=â€‰0.14, <i>D</i>â€‰=â€‰0.48), but on the ventral surface +pRFs in VPMA were significantly larger than âˆ’pRFs in VPMA (<i>t</i>(11)â€‰=â€‰2.87, <i>P</i><sub>corr</sub>â€‰=â€‰0.03, <i>D</i>â€‰=â€‰1.06). This result of smaller pRFs in the PMAs compared with the SPAs is particularly notable, as it runs counter to the typical pattern of pRFs becoming larger moving anteriorly from early visual areas toward higher-level brain regions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Wandell, B. A., Dumoulin, S. O. &amp; Brewer, A. A. Visual field maps in human cortex. Neuron 56, 366â€“383 (2007)." href="/articles/s41593-023-01512-3#ref-CR8" id="ref-link-section-d41748316e982">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Dumoulin, S. O. &amp; Wandell, B. A. Population receptive field estimates in human visual cortex. Neuroimage 39, 647 (2008)." href="/articles/s41593-023-01512-3#ref-CR17" id="ref-link-section-d41748316e985">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Breedlove, J. L., St-Yves, G., Olman, C. A. &amp; Naselaris, T. Generative feedback explains distinct brain activity codes for seen and mental images. Curr. Biol. &#xA;                  https://doi.org/10.1016/j.cub.2020.04.014&#xA;                  &#xA;                 (2020)." href="/articles/s41593-023-01512-3#ref-CR28" id="ref-link-section-d41748316e988">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Favila, S. E., Kuhl, B. A. &amp; Winawer, J. Perception and memory have distinct spatial tuning properties in human visual cortex. Nat. Commun. 13, 5864 (2022)." href="/articles/s41593-023-01512-3#ref-CR29" id="ref-link-section-d41748316e991">29</a></sup>. Although it is not clear how the additional spatial precision manifests in these anterior, this result suggests that the PMAs could potentially represent highly specific information even compared to their perceptual counterparts (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig3">3</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Memory areas contain smaller pRFs compared to their paired perceptual areas."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3: Memory areas contain smaller pRFs compared to their paired perceptual areas.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="273"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Left, group average pRF size with memory areas and perception areas overlaid. Nodes are threshold at <i>R</i><sup>2</sup>â€‰&gt;â€‰0.08. Right, bars represent the mean pRF size for +pRFs in SPAs (OPA, PPA) and +/âˆ’pRFs in PMAs (LPMA, VPMA). Individual data points are shown for each participant. Across both surfaces, pRFs were significantly smaller on average in the PMAs than their perceptual counterparts (repeated measures ANOVA, Bonferroni-corrected <i>t</i>-tests). *<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.05, ***<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.001.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>The enriched concentration of âˆ’pRFs in mnemonic (PMA) compared with perceptual (SPA) areas led to a specific hypothesis regarding their functional role. The PMAs are thought to act as a bridge between the perceptual SPAs and the spatio-mnemonic system in the medial temporal lobe<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1036">24</a></sup>, but the format for sharing information between these systems is not clear. We hypothesized that retinotopic coding could serve as a shared substrate to scaffold the interaction between perceptual and mnemonic systems. If this proposal is correct, we should observe evidence for a functional interaction between these areas that depends on retinotopic position. We explored three tests of this hypothesis: (1) Do paired +/âˆ’pRFs represent similar portions of the visual field (Exp. 1)? (2) Do the +/âˆ’pRFs identified during visual stimulation maintain their opponent activation profiles during top-down memory recall (Exp. 2). (3) Is the functional link between +/âˆ’pRFs recapitulated when viewing familiar scene images (Exp. 3)?</p><p>Next, we reasoned that if the retinotopic code scaffolds communication between perceptual and mnemonic systems, âˆ’pRFs within mnemonic areas should exhibit the same differential visual-field biases as their perceptual counterparts<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Silson, E. H., Chan, A. W. Y., Reynolds, R. C., Kravitz, D. J. &amp; Baker, C. I. A retinotopic basis for the division of high-level scene processing between lateral and ventral human occipitotemporal cortex. J. Neurosci. 35, 11921â€“11935 (2015)." href="/articles/s41593-023-01512-3#ref-CR18" id="ref-link-section-d41748316e1043">18</a></sup>. Visual-field representations in OPA and PPA are biased toward the lower and upper visual fields, respectively. Do +/âˆ’pRFs in their respective PMAs share these biases? Using pRF data (Exp. 1), we calculated visual-field-coverage estimates for each pRF population (+pRFs in SPAs, +pRFs and âˆ’pRFs in PMAs). Consistent with earlier reports, we found that OPA and PPA showed lower and upper field biases, respectively (elevation bias OPA versus PPA: <i>t</i>(16)â€‰=â€‰2.42, <i>P</i>â€‰=â€‰0.02, <i>D</i>â€‰=â€‰0.98) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig4">4a</a>). Critically, we found that the visual-field representations of the âˆ’pRFs in memory areas closely matched their paired perceptual counterparts (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig4">4b</a>). âˆ’pRFs in LPMA were biased toward the lower visual field (matching OPA), whereas âˆ’pRFs in VPMA were biased toward the upper visual field (matching PPA) (elevation bias âˆ’LPMA versus âˆ’VPMA: <i>t</i>(11)â€‰=â€‰4.53, <i>P</i>â€‰=â€‰0.0008, <i>D</i>â€‰=â€‰0.94). By contrast, the +pRF populations in LPMA/VPMA did not show biases that corresponded to their perceptual counterparts: +pRFs in LPMA were biased toward the upper visual field, the opposite of OPA, and +pRFs in VPMA showed no clear elevation bias (elevation bias +LPMA versus +VPMA: <i>t</i>(16)â€‰=â€‰2.78, <i>P</i>â€‰=â€‰0.01, <i>D</i>â€‰=â€‰0.65). These data show that the âˆ’pRFs in the PMAs represent similar visual-field locations as their paired SPAs, and, based on the known functional interaction between the paired PMAs and SPAs during scene processing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1082">24</a></sup>, we suggest that the visual-field representation may be, in part, inherited from feedforward connections originating in the SPAs.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Shared visual-field representations between paired perception and memory areas."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4: Shared visual-field representations between paired perception and memory areas.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="614"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p><b>a</b>, Ventral and lateral SPAs/PMAs differentially represent the upper (ventral areas) and lower (lateral areas) visual fields. Group visual-field-coverage plots for SPAs and PMAs. The <i>x</i>-axis represents ipsilateral to contralateral visual field (aligned across hemispheres) while the <i>y-</i>axis represents elevation. All regions show the expected contralateral visual-field bias. <b>b</b>, With respect to elevation, SPAs differentially represent the lower (OPA) and upper (PPA) visual field, respectively (left column). The same differential representation of the lower and upper visual fields is evident for âˆ’pRFs in LPMA and VPMA (middle column) but not for +pRFs in these areas (right column). The elevation biases are quantified in <b>b</b> and compared using paired-sample <i>t</i>-tests. Bars represent average visual-field coverage for contralateral upper versus lower visual field (UVFâ€“LVF) with individual participant data points overlaid. *<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.05, ***<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.01.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>If, as hypothesized, +/âˆ’pRF populations reflect bottom-up sensory and top-down internal mnemonic processes, we predicted that the sign of the spatially specific opponent interactions observed during visual mapping (Exp. 1) would reverse during a top-down memory paradigm. Exp. 1 showed that when activity was high in +pRFs within the SPAs, activity was low in âˆ’pRFs within the PMAs. By contrast, we hypothesized that during a recall task, when âˆ’pRF activity would be high, +pRF activity would be low. To test for this competitive interaction during recall, in Exp. 2, we examined the activation profile of +/âˆ’pRFs during a place memory task, wherein participants recalled personally familiar visual environments (for example, their kitchen (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig5">5a</a>)). For this analysis, we first partitioned LPMA and VPMA into their +pRF and âˆ’pRF populations, respectively. Then, for each subject, we calculated the average activity (activation values versus baseline) from each of the 36 trials of the memory task for each population and ROI (for example, âˆ’pRFs in the PMA, +pRFs in the SPA) and <i>z</i>-scored the activation values in each ROI. We compared the <i>z</i>-scored values using a partial correlation between the âˆ’pRF/+pRFs in the PMAs and the SPAs (for example, correlation between âˆ’pRFs in LPMA with +pRFs in OPA, while controlling for +pRFs in LPMA, and vice versa) for each subject. Partial correlation allowed us to compare the unique impact of these distinct neural populations, while simultaneously controlling for non-specific effects (like motion and attention) that impact beta estimates on each trial. We compared the partial correlation values from the different pRF populations (that is, âˆ’LPMAâ€‰Ã—â€‰OPA versus +LPMAâ€‰Ã—â€‰OPA) for all subjects using paired <i>t</i>-tests separately for the lateral and ventral surfaces.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Positive pRFs in SPAs and negative pRFs in PMAs exhibit a spatially specific pushâ€“pull dynamic during memory recall."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5: Positive pRFs in SPAs and negative pRFs in PMAs exhibit a spatially specific pushâ€“pull dynamic during memory recall.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="557"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p><b>a</b>, In Exp. 2, participants visually recalled personally familiar places for 10â€‰s (cued with stimulus name; 36 trials per participant), and we calculated activation versus baseline at each trial. <b>b</b>, Negative and positive pRF (âˆ’pRF, +pRF) populations in SPAs and PMAs exhibit an opponent interaction during recall. Correlation in trialâ€‰Ã—â€‰trial activation of pRFs in SPAs was compared with +/âˆ’pRFs in PMAs using paired-sample <i>t</i>-tests. On both the lateral and ventral surfaces, when the activity of âˆ’pRFs in the PMA is high, activity in the corresponding SPA is reduced. By contrast, when activity in +pRFs in a PMA is high, activity in the adjacent SPA is also high. Inset, scatter plots show normalized trial-wise activation of each region for all trials in all participants. <b>c</b>, Schematic of pRF matching between OPA with âˆ’pRFs in LPMA. Schematic pRFs are depicted as circles. The OPA pRF is shown in orange, along with its best matched âˆ’pRF in LPMA (shown in dark blue) and randomly matched âˆ’pRF in LPMA (light blue). Inset, the histogram indicates the Dice coefficients for iterative matching between OPA pRFs and randomly paired pRFs from LPMA (light blue) compared to matched âˆ’pRFs from LPMA (dark blue) for one example participant, showing better correspondence between matched and random â€˜unmatchedâ€™ pRFs. This pattern was consistent in all participants. <b>d</b>,<b>e</b>, Matched pRFs had a significantly stronger association in trialâ€‰Ã—â€‰trial activation than unmatched pRFs on the lateral (<b>d</b>) and ventral (<b>e</b>) surfaces, which suggests that the interaction between the perceptual and memory areas is spatially specific (paired <i>t</i>-tests) *<i>P</i><sub>two-tailed</sub>&lt;â€‰0.05, **<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.01, ***<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.001.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>As predicted, we observed an opponent relationship between activation of the âˆ’pRFs in the PMAs and the +pRFs in the SPAs during the place memory recall task (âˆ’LPMAâ€‰Ã—â€‰OPA versus +LPMAâ€‰Ã—â€‰OPA: <i>t</i>(16)â€‰=â€‰3.10, <i>P</i>â€‰=â€‰0.0006, <i>D</i>â€‰=â€‰1.52; âˆ’VPMAâ€‰Ã—â€‰PPA versus +VPMA Ã— PPA: <i>t</i>(11)â€‰=â€‰5.27, <i>P</i>â€‰&lt;â€‰0.0001, <i>D</i>â€‰=â€‰2.98). In trials where the activity of âˆ’pRFs in PMAs was high, SPA activation was reduced (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig5">5b</a>) (<i>t</i>-test versus zero:â€‰lateral (<i>t</i>(16)â€‰=â€‰âˆ’2.19, <i>P</i>â€‰=â€‰0.04, <i>D</i>â€‰=â€‰0.53); ventral (<i>t</i>(11)â€‰=â€‰âˆ’3.63, <i>P</i>â€‰=â€‰0.003, <i>D</i>â€‰=â€‰1.04). By contrast, the +pRFs in the PMAs did not show a pushâ€“pull dynamic: on trials where activity of +pRFs in the PMA was high, activation of the SPA also increased (<i>t</i>-test versus zero: lateral (<i>t</i>(16)â€‰=â€‰3.76, <i>P</i>â€‰=â€‰0.001, <i>D</i>â€‰=â€‰1.69); ventral (<i>t</i>(11)â€‰=â€‰5.88, <i>P</i>â€‰=â€‰0.0001, <i>D</i>â€‰=â€‰1.69) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig5">5b</a>). We found a similar pattern when we considered all trials from all subjects pooled together (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig5">5b</a> insets and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig11">5</a>), and we replicated this effect in an independently collected dataset (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig12">6</a>).</p><p>Is the interaction between perceptual and mnemonic spatially specific? Importantly, if the interaction between the PMAs and SPAs is structured by a retinotopic code, we expect that the opponent dynamic between âˆ’pRFs in the PMAs with +pRFs in the SPAs would be stronger between pRFs representing shared regions of visual space. To test this, we again compared the partial correlation in trialâ€‰Ã—â€‰trial activation between +/âˆ’pRFs of the perception and memory areas, this time focusing on subpopulations of +/âˆ’pRFs with matched (versus unmatched) visual-field representations (in <i>x</i>, <i>y</i> and sigma) (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-023-01512-3#Sec4">Methods</a> and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig5">5c</a>). Because of our stringent pRF matching criteria (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-023-01512-3#Sec4">Methods</a>), the overall number of subjects included in this analysis was reduced (lateral: <i>n</i>â€‰=â€‰14; ventral: <i>n</i>â€‰=â€‰7).</p><p>This analysis revealed that the inhibitory interaction between âˆ’pRFs in PMAs and +pRFs in SPAs is structured by a retinotopic code (that is, spatially specific) (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig5">5d,e</a>). The opponent relationship between âˆ’pRF activation in the PMAs and matched +pRF activation in the SPAs was significant on both the lateral (<i>F</i>(1,13)â€‰=â€‰16.45, <i>P</i>â€‰=â€‰0.0013) and ventral (<i>F</i>(1,6)â€‰=â€‰10.93, <i>P</i>â€‰=â€‰0.016) surfaces, reflecting the fact that âˆ’pRFs in PMAs exhibit a negative relationship with spatially matched SPAs, whereas +pRFs in PMAs show a positive relationship with spatially matched SPAs. It should be noted that this relationship was modulated by matching on the lateral (amplitudeâ€‰Ã—â€‰matching: <i>F</i>(1,13)â€‰=â€‰4.64, <i>P</i>â€‰=â€‰0.05) and ventral (amplitudeâ€‰Ã—â€‰matching: <i>F</i>(1,6)â€‰=â€‰5.96, <i>P</i>â€‰=â€‰0.05) surfaces. On the lateral surface, when trialâ€‰Ã—â€‰trial activity in SPA was high, activity in spatially matched PMA âˆ’pRFs was relatively low (matched versus zero: <i>t</i>(13)â€‰=â€‰2.73, <i>P</i>â€‰=â€‰0.017, <i>D</i>â€‰=â€‰0.75), and this anticorrelation was significantly stronger for matched versus unmatched âˆ’pRFs (<i>t</i>(13)â€‰=â€‰2.48, <i>P</i>â€‰=â€‰0.027, <i>D</i>â€‰=â€‰1.01). On the ventral surface, a similar pattern was observed despite the small number of participants, but it did not reach significance (matched versus zero: <i>t</i>(6)â€‰=â€‰1.83, <i>P</i>â€‰=â€‰0.11, <i>D</i>â€‰=â€‰0.76; matched versus unmatched: <i>t</i>(6)â€‰=â€‰2.06, <i>P</i>â€‰=â€‰0.08, <i>D</i>â€‰=â€‰1.28). By contrast, for +pRFs in the PMAs, we observed a positive correlation with spatially matched versus unmatched +pRFs in the SPAs (lateral matched versus zero: <i>t</i>(13)â€‰=â€‰4.16, <i>P</i>â€‰=â€‰0.0011, <i>D</i>â€‰=â€‰1.15; ventral matched versus zero: <i>t</i>(6)â€‰=â€‰3.41, <i>P</i>â€‰=â€‰0.014, <i>D</i>â€‰=â€‰1.37). These data show that the spatially specific opponent relationship between âˆ’pRFs in the PMAs and +pRFs in the SPAs evidenced during bottom-up visual stimulation (that is, pRF mapping in Exp. 1) is reversed during top-down memory recall, revealing a pushâ€“pull dynamic between +/âˆ’pRFs that represent similar regions of visual space.</p><p>Although the spatially specific pushâ€“pull dynamic observed between +/âˆ’pRFs during both perception (Exp. 1) and recall (Exp. 2) is compelling, these two tasks represent situations wherein activation of the visual and memory systems should be maximally opposed (that is, focusing attention externally on a visual stimulus versus focusing attention internally during visual recall). Do âˆ’pRFs in the PMAs and +pRFs in the SPAs interact in a mutually inhibitory fashion in contexts where perceptual and memory systems are expected to interact, such as during familiar scene perception? As a final test of the interaction between the SPA and PMA pRFs, we asked whether the mutually inhibitory interaction between âˆ’pRFs in the PMAs and +pRFs in the SPAs is evident when participants view images of locations that were familiar to them in real life. We tested two possible hypotheses. On the one hand, processing familiar scenes could be mutually excitatory for both the memory and perception areas, resulting in a positive trialâ€‰Ã—â€‰trial relationship between the SPAs and both +pRFs and âˆ’pRFs in PMAs. On the other hand, the opponent interaction might persist if the SPAs and âˆ’pRFs in the PMAs were interlocked in a mutually inhibitory relationship, like predictive coding<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Bastos, A. M. et al. Canonical microcircuits for predictive coding. Neuron 76, 695â€“711 (2012)." href="/articles/s41593-023-01512-3#ref-CR30" id="ref-link-section-d41748316e1406">30</a></sup>.</p><p>For this experiment (Exp. 3), a subset of participants (<i>n</i>â€‰=â€‰8) passively viewed portions of images (lower left and right quadrants) of recognizable Dartmouth College landmarks (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig6">6a</a>). We focused on the lateral surface (OPA and LPMA) because âˆ’pRFs could be localized most robustly in LPMA in our main sample of participants. Familiar scene stimuli were presented in the lower quadrants to maximally stimulate OPA and LPMA, and we specifically considered +/âˆ’pRFs with centers in the contralateral lower visual field. For this analysis, we tested whether the âˆ’pRFs in LPMA and +pRFs in OPA are correlated or anticorrelated during familiar scene perception. We hypothesized that activation of +pRFs in OPA would be inversely related to activation of âˆ’pRFs in LPMA, consistent with a mutually inhibitory interaction. In addition, we predicted that this interaction would be spatially specific: the inhibitory dynamic should be stronger when visual information was presented in the contralateral lower visual field, that is, preferred quadrant, relative to the ipsilateral lower visual field, that is, non-preferred quadrant. It should be noted that this is a coarser test of spatial specificity than that presented in Exp. 2 due to both the size of the stimuli presented in Exp. 3 and the comparison of preferred versus non-preferred quadrants (Exp. 3) as compared to matched versus unmatched individual pRFs (Exp. 2).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Positive pRFs in SPAs and negative pRFs in PMAs exhibit a pushâ€“pull dynamic during perception of familiar scene images."><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6: Positive pRFs in SPAs and negative pRFs in PMAs exhibit a pushâ€“pull dynamic during perception of familiar scene images.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="322"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Left, in Exp. 3, participants passively viewed portions of images depicting two familiar Dartmouth College landmarks in the lower visual field. We investigated the trialâ€‰Ã—â€‰trial correlation in activation between +pRFs in OPA and +/âˆ’pRFs in LPMA. Right, âˆ’pRFs in LPMA exhibit an opponent interaction with +pRFs in OPA. Six out of eight participants exhibited a negative correlation between these pRF populations, and this relationship was significantly stronger when stimuli were presented in the contralateral compared to ipsilateral visual field (repeated measures ANOVA, paired <i>t</i>-tests). By contrast, activation of the +pRFs in LPMA was significantly positive for both contralateral and ipsilateral visual-field presentations. *<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.05, ***<i>P</i><sub>two-tailed</sub>â€‰&lt;â€‰0.001.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-023-01512-3/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We found that a spatially specific inhibitory interaction between +pRFs in OPA and âˆ’pRFs in LPMA persists during familiar scene viewing (interaction between visual field and pRF association: <i>F</i>(1,7)â€‰=â€‰8.27, <i>P</i>â€‰=â€‰0.02; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig6">6</a>, Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig13">7</a>). The trialâ€‰Ã—â€‰trial opponent dynamic between OPA pRFs, and âˆ’pRFs and +pRFs in the PMAs differed by visual field (<i>t</i>(7)â€‰=â€‰2.79, <i>P</i>â€‰=â€‰0.026, <i>D</i>â€‰=â€‰0.98). As we observed in recall, this dynamic was driven by the opposing sign of the relationship between pRFs in OPA with +/âˆ’pRFs in LPMA. We found that the relationship between pRFs in OPA and âˆ’pRFs in LPMA was negative in six out of eight participants in the contralateral visual field, and the strength of the negative association between OPA and âˆ’pRF activity for stimuli in the contralateral visual field was significantly stronger than the ipsilateral visual field (<i>t</i>(7)â€‰=â€‰2.71, <i>P</i>â€‰=â€‰0.03, <i>D</i>â€‰=â€‰0.95). By contrast, the relationship between OPA and +pRFs in LPMA was positive in eight out of eight participants, and was numerically stronger for the contralateral hemifield (<i>t</i>(7)â€‰=â€‰1.75, <i>P</i>â€‰=â€‰0.12, <i>D</i>â€‰=â€‰0.62). Together, the opposing responses during visual stimulation (Exp. 1 and 3) and during recall (Exp. 2) strongly suggest that the spatially specific, mutually inhibitory interaction between âˆ’pRFs in mnemonic regions and +pRFs in perceptual regions is a generalizable description of their interaction that extends to naturalistic contexts, like familiar scene perception.</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Discussion</h2><div class="c-article-section__content" id="Sec3-content"><p>In this study we observe that a shared retinotopic code between externally oriented (perceptual) and internally oriented (mnemonic) areas of the brain structures their mutual activity, such that pRFs representing similar areas in visual space have highly anticorrelated activation during both bottom-up scene perception and also top-down memory recall. Together with recent reports showing retinotopic coding persisting as far as the â€˜cortical apexâ€™<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e1502">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e1505">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Knapen, T. Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain. Proc. Natl Acad. Sci. USA 118, e2017032118 (2021)." href="/articles/s41593-023-01512-3#ref-CR31" id="ref-link-section-d41748316e1508">31</a></sup>, including the DMN<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e1512">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e1515">16</a></sup>, and the hippocampus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Knapen, T. Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain. Proc. Natl Acad. Sci. USA 118, e2017032118 (2021)." href="/articles/s41593-023-01512-3#ref-CR31" id="ref-link-section-d41748316e1519">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Silson, E. H., Zeidman, P., Knapen, T. &amp; Baker, C. I. Representation of contralateral visual space in the human hippocampus. J. Neurosci. 41, 2382â€“2392 (2021)." href="/articles/s41593-023-01512-3#ref-CR32" id="ref-link-section-d41748316e1522">32</a></sup>, our findings challenge conventional views of brain organization, which generally assume that retinotopic coding is replaced by abstract amodal coding as information propagates through the visual hierarchy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Holmes, G. Disturbances of vision by cerebral lesions. Br. J. Ophthalmol. 2, 353â€“384 (1918)." href="#ref-CR7" id="ref-link-section-d41748316e1526">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wandell, B. A., Dumoulin, S. O. &amp; Brewer, A. A. Visual field maps in human cortex. Neuron 56, 366â€“383 (2007)." href="#ref-CR8" id="ref-link-section-d41748316e1526_1">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Guclu, U. &amp; van Gerven, M. A. J. Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream. J. Neurosci. 35, 10005â€“10014 (2015)." href="#ref-CR9" id="ref-link-section-d41748316e1526_2">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Groen, I. I. A., Dekker, T. M., Knapen, T. &amp; Silson, E. H. Visuospatial coding as ubiquitous scaffolding for human cognition. Trends Cogn. Sci. &#xA;                  https://doi.org/10.1016/j.tics.2021.10.011&#xA;                  &#xA;                 (2022)." href="/articles/s41593-023-01512-3#ref-CR10" id="ref-link-section-d41748316e1529">10</a></sup> toward memory structures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Popham, S. F. et al. Visual and linguistic semantic representations are aligned at the border of human visual cortex. Nat. Neurosci. 24, 1628â€“1636 (2021)." href="#ref-CR11" id="ref-link-section-d41748316e1533">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Huntenburg, J. M., Bazin, P. L. &amp; Margulies, D. S. Large-scale gradients in human cortical organization. Trends Cogn. Sci. 22, 21â€“31 (2018)." href="#ref-CR12" id="ref-link-section-d41748316e1533_1">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574â€“12579 (2016)." href="#ref-CR13" id="ref-link-section-d41748316e1533_2">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Bellmund, J. L. S., GÃ¤rdenfors, P., Moser, E. I. &amp; Doeller, C. F. Navigating cognition: spatial codes for human thinking. Science (1979) 362, eaat6766 (2018)." href="/articles/s41593-023-01512-3#ref-CR14" id="ref-link-section-d41748316e1536">14</a></sup>. In addition, by examining the interaction between functionally paired perceptual and memory-related areas, our work suggests that retinotopic coding may play an integral role in structuring information processing across the brain.</p><p>This conclusion has substantial implications for our systems-level understanding of information processing at the cortical apex. Along with earlier work in human and non-human primates<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e1543">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e1546">16</a></sup>, our work demonstrates that high-level brain areas approaching the cortical apex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Huntenburg, J. M., Bazin, P. L. &amp; Margulies, D. S. Large-scale gradients in human cortical organization. Trends Cogn. Sci. 22, 21â€“31 (2018)." href="/articles/s41593-023-01512-3#ref-CR12" id="ref-link-section-d41748316e1550">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proc. Natl Acad. Sci. USA 113, 12574â€“12579 (2016)." href="/articles/s41593-023-01512-3#ref-CR13" id="ref-link-section-d41748316e1553">13</a></sup> explicitly represent visual information in the environment. These regions have an inverted retinotopic code<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Favila, S. E., Lee, H. &amp; Kuhl, B. A. Transforming the concept of memory reactivation. Trends Neurosci. 43, 939â€“950 (2020)." href="/articles/s41593-023-01512-3#ref-CR5" id="ref-link-section-d41748316e1557">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Dumoulin, S. O. &amp; Wandell, B. A. Population receptive field estimates in human visual cortex. Neuroimage 39, 647 (2008)." href="/articles/s41593-023-01512-3#ref-CR17" id="ref-link-section-d41748316e1560">17</a></sup> that organizes their functional interaction with visual areas. This view directly contrasts with the classic view of the cortical apex as an amodal and â€˜internally orientedâ€™ neural system. Large-scale deactivation of mnemonic areas at the cortical apex (for example, the DMN) during visual tasks and activation during internally focused tasks is among the most striking and widely replicated network-level patterns in functional neuroimaging<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Zabelina, D. L. &amp; Andrews-Hanna, J. R. Dynamic network interactions supporting internally-oriented cognition. Curr. Opin. Neurobiol. 40, 86â€“93 (2016)." href="#ref-CR33" id="ref-link-section-d41748316e1564">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Shulman, G. L. et al. Common blood flow changes across visual tasks: II. Decreases in cerebral cortex. J. Cogn. Neurosci. 9, 648â€“663 (1997)." href="#ref-CR34" id="ref-link-section-d41748316e1564_1">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Fox, M. D. et al. The human brain is intrinsically organized into dynamic, anticorrelated functional networks. Proc. Natl Acad. Sci. USA 102, 9673â€“9678 (2005)." href="#ref-CR35" id="ref-link-section-d41748316e1564_2">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Raichle, M. E. The brainâ€™s default mode network. Annu Rev. Neurosci. 38, 433â€“447 (2015)." href="/articles/s41593-023-01512-3#ref-CR36" id="ref-link-section-d41748316e1567">36</a></sup>. Of particular importance is the observation that the deactivation within the DMN was not thought to represent stimulus information, but instead resulted from a trade-off between internally and externally oriented neural processes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Fox, M. D. et al. The human brain is intrinsically organized into dynamic, anticorrelated functional networks. Proc. Natl Acad. Sci. USA 102, 9673â€“9678 (2005)." href="/articles/s41593-023-01512-3#ref-CR35" id="ref-link-section-d41748316e1571">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Raichle, M. E. The brainâ€™s default mode network. Annu Rev. Neurosci. 38, 433â€“447 (2015)." href="/articles/s41593-023-01512-3#ref-CR36" id="ref-link-section-d41748316e1574">36</a></sup>. By contrast, our results suggest that the opponent activation profiles of DMN/non-DMN brain areas may reflect a mutually suppressive functional interaction between mnemonic and perceptual areas that are involved in processing the same stimulus, rather than a trade-off between dissociable processes (like internal and external cognition). As a result, it may be necessary to reconsider the DMNâ€™s role in tasks that require externally directed attention, as well as what representational content might be conveyed in negative blood-oxygen-level-dependent (BOLD) responses.</p><p>How general is retinotopic coding for structuring perceptualâ€“mnemonic interactions? On the one hand, because visually guided navigation has unique mnemonic demands (for example, representing visual information out of view), scene areas might have privileged access to memory information<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Robertson, C. E. et al. Neural representations integrate the current field of view with the remembered 360Â° panorama in scene-selective cortex. Curr. Biol. 26, 2463â€“2468 (2016)." href="/articles/s41593-023-01512-3#ref-CR37" id="ref-link-section-d41748316e1581">37</a></sup>. The scene memory and perception areas may uniquely span the boundary of DMN/visual cortex (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig1">1b</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig9">3</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1591">24</a></sup> (but see ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Popham, S. F. et al. Visual and linguistic semantic representations are aligned at the border of human visual cortex. Nat. Neurosci. 24, 1628â€“1636 (2021)." href="/articles/s41593-023-01512-3#ref-CR11" id="ref-link-section-d41748316e1595">11</a></sup>). Likewise, these unique mnemonic processes could lead to preferential coding of retinotopic information in scene memory areas, making the opponent interaction observed here â€˜scene specificâ€™. On the other hand, the present findings and others<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e1600">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Knapen, T. Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain. Proc. Natl Acad. Sci. USA 118, e2017032118 (2021)." href="/articles/s41593-023-01512-3#ref-CR31" id="ref-link-section-d41748316e1603">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Silson, E. H., Zeidman, P., Knapen, T. &amp; Baker, C. I. Representation of contralateral visual space in the human hippocampus. J. Neurosci. 41, 2382â€“2392 (2021)." href="/articles/s41593-023-01512-3#ref-CR32" id="ref-link-section-d41748316e1606">32</a></sup> show that pRFs, including âˆ’pRFs, are widely distributed throughout the brain. As such, retinotopic representations could be well-poised to structure interactions between many functionally coupled brain areas broadly in cortex, beyond the domain of scenes, including other functional subnetworks situated within the DMN<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1610">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Braga, R. M. &amp; Buckner, R. L. Parallel interdigitated distributed networks within the individual estimated by intrinsic functional connectivity. Neuron 95, 457â€“471.e5 (2017)." href="#ref-CR38" id="ref-link-section-d41748316e1613">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="DiNicola, L. M., Braga, R. M. &amp; Buckner, R. L. Parallel distributed networks dissociate episodic and social functions within the individual. J. Neurophysiol. 123, 1144â€“1179 (2020)." href="#ref-CR39" id="ref-link-section-d41748316e1613_1">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Silson, E. H., Steel, A. D. &amp; Baker, C. I. Scene-selectivity and retinotopy in medial parietal cortex. Front Hum. Neurosci. 10, 412 (2016)." href="#ref-CR40" id="ref-link-section-d41748316e1613_2">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Silson, E. H., Steel, A., Kidder, A., Gilmore, A. W. &amp; Baker, C. I. Distinct subdivisions of human medial parietal cortex support recollection of people and places. eLife 8, e47391 (2019)." href="#ref-CR41" id="ref-link-section-d41748316e1613_3">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Deen, B. &amp; Freiwald, W. A. Parallel systems for social and spatial reasoning within the cortical apex. Preprint at bioRxiv &#xA;                  https://doi.org/10.1101/2021.09.23.461550&#xA;                  &#xA;                 (2021)." href="#ref-CR42" id="ref-link-section-d41748316e1613_4">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Ranganath, C. &amp; Ritchey, M. Two cortical systems for memory-guided behaviour. Nat. Rev. Neurosci. 13, 713â€“726 (2012); &#xA;                  https://doi.org/10.1038/nrn3338&#xA;                  &#xA;                " href="/articles/s41593-023-01512-3#ref-CR43" id="ref-link-section-d41748316e1616">43</a></sup>. Matching visual (posterior) and language (anterior) areas have recently been identified at the anterior edge of visual cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Popham, S. F. et al. Visual and linguistic semantic representations are aligned at the border of human visual cortex. Nat. Neurosci. 24, 1628â€“1636 (2021)." href="/articles/s41593-023-01512-3#ref-CR11" id="ref-link-section-d41748316e1620">11</a></sup>, raising a question as to whether these areas might also be coupled via opponent dynamics that structure their communication. Beyond retinotopic codes, it is important to consider that the format of visual spatial coding within a region may depend on the computational roles a given region plays. For example, parietal, occipital and temporal areas utilize multiple different visuospatial coding motifs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Wandell, B. A., Dumoulin, S. O. &amp; Brewer, A. A. Visual field maps in human cortex. Neuron 56, 366â€“383 (2007)." href="/articles/s41593-023-01512-3#ref-CR8" id="ref-link-section-d41748316e1624">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pertzov, Y., Avidan, G. &amp; Zohary, E. Multiple reference frames for saccadic planning in the human parietal cortex. J. Neurosci. 31, 1059 (2011)." href="#ref-CR44" id="ref-link-section-d41748316e1627">44</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Gardner, J. L., Merriam, E. P., Movshon, J. A. &amp; Heeger, D. J. Maps of visual space in human occipital cortex are retinotopic, not spatiotopic. J. Neurosci. 28, 3988 (2008)." href="#ref-CR45" id="ref-link-section-d41748316e1627_1">45</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Fetsch, C. R., Wang, S., Gu, Y., DeAngelis, G. C. &amp; Angelaki, D. E. Spatial reference frames of visual, vestibular, and multimodal heading signals in the dorsal subdivision of the medial superior temporal area. J. Neurosci. 27, 700â€“712 (2007)." href="/articles/s41593-023-01512-3#ref-CR46" id="ref-link-section-d41748316e1630">46</a></sup>, including retinotopic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Wandell, B. A., Dumoulin, S. O. &amp; Brewer, A. A. Visual field maps in human cortex. Neuron 56, 366â€“383 (2007)." href="/articles/s41593-023-01512-3#ref-CR8" id="ref-link-section-d41748316e1634">8</a></sup>, spatiotopic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Pertzov, Y., Avidan, G. &amp; Zohary, E. Multiple reference frames for saccadic planning in the human parietal cortex. J. Neurosci. 31, 1059 (2011)." href="/articles/s41593-023-01512-3#ref-CR44" id="ref-link-section-d41748316e1638">44</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Gardner, J. L., Merriam, E. P., Movshon, J. A. &amp; Heeger, D. J. Maps of visual space in human occipital cortex are retinotopic, not spatiotopic. J. Neurosci. 28, 3988 (2008)." href="/articles/s41593-023-01512-3#ref-CR45" id="ref-link-section-d41748316e1641">45</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Golomb, J. D. &amp; Kanwisher, N. Higher level visual cortex represents retinotopic, not spatiotopic, object location. Cereb. Cortex 22, 2794â€“2810 (2012)." href="/articles/s41593-023-01512-3#ref-CR47" id="ref-link-section-d41748316e1644">47</a></sup> and head/body-centered formats<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Silson, E. H., Groen, I. I. A., Kravitz, D. J. &amp; Baker, C. I. Evaluating the correspondence between face-, scene-, and object-selectivity and retinotopic organization within lateral occipitotemporal cortex. J. Vis. 16, 14â€“14 (2016)." href="/articles/s41593-023-01512-3#ref-CR48" id="ref-link-section-d41748316e1649">48</a></sup>. As a result, while our data clearly show the mutual retinotopic code structures the shared activity between paired perceptual and mnemonic areas, future studies will be necessary to further elaborate the nature of the visuospatial coding spanning internally oriented and externally oriented networks in the brain.</p><p>Of particular interest is the fact that the PMAs contained a large proportion of +pRFs that, unlike the âˆ’pRFs, did not share the biased visual-field representations of their SPA counterparts. This raises two questions. First, what regions contribute visual information to the memory areasâ€™ +pRFs? While the present data offers no definitive answer, it is possible that they represent information arriving locally from other visual areas like the visual maps in the dorsal intraparietal sulcus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Swisher, J. D., Halko, M. A., Merabet, L. B., McMains, S. A. &amp; Somers, D. C. Visual topography of human intraparietal sulcus. J. Neurosci. 27, 5326â€“5337 (2007)." href="/articles/s41593-023-01512-3#ref-CR49" id="ref-link-section-d41748316e1656">49</a></sup> or via longer range connections like the vertical occipital fasciculus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Yeatman, J. D. et al. The vertical occipital fasciculus: a century of controversy resolved by in vivo measurements. Proc. Natl Acad. Sci. USA 111, E5214â€“E5223 (2014)." href="/articles/s41593-023-01512-3#ref-CR50" id="ref-link-section-d41748316e1660">50</a></sup>. Second, what do the +pRFs contribute to the PMAsâ€™ functions? The robust activation of both +pRFs and âˆ’pRFs in the PMAs during memory recall suggests that these populations have related activity and differ primarily in their response to visual stimulation. It should be noted that the PMAs are defined based on a single response property (response during recall of places versus people), and functional regions may contain subregions with different functional, structural and cytoarchitectonic characteristics (similar to the presence of multiple retinotopic maps within larger, functionally defined visual regions like OPA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Silson, E. H., Groen, I. I. A., Kravitz, D. J. &amp; Baker, C. I. Evaluating the correspondence between face-, scene-, and object-selectivity and retinotopic organization within lateral occipitotemporal cortex. J. Vis. 16, 14â€“14 (2016)." href="/articles/s41593-023-01512-3#ref-CR48" id="ref-link-section-d41748316e1664">48</a></sup>). Future work is needed to elucidate what differential roles the +/âˆ’pRFs in the PMAs might play.</p><p>To summarize, our results and others<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Szinte, M. &amp; Knapen, T. Visual organization of the default network. Cereb. Cortex 30, 3518â€“3527 (2020)." href="/articles/s41593-023-01512-3#ref-CR15" id="ref-link-section-d41748316e1672">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e1675">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Knapen, T. Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain. Proc. Natl Acad. Sci. USA 118, e2017032118 (2021)." href="/articles/s41593-023-01512-3#ref-CR31" id="ref-link-section-d41748316e1678">31</a></sup> show that retinotopy is a coding principle that straddles internally oriented (mnemonic) and externally oriented (perceptual) areas in the brain. The inverted retinotopic code at the cortical apex is functionally tied to the positive retinotopic code in perceptual areas and may be crucial for scaffolding communication between memory and perception.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Methods</h2><div class="c-article-section__content" id="Sec4-content"><p>This study was approved by the Dartmouth College Institutional Review Board (Protocol no. 31288).</p><h3 class="c-article__sub-heading" id="Sec5">Participants</h3><p>Seventeen adults (13 female; ageâ€‰=â€‰22.8â€‰Â±â€‰3.5 standard deviation (s.d.) years old) completed fMRI Exp. 1 and 2. A subset of nine participants (5 female; ageâ€‰=â€‰23.5â€‰Â±â€‰3.8 s.d. years old) completed Exp. 3, which examined perception of familiar places. No statistical methods were used to predetermine sample sizes but our sample sizes are similar to those reported in previous publications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1697">24</a></sup>. Data collection and analysis were not performed blind to the conditions of the experiments. Participants were not aware of the experimental manipulation (single-blind). Participants had normal or correct-to-normal vision, were not colorblind and were free from neurological or psychiatric conditions. Written consent was obtained from all participants in accordance with the Declaration of Helsinki and with a protocol and consent form approved by the Dartmouth College Institutional Review Board (Protocol no. 31288). Participants were compensated for their time using gift cards at a rate of US$20 per hour.</p><h3 class="c-article__sub-heading" id="Sec6">Visual stimuli and tasks</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec7">pRF mapping (Exp. 1)</h4><p>During pRF mapping sessions, a bar aperture traversed gradually through the visual field while revealing randomly selected scene fragments from 90 possible scenes. During each 36-s sweep, the aperture took 18 evenly spaced steps every 2â€‰s (1 repetition time (TR)) to traverse the entire screen. Across the 18 aperture positions, all 90 possible scene images were displayed once. A total of eight sweeps were made during each run (four orientations, two directions). The bar aperture progressed in the following order for all six runs: left to right, bottom right to top left, top to bottom, bottom left to top right, right to left, top left to bottom right, bottom to top and top right to bottom left). The bar stimuli covered a circular aperture (diameterâ€‰=â€‰11.4Â° of visual angle). Participants performed a color detection task at fixation, indicating via button press when the white fixation dot changed to red. Color fixation changes occurred semi-randomly, with approximately two color changes per sweep. Stimuli were presented using PsychoPy (v.3.2.3)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Peirce, J. W. PsychoPyâ€”psychophysics software in Python. J. Neurosci. Methods. 162, 8â€“13 (2007)." href="/articles/s41593-023-01512-3#ref-CR51" id="ref-link-section-d41748316e1713">51</a></sup>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec8">SPA localizer</h4><p>The SPAs, that is OPA and PPA, are defined as regions that selectively activate when an individual perceives places (that is, a kitchen) compared with other categories of visual stimuli (that is, faces, objects, bodies)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1725">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Epstein, R. &amp; Kanwisher, N. A cortical representation the local visual environment. Nature 392, 598â€“601 (1998)." href="/articles/s41593-023-01512-3#ref-CR27" id="ref-link-section-d41748316e1728">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Silson, E. H., Steel, A. D. &amp; Baker, C. I. Scene-selectivity and retinotopy in medial parietal cortex. Front Hum. Neurosci. 10, 412 (2016)." href="/articles/s41593-023-01512-3#ref-CR40" id="ref-link-section-d41748316e1731">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Weiner, K. S. et al. Defining the most probable location of the parahippocampal place area using cortex-based alignment and cross-validation. Neuroimage 170, 373â€“384 (2018)." href="/articles/s41593-023-01512-3#ref-CR52" id="ref-link-section-d41748316e1734">52</a></sup>. To identify these areas in each individual, participants performed an independent functional localizer scan. On each run of the localizer (two runs), participants passively viewed blocks of scene, face and object images presented in rapid succession (500â€‰ms stimulus, 500â€‰ms interstimulus interval (ISI)). Blocks were 24â€‰s long, and each run comprised 12 blocks (four blocks per condition). There was no interval between blocks.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec9">PMA localizer (recall task: Exp. 2)</h4><p>The PMAs are defined as regions that selectively activate when an individual recalls personally familiar places (that is, their kitchen) compared with personally familiar people (that is, their mother)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1746">24</a></sup>. To identify these areas in each individual, participants performed an independent functional localizer. Before fMRI scanning, participants generated a list of 36 personally familiar people and places to establish individualized stimuli (72 stimuli in total). These stimuli were generated based on the following instructions.</p><blockquote class="c-blockquote"><div class="c-blockquote__body">
                    <p>â€œFor your scan, you will be asked to visualize people and places that are personally familiar to you. So, we need you to provide these lists for us. For personally familiar people, please choose people that you know in real life (no celebrities) that you can visualize in great detail. You do not need to be contact with these people now, as long as you knew them personally and remember what they look like. So, you could choose a childhood friend even if you are no longer in touch with this person. Likewise, for personally familiar places, please list places that you have been to and can richly visualize. You should choose places that are personally relevant to you, so you should avoid choosing places that you have only been to one time. You should not choose famous places where you have never been. You can choose places that span your whole life, so you could do your current kitchen, as well as the kitchen from your childhood home.Ë®</p>
                  </div></blockquote><p>During fMRI scanning, participants recalled these people and places. In each trial, participants saw the name of a person or place and recalled them in as much detail as possible for the duration that the name appeared on the screen (10â€‰s). Trials were separated by a variable ISI (4â€“8â€‰s). PMAs were localized by contrasting activity when participants recalled personally familiar places compared with people (see â€˜ROI definitionâ€™ section). All trials were unique stimuli, and conditions (that is, people or place stimuli) were pseudo-randomly intermixed so that no more than two repeats per condition occurred in a row.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec10">Perception of familiar scenes (Exp. 3)</h4><p>A subset of participants in the main experiment (<i>n</i>â€‰=â€‰9) took part in this experiment, which involved viewing an image of two prominent Dartmouth College buildings (Baker Library and Rollins Chapel; one image per landmark). One participant was excluded for lack of familiarity with one building (Rollins Chapel). All remaining participants were familiar with the landmarks and had lived in the Hanover area for at least one year.</p><p>During scanning, participants passively viewed the familiar scene images. On each trial, participants maintained fixation while passively viewing the lower left or lower right quadrant of each image (display time: 1â€‰s). The order of presentations was randomly intermixed, and no stimuli were allowed to repeat more than two times in a row in a particular location. Images subtended as much of the whole lower visual-field quadrant possible (0Â°â€“8Â° visual angle). We focused on the lower quadrants to maximally stimulate OPA and LPMA. Before scanning, we showed participants the full image of each location to familiarize them with the specific image they would be seeing. Each image was presented eight times per location per run. Trials were separated by a variable ISI (4â€“8â€‰s). We collected two imaging runs, resulting in 32 trials for each visual-field location.</p><h3 class="c-article__sub-heading" id="Sec11">fMRI data processing</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec12">MRI acquisition</h4><p>All data were collected at Dartmouth College on a Siemens Prisma 3T scanner (Siemens) equipped with a 32-channel head coil. Images were transformed from dicom to nifti format using dcm2niix (v.1.0.20190902)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Li, X., Morgan, P. S., Ashburner, J., Smith, J. &amp; Rorden, C. The first step for neuroimaging data analysis: DICOM to NIfTI conversion. J. Neurosci. Methods. 264, 47â€“56 (2016)." href="/articles/s41593-023-01512-3#ref-CR53" id="ref-link-section-d41748316e1785">53</a></sup>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec13">T1 image</h4><p>For registration purposes, a high-resolution T1-weighted magnetization-prepared rapid acquisition gradient echo (MPRAGE) imaging sequence was acquired (TRâ€‰=â€‰2,300â€‰ms, echo time (TE)â€‰=â€‰2.32â€‰ms, inversion timeâ€‰=â€‰933â€‰ms, flip angleâ€‰=â€‰8Â°, field of viewâ€‰=â€‰256â€‰Ã—â€‰256â€‰mm, slicesâ€‰=â€‰255, voxel sizeâ€‰=â€‰1â€‰Ã—â€‰1â€‰Ã—â€‰1â€‰mm). T1 images segmented and surfaces were generated using FreeSurfer<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Fischl, B. FreeSurfer. NeuroImage 62, 774â€“781 (2012); &#xA;                  https://doi.org/10.1016/j.neuroimage.2012.01.021&#xA;                  &#xA;                " href="#ref-CR54" id="ref-link-section-d41748316e1797">54</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Fischl, B. et al. Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain. Neuron 33, 341â€“355 (2002)." href="#ref-CR55" id="ref-link-section-d41748316e1797_1">55</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Dale, A. M., Fischl, B. &amp; Sereno, M. I. Cortical surface-based analysis. I. Segmentation and surface reconstruction. Neuroimage 9, 179â€“194 (1999)." href="/articles/s41593-023-01512-3#ref-CR56" id="ref-link-section-d41748316e1800">56</a></sup> (v.6.0) and aligned to the fMRI data using align_epi_anat.py and @SUMA_AlignToExperiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Saad, Z. S. &amp; Reynolds, R. C. SUMA. Neuroimage 62, 768â€“773 (2012)." href="/articles/s41593-023-01512-3#ref-CR57" id="ref-link-section-d41748316e1804">57</a></sup>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec14">fMRI acquisition</h4><p>fMRI data were acquired using a multi-echo T2*-weighted sequence. The sequence parameters were: TRâ€‰=â€‰2,000â€‰ms, TEsâ€‰=â€‰[14.6, 32.84, 51.08], GRAPPA factorâ€‰=â€‰2, flip angleâ€‰=â€‰70Â°, field of viewâ€‰=â€‰240â€‰Ã—â€‰192â€‰mm, matrix sizeâ€‰=â€‰90â€‰Ã—â€‰72, slicesâ€‰=â€‰52, multiband factorâ€‰=â€‰2, voxel sizeâ€‰=â€‰2.7â€‰mm isotropic. The initial two frames of data acquisition were discarded by the scanner to allow the signal to reach steady state.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec15">Preprocessing</h4><p>Multi-echo data processing was implemented based on the multi-echo preprocessing pipeline from afni_proc.py in AFNI (v.21.3.10 â€˜Trajanâ€™)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Cox, R. W. AFNI: software for analysis and visualization of functional magnetic resonance neuroimages. Computers Biomed. Res. 29, 162â€“173 (1996)." href="/articles/s41593-023-01512-3#ref-CR58" id="ref-link-section-d41748316e1824">58</a></sup>. Signal outliers in the data were attenuated (3dDespike<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Jo, H. J. et al. Effective preprocessing procedures virtually eliminate distance-dependent motion artifacts in resting state FMRI. J. Appl. Math. 2013, 935154 (2013)." href="/articles/s41593-023-01512-3#ref-CR59" id="ref-link-section-d41748316e1828">59</a></sup>). Motion correction was calculated based on the second echo and these alignment parameters were applied to all runs. The optimal combination of the three echoes was calculated and the echoes were combined to form a single, optimally weighted time series (T2smap.py). Multi-echo independent component analysis (ICA) denoising<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Kundu, P., Inati, S. J., Evans, J. W., Luh, W. M. &amp; Bandettini, P. A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. Neuroimage 60, 1759â€“1770 (2012)." href="/articles/s41593-023-01512-3#ref-CR19" id="ref-link-section-d41748316e1832">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="DuPre, E. et al. TE-dependent analysis of multi-echo fMRI with *tedana*. J. Open Source Softw. 6, 3669 (2021)." href="#ref-CR60" id="ref-link-section-d41748316e1835">60</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="DuPre, E. et al. ME-ICA/tedana: 0.0.6. Zenodo &#xA;                  https://doi.org/10.5281/ZENODO.2558498&#xA;                  &#xA;                 (2019)." href="#ref-CR61" id="ref-link-section-d41748316e1835_1">61</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Evans, J. W., Kundu, P., Horovitz, S. G. &amp; Bandettini, P. A. Separating slow BOLD from non-BOLD baseline drifts using multi-echo fMRI. Neuroimage 105, 189â€“197 (2015)." href="/articles/s41593-023-01512-3#ref-CR62" id="ref-link-section-d41748316e1838">62</a></sup> was then performed (see â€˜Multi-echo ICAâ€™, below). Following denoising, signals were normalized to percent signal change.</p>
                    <h3 class="c-article__sub-heading" id="FPar1">Multi-echo ICA</h3>
                    <p>The data were denoised using multi-echo ICA denoising (tedana.py<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Kundu, P., Inati, S. J., Evans, J. W., Luh, W. M. &amp; Bandettini, P. A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. Neuroimage 60, 1759â€“1770 (2012)." href="/articles/s41593-023-01512-3#ref-CR19" id="ref-link-section-d41748316e1849">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="DuPre, E. et al. ME-ICA/tedana: 0.0.6. Zenodo &#xA;                  https://doi.org/10.5281/ZENODO.2558498&#xA;                  &#xA;                 (2019)." href="/articles/s41593-023-01512-3#ref-CR61" id="ref-link-section-d41748316e1852">61</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Evans, J. W., Kundu, P., Horovitz, S. G. &amp; Bandettini, P. A. Separating slow BOLD from non-BOLD baseline drifts using multi-echo fMRI. Neuroimage 105, 189â€“197 (2015)." href="/articles/s41593-023-01512-3#ref-CR62" id="ref-link-section-d41748316e1855">62</a></sup>, v.0.0.10). PCA was applied and thermal noise was removed using the Kundu decision tree method. Following this, data were decomposed using ICA, and the resulting components were classified as signal and noise based on the known properties of the T2* signal decay of the BOLD signal versus noise. Components classified as noise were discarded, and the remaining components were recombined to construct the optimally combined, denoised time series.</p>
                  <h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec16">pRF modeling</h4><p>Detailed description of the pRF model implemented in AFNI is provided elsewhere<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Silson, E. H., Chan, A. W. Y., Reynolds, R. C., Kravitz, D. J. &amp; Baker, C. I. A retinotopic basis for the division of high-level scene processing between lateral and ventral human occipitotemporal cortex. J. Neurosci. 35, 11921â€“11935 (2015)." href="/articles/s41593-023-01512-3#ref-CR18" id="ref-link-section-d41748316e1869">18</a></sup>. Given the position of the stimulus in the visual field at every time point, the model estimates the pRF parameters that yield the best fit to the data: pRF amplitude (positive, negative), pRF center location (<i>x</i>, <i>y</i>) and size (diameter of the pRF). Both Simplex and Powell optimization algorithms are used simultaneously to find the best time series/parameter sets (amplitude, <i>x</i>, <i>y</i>, size) by minimizing the least-squares error of the predicted time series with the acquired time series for each voxel. Relevant to the present work, the amplitude measure refers to the signed (positive or negative) degree of linear scaling applied to the pRF model, which reflects the sign of the neural response to visual stimulation of its receptive field.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec17">Sampling of fMRI data to the cortical surface</h4><p>For each participant, the analyzed functional data were projected onto surface reconstructions of each individual participantâ€™s hemispheres in the Surface Mapping with AFNI (SUMA) standard mesh (std.141 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Argall, B. D., Saad, Z. S. &amp; Beauchamp, M. S. Simplified intersubject averaging on the cortical surface using SUMA. Hum. Brain Mapp. 27, 14â€“27 (2006)." href="/articles/s41593-023-01512-3#ref-CR63" id="ref-link-section-d41748316e1893">63</a></sup>)), derived from the FreeSurfer autorecon script using the SUMA<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Saad, Z. S. &amp; Reynolds, R. C. SUMA. Neuroimage 62, 768â€“773 (2012)." href="/articles/s41593-023-01512-3#ref-CR57" id="ref-link-section-d41748316e1897">57</a></sup> software and the 3dvol2surf commands.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec18">ROI definition</h4><p>SPAs (OPA and PPA) were established using the same criterion used in our earlier work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1909">24</a></sup>. SPAs were drawn based on a general linear test comparing the coefficients of the general linear model (GLM) during scene versus face blocks. Comparable results were observed when identifying the SPAs by comparing scene versus object blocks. A vertex-wise significance of <i>P</i>â€‰&lt;â€‰0.001 along with expected anatomical locations was used to define the ROIs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Weiner, K. S. et al. Defining the most probable location of the parahippocampal place area using cortex-based alignment and cross-validation. Neuroimage 170, 373â€“384 (2018)." href="/articles/s41593-023-01512-3#ref-CR52" id="ref-link-section-d41748316e1916">52</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Julian, J. B., Fedorenko, E., Webster, J. &amp; Kanwisher, N. An algorithmic method for functionally defining regions of interest in the ventral visual pathway. NeuroImage 60, 2357â€“2364, &#xA;                  https://doi.org/10.1016/j.neuroimage.2012.02.055&#xA;                  &#xA;                 (2012)." href="/articles/s41593-023-01512-3#ref-CR64" id="ref-link-section-d41748316e1919">64</a></sup>.</p><p>To define category-selective memory areas, the familiar people or places memory data was modeled by fitting a gamma function of the trial duration for trials of each condition (people and places) using 3dDeconvolve. Estimated motion parameters were included as additional regressors of no-interest. PMAs were drawn based on a general linear test comparing coefficients of the GLM for people and place memory. A vertex-wise significance threshold of <i>P</i>â€‰&lt;â€‰0.001 was used to draw ROIs.</p><p>To control for differing ROI sizes across regions and people, we restricted all analyses to 300 vertices centered on the center of mass of each threshold ROI. Consistent with earlier work, we chose 300 vertices to ensure that no region or participant disproportionately contributed to any effects<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e1932">24</a></sup>. The results were qualitatively similar when 600 vertices were considered, suggesting our findings did not depend on ROI size.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec19">ROI analysis of pRF amplitude</h4><p>To calculate the percentage of âˆ’pRFs in each ROI, we applied the following procedures. First, pRFs were set to a threshold on variance explained by the pRF model (<i>R</i><sup>2</sup>â€‰&gt;â€‰0.08), which is consistent with earlier work using <i>R</i><sup>2</sup> thresholds ranging between 0.05 and 0.10 (refs. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. eLife 10, e67304 (2021)." href="/articles/s41593-023-01512-3#ref-CR16" id="ref-link-section-d41748316e1952">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Silson, E. H., Zeidman, P., Knapen, T. &amp; Baker, C. I. Representation of contralateral visual space in the human hippocampus. J. Neurosci. 41, 2382â€“2392 (2021)." href="/articles/s41593-023-01512-3#ref-CR32" id="ref-link-section-d41748316e1955">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Gomez, J., Barnett, M. &amp; Grill-Spector, K. Extensive childhood experience with PokÃ©mon suggests eccentricity drives organization of visual cortex. Nat. Hum. Behav. 3, 611â€“624, &#xA;                  https://doi.org/10.1038/s41562-019-0592-8&#xA;                  &#xA;                 (2019)." href="/articles/s41593-023-01512-3#ref-CR65" id="ref-link-section-d41748316e1958">65</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Gomez, J. et al. Development of population receptive fields in the lateral visual stream improves spatial coding amid stable structural-functional coupling. NeuroImage 188, 59â€“69 (2019)." href="/articles/s41593-023-01512-3#ref-CR66" id="ref-link-section-d41748316e1961">66</a></sup>). Our results were consistent at <i>R</i><sup>2</sup> thresholds between 0.05 and 0.20. Next, to avoid analyzing only very few pRFs within an ROI, only ROIs consisting of &gt;25 suprathreshold pRFs (&gt;8.3% of total ROI) were included. The percentage of suprathreshold pRFs with a negative amplitude within each ROI was then calculated and submitted for statistical analysis.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec20">Visual-field coverage</h4><p>Visual-field coverage (VFC) plots represent the sensitivity of each ROI to different positions in the visual field. To compute these, individual participant VFC plots were first derived. These plots combine the best Gaussian receptive field model for each suprathreshold voxel within each ROI. Here, a max operator is used, which stores, at each point in the visual field, the maximum value from all pRFs within the ROI. The resulting coverage plot thus represents the maximum envelope of sensitivity across the visual field. Individual participant VFC plots were averaged across participants to create group-level coverage plots.</p><p>To compute the elevation biases, we calculated the mean pRF value (defined as the mean value in a specific portion of the visual-field coverage plot) in the contralateral upper visual field (UVF) and contralateral lower visual field (LVF) and computed the difference (UVFâ€“LVF) for each participant, ROI and amplitude (+/âˆ’) separately. A positive value thus represents an upper visual-field bias, whereas a negative value represents a lower visual-field bias. Analysis of the visual-field biases considers pRF center location (like the center of mass calculation does), as well as pRF size and <i>R</i><sup>2</sup>. This makes the mean pRF value a preferable summary metric to analyzing pRF center position alone<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Silson, E. H., Chan, A. W. Y., Reynolds, R. C., Kravitz, D. J. &amp; Baker, C. I. A retinotopic basis for the division of high-level scene processing between lateral and ventral human occipitotemporal cortex. J. Neurosci. 35, 11921â€“11935 (2015)." href="/articles/s41593-023-01512-3#ref-CR18" id="ref-link-section-d41748316e1984">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Silson, E. H., Zeidman, P., Knapen, T. &amp; Baker, C. I. Representation of contralateral visual space in the human hippocampus. J. Neurosci. 41, 2382â€“2392 (2021)." href="/articles/s41593-023-01512-3#ref-CR32" id="ref-link-section-d41748316e1987">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Silson, E. H., Steel, A. D. &amp; Baker, C. I. Scene-selectivity and retinotopy in medial parietal cortex. Front Hum. Neurosci. 10, 412 (2016)." href="/articles/s41593-023-01512-3#ref-CR40" id="ref-link-section-d41748316e1990">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Silson, E. H., Groen, I. I. A., Kravitz, D. J. &amp; Baker, C. I. Evaluating the correspondence between face-, scene-, and object-selectivity and retinotopic organization within lateral occipitotemporal cortex. J. Vis. 16, 14â€“14 (2016)." href="/articles/s41593-023-01512-3#ref-CR48" id="ref-link-section-d41748316e1993">48</a></sup>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec21">Reliability of pRF amplitude and VFC</h4><p>To quantify the reliability of pRF estimates, we conducted a series of split-half analyses. First, pRF models were computed on the average time series of all odd runs (1, 3, 5) and even runs (2, 4, 6) separately for each participant. Then, for each ROI, we identified all suprathreshold pRFs (<i>R</i><sup>2</sup>â€‰&gt;â€‰0.08) and pooled these pRFs across participants. This was done separately for +pRFs and âˆ’pRFs in each split (odd, even). Next, we conducted three tests of split-half reliability. First, we computed the percentage of pRFs in each ROI whose amplitude sign (that is, positive or negative) remained consistent across splits. Second, to determine whether the sign of pRF amplitudes was reliable, we computed Pearsonâ€™s correlation coefficient in amplitude across independent splits (odd, even) separately for positive and negative pRFs. We compared these <i>R</i> values against zero (that is, no correlation) using <i>t</i>-tests (two-tailed). Third, to determine whether the ROI visual-field preferences are reliable, we computed VFC maps from all suprathreshold pRFs in each ROI and split. Next, we calculated the Dice coefficient in the overlap between the split-half coverage maps and tested these values against zero (that is, no overlap) using <i>t</i>-tests (two-tailed).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec22">Recall trialâ€‰Ã—â€‰trial analysis</h4><p>To assess the interaction between +pRFs in SPAs and âˆ’pRFs in SPAs during memory recall, we adopted the following procedures. For each participant and ROI, we sampled the pattern of activity (<i>t</i>-value versus baseline) elicited during the recall of each personally familiar place (36 places per participant) from the place memory localizer experiment. Suprathreshold pRFs were separated according to amplitude (+pRFs, âˆ’pRFs) before averaging the recall responses across pRFs. This produced 36 responses (one for each recalled place) per pRF amplitude in each participants ROI. We then <i>z</i>-scored these values for each participant and ROI separately.</p><p>After normalization, in each participant, we computed the partial correlation (Pearsonâ€™s <i>R</i>) between responses during memory recall of +pRFs in SPAs with âˆ’pRFs in PMAs, while controlling for the responses of +pRFs in PMAs and vice versa. To determine whether the +pRFs and âˆ’pRFs from the PMAs had differential influence on activity in the SPAs, we compared the correlation coefficients from each population against each other using paired <i>t</i>-tests. To determine whether the influence of the âˆ’pRFs and +pRFs was significant, we compared the Fisher-transformed correlation coefficients from each population (+pRFs and âˆ’pRFs in the PMAs) against zero (no correlation).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec23">Spatial specificity analysis</h4><p>We matched +pRFs in the SPAs with both +/âˆ’pRFs in the PMAs separately (for example, OPA to âˆ’LPMA and OPA to +LPMA) using the following procedure. On each iteration (1,000 iterations in total; randomized PMA pRF order): (1) for every pRF in a PMA, we computed the pairwise Euclidean distance (in <i>x</i>, <i>y</i> and sigma) to all +pRFs in the paired SPA and found the SPA pRF with the smallest distance that was smaller than the median distance of all possible pRF pairs, and then (2) we required that all pRF matches were uniquely matched, so if an SPA pRF was the best match for two PMA pRFs, then the second PMA pRF was excluded. To prevent under-sampling, only subjects with more than 10 matched +/âˆ’pRFs on average in each region were considered (lateral surface: <i>n</i>â€‰=â€‰14, ventral surface: <i>n</i>â€‰=â€‰7).</p><p>Following this, we compared the correlation in trialâ€‰Ã—â€‰trial activation matched (versus non-matched) pairs of pRFs with â€˜unmatchedâ€™ pRFs. To create the â€˜unmatchedâ€™, random pRF pairings, we randomly sampled pRFs in the memory area (repeated 1,000 times). We then computed the unique correlation in trialâ€‰Ã—â€‰trial activation during recall between SPA pRFs and PMA pRFs, using the same procedure as in our main analysis (for example, the partial correlation between SPA pRFs with PMA âˆ’pRFs, controlling for PMA +pRFs) for each iteration of the pRF matching. We compared the mean of the Fisher-transformed partial correlation values across the iterations for the matched pRFs with the mean of random (that is, unmatched) pRFs. To ensure that matched pRFs had better corresponding visual-field representations than unmatched pRFs, we calculated the visual-field overlap between pRF pairs in the matched samples, compared with the random samples (average Dice coefficient of the visual-field coverage for all matched versus unmatched iterations).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec24">Perception of familiar scenes trialâ€‰Ã—â€‰trial analysis</h4><p>To assess the interaction between pRFs in OPA and +/âˆ’pRFs in LPMA during perception, we adopted the following procedure. We modeled task-evoked activity using a GLM with each image presentation fit as a separate regressor and calculated the average trial-wise activation of pRFs in OPA and +/âˆ’pRFs in LPMA. It should be noted that, because of our interest in spatially specific interactions, we only considered pRFs with centers in the contralateral lower visual field, where the stimuli were presented (that is, left hemisphere OPA pRFs had to have centers in the lower right quadrant). We then Fisher-transformed these values for each participant and ROI separately.</p><p>After normalization, in each participant, we calculated the partial correlation between the trialâ€‰Ã—â€‰trial activation of OPA with the negative and positive pRFs in LPMA separately for each hemifield (that is, OPA with âˆ’pRFs in LPMA, controlling for +pRFs in LPMA when images were presented in the left hemifield). We compared the contralateral preference in the association (Fisher-transformed partial correlation values) between the +/âˆ’pRFs using a repeated measures ANOVA with visual field (ipsilateral, contralateral) and pRF association (OPAâ€‰Ã—â€‰+LPMA, OPAâ€‰Ã—â€‰âˆ’LPMA) as factors.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec25">Statistical analysis</h4><p>Statistics were calculated using the R Studio package (v.1.3)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="R Core Team. R: a language and environment for statistical computing (R Foundation for Statistical Computing, 2013); &#xA;                  www.r-project.org/&#xA;                  &#xA;                " href="/articles/s41593-023-01512-3#ref-CR67" id="ref-link-section-d41748316e2084">67</a></sup> and custom Matlab code (v.2022a, MathWorks). Data distributions were assumed to be normal, but this was not statistically tested. All individual participant data are shown. We conducted repeated measures analysis of variance using the ezANOVA function from the â€˜ezâ€™ package<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Lawrence, M. A. ez: easy analysis and visualization of factorial experiments. R package version 4.0.2 (2016)." href="/articles/s41593-023-01512-3#ref-CR68" id="ref-link-section-d41748316e2088">68</a></sup>. Alpha level of <i>P</i>â€‰&lt;â€‰0.05 was used to assess significance. We applied Bonferroni correction for multiple comparisons where appropriate.</p><h3 class="c-article__sub-heading" id="Sec26">Reporting summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-023-01512-3#MOESM1">Nature Portfolio Reporting Summary</a> linked to this article.</p></div></div></section>
                </div>
            

            <div>
                <section data-title="Data availability"><div class="c-article-section" id="data-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability">Data availability</h2><div class="c-article-section__content" id="data-availability-content">
              
              <p>Data are available on Open Science Framework (<a href="https://osf.io/sm2xf">https://osf.io/sm2xf</a>).</p>
            </div></div></section><section data-title="Code availability"><div class="c-article-section" id="code-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="code-availability">Code availability</h2><div class="c-article-section__content" id="code-availability-content">
              
              <p>Code used for data analysis is available on Open Science Framework (<a href="https://osf.io/sm2xf">https://osf.io/sm2xf</a>).</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Libby, A. &amp; Buschman, T. J. Rotational dynamics reduce interference between sensory and memory representations. <i>Nat. Neurosci.</i> <b>24</b>, 715â€“726 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXotVCgtLk%3D" aria-label="CAS reference 1">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33821001" aria-label="PubMed reference 1">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8102338" aria-label="PubMed Central reference 1">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Rotational%20dynamics%20reduce%20interference%20between%20sensory%20and%20memory%20representations&amp;journal=Nat.%20Neurosci.&amp;volume=24&amp;pages=715-726&amp;publication_year=2021&amp;author=Libby%2CA&amp;author=Buschman%2CTJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Kiyonaga, A., Scimeca, J. M., Bliss, D. P. &amp; Whitney, D. Serial dependence across perception, attention, and memory. <i>Trends Cogn. Sci.</i> <b>21</b>, 493 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28549826" aria-label="PubMed reference 2">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5516910" aria-label="PubMed Central reference 2">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Serial%20dependence%20across%20perception%2C%20attention%2C%20and%20memory&amp;journal=Trends%20Cogn.%20Sci.&amp;volume=21&amp;publication_year=2017&amp;author=Kiyonaga%2CA&amp;author=Scimeca%2CJM&amp;author=Bliss%2CDP&amp;author=Whitney%2CD">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Summerfield, C. &amp; de Lange, F. P. Expectation in perceptual decision making: neural and computational mechanisms. <i>Nat. Rev. Neurosci.</i> <b>15</b>, 745â€“756 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhslGjtbnP" aria-label="CAS reference 3">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25315388" aria-label="PubMed reference 3">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Expectation%20in%20perceptual%20decision%20making%3A%20neural%20and%20computational%20mechanisms&amp;journal=Nat.%20Rev.%20Neurosci.&amp;volume=15&amp;pages=745-756&amp;publication_year=2014&amp;author=Summerfield%2CC&amp;author=Lange%2CFP">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Rademaker, R. L., Chunharas, C. &amp; Serences, J. T. Coexisting representations of sensory and mnemonic information in human visual cortex. <i>Nat. Neurosci.</i> <b>22</b>, 1336â€“1344 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXht1yktL3L" aria-label="CAS reference 4">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31263205" aria-label="PubMed reference 4">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6857532" aria-label="PubMed Central reference 4">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Coexisting%20representations%20of%20sensory%20and%20mnemonic%20information%20in%20human%20visual%20cortex&amp;journal=Nat.%20Neurosci.&amp;volume=22&amp;pages=1336-1344&amp;publication_year=2019&amp;author=Rademaker%2CRL&amp;author=Chunharas%2CC&amp;author=Serences%2CJT">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Favila, S. E., Lee, H. &amp; Kuhl, B. A. Transforming the concept of memory reactivation. <i>Trends Neurosci.</i> <b>43</b>, 939â€“950 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhvFOhtbfE" aria-label="CAS reference 5">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33041061" aria-label="PubMed reference 5">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7688497" aria-label="PubMed Central reference 5">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Transforming%20the%20concept%20of%20memory%20reactivation&amp;journal=Trends%20Neurosci.&amp;volume=43&amp;pages=939-950&amp;publication_year=2020&amp;author=Favila%2CSE&amp;author=Lee%2CH&amp;author=Kuhl%2CBA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Yassa, M. A. &amp; Stark, C. E. L. Pattern separation in the hippocampus. <i>Trends Neurosci.</i> <b>34</b>, 515â€“525 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXht1antb%2FF" aria-label="CAS reference 6">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21788086" aria-label="PubMed reference 6">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3183227" aria-label="PubMed Central reference 6">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Pattern%20separation%20in%20the%20hippocampus&amp;journal=Trends%20Neurosci.&amp;volume=34&amp;pages=515-525&amp;publication_year=2011&amp;author=Yassa%2CMA&amp;author=Stark%2CCEL">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Holmes, G. Disturbances of vision by cerebral lesions. <i>Br. J. Ophthalmol.</i> <b>2</b>, 353â€“384 (1918).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD1c%2FhvVOiuw%3D%3D" aria-label="CAS reference 7">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18167806" aria-label="PubMed reference 7">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC513514" aria-label="PubMed Central reference 7">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Disturbances%20of%20vision%20by%20cerebral%20lesions&amp;journal=Br.%20J.%20Ophthalmol.&amp;volume=2&amp;pages=353-384&amp;publication_year=1918&amp;author=Holmes%2CG">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Wandell, B. A., Dumoulin, S. O. &amp; Brewer, A. A. Visual field maps in human cortex. <i>Neuron</i> <b>56</b>, 366â€“383 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXht12jsrvP" aria-label="CAS reference 8">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17964252" aria-label="PubMed reference 8">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20field%20maps%20in%20human%20cortex&amp;journal=Neuron&amp;volume=56&amp;pages=366-383&amp;publication_year=2007&amp;author=Wandell%2CBA&amp;author=Dumoulin%2CSO&amp;author=Brewer%2CAA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Guclu, U. &amp; van Gerven, M. A. J. Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream. <i>J. Neurosci.</i> <b>35</b>, 10005â€“10014 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26157000" aria-label="PubMed reference 9">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6605414" aria-label="PubMed Central reference 9">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20neural%20networks%20reveal%20a%20gradient%20in%20the%20complexity%20of%20neural%20representations%20across%20the%20ventral%20stream&amp;journal=J.%20Neurosci.&amp;volume=35&amp;pages=10005-10014&amp;publication_year=2015&amp;author=Guclu%2CU&amp;author=Gerven%2CMAJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Groen, I. I. A., Dekker, T. M., Knapen, T. &amp; Silson, E. H. Visuospatial coding as ubiquitous scaffolding for human cognition. <i>Trends Cogn. Sci.</i> <a href="https://doi.org/10.1016/j.tics.2021.10.011" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.tics.2021.10.011">https://doi.org/10.1016/j.tics.2021.10.011</a> (2022).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Popham, S. F. et al. Visual and linguistic semantic representations are aligned at the border of human visual cortex. <i>Nat. Neurosci.</i> <b>24</b>, 1628â€“1636 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXitlOksrfP" aria-label="CAS reference 11">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34711960" aria-label="PubMed reference 11">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20and%20linguistic%20semantic%20representations%20are%20aligned%20at%20the%20border%20of%20human%20visual%20cortex&amp;journal=Nat.%20Neurosci.&amp;volume=24&amp;pages=1628-1636&amp;publication_year=2021&amp;author=Popham%2CSF">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Huntenburg, J. M., Bazin, P. L. &amp; Margulies, D. S. Large-scale gradients in human cortical organization. <i>Trends Cogn. Sci.</i> <b>22</b>, 21â€“31 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29203085" aria-label="PubMed reference 12">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Large-scale%20gradients%20in%20human%20cortical%20organization&amp;journal=Trends%20Cogn.%20Sci.&amp;volume=22&amp;pages=21-31&amp;publication_year=2018&amp;author=Huntenburg%2CJM&amp;author=Bazin%2CPL&amp;author=Margulies%2CDS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale cortical organization. <i>Proc. Natl Acad. Sci. USA</i> <b>113</b>, 12574â€“12579 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2016PNAS..11312574M" aria-label="ADS reference 13">ADS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs1ykurnM" aria-label="CAS reference 13">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27791099" aria-label="PubMed reference 13">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5098630" aria-label="PubMed Central reference 13">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Situating%20the%20default-mode%20network%20along%20a%20principal%20gradient%20of%20macroscale%20cortical%20organization&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;volume=113&amp;pages=12574-12579&amp;publication_year=2016&amp;author=Margulies%2CDS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Bellmund, J. L. S., GÃ¤rdenfors, P., Moser, E. I. &amp; Doeller, C. F. Navigating cognition: spatial codes for human thinking. <i>Science (1979)</i> <b>362</b>, eaat6766 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Navigating%20cognition%3A%20spatial%20codes%20for%20human%20thinking&amp;journal=Science%20%281979%29&amp;volume=362&amp;publication_year=2018&amp;author=Bellmund%2CJLS&amp;author=G%C3%A4rdenfors%2CP&amp;author=Moser%2CEI&amp;author=Doeller%2CCF">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Szinte, M. &amp; Knapen, T. Visual organization of the default network. <i>Cereb. Cortex</i> <b>30</b>, 3518â€“3527 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32031204" aria-label="PubMed reference 15">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20organization%20of%20the%20default%20network&amp;journal=Cereb.%20Cortex&amp;volume=30&amp;pages=3518-3527&amp;publication_year=2020&amp;author=Szinte%2CM&amp;author=Knapen%2CT">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Christiaan Klink, P., Chen, X., Vanduffel, W. &amp; Roelfsema, P. R. Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex. <i>eLife</i> <b>10</b>, e67304 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34730515" aria-label="PubMed reference 16">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8641953" aria-label="PubMed Central reference 16">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Population%20receptive%20fields%20in%20non-human%20primates%20from%20whole-brain%20fMRI%20and%20large-scale%20neurophysiology%20in%20visual%20cortex&amp;journal=eLife&amp;volume=10&amp;publication_year=2021&amp;author=Christiaan%20Klink%2CP&amp;author=Chen%2CX&amp;author=Vanduffel%2CW&amp;author=Roelfsema%2CPR">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Dumoulin, S. O. &amp; Wandell, B. A. Population receptive field estimates in human visual cortex. <i>Neuroimage</i> <b>39</b>, 647 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17977024" aria-label="PubMed reference 17">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Population%20receptive%20field%20estimates%20in%20human%20visual%20cortex&amp;journal=Neuroimage&amp;volume=39&amp;publication_year=2008&amp;author=Dumoulin%2CSO&amp;author=Wandell%2CBA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Silson, E. H., Chan, A. W. Y., Reynolds, R. C., Kravitz, D. J. &amp; Baker, C. I. A retinotopic basis for the division of high-level scene processing between lateral and ventral human occipitotemporal cortex. <i>J. Neurosci.</i> <b>35</b>, 11921â€“11935 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXhslerurfJ" aria-label="CAS reference 18">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26311774" aria-label="PubMed reference 18">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4549403" aria-label="PubMed Central reference 18">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20retinotopic%20basis%20for%20the%20division%20of%20high-level%20scene%20processing%20between%20lateral%20and%20ventral%20human%20occipitotemporal%20cortex&amp;journal=J.%20Neurosci.&amp;volume=35&amp;pages=11921-11935&amp;publication_year=2015&amp;author=Silson%2CEH&amp;author=Chan%2CAWY&amp;author=Reynolds%2CRC&amp;author=Kravitz%2CDJ&amp;author=Baker%2CCI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Kundu, P., Inati, S. J., Evans, J. W., Luh, W. M. &amp; Bandettini, P. A. Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI. <i>Neuroimage</i> <b>60</b>, 1759â€“1770 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22209809" aria-label="PubMed reference 19">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Differentiating%20BOLD%20and%20non-BOLD%20signals%20in%20fMRI%20time%20series%20using%20multi-echo%20EPI&amp;journal=Neuroimage&amp;volume=60&amp;pages=1759-1770&amp;publication_year=2012&amp;author=Kundu%2CP&amp;author=Inati%2CSJ&amp;author=Evans%2CJW&amp;author=Luh%2CWM&amp;author=Bandettini%2CPA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Steel, A., Garcia, B. D., Silson, E. H. &amp; Robertson, C. E. Evaluating the efficacy of multi-echo ICA denoising on model-based fMRI. <i>Neuroimage</i> <b>264</b>, 119723 (2022).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36328274" aria-label="PubMed reference 20">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluating%20the%20efficacy%20of%20multi-echo%20ICA%20denoising%20on%20model-based%20fMRI&amp;journal=Neuroimage&amp;volume=264&amp;publication_year=2022&amp;author=Steel%2CA&amp;author=Garcia%2CBD&amp;author=Silson%2CEH&amp;author=Robertson%2CCE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Wang, L., Mruczek, R. E. B., Arcaro, M. J. &amp; Kastner, S. Probabilistic maps of visual topography in human cortex. <i>Cereb. Cortex</i> <b>25</b>, 3911â€“3931 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs1ektbs%3D" aria-label="CAS reference 21">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25452571" aria-label="PubMed reference 21">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Probabilistic%20maps%20of%20visual%20topography%20in%20human%20cortex&amp;journal=Cereb.%20Cortex&amp;volume=25&amp;pages=3911-3931&amp;publication_year=2015&amp;author=Wang%2CL&amp;author=Mruczek%2CREB&amp;author=Arcaro%2CMJ&amp;author=Kastner%2CS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Thomas Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. <i>J. Neurophysiol.</i> <b>106</b>, 1125â€“1165 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3174820" aria-label="PubMed Central reference 22">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20organization%20of%20the%20human%20cerebral%20cortex%20estimated%20by%20intrinsic%20functional%20connectivity&amp;journal=J.%20Neurophysiol.&amp;volume=106&amp;pages=1125-1165&amp;publication_year=2011&amp;author=Thomas%20Yeo%2CBT">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Shmuel, A. et al. Sustained negative BOLD, blood flow and oxygen consumption response and its coupling to the positive response in the human brain. <i>Neuron</i> <b>36</b>, 1195â€“1210 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3sXhtVOnsA%3D%3D" aria-label="CAS reference 23">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12495632" aria-label="PubMed reference 23">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Sustained%20negative%20BOLD%2C%20blood%20flow%20and%20oxygen%20consumption%20response%20and%20its%20coupling%20to%20the%20positive%20response%20in%20the%20human%20brain&amp;journal=Neuron&amp;volume=36&amp;pages=1195-1210&amp;publication_year=2002&amp;author=Shmuel%2CA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. <i>Nat. Commun.</i> <b>12</b>, 1â€“13 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20network%20linking%20scene%20perception%20and%20spatial%20memory%20systems%20in%20posterior%20cerebral%20cortex&amp;journal=Nat.%20Commun.&amp;volume=12&amp;pages=1-13&amp;publication_year=2021&amp;author=Steel%2CA&amp;author=Billings%2CMM&amp;author=Silson%2CEH&amp;author=Robertson%2CCE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Hasson, U., Levy, I., Behrmann, M., Hendler, T. &amp; Malach, R. Eccentricity bias as an organizing principle for human high-order object areas. <i>Neuron</i> <b>34</b>, 479â€“490 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38XjsFGnsr4%3D" aria-label="CAS reference 25">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11988177" aria-label="PubMed reference 25">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Eccentricity%20bias%20as%20an%20organizing%20principle%20for%20human%20high-order%20object%20areas&amp;journal=Neuron&amp;volume=34&amp;pages=479-490&amp;publication_year=2002&amp;author=Hasson%2CU&amp;author=Levy%2CI&amp;author=Behrmann%2CM&amp;author=Hendler%2CT&amp;author=Malach%2CR">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Dilks, D. D., Julian, J. B., Paunov, A. M. &amp; Kanwisher, N. The occipital place area is causally and selectively involved in scene perception. <i>J. Neurosci.</i> <b>33</b>, 1331â€“1336 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23345209" aria-label="PubMed reference 26">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3711611" aria-label="PubMed Central reference 26">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20occipital%20place%20area%20is%20causally%20and%20selectively%20involved%20in%20scene%20perception&amp;journal=J.%20Neurosci.&amp;volume=33&amp;pages=1331-1336&amp;publication_year=2013&amp;author=Dilks%2CDD&amp;author=Julian%2CJB&amp;author=Paunov%2CAM&amp;author=Kanwisher%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Epstein, R. &amp; Kanwisher, N. A cortical representation the local visual environment. <i>Nature</i> <b>392</b>, 598â€“601 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=1998Natur.392..598E" aria-label="ADS reference 27">ADS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK1cXis1Srurc%3D" aria-label="CAS reference 27">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9560155" aria-label="PubMed reference 27">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20cortical%20representation%20the%20local%20visual%20environment&amp;journal=Nature&amp;volume=392&amp;pages=598-601&amp;publication_year=1998&amp;author=Epstein%2CR&amp;author=Kanwisher%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Breedlove, J. L., St-Yves, G., Olman, C. A. &amp; Naselaris, T. Generative feedback explains distinct brain activity codes for seen and mental images. <i>Curr. Biol.</i> <a href="https://doi.org/10.1016/j.cub.2020.04.014" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.cub.2020.04.014">https://doi.org/10.1016/j.cub.2020.04.014</a> (2020).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Favila, S. E., Kuhl, B. A. &amp; Winawer, J. Perception and memory have distinct spatial tuning properties in human visual cortex. <i>Nat. Commun.</i> <b>13</b>, 5864 (2022).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2022NatCo..13.5864F" aria-label="ADS reference 29">ADS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB38Xis12mtLrM" aria-label="CAS reference 29">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36257949" aria-label="PubMed reference 29">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9579130" aria-label="PubMed Central reference 29">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Perception%20and%20memory%20have%20distinct%20spatial%20tuning%20properties%20in%20human%20visual%20cortex&amp;journal=Nat.%20Commun.&amp;volume=13&amp;publication_year=2022&amp;author=Favila%2CSE&amp;author=Kuhl%2CBA&amp;author=Winawer%2CJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Bastos, A. M. et al. Canonical microcircuits for predictive coding. <i>Neuron</i> <b>76</b>, 695â€“711 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC38XhslejsbzJ" aria-label="CAS reference 30">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23177956" aria-label="PubMed reference 30">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3777738" aria-label="PubMed Central reference 30">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Canonical%20microcircuits%20for%20predictive%20coding&amp;journal=Neuron&amp;volume=76&amp;pages=695-711&amp;publication_year=2012&amp;author=Bastos%2CAM">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Knapen, T. Topographic connectivity reveals task-dependent retinotopic processing throughout the human brain. <i>Proc. Natl Acad. Sci. USA</i> <b>118</b>, e2017032118 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXhsVCitLk%3D" aria-label="CAS reference 31">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33372144" aria-label="PubMed reference 31">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Topographic%20connectivity%20reveals%20task-dependent%20retinotopic%20processing%20throughout%20the%20human%20brain&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;volume=118&amp;publication_year=2021&amp;author=Knapen%2CT">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Silson, E. H., Zeidman, P., Knapen, T. &amp; Baker, C. I. Representation of contralateral visual space in the human hippocampus. <i>J. Neurosci.</i> <b>41</b>, 2382â€“2392 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXhtFSrtrnF" aria-label="CAS reference 32">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33500275" aria-label="PubMed reference 32">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7984600" aria-label="PubMed Central reference 32">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Representation%20of%20contralateral%20visual%20space%20in%20the%20human%20hippocampus&amp;journal=J.%20Neurosci.&amp;volume=41&amp;pages=2382-2392&amp;publication_year=2021&amp;author=Silson%2CEH&amp;author=Zeidman%2CP&amp;author=Knapen%2CT&amp;author=Baker%2CCI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Zabelina, D. L. &amp; Andrews-Hanna, J. R. Dynamic network interactions supporting internally-oriented cognition. <i>Curr. Opin. Neurobiol.</i> <b>40</b>, 86â€“93 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28XhtFSnsbbP" aria-label="CAS reference 33">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27420377" aria-label="PubMed reference 33">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamic%20network%20interactions%20supporting%20internally-oriented%20cognition&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;volume=40&amp;pages=86-93&amp;publication_year=2016&amp;author=Zabelina%2CDL&amp;author=Andrews-Hanna%2CJR">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Shulman, G. L. et al. Common blood flow changes across visual tasks: II. Decreases in cerebral cortex. <i>J. Cogn. Neurosci.</i> <b>9</b>, 648â€“663 (1997).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC3sbhs1GqtA%3D%3D" aria-label="CAS reference 34">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23965122" aria-label="PubMed reference 34">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Common%20blood%20flow%20changes%20across%20visual%20tasks%3A%20II.%20Decreases%20in%20cerebral%20cortex&amp;journal=J.%20Cogn.%20Neurosci.&amp;volume=9&amp;pages=648-663&amp;publication_year=1997&amp;author=Shulman%2CGL">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Fox, M. D. et al. The human brain is intrinsically organized into dynamic, anticorrelated functional networks. <i>Proc. Natl Acad. Sci. USA</i> <b>102</b>, 9673â€“9678 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2005PNAS..102.9673F" aria-label="ADS reference 35">ADS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXmsVaktb8%3D" aria-label="CAS reference 35">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15976020" aria-label="PubMed reference 35">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1157105" aria-label="PubMed Central reference 35">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20human%20brain%20is%20intrinsically%20organized%20into%20dynamic%2C%20anticorrelated%20functional%20networks&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;volume=102&amp;pages=9673-9678&amp;publication_year=2005&amp;author=Fox%2CMD">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Raichle, M. E. The brainâ€™s default mode network. <i>Annu Rev. Neurosci.</i> <b>38</b>, 433â€“447 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2MXhsVCjurfJ" aria-label="CAS reference 36">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25938726" aria-label="PubMed reference 36">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20brain%E2%80%99s%20default%20mode%20network&amp;journal=Annu%20Rev.%20Neurosci.&amp;volume=38&amp;pages=433-447&amp;publication_year=2015&amp;author=Raichle%2CME">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Robertson, C. E. et al. Neural representations integrate the current field of view with the remembered 360Â° panorama in scene-selective cortex. <i>Curr. Biol.</i> <b>26</b>, 2463â€“2468 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28XhsVykt7nF" aria-label="CAS reference 37">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27618266" aria-label="PubMed reference 37">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20representations%20integrate%20the%20current%20field%20of%20view%20with%20the%20remembered%20360%C2%B0%20panorama%20in%20scene-selective%20cortex&amp;journal=Curr.%20Biol.&amp;volume=26&amp;pages=2463-2468&amp;publication_year=2016&amp;author=Robertson%2CCE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Braga, R. M. &amp; Buckner, R. L. Parallel interdigitated distributed networks within the individual estimated by intrinsic functional connectivity. <i>Neuron</i> <b>95</b>, 457â€“471.e5 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXht1SmtbzN" aria-label="CAS reference 38">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28728026" aria-label="PubMed reference 38">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5519493" aria-label="PubMed Central reference 38">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Parallel%20interdigitated%20distributed%20networks%20within%20the%20individual%20estimated%20by%20intrinsic%20functional%20connectivity&amp;journal=Neuron&amp;volume=95&amp;pages=457-471.e5&amp;publication_year=2017&amp;author=Braga%2CRM&amp;author=Buckner%2CRL">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">DiNicola, L. M., Braga, R. M. &amp; Buckner, R. L. Parallel distributed networks dissociate episodic and social functions within the individual. <i>J. Neurophysiol.</i> <b>123</b>, 1144â€“1179 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32049593" aria-label="PubMed reference 39">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7099479" aria-label="PubMed Central reference 39">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Parallel%20distributed%20networks%20dissociate%20episodic%20and%20social%20functions%20within%20the%20individual&amp;journal=J.%20Neurophysiol.&amp;volume=123&amp;pages=1144-1179&amp;publication_year=2020&amp;author=DiNicola%2CLM&amp;author=Braga%2CRM&amp;author=Buckner%2CRL">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Silson, E. H., Steel, A. D. &amp; Baker, C. I. Scene-selectivity and retinotopy in medial parietal cortex. <i>Front Hum. Neurosci.</i> <b>10</b>, 412 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27588001" aria-label="PubMed reference 40">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4988988" aria-label="PubMed Central reference 40">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Scene-selectivity%20and%20retinotopy%20in%20medial%20parietal%20cortex&amp;journal=Front%20Hum.%20Neurosci.&amp;volume=10&amp;publication_year=2016&amp;author=Silson%2CEH&amp;author=Steel%2CAD&amp;author=Baker%2CCI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Silson, E. H., Steel, A., Kidder, A., Gilmore, A. W. &amp; Baker, C. I. Distinct subdivisions of human medial parietal cortex support recollection of people and places. <i>eLife</i> <b>8</b>, e47391 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXhtlaltr7M" aria-label="CAS reference 41">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31305238" aria-label="PubMed reference 41">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6667275" aria-label="PubMed Central reference 41">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Distinct%20subdivisions%20of%20human%20medial%20parietal%20cortex%20support%20recollection%20of%20people%20and%20places&amp;journal=eLife&amp;volume=8&amp;publication_year=2019&amp;author=Silson%2CEH&amp;author=Steel%2CA&amp;author=Kidder%2CA&amp;author=Gilmore%2CAW&amp;author=Baker%2CCI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Deen, B. &amp; Freiwald, W. A. Parallel systems for social and spatial reasoning within the cortical apex. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2021.09.23.461550" data-track="click" data-track-action="external reference" data-track-label="10.1101/2021.09.23.461550">https://doi.org/10.1101/2021.09.23.461550</a> (2021).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Ranganath, C. &amp; Ritchey, M. Two cortical systems for memory-guided behaviour. <i>Nat. Rev. Neurosci.</i> <b>13</b>, 713â€“726 (2012); <a href="https://doi.org/10.1038/nrn3338" data-track="click" data-track-action="external reference" data-track-label="10.1038/nrn3338">https://doi.org/10.1038/nrn3338</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Pertzov, Y., Avidan, G. &amp; Zohary, E. Multiple reference frames for saccadic planning in the human parietal cortex. <i>J. Neurosci.</i> <b>31</b>, 1059 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhsVemt7Y%3D" aria-label="CAS reference 44">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21248131" aria-label="PubMed reference 44">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6632924" aria-label="PubMed Central reference 44">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Multiple%20reference%20frames%20for%20saccadic%20planning%20in%20the%20human%20parietal%20cortex&amp;journal=J.%20Neurosci.&amp;volume=31&amp;publication_year=2011&amp;author=Pertzov%2CY&amp;author=Avidan%2CG&amp;author=Zohary%2CE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">Gardner, J. L., Merriam, E. P., Movshon, J. A. &amp; Heeger, D. J. Maps of visual space in human occipital cortex are retinotopic, not spatiotopic. <i>J. Neurosci.</i> <b>28</b>, 3988 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXkvV2htr0%3D" aria-label="CAS reference 45">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18400898" aria-label="PubMed reference 45">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2515359" aria-label="PubMed Central reference 45">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Maps%20of%20visual%20space%20in%20human%20occipital%20cortex%20are%20retinotopic%2C%20not%20spatiotopic&amp;journal=J.%20Neurosci.&amp;volume=28&amp;publication_year=2008&amp;author=Gardner%2CJL&amp;author=Merriam%2CEP&amp;author=Movshon%2CJA&amp;author=Heeger%2CDJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Fetsch, C. R., Wang, S., Gu, Y., DeAngelis, G. C. &amp; Angelaki, D. E. Spatial reference frames of visual, vestibular, and multimodal heading signals in the dorsal subdivision of the medial superior temporal area. <i>J. Neurosci.</i> <b>27</b>, 700â€“712 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXhtFSku7s%3D" aria-label="CAS reference 46">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17234602" aria-label="PubMed reference 46">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1995026" aria-label="PubMed Central reference 46">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatial%20reference%20frames%20of%20visual%2C%20vestibular%2C%20and%20multimodal%20heading%20signals%20in%20the%20dorsal%20subdivision%20of%20the%20medial%20superior%20temporal%20area&amp;journal=J.%20Neurosci.&amp;volume=27&amp;pages=700-712&amp;publication_year=2007&amp;author=Fetsch%2CCR&amp;author=Wang%2CS&amp;author=Gu%2CY&amp;author=DeAngelis%2CGC&amp;author=Angelaki%2CDE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Golomb, J. D. &amp; Kanwisher, N. Higher level visual cortex represents retinotopic, not spatiotopic, object location. <i>Cereb. Cortex</i> <b>22</b>, 2794â€“2810 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22190434" aria-label="PubMed reference 47">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Higher%20level%20visual%20cortex%20represents%20retinotopic%2C%20not%20spatiotopic%2C%20object%20location&amp;journal=Cereb.%20Cortex&amp;volume=22&amp;pages=2794-2810&amp;publication_year=2012&amp;author=Golomb%2CJD&amp;author=Kanwisher%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Silson, E. H., Groen, I. I. A., Kravitz, D. J. &amp; Baker, C. I. Evaluating the correspondence between face-, scene-, and object-selectivity and retinotopic organization within lateral occipitotemporal cortex. <i>J. Vis.</i> <b>16</b>, 14â€“14 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27105060" aria-label="PubMed reference 48">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4898275" aria-label="PubMed Central reference 48">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluating%20the%20correspondence%20between%20face-%2C%20scene-%2C%20and%20object-selectivity%20and%20retinotopic%20organization%20within%20lateral%20occipitotemporal%20cortex&amp;journal=J.%20Vis.&amp;volume=16&amp;pages=14-14&amp;publication_year=2016&amp;author=Silson%2CEH&amp;author=Groen%2CIIA&amp;author=Kravitz%2CDJ&amp;author=Baker%2CCI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Swisher, J. D., Halko, M. A., Merabet, L. B., McMains, S. A. &amp; Somers, D. C. Visual topography of human intraparietal sulcus. <i>J. Neurosci.</i> <b>27</b>, 5326â€“5337 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2sXlvFGhsr8%3D" aria-label="CAS reference 49">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17507555" aria-label="PubMed reference 49">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6672354" aria-label="PubMed Central reference 49">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20topography%20of%20human%20intraparietal%20sulcus&amp;journal=J.%20Neurosci.&amp;volume=27&amp;pages=5326-5337&amp;publication_year=2007&amp;author=Swisher%2CJD&amp;author=Halko%2CMA&amp;author=Merabet%2CLB&amp;author=McMains%2CSA&amp;author=Somers%2CDC">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">Yeatman, J. D. et al. The vertical occipital fasciculus: a century of controversy resolved by in vivo measurements. <i>Proc. Natl Acad. Sci. USA</i> <b>111</b>, E5214â€“E5223 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXhvFans7nF" aria-label="CAS reference 50">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25404310" aria-label="PubMed reference 50">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4260539" aria-label="PubMed Central reference 50">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20vertical%20occipital%20fasciculus%3A%20a%20century%20of%20controversy%20resolved%20by%20in%20vivo%20measurements&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;volume=111&amp;pages=E5214-E5223&amp;publication_year=2014&amp;author=Yeatman%2CJD">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Peirce, J. W. PsychoPyâ€”psychophysics software in Python. <i>J. Neurosci. Methods.</i> <b>162</b>, 8â€“13 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17254636" aria-label="PubMed reference 51">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2018741" aria-label="PubMed Central reference 51">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=PsychoPy%E2%80%94psychophysics%20software%20in%20Python&amp;journal=J.%20Neurosci.%20Methods.&amp;volume=162&amp;pages=8-13&amp;publication_year=2007&amp;author=Peirce%2CJW">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Weiner, K. S. et al. Defining the most probable location of the parahippocampal place area using cortex-based alignment and cross-validation. <i>Neuroimage</i> <b>170</b>, 373â€“384 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28435097" aria-label="PubMed reference 52">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Defining%20the%20most%20probable%20location%20of%20the%20parahippocampal%20place%20area%20using%20cortex-based%20alignment%20and%20cross-validation&amp;journal=Neuroimage&amp;volume=170&amp;pages=373-384&amp;publication_year=2018&amp;author=Weiner%2CKS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Li, X., Morgan, P. S., Ashburner, J., Smith, J. &amp; Rorden, C. The first step for neuroimaging data analysis: DICOM to NIfTI conversion. <i>J. Neurosci. Methods.</i> <b>264</b>, 47â€“56 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26945974" aria-label="PubMed reference 53">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20first%20step%20for%20neuroimaging%20data%20analysis%3A%20DICOM%20to%20NIfTI%20conversion&amp;journal=J.%20Neurosci.%20Methods.&amp;volume=264&amp;pages=47-56&amp;publication_year=2016&amp;author=Li%2CX&amp;author=Morgan%2CPS&amp;author=Ashburner%2CJ&amp;author=Smith%2CJ&amp;author=Rorden%2CC">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54."><p class="c-article-references__text" id="ref-CR54">Fischl, B. FreeSurfer. <i>NeuroImage</i> <b>62</b>, 774â€“781 (2012); <a href="https://doi.org/10.1016/j.neuroimage.2012.01.021" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.neuroimage.2012.01.021">https://doi.org/10.1016/j.neuroimage.2012.01.021</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55."><p class="c-article-references__text" id="ref-CR55">Fischl, B. et al. Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain. <i>Neuron</i> <b>33</b>, 341â€“355 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD38XjtlWnsbg%3D" aria-label="CAS reference 55">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11832223" aria-label="PubMed reference 55">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=Whole%20brain%20segmentation%3A%20automated%20labeling%20of%20neuroanatomical%20structures%20in%20the%20human%20brain&amp;journal=Neuron&amp;volume=33&amp;pages=341-355&amp;publication_year=2002&amp;author=Fischl%2CB">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56."><p class="c-article-references__text" id="ref-CR56">Dale, A. M., Fischl, B. &amp; Sereno, M. I. Cortical surface-based analysis. I. Segmentation and surface reconstruction. <i>Neuroimage</i> <b>9</b>, 179â€“194 (1999).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK1M7jt1Gisg%3D%3D" aria-label="CAS reference 56">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9931268" aria-label="PubMed reference 56">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20surface-based%20analysis.%20I.%20Segmentation%20and%20surface%20reconstruction&amp;journal=Neuroimage&amp;volume=9&amp;pages=179-194&amp;publication_year=1999&amp;author=Dale%2CAM&amp;author=Fischl%2CB&amp;author=Sereno%2CMI">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57."><p class="c-article-references__text" id="ref-CR57">Saad, Z. S. &amp; Reynolds, R. C. SUMA. <i>Neuroimage</i> <b>62</b>, 768â€“773 (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21945692" aria-label="PubMed reference 57">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 57" href="http://scholar.google.com/scholar_lookup?&amp;title=SUMA&amp;journal=Neuroimage&amp;volume=62&amp;pages=768-773&amp;publication_year=2012&amp;author=Saad%2CZS&amp;author=Reynolds%2CRC">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58."><p class="c-article-references__text" id="ref-CR58">Cox, R. W. AFNI: software for analysis and visualization of functional magnetic resonance neuroimages. <i>Computers Biomed. Res.</i> <b>29</b>, 162â€“173 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=1996cpsa.book.....C" aria-label="ADS reference 58">ADS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK28vgvVChug%3D%3D" aria-label="CAS reference 58">CAS</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=AFNI%3A%20software%20for%20analysis%20and%20visualization%20of%20functional%20magnetic%20resonance%20neuroimages&amp;journal=Computers%20Biomed.%20Res.&amp;volume=29&amp;pages=162-173&amp;publication_year=1996&amp;author=Cox%2CRW">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59."><p class="c-article-references__text" id="ref-CR59">Jo, H. J. et al. Effective preprocessing procedures virtually eliminate distance-dependent motion artifacts in resting state FMRI. <i>J. Appl. Math.</i> <b>2013</b>, 935154 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 59" href="http://scholar.google.com/scholar_lookup?&amp;title=Effective%20preprocessing%20procedures%20virtually%20eliminate%20distance-dependent%20motion%20artifacts%20in%20resting%20state%20FMRI&amp;journal=J.%20Appl.%20Math.&amp;volume=2013&amp;publication_year=2013&amp;author=Jo%2CHJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60."><p class="c-article-references__text" id="ref-CR60">DuPre, E. et al. TE-dependent analysis of multi-echo fMRI with *tedana*. <i>J. Open Source Softw.</i> <b>6</b>, 3669 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2021JOSS....6.3669D" aria-label="ADS reference 60">ADS</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 60" href="http://scholar.google.com/scholar_lookup?&amp;title=TE-dependent%20analysis%20of%20multi-echo%20fMRI%20with%20%2Atedana%2A&amp;journal=J.%20Open%20Source%20Softw.&amp;volume=6&amp;publication_year=2021&amp;author=DuPre%2CE">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61."><p class="c-article-references__text" id="ref-CR61">DuPre, E. et al. ME-ICA/tedana: 0.0.6. Zenodo <a href="https://doi.org/10.5281/ZENODO.2558498" data-track="click" data-track-action="external reference" data-track-label="10.5281/ZENODO.2558498">https://doi.org/10.5281/ZENODO.2558498</a> (2019).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62."><p class="c-article-references__text" id="ref-CR62">Evans, J. W., Kundu, P., Horovitz, S. G. &amp; Bandettini, P. A. Separating slow BOLD from non-BOLD baseline drifts using multi-echo fMRI. <i>Neuroimage</i> <b>105</b>, 189â€“197 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25449746" aria-label="PubMed reference 62">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Separating%20slow%20BOLD%20from%20non-BOLD%20baseline%20drifts%20using%20multi-echo%20fMRI&amp;journal=Neuroimage&amp;volume=105&amp;pages=189-197&amp;publication_year=2015&amp;author=Evans%2CJW&amp;author=Kundu%2CP&amp;author=Horovitz%2CSG&amp;author=Bandettini%2CPA">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63."><p class="c-article-references__text" id="ref-CR63">Argall, B. D., Saad, Z. S. &amp; Beauchamp, M. S. Simplified intersubject averaging on the cortical surface using SUMA. <i>Hum. Brain Mapp.</i> <b>27</b>, 14â€“27 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16035046" aria-label="PubMed reference 63">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="http://scholar.google.com/scholar_lookup?&amp;title=Simplified%20intersubject%20averaging%20on%20the%20cortical%20surface%20using%20SUMA&amp;journal=Hum.%20Brain%20Mapp.&amp;volume=27&amp;pages=14-27&amp;publication_year=2006&amp;author=Argall%2CBD&amp;author=Saad%2CZS&amp;author=Beauchamp%2CMS">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="64."><p class="c-article-references__text" id="ref-CR64">Julian, J. B., Fedorenko, E., Webster, J. &amp; Kanwisher, N. An algorithmic method for functionally defining regions of interest in the ventral visual pathway. <i>NeuroImage</i> <b>60</b>, 2357â€“2364, <a href="https://doi.org/10.1016/j.neuroimage.2012.02.055" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.neuroimage.2012.02.055">https://doi.org/10.1016/j.neuroimage.2012.02.055</a> (2012).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2012.02.055" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2012.02.055" aria-label="Article reference 64" data-doi="10.1016/j.neuroimage.2012.02.055">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BC38vlvVWntA%3D%3D" aria-label="CAS reference 64">CAS</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22398396" aria-label="PubMed reference 64">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20algorithmic%20method%20for%20functionally%20defining%20regions%20of%20interest%20in%20the%20ventral%20visual%20pathway&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2012.02.055&amp;volume=60&amp;pages=2357-2364&amp;publication_year=2012&amp;author=Julian%2CJB&amp;author=Fedorenko%2CE&amp;author=Webster%2CJ&amp;author=Kanwisher%2CN">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="65."><p class="c-article-references__text" id="ref-CR65">Gomez, J., Barnett, M. &amp; Grill-Spector, K. Extensive childhood experience with PokÃ©mon suggests eccentricity drives organization of visual cortex. <i>Nat. Hum. Behav.</i> <b>3</b>, 611â€“624, <a href="https://doi.org/10.1038/s41562-019-0592-8" data-track="click" data-track-action="external reference" data-track-label="10.1038/s41562-019-0592-8">https://doi.org/10.1038/s41562-019-0592-8</a> (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41562-019-0592-8" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41562-019-0592-8" aria-label="Article reference 65" data-doi="10.1038/s41562-019-0592-8">Article</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31061489" aria-label="PubMed reference 65">PubMed</a>Â 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7055538" aria-label="PubMed Central reference 65">PubMed Central</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=Extensive%20childhood%20experience%20with%20Pok%C3%A9mon%20suggests%20eccentricity%20drives%20organization%20of%20visual%20cortex&amp;journal=Nat.%20Hum.%20Behav.&amp;doi=10.1038%2Fs41562-019-0592-8&amp;volume=3&amp;pages=611-624&amp;publication_year=2019&amp;author=Gomez%2CJ&amp;author=Barnett%2CM&amp;author=Grill-Spector%2CK">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="66."><p class="c-article-references__text" id="ref-CR66">Gomez, J. et al. Development of population receptive fields in the lateral visual stream improves spatial coding amid stable structural-functional coupling. <i>NeuroImage</i> <b>188</b>, 59â€“69 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30508682" aria-label="PubMed reference 66">PubMed</a>Â 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20of%20population%20receptive%20fields%20in%20the%20lateral%20visual%20stream%20improves%20spatial%20coding%20amid%20stable%20structural-functional%20coupling&amp;journal=NeuroImage&amp;volume=188&amp;pages=59-69&amp;publication_year=2019&amp;author=Gomez%2CJ">
                    Google Scholar</a>Â 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="67."><p class="c-article-references__text" id="ref-CR67">R Core Team. R: a language and environment for statistical computing (R Foundation for Statistical Computing, 2013); <a href="http://www.r-project.org/" data-track="click" data-track-action="external reference" data-track-label="http://www.r-project.org/">www.r-project.org/</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="68."><p class="c-article-references__text" id="ref-CR68">Lawrence, M. A. ez: easy analysis and visualization of factorial experiments. R package version 4.0.2 (2016).</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-023-01512-3?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We thank I. Groen for assistance with specific analysis code. This work was supported by the National Institute of Mental Health under award number R01MH130529 (C.E.R.). A.S. was supported by the Neukom Institute for Computational Science and E.H.S. by the Biotechnology and Biological Sciences Research Council award number BB/V003917/1.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><span class="c-article-author-information__subtitle u-visually-hidden" id="author-notes">Author notes</span><ol class="c-article-author-information__list"><li class="c-article-author-information__item" id="na1"><p>These authors contributed equally: Adam Steel, Edward H. Silson.</p></li></ol><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Psychology and Brain Sciences, Dartmouth College, Hanover, NH, USA</p><p class="c-article-author-affiliation__authors-list">Adam Steel,Â Brenda D. GarciaÂ &amp;Â Caroline E. Robertson</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Psychosophy, Psychology, and Language Sciences, University of Edinburgh, Edinburgh, UK</p><p class="c-article-author-affiliation__authors-list">Edward H. Silson</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Adam-Steel-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Adam Steel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Adam%20Steel" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Adam%20Steel" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">Â </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Adam%20Steel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Edward_H_-Silson-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Edward H. Silson</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Edward%20H.%20Silson" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Edward%20H.%20Silson" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">Â </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Edward%20H.%20Silson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Brenda_D_-Garcia-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Brenda D. Garcia</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Brenda%20D.%20Garcia" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Brenda%20D.%20Garcia" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">Â </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Brenda%20D.%20Garcia%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Caroline_E_-Robertson-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Caroline E. Robertson</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Caroline%20E.%20Robertson" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Caroline%20E.%20Robertson" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide">Â </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Caroline%20E.%20Robertson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>A.S., E.H.S. and C.E.R. conceived of and designed the experiment. E.H.S. and B.D.G. contributed stimulus code. A.S. and B.D.G. collected the data. A.S. processed the data. A.S. and E.H.S. analyzed the data. A.S., E.H.S. and C.E.R. wrote and edited the paper.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:adamdanielsteel@gmail.com">Adam Steel</a> or <a id="corresp-c2" href="mailto:caroline.e.robertson@dartmouth.edu">Caroline E. Robertson</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar5">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div class="c-article-section" id="peer-review-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="peer-review">Peer review</h2><div class="c-article-section__content" id="peer-review-content">
              
              
                <h3 class="c-article__sub-heading" id="FPar4">Peer review information</h3>
                <p><i>Nature Neuroscience</i> thanks Christopher Baldassano, Alexander Huth and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p><b>Publisherâ€™s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Extended data"><div class="c-article-section" id="Sec28-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec28">Extended data</h2><div class="c-article-section__content" id="Sec28-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig7"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 1 transition from positive to n" href="/articles/s41593-023-01512-3/figures/7" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig7_ESM.jpg">Extended Data Fig. 1 Transition from positive to negative-amplitude population receptive fields (+pRF, -pRF) moving anteriorly from posterior cerebral cortex is evident in individual participants.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Figure depicts amplitude maps from all participantsâ€™ left hemispheres. Only vertices surviving the threshold applied in the main text (R<sup>2</sup>â€‰&gt;â€‰0.08) are shown. Individual participant SPAs and PMAs used for analysis are drawn in white (PMAs) and black (SPAs).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 2 retinotopic coding in spas an" href="/articles/s41593-023-01512-3/figures/8" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig8_ESM.jpg">Extended Data Fig. 2 Retinotopic coding in SPAs and PMAs.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>To quantify the extent to which retinotopic coding is expressed within each ROI we first calculated the percentage of suprathreshold pRFs (R<sup>2</sup>â€‰&gt;â€‰0.08) within our ROIs for each subject separately before testing each against a non-retinotopic prediction using t-tests (that is, t-test versus zero, with Bonferroni correction). Retinotopic coding was significantly present within each ROI (LH; OPA: t(12.51)=, pcorrâ€‰=â€‰3.35-9, Dâ€‰=â€‰2.99; PPA: t(16)â€‰=â€‰8.68, pcorrâ€‰=â€‰5.67-7, Dâ€‰=â€‰2.17; LPMA: t(16)â€‰=â€‰6.23, pcorrâ€‰=â€‰3.58-5, Dâ€‰=â€‰1.59; VPMA: t(16)â€‰=â€‰6.65, pcorrâ€‰=â€‰1.64-5, Dâ€‰=â€‰1.66; RH; OPA: t(16)â€‰=â€‰12.15, pcorrâ€‰=â€‰5.10-9, Dâ€‰=â€‰3.03; PPA: t(16)â€‰=â€‰11.97, pcorrâ€‰=â€‰6.32-9, Dâ€‰=â€‰3.12; LPMA: t(16)â€‰=â€‰8.75, pcorrâ€‰=â€‰5.05-7, Dâ€‰=â€‰2.18; VPMA: t(16)â€‰=â€‰6.39, pcorrâ€‰=â€‰2.68-5, Dâ€‰=â€‰1.55). Bars represent the mean percentage of suprathreshold pRFs (R<sup>2</sup>â€‰&gt;â€‰0.08) in each ROI/hemisphere for the lateral (left) and ventral (right) surfaces, respectively. Individual data points are overlaid. Each ROI exhibited a significant percentage of suprathreshold pRFs, ***p<sub>two-tailed</sub>â€‰&lt;â€‰0.001.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig9"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 3 comparison between the locati" href="/articles/s41593-023-01512-3/figures/9" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig9_ESM.jpg">Extended Data Fig. 3 Comparison between the location of the SPAs, PMAs, and default mode network in one participant.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Comparison between the location of the SPAs, PMAs, and default mode network in one participant (example participant from Main text Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig2">2</a>). This pattern was consistent in all individuals and at the group-level (<b>Main text</b> Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-023-01512-3#Fig1">1b</a>). Default mode network defined using the Yeo et al., 2011 parcellation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Steel, A., Billings, M. M., Silson, E. H. &amp; Robertson, C. E. A network linking scene perception and spatial memory systems in posterior cerebral cortex. Nat. Commun. 12, 1â€“13 (2021)." href="/articles/s41593-023-01512-3#ref-CR24" id="ref-link-section-d41748316e2323">24</a></sup>.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig10"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 4 correlation in trial Ã— trial " href="/articles/s41593-023-01512-3/figures/10" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig10_ESM.jpg">Extended Data Fig. 4 Correlation in trial Ã— trial activation during memory recall aggregated across participants.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Mean BOLD response amplitude relative to baseline during place recall trials for each ROI (OPA, LMPA) and pRF population (+/âˆ’).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig11"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 5 differential interaction betw" href="/articles/s41593-023-01512-3/figures/11" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig11_ESM.jpg">Extended Data Fig. 5 Differential interaction between pRFs in SPAs with âˆ’/+ pRFs in memory areas is evident across all trials.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Each scatter plot and corresponding correlation values depict the unique correlation between pRFs in the SPAs with -pRFs (blue) and +pRFs (red) in the PMAs (for example, correlation between +pRFs in OPA with -pRFs in LPMA, controlling for +pRFs in LPMA) quantified using Pearsonâ€™s correlation. Each data point represents the z-scored activation on a given trial for all pRFS in the population (that is, all -LPMA pRFS) for a given subject on a trial.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig12"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 6 trial x trial interaction bet" href="/articles/s41593-023-01512-3/figures/12" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig12_ESM.jpg">Extended Data Fig. 6 Trial x trial interaction between âˆ’/+ pRFs in the place memory areas and scene perception areas exhibit push-pull interaction in independent data.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Recall trials were identical to the trials used in the localizer. Participants fixated on a dot projected in the center of the screen. They were then cued with the stimulus to be recalled for 1â€‰second, followed by a 1â€‰s dynamic mask, and 10â€‰seconds of imagery. Trials were separated by a 4-8â€‰s jittered interstimulus interval. Participants completed 32 imagery trials (16 for each landmark) separated into two imaging runs. One participant was excluded from the analysis for lack of familiarity with the landmarks; the remaining participants were familiar with the locations and had lived in the Hanover area for at least one year. Two participants did not have -pRFs in the ventral surface regions of interest. We tested for the relationship between +/âˆ’ pRFs in the scene perception and place memory area using the same approach described in the Main text. We examined the unique correlation between the -/+ pRFs in the place memory areas and scene perception areas (that is, correlation between activation of -pRFs in memory areas with pRFs in scene perception areas, while controlling for activation of +pRFs in the memory areas). Using paired t-tests, we found evidence for the opponent interaction between -pRFs and +pRFs in this independent sample. We found that the relationship between the -/+ pRFs in the memory areas with the scene perception area pRFs was significantly different (Lateral â€“ t(8)â€‰=â€‰2.61, pâ€‰=â€‰0.018; Ventral â€“ t(6)â€‰=â€‰7.82, pâ€‰&lt;â€‰0.0001). As we observed in our original analysis, the majority of participants showed a negative correlation in the trial x trial activation of the -pRFs in the place memory areas with pRFs in the scene perception areas (Ventral â€“ 6/7 participants: t(6)â€‰=â€‰2.79, pâ€‰=â€‰0.031; Lateral â€“ 6/8 participants: t(8)â€‰=â€‰1.79, pâ€‰=â€‰0.11). Likewise, most participants showed a positive relationship between activation ofâ€‰+â€‰pRFs in the memory areas and pRFs in the perception areas (Ventral â€“ 7/7 participants; t(6)â€‰=â€‰7.77, pâ€‰=â€‰0.0002; Lateral â€“ 7/8 participants; t(8)â€‰=â€‰3.30, pâ€‰=â€‰0.01). This result gives us confidence that our original analysis was not influenced by potential circularity. * = p<sub>two-tailed</sub>â€‰&lt;â€‰0.05, *** = p<sub>two-tailed</sub>â€‰&lt;â€‰0.005.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig13"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 7 activation during recall of p" href="/articles/s41593-023-01512-3/figures/13" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_Fig13_ESM.jpg">Extended Data Fig. 7 Activation during recall of personally familiar places.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Mean BOLD response amplitude relative to baseline when familiar scenes were presented in each lower quadrant (hemifield: ipsilateral and contralateral) for each ROI (OPA, LPMA) and pRF population (+/âˆ’).</p></div></div></div></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec29-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec29">Supplementary information</h2><div class="c-article-section__content" id="Sec29-content"><div data-test="supplementary-info"><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="reporting summary" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-023-01512-3/MediaObjects/41593_2023_1512_MOESM1_ESM.pdf" data-supp-info-image="">Reporting Summary</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p>Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.</p><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=A%20retinotopic%20code%20structures%20the%20interaction%20between%20perception%20and%20memory%20systems&amp;author=Adam%20Steel%20et%20al&amp;contentID=10.1038%2Fs41593-023-01512-3&amp;copyright=The%20Author%28s%29%2C%20under%20exclusive%20licence%20to%20Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2024-01-02&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41593-023-01512-3" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41593-023-01512-3" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Steel, A., Silson, E.H., Garcia, B.D. <i>et al.</i> A retinotopic code structures the interaction between perception and memory systems.
                    <i>Nat Neurosci</i> <b>27</b>, 339â€“347 (2024). https://doi.org/10.1038/s41593-023-01512-3</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-023-01512-3?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-07-21">21 July 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2023-10-31">31 October 2023</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2024-01-02">02 January 2024</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2024-02">February 2024</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41593-023-01512-3</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Operational encoding enhances action knowledge integration: insights from event-related potential analysis" href="https://doi.org/10.1007/s00221-024-06788-w">
                                        Operational encoding enhances action knowledge integration: insights from event-related potential analysis
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Xiaomei Zhao</li><li>Shi Cheng</li><li>Zihan Liu</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Experimental Brain Research</i> (2024)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-023-01512-3.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-023-01512-3.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41593-023-01512-3;doi=10.1038/s41593-023-01512-3;subjmeta=1595,2613,2649,378,631;kwrd=Cognitive+neuroscience,Learning+and+memory,Neuroscience,Visual+system">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1649239955&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-023-01512-3%26doi%3D10.1038/s41593-023-01512-3%26subjmeta%3D1595,2613,2649,378,631%26kwrd%3DCognitive+neuroscience,Learning+and+memory,Neuroscience,Visual+system">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=-1649239955&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-023-01512-3%26doi%3D10.1038/s41593-023-01512-3%26subjmeta%3D1595,2613,2649,378,631%26kwrd%3DCognitive+neuroscience,Learning+and+memory,Neuroscience,Visual+system"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click||nav_language_services"
                                   data-track-context="header publish with us dropdown menu"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.protocols.io/"
                                                  data-track="click" data-track-action="protocols.io"
                                                  data-track-label="link">protocols.io</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter â€” what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing_input">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/s41593-023-01512-3&amp;format=js&amp;last_modified=2024-01-02" async></script>
<img src="/y1e7xej8/article/s41593-023-01512-3" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>