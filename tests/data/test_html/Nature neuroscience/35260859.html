<!DOCTYPE html>
<html lang="en" class="grade-c">
<head>
    <title>Neurons detect cognitive boundaries to structure episodic memories in humans | Nature Neuroscience</title>
    
        
<link rel="alternate" type="application/rss+xml" href="https://www.nature.com/neuro.rss"/>


    
        

        <script id="save-data-connection-testing">
            function hasConnection() {
                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;
            }

            function createLink(src) {
                var preloadLink = document.createElement("link");
                preloadLink.rel = "preload";
                preloadLink.href = src;
                preloadLink.as = "font";
                preloadLink.type = "font/woff2";
                preloadLink.crossOrigin = "";
                document.head.insertBefore(preloadLink, document.head.firstChild);
            }

            var connectionDetail = {
                saveDataEnabled: false,
                slowConnection: false
            };

            var connection = hasConnection();
            if (connection) {
                connectionDetail.saveDataEnabled = connection.saveData;
                if (/\slow-2g|2g/.test(connection.effectiveType)) {
                    connectionDetail.slowConnection = true;
                }
            }

            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {
                createLink("/static/fonts/HardingText-Regular-Web-cecd90984f.woff2");
            } else {
                document.documentElement.classList.add('save-data');
            }
        </script>
    

<link rel="preconnect" href="https://cmp.nature.com" crossorigin>

<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="applicable-device" content="pc,mobile">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes">
<meta name="360-site-verification" content="5a2dc4ab3fcb9b0393241ffbbb490480" />

<script data-test="dataLayer">
    window.dataLayer = [{"content":{"category":{"contentType":"article","legacy":{"webtrendsPrimaryArticleType":"research","webtrendsSubjectTerms":"cognitive-neuroscience;long-term-memory;neurophysiology","webtrendsContentCategory":null,"webtrendsContentCollection":null,"webtrendsContentGroup":"Nature Neuroscience","webtrendsContentGroupType":null,"webtrendsContentSubGroup":"Article"}},"article":{"doi":"10.1038/s41593-022-01020-w"},"attributes":{"cms":null,"deliveryPlatform":"oscar","copyright":{"open":false,"legacy":{"webtrendsLicenceType":null}}},"contentInfo":{"authors":["Jie Zheng","Andrea G. P. Schjetnan","Mar Yebra","Bernard A. Gomes","Clayton P. Mosher","Suneil K. Kalia","Taufik A. Valiante","Adam N. Mamelak","Gabriel Kreiman","Ueli Rutishauser"],"publishedAt":1646611200,"publishedAtString":"2022-03-07","title":"Neurons detect cognitive boundaries to structure episodic memories in humans","legacy":null,"publishedAtTime":null,"documentType":"aplusplus"},"journal":{"pcode":"neuro","title":"nature neuroscience","volume":"25","issue":"3"},"authorization":{"status":true},"features":[{"name":"furtherReadingSection","present":true}],"collection":null},"page":{"category":{"pageType":"article"},"attributes":{"template":"mosaic","featureFlags":[{"name":"nature-onwards-journey","active":false},{"name":"getftr-entitled","active":false},{"name":"paywall_recommendations","active":true}],"testGroup":null},"search":null},"privacy":{},"version":"1.0.0","product":null,"session":null,"user":null,"backHalfContent":true,"country":"US","hasBody":true,"uneditedManuscript":false,"twitterId":["o3xnx","o43y9","o3ef7"],"baiduId":"d38bce82bcb44717ccc29a90c4b781ea","japan":false}];
    window.dataLayer.push({
        ga4MeasurementId: 'G-ERRNTNZ807',
        ga360TrackingId: 'UA-71668177-1',
        twitterId: ['3xnx', 'o43y9', 'o3ef7'],
        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',
        ga4ServerUrl: 'https://collect.nature.com',
        imprint: 'nature'
    });
</script>

<script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>
 



     
    
    
        
    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:", "}.c-author-list>li:not(:only-child):last-child:before{content:" & "}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:" ... "}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:"";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url("data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>




    
        <link data-test="critical-css-handler" data-inline-css-source="critical-css" rel="stylesheet" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    
    <noscript>
        <link rel="stylesheet" type="text/css" href="/static/css/enhanced-article-nature-branded-950e2d5825.css" media="only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)">
    </noscript>

<link rel="stylesheet" type="text/css" href="/static/css/article-print-122346e276.css" media="print">
    



<link rel="apple-touch-icon" sizes="180x180" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>
<link rel="icon" type="image/png" sizes="48x48" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>
<link rel="icon" type="image/png" sizes="32x32" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>
<link rel="icon" type="image/png" sizes="16x16" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>
<link rel="manifest" href=/static/manifest.json crossorigin="use-credentials">
<link rel="mask-icon" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color="#000000">
<link rel="shortcut icon" href=/static/images/favicons/nature/favicon.ico>
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-config" content=/static/browserconfig.xml>
<meta name="theme-color" content="#000000">
<meta name="application-name" content="Nature">


<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



<!-- Google Tag Manager -->
<script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
<!-- End Google Tag Manager -->

    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            if (h.indexOf('preview-www.nature.com') > -1) return;

            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('nature.com') > -1) {
                if (h.indexOf('test-www.nature.com') > -1) {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                } else {
                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-54.js';
                    e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
                }
            } else {
                e.src = '/static/js/cookie-consent-es5-bundle-26e142e9c6.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>


<script id="js-position0">
    (function(w, d) {
        w.idpVerifyPrefix = 'https://verify.nature.com';
        w.ra21Host = 'https://wayf.springernature.com';
        var moduleSupport = (function() {
            return 'noModule' in d.createElement('script');
        })();

        if (w.config.mustardcut === true) {
            w.loader = {
                index: 0,
                registered: [],
                scripts: [
                    
                        {src: '/static/js/global-article-es6-bundle-782fd09f66.js', test: 'global-article-js', module: true},
                        {src: '/static/js/global-article-es5-bundle-d66d49033d.js', test: 'global-article-js', nomodule: true},
                        {src: '/static/js/shared-es6-bundle-aca08c055a.js', test: 'shared-js', module: true},
                        {src: '/static/js/shared-es5-bundle-4fba787158.js', test: 'shared-js', nomodule: true},
                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},
                        {src: '/static/js/header-150-es5-bundle-1fe07484e5.js', test: 'header-150-js', nomodule: true}
                    
                ].filter(function (s) {
                    if (s.src === null) return false;
                    if (moduleSupport && s.nomodule) return false;
                    return !(!moduleSupport && s.module);
                }),

                register: function (value) {
                    this.registered.push(value);
                },

                ready: function () {
                    if (this.registered.length === this.scripts.length) {
                        this.registered.forEach(function (fn) {
                            if (typeof fn === 'function') {
                                setTimeout(fn, 0); 
                            }
                        });
                        this.ready = function () {};
                    }
                },

                insert: function (s) {
                    var t = d.getElementById('js-position' + this.index);
                    if (t && t.insertAdjacentElement) {
                        t.insertAdjacentElement('afterend', s);
                    } else {
                        d.head.appendChild(s);
                    }
                    ++this.index;
                },

                createScript: function (script, beforeLoad) {
                    var s = d.createElement('script');
                    s.id = 'js-position' + (this.index + 1);
                    s.setAttribute('data-test', script.test);
                    if (beforeLoad) {
                        s.defer = 'defer';
                        s.onload = function () {
                            if (script.noinit) {
                                loader.register(true);
                            }
                            if (d.readyState === 'interactive' || d.readyState === 'complete') {
                                loader.ready();
                            }
                        };
                    } else {
                        s.async = 'async';
                    }
                    s.src = script.src;
                    return s;
                },

                init: function () {
                    this.scripts.forEach(function (s) {
                        loader.insert(loader.createScript(s, true));
                    });

                    d.addEventListener('DOMContentLoaded', function () {
                        loader.ready();
                        var conditionalScripts;
                        
                            conditionalScripts = [
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },
                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-8fc1a30809.js', test: 'pan-zoom-js',  nomodule: true },
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-e0c7186f28.js', test: 'math-js', module: true},
                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-2399be388c.js', test: 'math-js', nomodule: true}
                            ];
                        

                        if (conditionalScripts) {
                            conditionalScripts.filter(function (script) {
                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));
                            }).forEach(function (script) {
                                loader.insert(loader.createScript(script));
                            });
                        }
                    }, false);
                }
            };
            loader.init();
        }
    })(window, document);
</script>










<meta name="robots" content="noarchive">
<meta name="access" content="Yes">


<link rel="search" href="https://www.nature.com/search">
<link rel="search" href="https://www.nature.com/opensearch/opensearch.xml" type="application/opensearchdescription+xml" title="nature.com">
<link rel="search" href="https://www.nature.com/opensearch/request" type="application/sru+xml" title="nature.com">





    
    <script type="application/ld+json">{"mainEntity":{"headline":"Neurons detect cognitive boundaries to structure episodic memories in humans","description":"While experience is continuous, memories are organized as discrete events. Cognitive boundaries are thought to segment experience and structure memory, but how this process is implemented remains unclear. We recorded the activity of single neurons in the human medial temporal lobe (MTL) during the formation and retrieval of memories with complex narratives. Here, we show that neurons responded to abstract cognitive boundaries between different episodes. Boundary-induced neural state changes during encoding predicted subsequent recognition accuracy but impaired event order memory, mirroring a fundamental behavioral tradeoff between content and time memory. Furthermore, the neural state following boundaries was reinstated during both successful retrieval and false memories. These findings reveal a neuronal substrate for detecting cognitive boundaries that transform experience into mnemonic episodes and structure mental time travel during retrieval. Continuous experience is segmented into discrete mnemonic episodes. The authors identify neurons in the human brain whose responses to cognitive boundaries predict memory encoding success and mark timepoints that are reinstated during retrieval.","datePublished":"2022-03-07T00:00:00Z","dateModified":"2022-03-07T00:00:00Z","pageStart":"358","pageEnd":"368","sameAs":"https://doi.org/10.1038/s41593-022-01020-w","keywords":["Cognitive neuroscience","Long-term memory","Neurophysiology","Biomedicine","general","Neurosciences","Behavioral Sciences","Biological Techniques","Neurobiology","Animal Genetics and Genomics"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig3_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig4_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig5_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig6_HTML.png"],"isPartOf":{"name":"Nature Neuroscience","issn":["1546-1726","1097-6256"],"volumeNumber":"25","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Jie Zheng","url":"http://orcid.org/0000-0002-9086-3760","affiliation":[{"name":"Children’s Hospital, Harvard Medical School","address":{"name":"Department of Ophthalmology, Children’s Hospital, Harvard Medical School, Boston, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Andrea G. P. Schjetnan","affiliation":[{"name":"University Health Network (UHN), University of Toronto","address":{"name":"Krembil Brain Institute and Division of Neurosurgery, University Health Network (UHN), University of Toronto, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Mar Yebra","affiliation":[{"name":"Cedars-Sinai Medical Center","address":{"name":"Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Bernard A. Gomes","url":"http://orcid.org/0000-0002-2803-964X","affiliation":[{"name":"Cedars-Sinai Medical Center","address":{"name":"Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Clayton P. Mosher","affiliation":[{"name":"Cedars-Sinai Medical Center","address":{"name":"Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Suneil K. Kalia","affiliation":[{"name":"University Health Network (UHN), University of Toronto","address":{"name":"Krembil Brain Institute and Division of Neurosurgery, University Health Network (UHN), University of Toronto, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Taufik A. Valiante","url":"http://orcid.org/0000-0002-3443-3790","affiliation":[{"name":"University Health Network (UHN), University of Toronto","address":{"name":"Krembil Brain Institute and Division of Neurosurgery, University Health Network (UHN), University of Toronto, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"University of Toronto","address":{"name":"Department of Surgery (Neurosurgery), Institute of Biomedical Engineering, and Electrical and Computer Engineering, University of Toronto, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"University of Toronto","address":{"name":"Max Planck-University of Toronto Center for Neural Science and Technology, University of Toronto, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"University of Toronto","address":{"name":"Center for Advancing Neurotechnological Innovation to Application, University Health Network, University of Toronto, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Adam N. Mamelak","affiliation":[{"name":"Cedars-Sinai Medical Center","address":{"name":"Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Gabriel Kreiman","url":"http://orcid.org/0000-0003-3505-8475","affiliation":[{"name":"Children’s Hospital, Harvard Medical School","address":{"name":"Department of Ophthalmology, Children’s Hospital, Harvard Medical School, Boston, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Center for Brains, Minds and Machines","address":{"name":"Center for Brains, Minds and Machines, Cambridge, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"gabriel.kreiman@childrens.harvard.edu","@type":"Person"},{"name":"Ueli Rutishauser","url":"http://orcid.org/0000-0002-9207-7069","affiliation":[{"name":"Cedars-Sinai Medical Center","address":{"name":"Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Cedars-Sinai Medical Center","address":{"name":"Department of Neurology, Cedars-Sinai Medical Center, Los Angeles, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"Department of Biomedical Sciences, Cedars-Sinai Medical Center","address":{"name":"Center for Neural Science and Medicine, Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, USA","@type":"PostalAddress"},"@type":"Organization"},{"name":"California Institute of Technology","address":{"name":"Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"ueli.rutishauser@cshs.org","@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>




    
    
    


    
    <link rel="canonical" href="https://www.nature.com/articles/s41593-022-01020-w">
    
    
    <meta name="journal_id" content="41593"/>
    <meta name="dc.title" content="Neurons detect cognitive boundaries to structure episodic memories in humans"/>
    <meta name="dc.source" content="Nature Neuroscience 2022 25:3"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Nature Publishing Group"/>
    <meta name="dc.date" content="2022-03-07"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rights" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="While experience is continuous, memories are organized as discrete events. Cognitive boundaries are thought to segment experience and structure memory, but how this process is implemented remains unclear. We recorded the activity of single neurons in the human medial temporal lobe (MTL) during the formation and retrieval of memories with complex narratives. Here, we show that neurons responded to abstract cognitive boundaries between different episodes. Boundary-induced neural state changes during encoding predicted subsequent recognition accuracy but impaired event order memory, mirroring a fundamental behavioral tradeoff between content and time memory. Furthermore, the neural state following boundaries was reinstated during both successful retrieval and false memories. These findings reveal a neuronal substrate for detecting cognitive boundaries that transform experience into mnemonic episodes and structure mental time travel during retrieval. Continuous experience is segmented into discrete mnemonic episodes. The authors identify neurons in the human brain whose responses to cognitive boundaries predict memory encoding success and mark timepoints that are reinstated during retrieval."/>
    <meta name="prism.issn" content="1546-1726"/>
    <meta name="prism.publicationName" content="Nature Neuroscience"/>
    <meta name="prism.publicationDate" content="2022-03-07"/>
    <meta name="prism.volume" content="25"/>
    <meta name="prism.number" content="3"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="358"/>
    <meta name="prism.endingPage" content="368"/>
    <meta name="prism.copyright" content="2022 The Author(s), under exclusive licence to Springer Nature America, Inc."/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://www.nature.com/articles/s41593-022-01020-w"/>
    <meta name="prism.doi" content="doi:10.1038/s41593-022-01020-w"/>
    <meta name="citation_pdf_url" content="https://www.nature.com/articles/s41593-022-01020-w.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://www.nature.com/articles/s41593-022-01020-w"/>
    <meta name="citation_journal_title" content="Nature Neuroscience"/>
    <meta name="citation_journal_abbrev" content="Nat Neurosci"/>
    <meta name="citation_publisher" content="Nature Publishing Group"/>
    <meta name="citation_issn" content="1546-1726"/>
    <meta name="citation_title" content="Neurons detect cognitive boundaries to structure episodic memories in humans"/>
    <meta name="citation_volume" content="25"/>
    <meta name="citation_issue" content="3"/>
    <meta name="citation_publication_date" content="2022/03"/>
    <meta name="citation_online_date" content="2022/03/07"/>
    <meta name="citation_firstpage" content="358"/>
    <meta name="citation_lastpage" content="368"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1038/s41593-022-01020-w"/>
    <meta name="DOI" content="10.1038/s41593-022-01020-w"/>
    <meta name="size" content="239743"/>
    <meta name="citation_doi" content="10.1038/s41593-022-01020-w"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1038/s41593-022-01020-w&amp;api_key="/>
    <meta name="description" content="While experience is continuous, memories are organized as discrete events. Cognitive boundaries are thought to segment experience and structure memory, but how this process is implemented remains unclear. We recorded the activity of single neurons in the human medial temporal lobe (MTL) during the formation and retrieval of memories with complex narratives. Here, we show that neurons responded to abstract cognitive boundaries between different episodes. Boundary-induced neural state changes during encoding predicted subsequent recognition accuracy but impaired event order memory, mirroring a fundamental behavioral tradeoff between content and time memory. Furthermore, the neural state following boundaries was reinstated during both successful retrieval and false memories. These findings reveal a neuronal substrate for detecting cognitive boundaries that transform experience into mnemonic episodes and structure mental time travel during retrieval. Continuous experience is segmented into discrete mnemonic episodes. The authors identify neurons in the human brain whose responses to cognitive boundaries predict memory encoding success and mark timepoints that are reinstated during retrieval."/>
    <meta name="dc.creator" content="Zheng, Jie"/>
    <meta name="dc.creator" content="Schjetnan, Andrea G. P."/>
    <meta name="dc.creator" content="Yebra, Mar"/>
    <meta name="dc.creator" content="Gomes, Bernard A."/>
    <meta name="dc.creator" content="Mosher, Clayton P."/>
    <meta name="dc.creator" content="Kalia, Suneil K."/>
    <meta name="dc.creator" content="Valiante, Taufik A."/>
    <meta name="dc.creator" content="Mamelak, Adam N."/>
    <meta name="dc.creator" content="Kreiman, Gabriel"/>
    <meta name="dc.creator" content="Rutishauser, Ueli"/>
    <meta name="dc.subject" content="Cognitive neuroscience"/>
    <meta name="dc.subject" content="Long-term memory"/>
    <meta name="dc.subject" content="Neurophysiology"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Sci.; citation_title=What constitutes an episode in episodic memory?; citation_author=Y Ezzyat, L Davachi; citation_volume=22; citation_publication_date=2011; citation_pages=243-252; citation_doi=10.1177/0956797610393742; citation_id=CR1"/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Psychol.; citation_title=Episodic memory: from mind to brain; citation_author=E Tulving; citation_volume=53; citation_publication_date=2002; citation_pages=1-25; citation_doi=10.1146/annurev.psych.53.100901.135114; citation_id=CR2"/>
    <meta name="citation_reference" content="Radvansky, G. A. &amp; Zacks, J. M. Event Cognition (Oxford University Press, 2014)."/>
    <meta name="citation_reference" content="citation_journal_title=Annu. Rev. Neurosci.; citation_title=Neural mechanisms of selective visual attention; citation_author=R Desimone, J Duncan; citation_volume=18; citation_publication_date=1995; citation_pages=193-222; citation_doi=10.1146/annurev.ne.18.030195.001205; citation_id=CR4"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Human brain activity time-locked to perceptual event boundaries; citation_author=JM Zacks; citation_volume=4; citation_publication_date=2001; citation_pages=651-655; citation_doi=10.1038/88486; citation_id=CR5"/>
    <meta name="citation_reference" content="citation_journal_title=Cognition; citation_title=The emergence of events; citation_author=J Avrahami, Y Kareev; citation_volume=53; citation_publication_date=1994; citation_pages=239-261; citation_doi=10.1016/0010-0277(94)90050-7; citation_id=CR6"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Gen.; citation_title=The influence of context boundaries on memory for the sequential order of events; citation_author=S DuBrow, L Davachi; citation_volume=142; citation_publication_date=2013; citation_pages=1277-1286; citation_doi=10.1037/a0034024; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Shared memories reveal shared structure in neural activity across individuals; citation_author=J Chen; citation_volume=20; citation_publication_date=2017; citation_pages=115-125; citation_doi=10.1038/nn.4450; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Segmentation in the perception and memory of events; citation_author=CA Kurby, JM Zacks; citation_volume=12; citation_publication_date=2008; citation_pages=72-79; citation_doi=10.1016/j.tics.2007.11.004; citation_id=CR9"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Bull.; citation_title=Event perception: a mind&#8211;brain perspective; citation_author=JM Zacks, NK Speer, KM Swallow, TS Braver, JR Reynolds; citation_volume=133; citation_publication_date=2007; citation_pages=273-293; citation_doi=10.1037/0033-2909.133.2.273; citation_id=CR10"/>
    <meta name="citation_reference" content="citation_journal_title=J. Cogn. Neurosci.; citation_title=Medial orbitofrontal cortex, dorsolateral prefrontal cortex, and hippocampus differentially represent the event saliency; citation_author=A Jafarpour, S Griffin, JJ Lin, RT Knight; citation_volume=31; citation_publication_date=2019; citation_pages=874-884; citation_doi=10.1162/jocn_a_01392; citation_id=CR11"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=The hippocampal film editor: sensitivity and specificity to event boundaries in continuous experience; citation_author=A Ben-Yakov, RN Henson; citation_volume=38; citation_publication_date=2018; citation_pages=10057-10068; citation_doi=10.1523/JNEUROSCI.0524-18.2018; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=Discovering event structure in continuous narrative perception and memory; citation_author=C Baldassano; citation_volume=95; citation_publication_date=2017; citation_pages=709-721; citation_doi=10.1016/j.neuron.2017.06.041; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Cereb. Cortex; citation_title=Place field repetition and purely local remapping in a multicompartment environment; citation_author=HJ Spiers, RM Hayman, A Jovalekic, E Marozzi, KJ Jeffery; citation_volume=25; citation_publication_date=2015; citation_pages=10-25; citation_doi=10.1093/cercor/bht198; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Fragmentation of grid cell maps in a multicompartment environment; citation_author=D Derdikman; citation_volume=12; citation_publication_date=2009; citation_pages=1325-1332; citation_doi=10.1038/nn.2396; citation_id=CR15"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Boundary vector cells in the subiculum of the hippocampal formation; citation_author=C Lever, S Burton, A Jeewajee, J O&#8217;Keefe, N Burgess; citation_volume=29; citation_publication_date=2009; citation_pages=9771-9777; citation_doi=10.1523/JNEUROSCI.1319-09.2009; citation_id=CR16"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Geometric determinants of the place fields of hippocampal neurons; citation_author=J O&#8217;Keefe, N Burgess; citation_volume=381; citation_publication_date=1996; citation_pages=425-428; citation_doi=10.1038/381425a0; citation_id=CR17"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Place cells in the hippocampus: eleven maps for eleven rooms; citation_author=CB Alme; citation_volume=111; citation_publication_date=2014; citation_pages=18428-18435; citation_doi=10.1073/pnas.1421056111; citation_id=CR18"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Neurosci.; citation_title=Understanding memory through hippocampal remapping; citation_author=LL Colgin, EI Moser, MB Moser; citation_volume=31; citation_publication_date=2008; citation_pages=469-477; citation_doi=10.1016/j.tins.2008.06.008; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Hippocampus; citation_title=Place field repetition and spatial learning in a multicompartment environment; citation_author=RM Grieves, BW Jenkins, BC Harland, ER Wood, PA Dudchenko; citation_volume=26; citation_publication_date=2016; citation_pages=118-134; citation_doi=10.1002/hipo.22496; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Hippocampal neurons represent events as transferable units of experience; citation_author=C Sun, W Yang, J Martin, S Tonegawa; citation_volume=23; citation_publication_date=2020; citation_pages=651-663; citation_doi=10.1038/s41593-020-0614-x; citation_id=CR21"/>
    <meta name="citation_reference" content="citation_journal_title=Brain; citation_title=Episodic memory and the self in a case of isolated retrograde amnesia; citation_author=B Levine; citation_volume=121; citation_publication_date=1998; citation_pages=1951-1973; citation_doi=10.1093/brain/121.10.1951; citation_id=CR22"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Testing models of human declarative memory at the single-neuron level; citation_author=U Rutishauser; citation_volume=23; citation_publication_date=2019; citation_pages=510-524; citation_doi=10.1016/j.tics.2019.03.006; citation_id=CR23"/>
    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Human memory strength is predicted by theta-frequency phase-locking of single neurons; citation_author=U Rutishauser, IB Ross, AN Mamelak, EM Schuman; citation_volume=464; citation_publication_date=2010; citation_pages=903-907; citation_doi=10.1038/nature08860; citation_id=CR24"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Coordinated representational reinstatement in the human hippocampus and lateral temporal cortex during episodic memory retrieval; citation_author=D Pacheco Estefan; citation_volume=10; citation_publication_date=2019; citation_doi=10.1038/s41467-019-09569-0; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Proc. Natl Acad. Sci. USA; citation_title=Oscillatory patterns in temporal lobe reveal context reinstatement during memory search; citation_author=JR Manning, SM Polyn, GH Baltuch, B Litt, MJ Kahana; citation_volume=108; citation_publication_date=2011; citation_pages=12893-12897; citation_doi=10.1073/pnas.1015174108; citation_id=CR26"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Human episodic memory retrieval is accompanied by a neural contiguity effect; citation_author=S Folkerts, U Rutishauser, MW Howard; citation_volume=38; citation_publication_date=2018; citation_pages=4200-4211; citation_doi=10.1523/JNEUROSCI.2312-17.2018; citation_id=CR27"/>
    <meta name="citation_reference" content="citation_journal_title=Psychol. Rev.; citation_title=The temporal context model in spatial navigation and relational learning: toward a common explanation of medial temporal lobe function across domains; citation_author=MW Howard, MS Fotedar, AV Datey, ME Hasselmo; citation_volume=112; citation_publication_date=2005; citation_pages=75-116; citation_doi=10.1037/0033-295X.112.1.75; citation_id=CR28"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Gen.; citation_title=Event boundaries in perception affect memory encoding and updating; citation_author=KM Swallow, JM Zacks, RA Abrams; citation_volume=138; citation_publication_date=2009; citation_pages=236-257; citation_doi=10.1037/a0015631; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=J. Appl. Res. Mem. Cogn.; citation_title=Event perception: translations and applications; citation_author=LL Richmond, DA Gold, JM Zacks; citation_volume=6; citation_publication_date=2017; citation_pages=111-120; citation_doi=10.1016/j.jarmac.2016.11.002; citation_id=CR30"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Constructing realistic engrams: poststimulus activity of hippocampus and dorsal striatum predicts subsequent episodic memory; citation_author=A Ben-Yakov, Y Dudai; citation_volume=31; citation_publication_date=2011; citation_pages=9032-9042; citation_doi=10.1523/JNEUROSCI.0702-11.2011; citation_id=CR31"/>
    <meta name="citation_reference" content="citation_journal_title=J. Exp. Psychol. Gen.; citation_title=Hippocampal immediate poststimulus activity in the encoding of consecutive naturalistic episodes; citation_author=A Ben-Yakov, N Eshel, Y Dudai; citation_volume=142; citation_publication_date=2013; citation_pages=1255-1263; citation_doi=10.1037/a0033558; citation_id=CR32"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=What is changing when: decoding visual information in movies from human intracranial recordings; citation_author=L Isik, J Singer, JR Madsen, N Kanwisher, G Kreiman; citation_volume=180; citation_publication_date=2018; citation_pages=147-159; citation_doi=10.1016/j.neuroimage.2017.08.027; citation_id=CR33"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=The role of the parahippocampal cortex in cognition; citation_author=EM Aminoff, K Kveraga, M Bar; citation_volume=17; citation_publication_date=2013; citation_pages=379-390; citation_doi=10.1016/j.tics.2013.06.009; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Neuron; citation_title=The hippocampal-VTA loop: controlling the entry of information into long-term memory; citation_author=JE Lisman, AA Grace; citation_volume=46; citation_publication_date=2005; citation_pages=703-713; citation_doi=10.1016/j.neuron.2005.05.002; citation_id=CR35"/>
    <meta name="citation_reference" content="citation_journal_title=Hippocampus; citation_title=Hippocampus as comparator: role of the two input and two output systems of the hippocampus in selection and registration of information; citation_author=OS Vinogradova; citation_volume=11; citation_publication_date=2001; citation_pages=578-598; citation_doi=10.1002/hipo.1073; citation_id=CR36"/>
    <meta name="citation_reference" content="citation_journal_title=Science; citation_title=Representation of geometric borders in the entorhinal cortex; citation_author=T Solstad, CN Boccara, E Kropff, MB Moser, EI Moser; citation_volume=322; citation_publication_date=2008; citation_pages=1865-1868; citation_doi=10.1126/science.1166466; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Transformed neural pattern reinstatement during episodic memory retrieval; citation_author=X Xiao; citation_volume=37; citation_publication_date=2017; citation_pages=2986-2998; citation_doi=10.1523/JNEUROSCI.2324-16.2017; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci.; citation_title=Parietal representations of stimulus features are amplified during memory retrieval and flexibly aligned with top&#8211;down goals; citation_author=SE Favila, R Samide, SC Sweigart, BA Kuhl; citation_volume=38; citation_publication_date=2018; citation_pages=7809-7821; citation_doi=10.1523/JNEUROSCI.0564-18.2018; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Curr. Biol.; citation_title=Human cortical neurons in the anterior temporal lobe reinstate spiking activity during verbal memory retrieval; citation_author=AI Jang, JH Wittig, SK Inati, KA Zaghloul; citation_volume=27; citation_publication_date=2017; citation_pages=1700-1705; citation_doi=10.1016/j.cub.2017.05.014; citation_id=CR40"/>
    <meta name="citation_reference" content="citation_journal_title=Neural Netw.; citation_title=Place from time: reconstructing position from a distributed representation of temporal context; citation_author=MW Howard, VS Natu; citation_volume=18; citation_publication_date=2005; citation_pages=1150-1162; citation_doi=10.1016/j.neunet.2005.08.002; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=Trends Cogn. Sci.; citation_title=Memory search and the neural representation of context; citation_author=SM Polyn, MJ Kahana; citation_volume=12; citation_publication_date=2008; citation_pages=24-30; citation_doi=10.1016/j.tics.2007.10.010; citation_id=CR42"/>
    <meta name="citation_reference" content="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. in NIPS&#8217;12: Proceedings of the 25th International Conference on Neural Information Processing Systems, Vol. 1 (eds Bartlett, P., Pereira, F. C. N., Burges, C. J. C., Bottoue, L., &amp; Weinberger K. Q.) 1097&#8211;1105 (Morgan Kaufmann, 2012)."/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci. Methods; citation_title=Online detection and sorting of extracellularly recorded action potentials in human medial temporal lobe recordings, in vivo; citation_author=U Rutishauser, EM Schuman, AN Mamelak; citation_volume=154; citation_publication_date=2006; citation_pages=204-224; citation_doi=10.1016/j.jneumeth.2005.12.033; citation_id=CR44"/>
    <meta name="citation_reference" content="Fried, I., Rutishauser, U., Cerf, M. &amp; Kreiman, G. Single Neuron Studies of the Human Brain: Probing Cognition (The MIT Press, 2014)."/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Neurosci.; citation_title=Persistently active neurons in human medial frontal and medial temporal lobe support working memory; citation_author=J Kaminski; citation_volume=20; citation_publication_date=2017; citation_pages=590-601; citation_doi=10.1038/nn.4509; citation_id=CR46"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci. Methods; citation_title=Using noise signature to optimize spike-sorting and to assess neuronal classification quality; citation_author=C Pouzat, O Mazor, G Laurent; citation_volume=122; citation_publication_date=2002; citation_pages=43-57; citation_doi=10.1016/S0165-0270(02)00276-5; citation_id=CR47"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurophysiol.; citation_title=Accuracy of tetrode spike separation as determined by simultaneous intracellular and extracellular measurements; citation_author=KD Harris, DA Henze, J Csicsvari, H Hirase, G Buzsaki; citation_volume=84; citation_publication_date=2000; citation_pages=401-414; citation_doi=10.1152/jn.2000.84.1.401; citation_id=CR48"/>
    <meta name="citation_reference" content="citation_journal_title=Neuroimage; citation_title=Highly accurate inverse consistent registration: a robust approach; citation_author=M Reuter, HD Rosas, B Fischl; citation_volume=53; citation_publication_date=2010; citation_pages=1181-1196; citation_doi=10.1016/j.neuroimage.2010.07.020; citation_id=CR49"/>
    <meta name="citation_reference" content="citation_journal_title=Sci. Data; citation_title=A high-resolution probabilistic in vivo atlas of human subcortical brain nuclei; citation_author=WM Pauli, AN Nili, JM Tyszka; citation_volume=5; citation_publication_date=2018; citation_doi=10.1038/sdata.2018.63; citation_id=CR50"/>
    <meta name="citation_reference" content="citation_journal_title=Acad. Radiol.; citation_title=Multivariate analysis of structural and diffusion imaging in traumatic brain injury; citation_author=B Avants; citation_volume=15; citation_publication_date=2008; citation_pages=1360-1375; citation_doi=10.1016/j.acra.2008.07.007; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci. Methods; citation_title=Adaptive spike-artifact removal from local field potentials uncovers prominent beta and gamma band neuronal synchronization; citation_author=K Banaie Boroujeni, P Tiesinga, T Womelsdorf; citation_volume=330; citation_publication_date=2020; citation_pages=108485; citation_doi=10.1016/j.jneumeth.2019.108485; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=Comput Intell. Neurosci.; citation_title=FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data; citation_author=R Oostenveld, P Fries, E Maris, JM Schoffelen; citation_volume=2011; citation_publication_date=2011; citation_pages=156869; citation_doi=10.1155/2011/156869; citation_id=CR53"/>
    <meta name="citation_reference" content="citation_journal_title=J. Neurosci. Methods; citation_title=EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis; citation_author=A Delorme, S Makeig; citation_volume=134; citation_publication_date=2004; citation_pages=9-21; citation_doi=10.1016/j.jneumeth.2003.10.009; citation_id=CR54"/>
    <meta name="citation_reference" content="Kobak, D. et al. Demixed principal component analysis of neural population data. eLife 5, e10989 (2016)"/>
    <meta name="citation_reference" content="citation_journal_title=Nat. Commun.; citation_title=Concept neurons in the human medial temporal lobe flexibly represent abstract relations between concepts; citation_author=M Bausch; citation_volume=12; citation_publication_date=2021; citation_doi=10.1038/s41467-021-26327-3; citation_id=CR56"/>
    <meta name="citation_author" content="Zheng, Jie"/>
    <meta name="citation_author_institution" content="Department of Ophthalmology, Children&#8217;s Hospital, Harvard Medical School, Boston, USA"/>
    <meta name="citation_author" content="Schjetnan, Andrea G. P."/>
    <meta name="citation_author_institution" content="Krembil Brain Institute and Division of Neurosurgery, University Health Network (UHN), University of Toronto, Toronto, Canada"/>
    <meta name="citation_author" content="Yebra, Mar"/>
    <meta name="citation_author_institution" content="Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA"/>
    <meta name="citation_author" content="Gomes, Bernard A."/>
    <meta name="citation_author_institution" content="Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA"/>
    <meta name="citation_author" content="Mosher, Clayton P."/>
    <meta name="citation_author_institution" content="Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA"/>
    <meta name="citation_author" content="Kalia, Suneil K."/>
    <meta name="citation_author_institution" content="Krembil Brain Institute and Division of Neurosurgery, University Health Network (UHN), University of Toronto, Toronto, Canada"/>
    <meta name="citation_author" content="Valiante, Taufik A."/>
    <meta name="citation_author_institution" content="Krembil Brain Institute and Division of Neurosurgery, University Health Network (UHN), University of Toronto, Toronto, Canada"/>
    <meta name="citation_author_institution" content="Department of Surgery (Neurosurgery), Institute of Biomedical Engineering, and Electrical and Computer Engineering, University of Toronto, Toronto, Canada"/>
    <meta name="citation_author_institution" content="Max Planck-University of Toronto Center for Neural Science and Technology, University of Toronto, Toronto, Canada"/>
    <meta name="citation_author_institution" content="Center for Advancing Neurotechnological Innovation to Application, University Health Network, University of Toronto, Toronto, Canada"/>
    <meta name="citation_author" content="Mamelak, Adam N."/>
    <meta name="citation_author_institution" content="Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA"/>
    <meta name="citation_author" content="Kreiman, Gabriel"/>
    <meta name="citation_author_institution" content="Department of Ophthalmology, Children&#8217;s Hospital, Harvard Medical School, Boston, USA"/>
    <meta name="citation_author_institution" content="Center for Brains, Minds and Machines, Cambridge, USA"/>
    <meta name="citation_author" content="Rutishauser, Ueli"/>
    <meta name="citation_author_institution" content="Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, USA"/>
    <meta name="citation_author_institution" content="Department of Neurology, Cedars-Sinai Medical Center, Los Angeles, USA"/>
    <meta name="citation_author_institution" content="Center for Neural Science and Medicine, Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, USA"/>
    <meta name="citation_author_institution" content="Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, USA"/>
    <meta name="access_endpoint" content="https://www.nature.com/platform/readcube-access"/>
    <meta name="twitter:site" content="@natureneuro"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Neurons detect cognitive boundaries to structure episodic memories in humans"/>
    <meta name="twitter:description" content="Nature Neuroscience - Continuous experience is segmented into discrete mnemonic episodes. The authors identify neurons in the human brain whose responses to cognitive boundaries predict memory..."/>
    <meta name="twitter:image" content="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig1_HTML.png"/>
    

    
    
    <meta property="og:url" content="https://www.nature.com/articles/s41593-022-01020-w"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="Nature"/>
    <meta property="og:title" content="Neurons detect cognitive boundaries to structure episodic memories in humans - Nature Neuroscience"/>
    <meta property="og:description" content="Continuous experience is segmented into discrete mnemonic episodes. The authors identify neurons in the human brain whose responses to cognitive boundaries predict memory encoding success and mark timepoints that are reinstated during retrieval."/>
    <meta property="og:image" content="https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig1_HTML.png"/>
    

    <script>
        window.eligibleForRa21 = 'true'; 
    </script>
</head>
<body class="article-page">

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<div class="position-relative cleared z-index-50 background-white" data-test="top-containers">
    <a class="c-skip-link" href="#content">Skip to main content</a>



<div class="c-grade-c-banner u-hide">
    <div class="c-grade-c-banner__container">
        
        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain
            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in
            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles
            and JavaScript.</p>

    </div>
</div>

    

    <div class="u-lazy-ad-wrapper u-mbs-0">
            <div class="deferred-placeholder" data-replace="true"
                 data-placeholder="/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container"></div>
            <aside class="c-ad c-ad--728x90">
                <div class="c-ad__inner" data-container-type="banner-advert">
                    <p class="c-ad__label">Advertisement</p>
                    
        
            
    <div id="div-gpt-ad-top-1"
         class="div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide"
         data-ad-type="top"
         data-test="top-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="728x90"
         data-gpt-targeting="type=article;pos=top;artid=s41593-022-01020-w;doi=10.1038/s41593-022-01020-w;subjmeta=1595,2167,2649,376,378,443,631;kwrd=Cognitive+neuroscience,Long-term+memory,Neurophysiology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=607053895&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-022-01020-w%26doi%3D10.1038/s41593-022-01020-w%26subjmeta%3D1595,2167,2649,376,378,443,631%26kwrd%3DCognitive+neuroscience,Long-term+memory,Neurophysiology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=728x90&amp;c=607053895&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41593-022-01020-w%26doi%3D10.1038/s41593-022-01020-w%26subjmeta%3D1595,2167,2649,376,378,443,631%26kwrd%3DCognitive+neuroscience,Long-term+memory,Neurophysiology"
                     alt="Advertisement"
                     width="728"
                     height="90"></a>
        </noscript>
    </div>

        
    
                </div>
            </aside>
        </div>
    <header class="c-header" id="header" data-header data-track-component="nature-150-split-header" style="border-color:#00928c">
        <div class="c-header__row">
            <div class="c-header__container">
                <div class="c-header__split">
                    
                    
                    <div class="c-header__logo-container">
                        
                        <a href="/neuro"
                           data-track="click" data-track-action="home" data-track-label="image">
                            <picture class="c-header__logo">
                                <source srcset="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-0ccc487532906d646419e51f647ce79a.svg" media="(min-width: 875px)">
                                <img src="https://media.springernature.com/full/nature-cms/uploads/product/neuro/header-880e5942f43b9213989c58a04ab5c8e6.svg" height="32" alt="Nature Neuroscience">
                            </picture>
                        </a>
                    
                    </div>
                    
                    <ul class="c-header__menu c-header__menu--global">
                        <li class="c-header__item c-header__item--padding c-header__item--hide-md-max">
                            <a class="c-header__link" href="https://www.nature.com/siteindex" data-test="siteindex-link"
                               data-track="click" data-track-action="open nature research index" data-track-label="link">
                                <span>View all journals</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--pipe">
                            <a class="c-header__link c-header__link--search"
                                href="#search-menu"
                                data-header-expander
                                data-test="search-link" data-track="click" data-track-action="open search tray" data-track-label="button">
                                <svg role="img" aria-hidden="true" focusable="false" height="22" width="22" viewBox="0 0 18 18" xmlns="http://www.w3.org/2000/svg"><path d="M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z"/></svg><span>Search</span>
                            </a>
                        </li>
                        <li class="c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe">
                            
                                <a class="c-header__link eds-c-header__link" id="identity-account-widget" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41593-022-01020-w'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
                            
                        </li>
                    </ul>
                </div>
            </div>
        </div>
        
            <div class="c-header__row">
                <div class="c-header__container" data-test="navigation-row">
                    <div class="c-header__split">
                        <ul class="c-header__menu c-header__menu--journal">
                            
                                <li class="c-header__item c-header__item--dropdown-menu" data-test="explore-content-button">
                                    <a href="#explore"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--explore"
                                       data-track="click" data-track-action="open explore expander" data-track-label="button">
                                        <span><span class="c-header__show-text">Explore</span> content</span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--dropdown-menu">
                                    <a href="#about-the-journal"
                                       class="c-header__link"
                                       data-header-expander
                                       data-test="menu-button--about-the-journal"
                                       data-track="click" data-track-action="open about the journal expander" data-track-label="button">
                                        <span>About <span class="c-header__show-text">the journal</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                    </a>
                                </li>
                                
                                    <li class="c-header__item c-header__item--dropdown-menu" data-test="publish-with-us-button">
                                        <a href="#publish-with-us"
                                           class="c-header__link c-header__link--dropdown-menu"
                                           data-header-expander
                                           data-test="menu-button--publish"
                                           data-track="click" data-track-action="open publish with us expander" data-track-label="button">
                                            <span>Publish <span class="c-header__show-text">with us</span></span><svg role="img" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" transform="matrix(0 1 -1 0 11 3)"/></svg>
                                        </a>
                                    </li>
                                
                            
                            
                        </ul>
                        <ul class="c-header__menu c-header__menu--hide-lg-max">
                            
                                <li class="c-header__item">
                                    <a class="c-header__link"
                                       href="https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D6"
                                       rel="nofollow"
                                       data-track="click"
                                       data-track-action="Sign up for alerts"
                                       data-track-label="link (desktop site header)"
                                       data-track-external>
                                        <span>Sign up for alerts</span><svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#222"/></svg>
                                    </a>
                                </li>
                            
                            
                                <li class="c-header__item c-header__item--pipe">
                                    <a class="c-header__link"
                                       href="https://www.nature.com/neuro.rss"
                                       data-track="click"
                                       data-track-action="rss feed"
                                       data-track-label="link">
                                            <span>RSS feed</span>
                                    </a>
                                </li>
                            
                        </ul>
                    </div>
                </div>
            </div>
        
    </header>


    
    
        <nav class="u-mb-16" aria-label="breadcrumbs">
            <div class="u-container">
                <ol class="c-breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature"><span itemprop="name">nature</span></a><meta itemprop="position" content="1">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:nature neuroscience"><span itemprop="name">nature neuroscience</span></a><meta itemprop="position" content="2">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a class="c-breadcrumbs__link"
                               href="/neuro/articles?type&#x3D;article" itemprop="item"
                               data-track="click" data-track-action="breadcrumb" data-track-category="header" data-track-label="link:articles"><span itemprop="name">articles</span></a><meta itemprop="position" content="3">
                                    <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10"
                                         xmlns="http://www.w3.org/2000/svg">
                                        <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z"
                                              fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                                    </svg>
                                </li><li class="c-breadcrumbs__item" id="breadcrumb3" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                                    <span itemprop="name">article</span><meta itemprop="position" content="4"></li>
                </ol>
            </div>
        </nav>
    



    

</div>


<div class="u-container u-mt-32 u-mb-32 u-clearfix" id="content" data-component="article-container"  data-container-type="article">
    <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
        
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Neurons detect cognitive boundaries to structure episodic memories in humans
                    </div>
                    
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01020-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

                </div>
            </div>
        
        <article lang="en">
            
            <div class="c-article-header">
                <header>
                    <ul class="c-article-identifiers" data-test="article-identifier">
                        
        <li class="c-article-identifiers__item" data-test="article-category">Article</li>
    
    

                        <li class="c-article-identifiers__item">Published: <time datetime="2022-03-07">07 March 2022</time></li>
                    </ul>

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Neurons detect cognitive boundaries to structure episodic memories in humans</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jie-Zheng-Aff1" data-author-popup="auth-Jie-Zheng-Aff1" data-author-search="Zheng, Jie">Jie Zheng</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-9086-3760"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-9086-3760</a></span><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Andrea_G__P_-Schjetnan-Aff2" data-author-popup="auth-Andrea_G__P_-Schjetnan-Aff2" data-author-search="Schjetnan, Andrea G. P.">Andrea G. P. Schjetnan</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Mar-Yebra-Aff3" data-author-popup="auth-Mar-Yebra-Aff3" data-author-search="Yebra, Mar">Mar Yebra</a><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Bernard_A_-Gomes-Aff3" data-author-popup="auth-Bernard_A_-Gomes-Aff3" data-author-search="Gomes, Bernard A.">Bernard A. Gomes</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-2803-964X"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-2803-964X</a></span><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Clayton_P_-Mosher-Aff3" data-author-popup="auth-Clayton_P_-Mosher-Aff3" data-author-search="Mosher, Clayton P.">Clayton P. Mosher</a><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Suneil_K_-Kalia-Aff2" data-author-popup="auth-Suneil_K_-Kalia-Aff2" data-author-search="Kalia, Suneil K.">Suneil K. Kalia</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Taufik_A_-Valiante-Aff2-Aff4-Aff5-Aff6" data-author-popup="auth-Taufik_A_-Valiante-Aff2-Aff4-Aff5-Aff6" data-author-search="Valiante, Taufik A.">Taufik A. Valiante</a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-3443-3790"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-3443-3790</a></span><sup class="u-js-hide"><a href="#Aff2">2</a>,<a href="#Aff4">4</a>,<a href="#Aff5">5</a>,<a href="#Aff6">6</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Adam_N_-Mamelak-Aff3" data-author-popup="auth-Adam_N_-Mamelak-Aff3" data-author-search="Mamelak, Adam N.">Adam N. Mamelak</a><sup class="u-js-hide"><a href="#Aff3">3</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Gabriel-Kreiman-Aff1-Aff7" data-author-popup="auth-Gabriel-Kreiman-Aff1-Aff7" data-author-search="Kreiman, Gabriel" data-corresp-id="c1">Gabriel Kreiman<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0003-3505-8475"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-3505-8475</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff7">7</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 10 authors for this article" title="Show all 10 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Ueli-Rutishauser-Aff3-Aff8-Aff9-Aff10" data-author-popup="auth-Ueli-Rutishauser-Aff3-Aff8-Aff9-Aff10" data-author-search="Rutishauser, Ueli" data-corresp-id="c2">Ueli Rutishauser<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide"> 
            <a class="js-orcid" href="http://orcid.org/0000-0002-9207-7069"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-9207-7069</a></span><sup class="u-js-hide"><a href="#Aff3">3</a>,<a href="#Aff8">8</a>,<a href="#Aff9">9</a>,<a href="#Aff10">10</a></sup> </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>

                    

                    <p class="c-article-info-details" data-container-section="info">
                        
    <a data-test="journal-link" href="/neuro" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Nature Neuroscience</i></a>

                        <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 25</b>, <span class="u-visually-hidden">pages </span>358–368 (<span data-test="article-publication-year">2022</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                    </p>
                    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-reset">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">17k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">38 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">457 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/articles/s41593-022-01020-w/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
                    
                </header>

                
    <div class="u-js-hide" data-component="article-subject-links">
        <h3 class="c-article__sub-heading">Subjects</h3>
        <ul class="c-article-subject-list">
            <li class="c-article-subject-list__subject"><a href="/subjects/cognitive-neuroscience" data-track="click" data-track-action="view subject" data-track-label="link">Cognitive neuroscience</a></li><li class="c-article-subject-list__subject"><a href="/subjects/long-term-memory" data-track="click" data-track-action="view subject" data-track-label="link">Long-term memory</a></li><li class="c-article-subject-list__subject"><a href="/subjects/neurophysiology" data-track="click" data-track-action="view subject" data-track-label="link">Neurophysiology</a></li>
        </ul>
    </div>

                
    
    

    
    

                
            </div>

        <div class="c-article-body">
            <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>While experience is continuous, memories are organized as discrete events. Cognitive boundaries are thought to segment experience and structure memory, but how this process is implemented remains unclear. We recorded the activity of single neurons in the human medial temporal lobe (MTL) during the formation and retrieval of memories with complex narratives. Here, we show that neurons responded to abstract cognitive boundaries between different episodes. Boundary-induced neural state changes during encoding predicted subsequent recognition accuracy but impaired event order memory, mirroring a fundamental behavioral tradeoff between content and time memory. Furthermore, the neural state following boundaries was reinstated during both successful retrieval and false memories. These findings reveal a neuronal substrate for detecting cognitive boundaries that transform experience into mnemonic episodes and structure mental time travel during retrieval.</p></div></div></section>

            <noscript>
                
                    
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01020-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                
            </noscript>

            
                <div class="js-context-bar-sticky-point-mobile">
                    
                        <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-entitled-mobile
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01020-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

                    
                </div>
            

            
                
                    
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41562-023-01706-6/MediaObjects/41562_2023_1706_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41562-023-01706-6?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1038/s41562-023-01706-6">Hippocampal neurons code individual episodic memories in humans
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">05 October 2023</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Luca D. Kolibius, Frederic Roux, … Simon Hanslmayr</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-023-36805-5/MediaObjects/41467_2023_36805_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-023-36805-5?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1038/s41467-023-36805-5">Flexible reuse of cortico-hippocampal representations during encoding and recall of naturalistic events
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">08 March 2023</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Zachariah M. Reagh &amp; Charan Ranganath</p>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-020-17713-4/MediaObjects/41467_2020_17713_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://www.nature.com/articles/s41467-020-17713-4?fromPaywallRec=false"
                                           data-track="click"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1038/s41467-020-17713-4">Aging alters neural activity at event boundaries in the hippocampus and Posterior Medial network
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                         <span class="c-article-meta-recommendations__access-type">Open access</span>
                                         <span class="c-article-meta-recommendations__date">07 August 2020</span>
                                    </div>
                                </div>
                                <p class="c-article-recommendations-card__authors u-sans-serif">Zachariah M. Reagh, Angelique I. Delarazan, … Charan Ranganath</p>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'speedy-BootstrappedUCB',
                        timestamp: 1711582413,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                
                
                <div class="main-content">
                    <section data-title="Main"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Main</h2><div class="c-article-section__content" id="Sec1-content"><p>Our lives unfold over time, weaving rich information into a continuous sequence of experiences. However, our memories are not continuous. Rather, we remember discrete episodes (‘events’)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Ezzyat, Y. &amp; Davachi, L. What constitutes an episode in episodic memory? Psychol. Sci. 22, 243–252 (2011)." href="/articles/s41593-022-01020-w#ref-CR1" id="ref-link-section-d20974544e675">1</a></sup>, which serve as anchors to bind together the myriad different aspects (where, when and what) of a given autobiographical memory<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Tulving, E. Episodic memory: from mind to brain. Annu. Rev. Psychol. 53, 1–25 (2002)." href="/articles/s41593-022-01020-w#ref-CR2" id="ref-link-section-d20974544e679">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Radvansky, G. A. &amp; Zacks, J. M. Event Cognition (Oxford University Press, 2014)." href="/articles/s41593-022-01020-w#ref-CR3" id="ref-link-section-d20974544e682">3</a></sup>, much like objects do in perception<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Desimone, R. &amp; Duncan, J. Neural mechanisms of selective visual attention. Annu. Rev. Neurosci. 18, 193–222 (1995)." href="/articles/s41593-022-01020-w#ref-CR4" id="ref-link-section-d20974544e686">4</a></sup>. A fundamental unresolved question in human memory is, therefore, what marks the beginning and the end of an episode?<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Zacks, J. M. et al. Human brain activity time-locked to perceptual event boundaries. Nat. Neurosci. 4, 651–655 (2001)." href="/articles/s41593-022-01020-w#ref-CR5" id="ref-link-section-d20974544e690">5</a></sup></p><p>The transformation from ongoing experience to distinct events is thought to rely on the identification of boundaries that separate events<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Ezzyat, Y. &amp; Davachi, L. What constitutes an episode in episodic memory? Psychol. Sci. 22, 243–252 (2011)." href="/articles/s41593-022-01020-w#ref-CR1" id="ref-link-section-d20974544e696">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Avrahami, J. &amp; Kareev, Y. The emergence of events. Cognition 53, 239–261 (1994)." href="#ref-CR6" id="ref-link-section-d20974544e699">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="DuBrow, S. &amp; Davachi, L. The influence of context boundaries on memory for the sequential order of events. J. Exp. Psychol. Gen. 142, 1277–1286 (2013)." href="#ref-CR7" id="ref-link-section-d20974544e699_1">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chen, J. et al. Shared memories reveal shared structure in neural activity across individuals. Nat. Neurosci. 20, 115–125 (2017)." href="#ref-CR8" id="ref-link-section-d20974544e699_2">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kurby, C. A. &amp; Zacks, J. M. Segmentation in the perception and memory of events. Trends Cogn. Sci. 12, 72–79 (2008)." href="#ref-CR9" id="ref-link-section-d20974544e699_3">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Zacks, J. M., Speer, N. K., Swallow, K. M., Braver, T. S. &amp; Reynolds, J. R. Event perception: a mind–brain perspective. Psychol. Bull. 133, 273–293 (2007)." href="#ref-CR10" id="ref-link-section-d20974544e699_4">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Jafarpour, A., Griffin, S., Lin, J. J. &amp; Knight, R. T. Medial orbitofrontal cortex, dorsolateral prefrontal cortex, and hippocampus differentially represent the event saliency. J. Cogn. Neurosci. 31, 874–884 (2019)." href="/articles/s41593-022-01020-w#ref-CR11" id="ref-link-section-d20974544e702">11</a></sup>. This theory is motivated by large-scale patterns of activity changes in the human brain around event boundaries<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Zacks, J. M. et al. Human brain activity time-locked to perceptual event boundaries. Nat. Neurosci. 4, 651–655 (2001)." href="/articles/s41593-022-01020-w#ref-CR5" id="ref-link-section-d20974544e706">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Ben-Yakov, A. &amp; Henson, R. N. The hippocampal film editor: sensitivity and specificity to event boundaries in continuous experience. J. Neurosci. 38, 10057–10068 (2018)." href="/articles/s41593-022-01020-w#ref-CR12" id="ref-link-section-d20974544e709">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Baldassano, C. et al. Discovering event structure in continuous narrative perception and memory. Neuron 95, 709–721 (2017)." href="/articles/s41593-022-01020-w#ref-CR13" id="ref-link-section-d20974544e712">13</a></sup>, but the underlying neural mechanisms and their relationship to memory are unknown. Neurons in the rodent hippocampus elevate their firing rates in the vicinity of investigator-imposed spatial boundaries<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Spiers, H. J., Hayman, R. M., Jovalekic, A., Marozzi, E. &amp; Jeffery, K. J. Place field repetition and purely local remapping in a multicompartment environment. Cereb. Cortex 25, 10–25 (2015)." href="/articles/s41593-022-01020-w#ref-CR14" id="ref-link-section-d20974544e716">14</a></sup>, and the place fields of hippocampal neurons are shaped by physical boundaries<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Derdikman, D. et al. Fragmentation of grid cell maps in a multicompartment environment. Nat. Neurosci. 12, 1325–1332 (2009)." href="#ref-CR15" id="ref-link-section-d20974544e720">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lever, C., Burton, S., Jeewajee, A., O’Keefe, J. &amp; Burgess, N. Boundary vector cells in the subiculum of the hippocampal formation. J. Neurosci. 29, 9771–9777 (2009)." href="#ref-CR16" id="ref-link-section-d20974544e720_1">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="O’Keefe, J. &amp; Burgess, N. Geometric determinants of the place fields of hippocampal neurons. Nature 381, 425–428 (1996)." href="/articles/s41593-022-01020-w#ref-CR17" id="ref-link-section-d20974544e723">17</a></sup>. In accordance with the boundaries of subenvironments<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Spiers, H. J., Hayman, R. M., Jovalekic, A., Marozzi, E. &amp; Jeffery, K. J. Place field repetition and purely local remapping in a multicompartment environment. Cereb. Cortex 25, 10–25 (2015)." href="/articles/s41593-022-01020-w#ref-CR14" id="ref-link-section-d20974544e727">14</a></sup>, hippocampal place fields remap<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Alme, C. B. et al. Place cells in the hippocampus: eleven maps for eleven rooms. Proc. Natl Acad. Sci. USA 111, 18428–18435 (2014)." href="/articles/s41593-022-01020-w#ref-CR18" id="ref-link-section-d20974544e732">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Colgin, L. L., Moser, E. I. &amp; Moser, M. B. Understanding memory through hippocampal remapping. Trends Neurosci. 31, 469–477 (2008)." href="/articles/s41593-022-01020-w#ref-CR19" id="ref-link-section-d20974544e735">19</a></sup> in response to context shifts and are reinstated<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Derdikman, D. et al. Fragmentation of grid cell maps in a multicompartment environment. Nat. Neurosci. 12, 1325–1332 (2009)." href="/articles/s41593-022-01020-w#ref-CR15" id="ref-link-section-d20974544e739">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Grieves, R. M., Jenkins, B. W., Harland, B. C., Wood, E. R. &amp; Dudchenko, P. A. Place field repetition and spatial learning in a multicompartment environment. Hippocampus 26, 118–134 (2016)." href="/articles/s41593-022-01020-w#ref-CR20" id="ref-link-section-d20974544e742">20</a></sup> when the animal is placed back into a familiar context. Additionally, rodent hippocampal neuron ensembles encode lap-specific representations in a maze irrespective of an animal’s spatial location<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Sun, C., Yang, W., Martin, J. &amp; Tonegawa, S. Hippocampal neurons represent events as transferable units of experience. Nat. Neurosci. 23, 651–663 (2020)." href="/articles/s41593-022-01020-w#ref-CR21" id="ref-link-section-d20974544e746">21</a></sup>, presumably representing cognitive boundaries between distinct events. Boundaries shape mnemonic representations of both spatial environments and the events that occur during navigation and structure the place fields and event-specific representations of cognitive maps. No such understanding at the single-cell level exists for the non-spatial episodic memories that define us as individual human beings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Tulving, E. Episodic memory: from mind to brain. Annu. Rev. Psychol. 53, 1–25 (2002)." href="/articles/s41593-022-01020-w#ref-CR2" id="ref-link-section-d20974544e750">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Levine, B. et al. Episodic memory and the self in a case of isolated retrograde amnesia. Brain 121, 1951–1973 (1998)." href="/articles/s41593-022-01020-w#ref-CR22" id="ref-link-section-d20974544e753">22</a></sup>.</p><p>We investigated the neuronal mechanisms underlying the identification of event boundaries in humans under semirealistic continuous experience. We recorded single-neuron activity from individuals with drug-resistant epilepsy implanted with depth electrodes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Rutishauser, U. Testing models of human declarative memory at the single-neuron level. Trends Cogn. Sci. 23, 510–524 (2019)." href="/articles/s41593-022-01020-w#ref-CR23" id="ref-link-section-d20974544e760">23</a></sup> while testing their memory for the content of video clips with two kinds of embedded cognitive boundaries: soft boundaries (SBs) and hard boundaries (HBs). SBs are episodic transitions between related events within the same movie, while HBs are episodic transitions between two unrelated movies. Behaviorally, both SBs and HBs enhanced recognition of video clip content that followed a boundary, whereas HBs impaired memory of the temporal order of events. We found neurons in the MTL that signaled the timing of both types of boundaries. The activity of these boundary-responsive neurons predicted memory strength as assessed by scene recognition and temporal order discrimination accuracy.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2">Results</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3">Boundaries boost recognition but disrupt serial order memory</h3><p>We studied how boundaries influence the formation and retrieval of memories of brief video clips. Twenty individuals performed the task while we recorded the activity of single neurons (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1e</a>, Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig7">1</a> and Supplementary Tables <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">3</a> show the participant demographics and the location of microwire bundles). The task consisted of three parts: encoding, scene recognition and time discrimination. During encoding (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1a</a>), individuals watched 90 different and new video clips containing either no boundaries (NBs; one continuous movie shot), SBs (cuts to a new scene within the same movie) or HBs (cuts to a new scene from a different movie; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1b</a>). A question about the prior movie appeared every four to eight clips (for example, is anyone wearing glasses?). Participants answered 89 ± 5% of these questions accurately.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Experiment and recording locations."><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1: Experiment and recording locations.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="700"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p><b>a</b>, Encoding task. Individuals watched 90 video clips (~ 8 s each, no audio) with either NB (continuous movie shot), an SB (cut to a new scene within the same movie, one to three SBs per clip) or an HB (cut to a different movie, one HB per clip). Every four to eight clips, individuals were prompted to answer a yes or no question related to the content of the immediately preceding clip together with a confidence rating (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). RT, reaction time. <b>b</b>, Example boundaries (visual features of boundaries are in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">1</a>). Owing to copyright restrictions, the images shown are different from those used for the experiment. <b>c</b>, Scene recognition memory task. Individuals indicated whether a static image was new or old (seen during encoding task) together with a confidence rating. <b>d</b>, Time discrimination task. Individuals indicated which of two frames they saw first during the encoding task together with a confidence rating. <b>e</b>, Recording locations of the 39 microwire bundles that contained at least one boundary/event neuron (see Montreal Neurological Institute (MNI) coordinates in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">3</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig7">1</a>) across all individuals (participant information is in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2</a>) in the amygdala (red), hippocampus (blue) or parahippocampal gyrus (cyan), rendered on a template brain. Each dot represents the location of a microwire bundle.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We subsequently evaluated what individuals remembered about the video clips with two memory tests: scene recognition (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1c</a>) and time discrimination (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1d</a>). During the scene recognition test, individuals were presented with a single static frame. These frames were chosen with equal probability from either the previously presented video clips (‘targets’) or from other video clips that were not shown to the participants (‘foils’). Participants made an ‘old’ or ‘new’ decision together with a confidence rating (sure, less sure and very unsure) in each trial. During the time discrimination test, individuals were shown two old frames chosen from the same video clip, presented side by side, and had to indicate which frame was seen earlier in time together with a confidence rating.</p><p>In the time discrimination task, participants correctly identified which frame was shown first in 73 ± 7% and 73 ± 8% of trials when the two frames were separated by a NB or an SB, respectively (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig2">2a</a>; both above chance of 50%; one sample <i>t</i>-test, NB: <i>t</i><sub>19</sub> = 13.97, <i>P</i> = 2 × 10<sup>−11</sup>; SB: <i>t</i><sub>19</sub> = 11.63, <i>P</i> = 4 × 10<sup>−10</sup>). By contrast, participants performed significantly worse when discriminating the order of frames separated by an HB (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig2">2a</a>; HB: 53 ± 5%, <i>P</i> = 0.02 against chance level; significantly lower than NB and SB: <i>F</i><sub>2,57</sub> = 51.33, <i>P</i> = 2 × 10<sup>−13</sup>). Individuals also showed longer reaction times (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig2">2b</a>; HB: 2.10 ± 0.37 s; NB: 1.62 ± 0.28 s; SB: 1.59 ± 0.34 s; <i>F</i><sub>2,57</sub> = 14.25, <i>P</i> = 10 × 10<sup>−6</sup>) and lower confidence ratings when discriminating the order of frames separated by an HB (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig2">2c</a>; HB: 1.95 ± 0.45; NB: 2.52 ± 0.29; SB: 2.59 ± 0.23; <i>F</i><sub>2,57</sub> = 20.41, <i>P</i> = 2 × 10<sup>−7</sup>). This effect on reaction times and confidence was not driven by accuracy differences, as it was observed for both correct and incorrect trials independently (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">1</a>). Discriminating the temporal order of two frames was not possible by reasoning alone without having seen the video clips (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Behavior."><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2: Behavior.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="404"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>HBs impaired time discrimination memory, while SBs and HBs improved scene recognition memory for frames close to them. <b>a</b>–<b>c</b>, Performance in time discrimination task (see also Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">1</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2</a>) quantified by accuracy (<b>a</b>) (<i>F</i><sub>2,57</sub> = 51.33, <i>P</i> = 2 × 10<sup>−13</sup>, one-tailed analysis of variance (ANOVA)), reaction time (<b>b</b>) (<i>F</i><sub>2,57</sub> = 14.25, <i>P</i> = 10 × 10<sup>−6</sup>, one-tailed ANOVA) and mean confidence level (<b>c</b>) (<i>F</i><sub>2,57</sub> = 20.41, <i>P</i> = 2 × 10<sup>−7</sup>, one-tailed ANOVA) across all the trials for NBs (green), SBs (blue) and HBs (red). Behavioral data for the scene recognition task are shown in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig8">2</a>. <b>d</b>–<b>f</b>, Scene recognition accuracy as a function of time elapsed between the target frame and its nearest past boundary (the distance effect for time discrimination accuracy and future boundaries is shown in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">3</a>) plotted separately for NB (<b>d</b>), SB (<b>e</b>) and HB (<b>f</b>). For NB clips, time from the past boundary is measured relative to the middle of the clip. Each dot represents one recording session in <b>a–</b><b>c</b> and one clip in <b>d–</b><b>f</b>. Black lines in <b>a</b>–<b>c</b> denote the mean of the results, and colored lines in <b>d</b>–<b>f</b> are the fitted lines for linear regression; ***<i>P</i> &lt; 0.001.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Across all trials, the ability to recognize a frame as old did not differ significantly between the types of boundaries preceding the frame (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig8">2a</a>; NB: 76% ± 10%; SB: 75% ± 9%; HB: 75% ± 8%; <i>F</i><sub>2,57</sub> = 0.07, <i>P</i> = 0.94). The reaction times and confidence ratings during the scene recognition task were also similar across the different types of boundaries (reaction times are presented in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig8">2b</a>; NB = 1.47 ± 0.18 s, SB = 1.43 ± 0.16 s and HB = 1.49 ± 0.15 s, <i>F</i><sub>2,57</sub> = 0.28, <i>P</i> = 0.76; confidence ratings are presented in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig8">2c</a>; NB = 2.60 ± 0.18, SB = 2.60 ± 0.20 and HB = 2.52 ± 0.28, <i>F</i><sub>2,57</sub> = 0.54, <i>P</i> = 0.56). Therefore, the impaired time discrimination ability across HB transitions was not due to differences in memory strength as measured by scene recognition accuracy. Even though the overall accuracy was similar among NB, SB and HB conditions, the recognition accuracy of target frames decreased as a function of the time elapsed between the target frame and its immediately preceding boundary. Target frames presented shortly after an SB and HB were remembered better than those farther away from the boundary (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig2">2e,f</a>; SB: <i>r</i> = −0.61, <i>P</i> = 4 × 10<sup>−4</sup>; HB: <i>r</i> = −0.44, <i>P</i> = 0.015). By contrast, recognition accuracy did not differ significantly as a function of time relative to NBs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig2">2d</a>; Pearson correlation; NB: <i>r</i> = 0.085, <i>P</i> = 0.65). The temporal distance to boundary effects was unidirectional; the temporal distance to future boundaries did not correlate with memory performance (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">3a,b</a>). Additionally, no temporal distance effect was present in the time discrimination task accuracy (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">3c,d</a>). Also, the scene recognition accuracy and time discrimination accuracy were not significantly related to the time at which the tested frames were shown during encoding (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>; scene recognition: <i>F</i><sub>5,114</sub> = 1.87, <i>P</i> = 0.11; time discrimination: <i>F</i><sub>5,114</sub> = 1.1, <i>P</i> = 0.37). Together, the behavioral analyses revealed that frames that closely followed an SB or HB were more likely to be remembered. Temporal order memory, however, was disrupted by the presence of HBs. These results reveal a tradeoff in the effect of HBs on memories, with enhanced scene recognition memory and disrupted temporal order memory.</p><h3 class="c-article__sub-heading" id="Sec4">MTL neurons demarcate episodic transitions</h3><p>We next investigated the neuronal responses to boundaries and their relationship to memory by recording from neurons in the MTL (including the hippocampus, amygdala and parahippocampal gyrus; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1e</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig7">1</a>) and other brain areas (Supplementary Tables<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1"> 2</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>). Across all areas, we recorded the activity of 985 neurons from 19 individuals (1 of the 20 individuals yielded no usable recordings; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2</a>). Of these 985 neurons, 580 were recorded from the MTL. We first tested whether neurons changed their activity following boundaries by comparing their firing rate in a 1-s-long window following boundaries relative to baseline (1 s before boundary; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). For video clips with NBs, we aligned responses to the middle of the clip and compared responses between before and after this virtual boundary. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3a,b</a> shows two example neurons recorded from the hippocampus and parahippocampal gyrus, respectively. These neurons showed a transient increase in firing rates within approximately 300 ms after both SBs (blue) and HBs (red). No such change was observed in the clips without boundaries (green). We refer to this type of neuron as a ‘boundary cell’; 42 of 580 MTL neurons (7.24%; expected proportion by chance for all MTL neurons = 2.11%) were classified as boundary cells (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3c</a>). The regions with the largest proportion of boundary cells were the parahippocampal gyrus (<i>n</i> = 18/68, 26.47%), amygdala (<i>n</i> = 12/169, 7.10%) and hippocampus (<i>n</i> = 12/343, 3.50%). These proportions are all significantly larger than expected by chance (<i>P</i> &lt; 0.05; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Boundary cells and event cells demarcate different types of episodic transitions."><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3: Boundary cells and event cells demarcate different types of episodic transitions.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="713"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p><b>a</b>,<b>b</b>, Responses during the encoding stage from two example boundary cells located in the hippocampus (HPC) (<b>a</b>) and parahippocampal gyrus (PHG) (<b>b</b>), respectively (spike sorting quality of all detected cells is shown in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">5</a>). Boundary cells responded to both SB (blue) and HB (red) transitions. Responses are aligned to the middle point of the clip (NB, green) or to the boundary (SB, HB); top, raster plots; bottom, poststimulus time histogram (bin size = 200 ms; step size = 2 ms; shaded areas represent ±s.e.m. across trials); insets, all spike extracellular waveforms (gray) and mean (black). <b>c</b>,<b>d</b>, Firing rates of all 42 boundary cells (solid and dashed arrows denote the examples in <b>a</b> and <b>b</b>, respectively) during the encoding stage aligned to the boundaries (<b>c</b>) or clip onsets (<b>d</b>) averaged over trials within each boundary type and normalized to each neuron’s maximum firing rate from the entire task recording (see color scale on bottom). <b>e</b>,<b>f</b>, Responses during the encoding stage from two example event cells located in the amygdala (AMY) (<b>e</b>) and hippocampus (<b>f</b>), respectively. Event cells responded to HB (red) but not SB (blue) transitions; poststimulus time histogram: bin size = 200 ms, step size = 2 ms and shaded areas represent ±s.e.m. across trials. <b>g</b>,<b>h</b>, Firing rates of all 36 event cells (solid and dashed arrows denote the examples in <b>e</b> and <b>f</b>, respectively) during the encoding stage, using the same format as in <b>c</b> and <b>d</b> (aligned to boundaries (<b>g</b>) or clip onsets (<b>h</b>)). Both boundary cells and event cells in the MTL do not respond to the clip onsets (<b>d</b>, <b>h</b>) and clip offsets (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig9">3</a>) during encoding and image onsets and offsets during scene recognition and time discrimination (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig10">4</a>). No significant difference in saccades was found after clip onsets versus after boundary transitions for one individual where we could record eye movement data simultaneously with the neurophysiological data (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">7</a>). <b>i</b>, Latency analysis. Firing rate during HB transitions (to which both boundary cells and event cells responded) reached peak response earlier for boundary cells (pink) than event cells (purple). The average <i>z</i>-scored firing rate normalized using the average and s.d. of the firing rates and aligned to HB is shown (bin size = 200 ms, step size = 2 ms, shaded areas represent ±s.e.m. across all boundary cells or event cells). <b>j</b>, Peak times of average firing rate traces of all boundary cells (pink) and all event cells (purple) (<i>F</i><sub>1,76</sub> = 274.78, <i>P</i> = 6 × 10<sup>−27</sup>, one-tailed ANOVA). Each dot represents one boundary cell (pink) or one event cell (purple). Black lines denote the mean averaged across all boundary cells or event cells; ***<i>P</i> &lt; 0.001, one-way ANOVA, d.f. = 1,76. The spatial distribution of boundary cells and event cells is shown in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Was the response of boundary cells a result of the abrupt changes in pixel-level content between the frame before and after the boundary? To answer this question, we considered the responses of the cells during other abrupt changes of visual input: video clip onsets (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3d</a>) and offsets (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig9">3</a>) during encoding and image onsets and offsets during scene recognition and time discrimination (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig10">4</a>). Boundary cells did not respond significantly to either clip or image onsets or offsets (<i>P</i> &gt; 0.05; permutation <i>t</i>-test, <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>), showing that the response of boundary cells is likely related to higher-level cognitive discontinuities rather than pure visual changes.</p><p>We also found a second group of neurons that transiently increased their firing rate only following HBs but not SBs or NBs. Two examples of such cells, located in the amygdala and hippocampus, are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3e,f</a>. We refer to this type of neuron as an ‘event cell’; 36 of 580 MTL neurons (6.20%; proportion expected by chance for all MTL neurons = 2.26%) were classified as event cells (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3g</a>). The regions with the largest proportion of event cells were the hippocampus (<i>n</i> = 27/343, 7.87%), amygdala (<i>n</i> = 7/169, 4.27%) and parahippocampal gyrus (<i>n</i> = 2/68, 2.94%). These proportions are all significantly larger than expected by chance (<i>P</i> &lt; 0.05; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>). Similar to boundary cells, event cells did not significantly change their firing rates following video clip onsets or offsets (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3h</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig9">3</a>) during encoding nor did they respond to image onsets or offsets during scene recognition or time discrimination (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig10">4</a>; <i>P</i> &gt; 0.05, permutation <i>t</i>-test; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). However, boundary cells and event cells did increase their firing rates to the randomly interspersed probe questions that followed some clip offsets (randomly present every four to eight trials; Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">6</a>). Seventy six of 580 (13.1%, <i>P</i> = 0.01) and 4 of 580 (0.7%, <i>P</i> = 0.43) MTL cells changed their firing rate in response to clip onsets and clip offsets, respectively, but neither of these cells qualified as boundary cells or event cells (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig11">5</a>).</p><p>SBs and HBs differed in terms of their high-level conceptual narrative, which is interrupted in HBs but not in SBs. To evaluate whether it is possible to determine from visual features alone whether a boundary is soft or hard, we computed the differences between pre- and postboundary frames in terms of pixel-level characteristics (that is, luminance, contrast, complexity, entropy and color distribution), high-level visual features (that is, objects) and perceptual similarity ratings. These analyses revealed that SB and HB transitions did not differ significantly from each other in any of the attributes we tested (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">1</a>). Therefore, the differential activation of event cells to HBs but not SBs was likely a result of detection of the disruption in the conceptual narrative, that is, a transition between two different episodes.</p><p>While both boundary cells and event cells responded to HB transitions, a comparison of their response dynamics indicated that boundary cells responded to HBs approximately 100 ms earlier than event cells (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3i</a>). This latency difference was also observed when comparing the time at which the peak responses were reached; boundary cells showed a peak at 197 ± 49 ms, whereas event cells showed a peak at 301 ± 55 ms (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3j</a>; <i>F</i><sub>1,76</sub> = 274.78, <i>P</i> = 6 × 10<sup>−27</sup>).</p><p>We also evaluated the existence of boundary and event cells in brain areas other than the MTL, such as the medial frontal cortex, insula and orbitofrontal cortex (OFC). We found 8/405 (1.96%) boundary cells and 9/405 (2.22%) event cells among the non-MTL group (Supplementary Tables 2 and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>), with only event cells in the OFC exceeding the proportions expected by chance. Thus, boundary-responsive neurons are largely within the MTL, to which we restricted the following analyses.</p><h3 class="c-article__sub-heading" id="Sec5">Responses of boundary and event cells predict memory strength</h3><p>We next asked whether the responses of boundary cells and event cells during encoding correlated with later measures of memory for the content of the videos. We examined whether the strength of responses of boundary cells or event cells to boundaries varied as a function of whether the familiarity or temporal order of a stimulus was later remembered or forgotten. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4a</a> shows an example boundary cell located in the hippocampus whose response during encoding differed between video clips, from which frames were later correctly remembered as familiar (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4a(i)</a>) versus incorrectly identified as new (forgotten; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4a(ii)</a>); the responses to boundaries that preceded later-remembered frames were stronger. This effect was present, on average, among boundary cells (<i>n</i> = 42) for frames preceded or followed by both SBs and HBs but not by NBs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4c</a>, SB: <i>F</i><sub>1,82</sub> = 82.93, <i>P</i> = 4 × 10<sup>−14</sup>; HB: <i>F</i><sub>1,82</sub> = 156.9, <i>P</i> = 1 × 10<sup>−20</sup>; NB: <i>F</i><sub>1,82</sub> = 1.18, <i>P</i> = 0.28; Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">8</a>, SB: <i>F</i><sub>1,82</sub> = 91.67, <i>P</i> = 5 × 10<sup>−15</sup>; HB: <i>F</i><sub>1,82</sub> = 62.78, <i>P</i> = 1 × 10<sup>−11</sup>; NB: <i>F</i><sub>1,82</sub> = 0.05, <i>P</i> = 0.83). This effect was specific to scene recognition and boundary cells. First, the firing rate of boundary cells did not significantly predict performance in the time discrimination task (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig12">6a,c</a>; NB: <i>F</i><sub>1,82</sub> = 1.25, <i>P</i> = 0.27; SB: <i>F</i><sub>1,82</sub> = 1.35, <i>P</i> = 0.25; HB: <i>F</i><sub>1,82</sub> = 1.14, <i>P</i> = 0.29). The firing rate of event cells (<i>n</i> = 36) during encoding was not predictive of scene recognition memory and temporal order memory (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4e,g</a> and Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig13">7a,c</a>; NB: <i>F</i><sub>1,70</sub> = 1.12, <i>P</i> = 0.29; SB: <i>F</i><sub>1,70</sub> = 1.63, <i>P</i> = 0.21; HB: <i>F</i><sub>1,70</sub> = 0.79, <i>P</i> = 0.38).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Responses of boundary cells and event cells during encoding correlate with later retrieval success."><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4: Responses of boundary cells and event cells during encoding correlate with later retrieval success.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="744"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p><b>a</b>–<b>d</b>, Response of boundary cells during encoding grouped by participants’ subsequent memory performance in the scene recognition task. <b>a</b>, Boundary cell recorded in the hippocampus. During encoding, this cell responded more strongly to SB and HB transitions than NB if the frame following the boundary in that trial was correctly identified during the scene recognition task (i) compared to incorrect trials (ii). The format is as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3</a>. Shaded areas represent ±s.e.m. across trials. <b>b</b>, Timing of spikes from the same boundary cell shown in <b>a</b> relative to theta phase calculated from the LFPs for clips of which frames were later remembered (i) or forgotten (ii) (left). The phase distribution of spike times in the 1-s period following the middle of the clip (NB) or boundary (SB, HB) for clips from which frames were remembered (i) and forgotten (ii) is shown on the right. <b>c</b>,<b>d</b>, Population summary for all 42 boundary cells. Black lines denote the mean results averaged across all 42 boundary cells. <b>c</b>, <i>Z</i>-scored firing rate (0–1 s after boundaries during encoding) differed significantly between boundaries after which frames were remembered (color filled) versus forgotten (empty) for both SB and HB (SB: <i>F</i><sub>1,82</sub> = 82.93, <i>P</i> = 4 × 10<sup>−14</sup>; HB: <i>F</i><sub>1,82</sub> = 156.9, <i>P</i> = 1 × 10<sup>−20</sup>; NB: <i>F</i><sub>1,82</sub> = 1.18, <i>P</i> = 0.28; one-tailed ANOVA); NS, not significant. <b>d</b>, Mean resultant length (MRL) of spike times (that is, sum of vectors with vector lengths equal to 1 and vector angles equal to the spike timings relative to theta phases 0–1 s after boundaries during encoding divided by total number of vectors; value range (0 to 1): 0, uniform distribution (i.e., neurons fire at random theta phases); 1, unimodal distribution (i.e., neurons firing at the same theta phase across all boundary cells for each boundary type did not differ significantly between correct (color filled) and incorrect (empty) clips). <b>e</b>,<b>f</b>, Response of boundary cells during encoding grouped by participants’ subsequent memory performance in the time discrimination task. <b>e</b>, Example event cell recorded in the hippocampus that responded to HB transition regardless of whether the temporal order of the clip was later correctly (i) or incorrectly (ii) recalled in the time discrimination task. Shaded areas represent ±s.e.m. across trials. The format is the same as in <b>a</b>, but clips were grouped based on memory outcomes in the time discrimination task. <b>f</b>, The spike timing of the same event cell shown in <b>e</b> relative to theta phase plotted for correct (i) and incorrect (ii) trials. The format is the same as in <b>b</b>, but clips were grouped based on memory outcomes in the time discrimination task. <b>g</b>,<b>h</b>, Population summary for all 36 event cells. Black lines denote the mean results averaged across all 36 event cells. <b>g</b>, <i>Z</i>-scored firing rate (0–1 s after boundaries during encoding) did not differ significantly between later correctly (color filled) or incorrectly (empty) remembered temporal orders for all three boundary types. <b>h</b>, MRL of spike times (relative to theta phases, 0–1 s after boundaries during encoding) was significantly larger after SB and HB transitions if the temporal order of the clip was correctly recalled (color filled) than if it was incorrectly recalled (empty) (SB: <i>F</i><sub>1,70</sub> = 81.55, <i>P</i> = 2 × 10<sup>−13</sup>; HB: <i>F</i><sub>1,70</sub> = 60.79, <i>P</i> = 4 × 10<sup>−11</sup>; NB: <i>F</i><sub>1,70</sub> = 1.53, <i>P</i> = 0.22; one-tailed ANOVA). Each dot represents one boundary cell (<b>c</b> and <b>d</b>) or one event cell (<b>g</b> and <b>h</b>). Black lines in <b>c</b>, <b>d</b>, <b>g</b> and <b>h</b> denote the mean of the results. Note that in <b>a</b>–<b>d</b>, the neural responses of boundary cells reflect whether participants remembered or forgot target frames that followed a boundary. Results computed based on trials grouped by participants’ memory performance for a target frame before a boundary are shown in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">8</a>; ***<i>P</i> &lt; 0.001, one-way ANOVA, d.f. = 1,82 for <b>c</b> and <b>d</b>, and d.f. = 1,70 for <b>g</b> and <b>h</b>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Given the importance of theta frequency band spike field coherence in plasticity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Rutishauser, U., Ross, I. B., Mamelak, A. N. &amp; Schuman, E. M. Human memory strength is predicted by theta-frequency phase-locking of single neurons. Nature 464, 903–907 (2010)." href="/articles/s41593-022-01020-w#ref-CR24" id="ref-link-section-d20974544e1762">24</a></sup>, we next considered the timing of spikes with respect to the theta band in the local field potentials (LFPs; 4–8 Hz, measured on the same microwire from which the neuron was recorded; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a> and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">9</a>). We determined the theta phase of each spike that occurred within 1 s following boundaries and compared the resulting phase distributions among NB, SB and HB. Event cells tended to fire at a consistent phase of the theta band LFP following both HBs and SBs for clips whose temporal order was later remembered correctly (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4f</a>). To summarize this effect across the population, we computed the MRL across all phases for all spikes fired by a given cell (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). If the time of spikes are randomly distributed, the MRL equals 0, whereas an identical phase for all spikes would result in an MRL of 1. The mean MRL across all event cells (<i>n</i> = 36) was significantly larger following both SB and HB but not NB if temporal order was later correctly remembered (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4h</a>; SB: <i>F</i><sub>1,70</sub> = 81.55, <i>P</i> = 2 × 10<sup>−13</sup>; HB: <i>F</i><sub>1,70</sub> = 60.79, <i>P</i> = 4 × 10<sup>−11</sup>; NB: <i>F</i><sub>1,70</sub> = 1.53, <i>P</i> = 0.22). This effect was specific to event cells and temporal order memory. First, the strength of theta phase locking of event cells did not predict scene recognition memory success (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig13">7b,d</a>; NB: <i>F</i><sub>1,70</sub> = 0.75, <i>P</i> = 0.39; SB: <i>F</i><sub>1,70</sub> = 1.1, <i>P</i> = 0.30; HB: <i>F</i><sub>1,70</sub> = 2.13, <i>P</i> = 0.15). Second, the strength of phase locking of boundary cells neither predicted scene recognition memory success (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4b,d</a>; NB: <i>F</i><sub>1,82</sub> = 1.16, <i>P</i> = 0.28; SB: <i>F</i><sub>1,82</sub> = 1.87, <i>P</i> = 0.18; HB: <i>F</i><sub>1,82</sub> = 0.45, <i>P</i> = 0.5) nor temporal order memory (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig12">6b,d</a>; <i>F</i><sub>1,82</sub> = 1.33, <i>P</i> = 0.25; SB: <i>F</i><sub>1,82</sub> = 0.14, <i>P</i> = 0.71; HB: <i>F</i><sub>1,82</sub> = 1.98, <i>P</i> = 0.16). Third, we evaluated whether there were cells whose theta band phase locking of spikes following boundaries was predictive of the success of memory formation regardless of whether their firing rate was modulated (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). There were 32 of 580 MTL cells that showed an enhanced number of spikes phase locked in the theta band after a boundary compared to before a boundary and where the phase locking was correlated with correct/incorrect performance in either one of the two memory tasks. Of those 32 cells, 20 (56%) were also event cells. By contrast, there was no significant overlap between the 32 cells and boundary cells (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">5</a>).</p><p>In summary, boundary cells and event cells predicted distinct aspects of memory formation; whereas the firing rate of boundary cells was predictive of later scene recognition memory performance, the phase locking of event cells was predictive of temporal order memory performance.</p><h3 class="c-article__sub-heading" id="Sec6">Neural state shifts across boundaries reflect memory strength</h3><p>We next investigated the changes in the neural responses following boundaries at the population level of all <i>n</i> = 580 MTL cells (pseudopopulation, <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). We examined the dynamics of population activity around the boundaries by evaluating the change of activity using principal component analysis (PCA). During NB video clips, the neural state exhibited only slow changes as a function of time (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5a</a>). By contrast, the neural state changed abruptly following SBs and HBs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5b,c</a>). These abrupt ‘neural state shifts’ were consistent with the changes in firing rates we reported for boundary cells and event cells, but the observations in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5</a> reflect the activity of all MTL cells. To quantify the size of state shifts, we computed the multidimensional Euclidean distance (MDD(<i>t</i>)) in state space between a given time <i>t</i> and the boundary (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5d–g</a>). The dimensionality of the state space we used was the number of principal components (PCs) that explained ≥99% of the variance. Plotting MDD as a function of time revealed an abrupt change within ~300 ms after the boundary for SB and HB video clips (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5d–g</a>). This abrupt change can also be seen at the level of individuals (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig14">8</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Population neural state shift magnitude following episodic transitions reflects participants’ subsequent memory performance."><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5: Population neural state shift magnitude following episodic transitions reflects participants’ subsequent memory performance.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="421"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p><b>a</b>–<b>c</b>, Trajectories in neural state space formed by the top three PCs (with most explained variance: PC1 = 26.05%, PC2 = 10.89% and PC3 = 6.69%) summarizing the activity of all MTL cells during the encoding stage for clips containing NBs (<b>a</b>), SBs (<b>b</b>) and HBs (<b>c</b>). Each data point indicates the neural state at a specific time relative to boundary onset (line thickness indicates time; see scale on bottom). Black dots mark the time of the boundary (SB, HB) or the middle of the clip (NB). <b>d</b>–<b>g</b>, MDD (that is, Euclidean distance relative to boundaries in the PC space formed by all PCs that cover explained variance ≥99%) as a function of time aligned to the middle of the clip (green, NB) and boundaries (blue, SB; red, HB). MDD is shown for all MTL cells (<b>d</b>; <i>n</i> = 580 in the top 55 PCs space), all boundary cells (<b>e</b>; <i>n</i> = 42 in the top 27 PCs space), all event cells (<b>f</b>; <i>n</i> = 36 in the top 26 PCs space) and all other MTL cells (that is, non-boundary/event cells in the MTL; <b>g</b>; <i>n</i> = 502 in the top 58 PCs space). Shaded areas represent ±s.e.m. across trials. See neural state shifts within each individual in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig14">8</a>. <b>h</b>, Latency analysis. Time when MDD shown in <b>d</b>–<b>g</b> reached peak value following HB (red lines) significantly differed when computed with different groups of cells (<i>F</i><sub>3,76</sub> = 103.96, <i>P</i> = 8 × 10<sup>−27</sup>, one-tailed ANOVA). Black lines denote the mean results averaged across different cell populations. <b>i</b>,<b>j</b>, Correlation between distance traveled in state space following boundaries and behavior. <b>i</b>, Positive correlation between area under the curve (AUC) MDD (sum of Euclidean distances within a 0- to 1-s time window after boundaries in the PC space) and scene recognition accuracy. Dots mark the accuracy in the scene recognition task (<i>x</i> axis) and the AUC MDD during encoding (<i>y</i> axis) of the target frames plotted separately for frames that follow NB (green, <i>r</i> = 0.214, <i>P</i> = 0.256, Pearson correlation), SB (blue, <i>r</i> = 0.653, <i>P</i> = 0.002, Pearson correlation) and HB (red, <i>r</i> = 0.565, <i>P</i> = 0.009, Pearson correlation). <b>j</b>, Negative correlation between the AUC MDD versus time discrimination accuracy plotted in the same format as in <b>i</b> for NB (green, <i>r</i> = 0.212, <i>P</i> = 0.261, Pearson correlation), SB (blue, <i>r</i> = −0.273, <i>P</i> = 0.244, Pearson correlation) and HB (red, <i>r</i> = −0.677, <i>P</i> = 0.001, Pearson correlation);***<i>P</i> &lt; 0.001, one-way ANOVA, d.f. = 3,72 in <b>h</b>.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We evaluated what types of cells contributed most to the neural state shift. First, neural state shifts following SBs were only visible when boundary cells were included (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5d,e</a>). Second, early neural state shifts after HBs were only visible when event cells were included, while later HB-related shifts remained present in the absence of either event cells (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5f</a>) or both event and boundary cells (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5g</a>). Third, the point of time at which MDD reached its maximal value varied systematically between groups of cells; the responses carried by boundary cells appeared significantly earlier than those carried by event cells and non-boundary/event cells (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5h</a>; <i>F</i><sub>3,76</sub> = 103.96, <i>P</i> = 8 × 10<sup>−27</sup>). Together, this shows that early population-level state shifts are principally due to the activity of boundary cells, whereas event cells and non-boundary/event cells in MTL contribute to slower-latency HB-related state shifts.</p><p>We next assessed whether the size of neural state shifts following boundaries during encoding was related to whether a stimulus was later remembered or not. We computed the extent of state changes in the population following a boundary by calculating the total Euclidean distance traversed in state space in the 0- to 1-s time window after boundaries (AUC MDD; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). The AUC MDD was positively correlated with recognition accuracy for frames following SBs and HBs but not NBs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5i</a>; SB: <i>r</i> = 0.653, <i>P</i> = 0.002; HB: <i>r</i> = 0.565, <i>P</i> = 0.009; NB: <i>r</i> = 0.214, <i>P</i> = 0.256). By contrast, the AUC MDD was negatively correlated with accuracy in the time discrimination task for HBs but not for NBs or SBs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5j</a>; HB: <i>r</i> = −0.677, <i>P</i> = 0.001; NB: <i>r</i> = 0.212, <i>P</i> = 0.261; SB: <i>r</i> = −0.273, <i>P</i> = 0.244). Together, these results reveal a neural correlate of the tradeoff between these two types of memory, with large neural state shifts beneficial for scene recognition memory but detrimental for order memory.</p><h3 class="c-article__sub-heading" id="Sec7">Neural context after boundaries reinstates during recognition</h3><p>It is thought that reinstatement of the neural context present at encoding enables mental time travel during memory retrieval<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Pacheco Estefan, D. et al. Coordinated representational reinstatement in the human hippocampus and lateral temporal cortex during episodic memory retrieval. Nat. Commun. 10, 2255 (2019)." href="/articles/s41593-022-01020-w#ref-CR25" id="ref-link-section-d20974544e2175">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Manning, J. R., Polyn, S. M., Baltuch, G. H., Litt, B. &amp; Kahana, M. J. Oscillatory patterns in temporal lobe reveal context reinstatement during memory search. Proc. Natl Acad. Sci. USA 108, 12893–12897 (2011)." href="/articles/s41593-022-01020-w#ref-CR26" id="ref-link-section-d20974544e2178">26</a></sup>. However, it remains unknown what exactly is reinstated for continuous experience and how boundaries shape the retrieval process. To address this question, for each individual, we quantified the degree and timing of reinstatement by computing the correlation between the vectors of spike counts of all recorded MTL neurons during the scene recognition task (1.5-s fixed time window) and during encoding (1.5-s sliding window, step size of 0.1 s; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). Correct targets (that is, frames from presented clips during encoding that were correctly remembered as old) were accompanied by a significant positive correlation between neural activity during the scene recognition and the encoding period shortly after SB/HB transitions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6a,e</a>; <i>P</i> &lt; 0.01, permutation test; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). By contrast, we observed no significant correlation for forgotten targets (that is, frames from presented clips that were incorrectly marked as new; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6b,f</a>). This effect could not be explained by individuals not attending to the scene recognition task because visually responsive cells responded equally well to both remembered and forgotten target trials (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig15">9</a>).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Reinstatement of neural context after boundaries during recognition."><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6: Reinstatement of neural context after boundaries during recognition.</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="624"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p><b>a</b>–<b>d</b>, Single subject example. The color code indicates correlation between the population response during scene recognition (0–1.5 s relative to stimulus onset) and the encoding period (sliding window of 1.5 s and 100-ms step size). Correlations are aligned to the middle of the clip (NB) or boundaries (SB, HB) and are shown separately for correctly recognized familiar targets (<b>a</b>), correctly recognized new (not seen) foils (<b>c</b>), forgotten targets (<b>b</b>) and incorrectly recognized foils (false positives; <b>d</b>) in the scene recognition task. The same plots for all subjects are shown in Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">10</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">11</a>. <b>e</b>–<b>h</b>, Population summary. Correlation coefficients, as shown in <b>a</b>–<b>d</b>, averaged across all participants for NB (green), SB (blue) and HB (red) trials. Shaded areas represent ±s.e.m. across participants. The gray dashed horizontal lines denote the significance threshold (<i>P</i> &lt; 0.01, one-tailed permutation test; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). Data are shown for correctly recognized familiar targets (<b>e</b>), forgotten targets (<b>f</b>), correctly recognized new foils (<b>g</b>) and incorrectly recognized foils (<b>h</b>) in the scene recognition task. See the same analyses after excluding boundary cells and event cells and only for boundary cells and event cells in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">12</a>. <b>i</b>, The reinstated neural context was located in between the boundary and the tested frame. For trials with target frames extracted after boundaries, the time distance from when the correlation coefficient peaks to the time of SB and HB (filled circles: SB: −1.26 ± 0.38 s, <i>t</i><sub>19</sub> = 14.68, <i>P</i> = 8 × 10<sup>−12</sup>; HB: −1.28 ± 0.48 s, <i>t</i><sub>19</sub> = 11.80, <i>P</i> = 3 × 10<sup>−10</sup>; one-tailed <i>t</i>-test) or target frames (empty circles; SB: 1.53 ± 0.61 s, <i>t</i><sub>19</sub> = 11.18, <i>P</i> = 8 × 10<sup>−10</sup>; HB: 1.72 ± 1.03 s, <i>t</i><sub>19</sub> = 7.44, <i>P</i> = 5 × 10<sup>−7</sup>; one-tailed <i>t</i>-test) is shown. Negative/positive values denote the point of time of boundaries (negative) or target frames (positive) relative to when the correlation coefficient reaches its peak value. Asterisks indicate the significance of the peak correlation leading the time of target frames. See the same analyses with the correlation computed using different window sizes in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">13</a>. <b>j</b>–<b>m</b>, Population summary (confidence). Reinstatement differed between frames remembered with high (filled circles) and low (empty circles) confidence responses for "old" decisions (correct targets (<b>j</b>) and incorrect foils (<b>m</b>)) in SB and HB conditions but not "new" decisions (correct foils (<b>l</b>) and incorrect targets (<b>k</b>)) and NB conditions, regardless of whether they were correct or incorrect (SB, correct targets: <i>P</i> = 5 × 10<sup>−10</sup>; HB, correct targets: <i>P</i> = 4 × 10<sup>−6</sup>; NB, correct targets: <i>P</i> = 0.79; SB, incorrect foils: <i>P</i> = 5 × 10<sup>−7</sup>; HB, incorrect foils: <i>P</i> = 5 × 10<sup>−5</sup>; NB, incorrect foils: <i>P</i> = 0.18; one-tailed <i>t</i>-test). Correlation coefficients are as shown in <b>e</b>–<b>h</b> averaged over 0–1 s after boundaries. <b>n</b>,<b>o</b>, Population summary (target–foil similarity). Correlation coefficients versus similarity ratings between targets and foils are plotted for correct (<b>n</b>; <i>F</i><sub>2,54</sub> = 2.182, <i>P</i> = 0.144; one-tailed ANOVA) and incorrect recognized foils (<b>o</b>; <i>F</i><sub>2,54</sub> = 10.67, <i>P</i> = 1 × 10<sup>−4</sup>; one-tailed ANOVA). Each dot represents one recording session. Black lines in <b>i</b>–<b>m</b> and <b>o</b> denote the mean results averaged across all recording sessions; ***<i>P</i> &lt; 0.001.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/articles/s41593-022-01020-w/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>The reinstated neural context during retrieval was most similar to the neural context present during encoding approximately ~1.2 s after the boundary that preceded the tested frame (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6i</a>, filled circles; SB: −1.26 ± 0.38 s, <i>t</i><sub>19</sub> = 14.68, <i>P</i> = 8 × 10<sup>−12</sup>; HB: −1.28 ± 0.48 s, <i>t</i><sub>19</sub> = 11.80, <i>P</i> = 3 × 10<sup>−10</sup>). Notably, the point of time of maximal similarity preceded the time at which the later tested frame was shown by 1–1.5 s (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6i</a>, empty circles; SB: 1.53 ± 0.61 s, <i>t</i><sub>19</sub> = 11.18, <i>P</i> = 8 × 10<sup>−10</sup>; HB: 1.72 ± 1.03 s, <i>t</i><sub>19</sub> = 7.44, <i>P</i> = 5 × 10<sup>−7</sup>). This observation remains true also for smaller window sizes used to compute the correlations (Supplementary Fig.<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">13</a>), indicating that the neural state reinstated during testing is the one that was present in between the preceding boundary and the tested frame. Thus, the neural state that was reinstated is the one present well before the tested frame was shown during encoding. Together with an absence of significant reinstatement during incorrect targets (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6b</a>), these analyses suggest that the neural correlate of reinstatement is not the result of identical sensory inputs in the clips and tested frames. Additionally, no significant correlation for correctly identified foils was observed (that is, frames from unpresented clips correctly marked as new; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6c,g</a>).</p><p>Reinstatement is thought to contribute primarily to the recollection of memories that are remembered with high confidence<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Folkerts, S., Rutishauser, U. &amp; Howard, M. W. Human episodic memory retrieval is accompanied by a neural contiguity effect. J. Neurosci. 38, 4200–4211 (2018)." href="/articles/s41593-022-01020-w#ref-CR27" id="ref-link-section-d20974544e2489">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Howard, M. W., Fotedar, M. S., Datey, A. V. &amp; Hasselmo, M. E. The temporal context model in spatial navigation and relational learning: toward a common explanation of medial temporal lobe function across domains. Psychol. Rev. 112, 75–116 (2005)." href="/articles/s41593-022-01020-w#ref-CR28" id="ref-link-section-d20974544e2492">28</a></sup>. Compatible with this view, the correlations following boundary transitions were significantly stronger in high- than in low-confidence trials (converted from three levels of confidence; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>). This difference was observed during both correctly remembered targets and falsely recognized foils (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6j–m</a>; SB, correct targets: <i>P</i> = 5 × 10<sup>−10</sup>; HB, correct targets: <i>P</i> = 4 × 10<sup>−6</sup>; NB, correct targets: <i>P</i> = 0.79; SB, incorrect foils: <i>P</i> = 5 × 10<sup>−7</sup>; HB, incorrect foils: <i>P</i> = 5 × 10<sup>−5</sup>; NB, incorrect foils: <i>P</i> = 0.18; <i>t</i>-test).</p><p>Notably, strong correlations between the neural state at retrieval and encoding also occurred when a new image was incorrectly classified as seen before (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6d,h</a>; incorrect foil, <i>P</i> &lt; 0.01, permutation test; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec9">Methods</a>), thereby revealing a neural explanation for the false alarms. Were these false alarms, which were accompanied by neural reinstatement, caused by visual similarity between the targets and foils? To address this question, we assessed the similarity between each target and foil by acquiring similarity ratings from an independent control group of individuals (<i>n</i> = 30). Similarity values were balanced across NB, SB and HB (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2a</a>). We split foils into low (top 66.67–100%), medium (top 33.33–66.67%) and high (top 1–33.33%) similarity groups. Correlations between encoding and scene recognition were significantly stronger for highly similar foils falsely recognized as old than for low- and medium-similarity foils (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6o</a>; incorrect foil: <i>F</i><sub>2,54</sub> = 10.67, <i>P</i> = 1 × 10<sup>−4</sup>). By contrast, the extent of correlation for correctly rejected foils (true negatives) did not vary as a function of similarity (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6n</a>; correct foil: <i>F</i><sub>2,54</sub> = 2.182, <i>P</i> = 0.144). Thus, the reason for false alarms is that the wrong context is reinstated due to the high similarity of the foil with a target. Together, these results support the notion that the neural state present at encoding following the boundary is reinstated during memory retrieval.</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec8-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec8">Discussion</h2><div class="c-article-section__content" id="Sec8-content"><p>Memories are often conceptualized as discrete events on a narrative timeline<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Avrahami, J. &amp; Kareev, Y. The emergence of events. Cognition 53, 239–261 (1994)." href="/articles/s41593-022-01020-w#ref-CR6" id="ref-link-section-d20974544e2584">6</a></sup>. However, the very definition of an event remains enigmatic. Where do events start and end, and how are multiple signals bound together over time to form a singular event? Here, we test the hypothesis that boundary detection is a mechanism that segments continuous experience into discrete events. Behaviorally<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Swallow, K. M., Zacks, J. M. &amp; Abrams, R. A. Event boundaries in perception affect memory encoding and updating. J. Exp. Psychol. Gen. 138, 236–257 (2009)." href="/articles/s41593-022-01020-w#ref-CR29" id="ref-link-section-d20974544e2588">29</a></sup>, boundaries enhance scene recognition memory for temporally proximal events while disrupting temporal order memory. We found two types of cells that responded to cognitive boundaries; one responded to both SBs and HBs, while another group responded only after HBs.</p><p>Both SBs and HBs are accompanied by salient visual changes, whereas the NB control condition does not (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1b</a>). However, the observed responses to boundaries (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3</a>) cannot be explained by these sharp visual input changes. First, cells differentiate between SBs and HBs even though both types encompass similar changes at the pixel level (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">1</a>). Second, boundary and event cells did not respond to strong visual changes at clip onsets (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3d,h</a>) or offsets (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig9">3</a>) during encoding nor to the image onsets or offsets during the scene recognition and time discrimination tasks (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig10">4</a>). In our task, trial structure is predictable, that is, the intertrial interval is always followed by a video and then the next intertrial interval (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1a–d</a>). By contrast, whether a boundary will occur in a given video and if so what type (SB or HB) is not predictable. One hypothesis for the absence of responses to clip onsets and offsets is therefore their predictability, which would lead to an absence of prediction errors that are hypothesized to underly event segmentation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Richmond, L. L., Gold, D. A. &amp; Zacks, J. M. Event perception: translations and applications. J. Appl. Res. Mem. Cogn. 6, 111–120 (2017)." href="/articles/s41593-022-01020-w#ref-CR30" id="ref-link-section-d20974544e2617">30</a></sup>. Supporting this hypothesis, boundary and event cells also increased their responses following the unpredictable probe question during encoding (present randomly every four to eight trials; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1a</a>). In contrast to the selective single-neuron response to cognitive boundaries, prior functional magnetic resonance imaging (fMRI) work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Ben-Yakov, A. &amp; Dudai, Y. Constructing realistic engrams: poststimulus activity of hippocampus and dorsal striatum predicts subsequent episodic memory. J. Neurosci. 31, 9032–9042 (2011)." href="/articles/s41593-022-01020-w#ref-CR31" id="ref-link-section-d20974544e2624">31</a></sup> reported a clip offset-triggered blood oxygenation level–dependent signal change in the hippocampus whose magnitude was predictive of subsequent memory strength. This off response has been interpreted to have the same origin as the between-event responses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Ben-Yakov, A., Eshel, N. &amp; Dudai, Y. Hippocampal immediate poststimulus activity in the encoding of consecutive naturalistic episodes. J. Exp. Psychol. Gen. 142, 1255–1263 (2013)." href="/articles/s41593-022-01020-w#ref-CR32" id="ref-link-section-d20974544e2628">32</a></sup> and was present despite the fixed clip length and trial structure.</p><p>Boundary cells respond to both SBs and HBs, whereas event cells respond only to HBs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3</a>). These distinct responses may reflect the hierarchical structure of episodic memory, with event cells representing episodic transitions between distinct events, while boundary cells represent more frequent but smaller episodic transitions within the same overall narrative. These findings provide evidence for the theory that event segmentation is a hierarchical dynamic procedure, with fine-to-coarse segmentations associated with different kinds of cognitive boundaries<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Kurby, C. A. &amp; Zacks, J. M. Segmentation in the perception and memory of events. Trends Cogn. Sci. 12, 72–79 (2008)." href="/articles/s41593-022-01020-w#ref-CR9" id="ref-link-section-d20974544e2638">9</a></sup>. The anatomical location and response latency of the cells are also compatible with this proposal; boundary cells respond first and are most common in the parahippocampal gyrus, whereas event cells respond later and are most common in the hippocampus (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>). This distinction is also visible at the population level, with neural state shifts for SBs mainly driven by boundary cells, whereas HB-related state shifts occur later and are driven by a broader group of cells (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5d–h</a>). Notably, the late HB-related state shifts are partially driven by cells that are not classified as event cells (a conclusion that holds even when using a more liberal definition of event cells at <i>P</i> &lt; 0.01). This suggests that besides the early HB-related responses, there is a secondary later response to HBs that is encoded as a distributed population response. We hypothesize that the early responses of boundary cells reflect contextual changes detected in the higher-level visual areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Isik, L., Singer, J., Madsen, J. R., Kanwisher, N. &amp; Kreiman, G. What is changing when: decoding visual information in movies from human intracranial recordings. Neuroimage 180, 147–159 (2018)." href="/articles/s41593-022-01020-w#ref-CR33" id="ref-link-section-d20974544e2652">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Aminoff, E. M., Kveraga, K. &amp; Bar, M. The role of the parahippocampal cortex in cognition. Trends Cogn. Sci. 17, 379–390 (2013)." href="/articles/s41593-022-01020-w#ref-CR34" id="ref-link-section-d20974544e2655">34</a></sup>, while event cells are the result of a late output signal from a comparator operation between predicted and received signals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Lisman, J. E. &amp; Grace, A. A. The hippocampal-VTA loop: controlling the entry of information into long-term memory. Neuron 46, 703–713 (2005)." href="/articles/s41593-022-01020-w#ref-CR35" id="ref-link-section-d20974544e2659">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Vinogradova, O. S. Hippocampus as comparator: role of the two input and two output systems of the hippocampus in selection and registration of information. Hippocampus 11, 578–598 (2001)." href="/articles/s41593-022-01020-w#ref-CR36" id="ref-link-section-d20974544e2662">36</a></sup>.</p><p>Responses of boundary or event cells bring to mind border and place cells in the rodent hippocampus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Lever, C., Burton, S., Jeewajee, A., O’Keefe, J. &amp; Burgess, N. Boundary vector cells in the subiculum of the hippocampal formation. J. Neurosci. 29, 9771–9777 (2009)." href="/articles/s41593-022-01020-w#ref-CR16" id="ref-link-section-d20974544e2669">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Solstad, T., Boccara, C. N., Kropff, E., Moser, M. B. &amp; Moser, E. I. Representation of geometric borders in the entorhinal cortex. Science 322, 1865–1868 (2008)." href="/articles/s41593-022-01020-w#ref-CR37" id="ref-link-section-d20974544e2672">37</a></sup>. As rodents move between compartments, place cells cluster at boundaries (for example, doorways)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Spiers, H. J., Hayman, R. M., Jovalekic, A., Marozzi, E. &amp; Jeffery, K. J. Place field repetition and purely local remapping in a multicompartment environment. Cereb. Cortex 25, 10–25 (2015)." href="/articles/s41593-022-01020-w#ref-CR14" id="ref-link-section-d20974544e2676">14</a></sup>, the crossing of which is followed by remapping<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Alme, C. B. et al. Place cells in the hippocampus: eleven maps for eleven rooms. Proc. Natl Acad. Sci. USA 111, 18428–18435 (2014)." href="/articles/s41593-022-01020-w#ref-CR18" id="ref-link-section-d20974544e2680">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Colgin, L. L., Moser, E. I. &amp; Moser, M. B. Understanding memory through hippocampal remapping. Trends Neurosci. 31, 469–477 (2008)." href="/articles/s41593-022-01020-w#ref-CR19" id="ref-link-section-d20974544e2683">19</a></sup> or reinstatement<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Derdikman, D. et al. Fragmentation of grid cell maps in a multicompartment environment. Nat. Neurosci. 12, 1325–1332 (2009)." href="/articles/s41593-022-01020-w#ref-CR15" id="ref-link-section-d20974544e2687">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Grieves, R. M., Jenkins, B. W., Harland, B. C., Wood, E. R. &amp; Dudchenko, P. A. Place field repetition and spatial learning in a multicompartment environment. Hippocampus 26, 118–134 (2016)." href="/articles/s41593-022-01020-w#ref-CR20" id="ref-link-section-d20974544e2690">20</a></sup> of a different set of hippocampal place fields. Here, boundary cells and event cells respond to transitions (boundaries) between different episodic contexts. Also, similar to place field remapping, the neural state changed abruptly following a boundary. When participants are reexposed to familiar target frames during the later recognition test, the neural state reinstates if the item is successfully recognized. Similar to place field reinstatement, the reinstated neural state is most similar to the one following boundaries even before when the tested frame is shown. This finding provides insight into the question of what neural context is reinstated during mental time travel and memory search<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Xiao, X. et al. Transformed neural pattern reinstatement during episodic memory retrieval. J. Neurosci. 37, 2986–2998 (2017)." href="#ref-CR38" id="ref-link-section-d20974544e2694">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Favila, S. E., Samide, R., Sweigart, S. C. &amp; Kuhl, B. A. Parietal representations of stimulus features are amplified during memory retrieval and flexibly aligned with top–down goals. J. Neurosci. 38, 7809–7821 (2018)." href="#ref-CR39" id="ref-link-section-d20974544e2694_1">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Jang, A. I., Wittig, J. H. Jr., Inati, S. K. &amp; Zaghloul, K. A. Human cortical neurons in the anterior temporal lobe reinstate spiking activity during verbal memory retrieval. Curr. Biol. 27, 1700–1705 (2017)." href="#ref-CR40" id="ref-link-section-d20974544e2694_2">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Howard, M. W. &amp; Natu, V. S. Place from time: reconstructing position from a distributed representation of temporal context. Neural Netw. 18, 1150–1162 (2005)." href="#ref-CR41" id="ref-link-section-d20974544e2694_3">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Polyn, S. M. &amp; Kahana, M. J. Memory search and the neural representation of context. Trends Cogn. Sci. 12, 24–30 (2008)." href="/articles/s41593-022-01020-w#ref-CR42" id="ref-link-section-d20974544e2697">42</a></sup>. This finding also indicates that abrupt changes in neural context are important to demarcate periods of time that can be reinstated later. We note several differences between boundary and event cells and border cells in rodents. Border cells respond to physical boundaries and are observed in tasks in which rodents are extensively trained. By contrast, boundary or event cells in humans respond to cognitive boundaries in a variety of different videos, none of which inidividuals have seen before. This property is an essential requirement for a process to divide experience into episodes to shape episodic memories, which, by definition, occur only once in new environments.</p><p>What roles do boundary responses play in episodic memory? At the single-cell level, the firing rate of boundary cells predicts scene recognition memory strength and the clustering of event cells’ spike timing relative to theta phase predicts temporal order memory encoding success. This indicates that these two kinds of cells play distinct roles during encoding, with each strengthening only one kind of memory using a different mechanism. The response of boundary and event cells during encoding was ‘content invariant’ because they responded to many clips with varying content (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3</a>). The role of boundary responses during retrieval was in guiding the points of time that would later be reinstated (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6i</a>) but not participating in the reinstatement process itself. This is expected if boundary cells do not carry information about content. Confirming this, the results on reinstatement remain essentially unchanged after excluding boundary and event cells from the analysis (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">12</a>). Together, these findings suggest that boundary and event cells play two roles in episodic memory; they structure memories during encoding, and they serve as markers for periods of time that are later reinstated.</p></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec9-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec9">Methods</h2><div class="c-article-section__content" id="Sec9-content"><h3 class="c-article__sub-heading" id="Sec10">Participants</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec11">Individuals with drug-resistant epilepsy</h4><p>Twenty individuals with drug-resistant epilepsy volunteered for this study and gave their informed consents. The institutional review boards of Toronto Western Hospital and Cedars-Sinai Medical Center approved all protocols. The task was conducted while the individuals stayed in the hospital after implantation of depth electrodes for monitoring seizures. The location of the implanted electrodes was solely determined by clinical needs. The behavioral analyses included results from all 20 individuals, and the neural results were analyzed across 19 individuals (participant 20 had no usable recordings; Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec12">Amazon Mechanical Turk (MTurk) workers</h4><p>MTurk workers were recruited for similarity ratings (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec18">Similarity ratings</a>), including 30 individuals (age 23.25 ± 3.42 years, nine female) for rating the visual properties of different boundaries (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">1</a>), 30 individuals (age 22.79 ± 5.73 years, 11 female) for rating the similarity between target and foil frames (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2a</a>) and 30 individuals (age 25.06 ± 6.11 years, 7 female) for performing the time discrimination task without an encoding session (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2b</a>). All control tasks conducted on Amazon MTurk workers were under the approval of the institutional review board of Boston Children’s Hospital, and informed consents were obtained with digital signatures for each individual.</p><h3 class="c-article__sub-heading" id="Sec13">Task</h3><p>The task consisted of three parts: encoding, scene recognition and time discrimination (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1a,c,d</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec14">Encoding</h4><p>Participants watched a series of 90 unique clips with no sound and were instructed to remember as much of the clips as possible. Each trial started with a baseline period, a fixation cross reminding individuals to fixate at the center of the screen throughout the task. The duration of the baseline period ranged from 0.9 to 1.1 s (randomized, sampled from uniform distribution). The fixation period was followed by the presentation of a video clip that contained either NBs (continuous movie shots; virtual NBs for analysis purposes were always located in the middle of the clip), SBs (cuts to a new scene within the same movie, one to three SBs per clip randomly distributed in the clips) or an HB (cuts to a new scene from a different movie, one HB per clip located at 4 s after the start of the clip). Examples of SBs and HBs are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1b</a>. A yes or no question related to the content of the clip (for example, is anyone in the clip wearing glasses?) appeared randomly after every four to eight clips.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec15">Scene recognition</h4><p>After watching all 90 clips, participants’ memory for the content of the videos was evaluated in a scene recognition test. During scene recognition, frames extracted from encoded clips (target frames) and frames from new, never shown clips (foil frames) were presented to the participants. Individuals were instructed to identify whether these frames were old or new (that is, whether they had seen the frame during the encoding session). To generate the testing frames for scene recognition, we first extracted two frames from each clip, one randomly pulled out from the first half of the clip and the other one from the second half. We then kept half of these frames extracted from the first/second half of the clip (in total, <i>n</i> = 90) as target frames and used the other half as templates to search for foil frames (in total, <i>n</i> = 90) from a different movie played by different actors/actresses (<i>n</i> = 30), a different movie played by the same actors/actresses (<i>n</i> = 30) or the unpresented portion from the same movie played by the same actors/actress (<i>n</i> = 30) to introduce different levels of similarity between the target frames and foil frames. The total number of target and foil frames (30 target frames and 30 foil frames for each boundary type) and the average similarity level of foil frames were counterbalanced across different boundary types (<i>F</i><sub>2,87</sub> = 1.72, <i>P</i> = 0.19; rated by Amazon MTurk workers; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec18">Similarity ratings</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec16">Time discrimination</h4><p>After the scene recognition test, we evaluated participants’ memory about the temporal structure of the clip with a time discrimination test. In each trial, two frames (half of them picked at 1 s and 7 s and the other half picked at 3 s and 5 s of the clip) separated by different kinds of boundaries (NB, SB or HB) were extracted from the same video clip and were presented side by side. Participants were instructed to indicate which of the two frames (that is, ‘left’ or ‘right’) appeared first (earlier in time) in the videos they watched during encoding. In both the time discrimination and recognition memory test, the duration of the baseline period ranged from 0.45 to 0.55 s (randomized, sampled from uniform distribution).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec17">Confidence measurement</h4><p>All binary choices through the encoding session, scene recognition and time discrimination were made together with a subjective confidence judgment (that is, sure, less sure and very unsure). Thus, there were always six possible responses for each question. Given that there were fewer ‘less sure’ and ‘very unsure’ responses than ‘sure’ responses, we grouped ‘very unsure’ and ‘less sure’ responses together as ‘low confidence’ and labeled ‘sure’ responses as ‘high confidence’ in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6j–m</a>.</p><h3 class="c-article__sub-heading" id="Sec18">Similarity ratings</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec19">Visual properties of SBs and HBs</h4><p>Both SB and HB transitions were accompanied by transient visual changes (cuts to a new scene), whereas there were no such visual changes for the NB condition. We quantified the visual changes of each boundary type by computing metrics that relate to pixel-level differences, luminance, contrast, complexity, entropy and color distribution between pre- and postboundary frames. In addition, to quantify visual differences not directly captured at the pixel level, we used pre- and postboundary frames as inputs for the AlexNet network (pretrained on ImageNet dataset)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. in NIPS’12: Proceedings of the 25th International Conference on Neural Information Processing Systems, Vol. 1 (eds Bartlett, P., Pereira, F. C. N., Burges, C. J. C., Bottoue, L., &amp; Weinberger K. Q.) 1097–1105 (Morgan Kaufmann, 2012)." href="/articles/s41593-022-01020-w#ref-CR43" id="ref-link-section-d20974544e2842">43</a></sup>, extracted the activation matrices from the layer ‘fc7’ for both images and computed the Euclidean distance between their activation matrices. Moreover, we collected perceptual ratings (that is, similarity ratings between pre- and postboundary frames) from Amazon MTurk workers. During similarity ratings, pre- and postboundary frames were presented side by side, and MTurk workers were instructed to rate the similarity of the image pairs by clicking on a scaling bar (0–1: 0, different; 1, identical). See results in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">1</a>.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec20">Similarity ratings between target and foil frames</h4><p>When selecting foil frames, we used target frames as templates to search for foil frames with different similarity levels (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="/articles/s41593-022-01020-w#Sec13">Task</a>). We presented the target frame with its corresponding foil frame side by side and instructed MTurk workers to rate the similarity between them (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2a</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec21">Time discrimination without encoding</h4><p>To ensure that the time discrimination task could not be solved by pure reasoning, we recruited MTurk workers to perform the time discrimination test without watching clips (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">2b</a>).</p><h3 class="c-article__sub-heading" id="Sec22">Electrophysiology</h3><p>We recorded bilaterally from the amygdala, hippocampus and parahippocampal gyrus and other regions outside the MTL using hybrid depth electrodes (Ad-Tech Company), which contained eight microwires (40 μm in diameter) at the tip of each electrode shank. For each microwire, broadband signals (0.1–9,000 Hz filtered) were recorded at 32 kHz using the ATLAS system (Neuralynx).</p><h3 class="c-article__sub-heading" id="Sec23">Spike sorting and quality metrics of single units</h3><p>The recorded signals were filtered offline in the 300- to 3,000-Hz band with a zero-phase lag filter. Spikes were detected and sorted using the semiautomated template-matching algorithm Osort<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Rutishauser, U., Schuman, E. M. &amp; Mamelak, A. N. Online detection and sorting of extracellularly recorded action potentials in human medial temporal lobe recordings, in vivo. J. Neurosci. Methods 154, 204–224 (2006)." href="/articles/s41593-022-01020-w#ref-CR44" id="ref-link-section-d20974544e2892">44</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Fried, I., Rutishauser, U., Cerf, M. &amp; Kreiman, G. Single Neuron Studies of the Human Brain: Probing Cognition (The MIT Press, 2014)." href="/articles/s41593-022-01020-w#ref-CR45" id="ref-link-section-d20974544e2895">45</a></sup> v4. We computed spike sorting quality metrics for all putative single units (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">5</a>) to quantify our recording and sorting quality<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kaminski, J. et al. Persistently active neurons in human medial frontal and medial temporal lobe support working memory. Nat. Neurosci. 20, 590–601 (2017)." href="#ref-CR46" id="ref-link-section-d20974544e2902">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pouzat, C., Mazor, O. &amp; Laurent, G. Using noise signature to optimize spike-sorting and to assess neuronal classification quality. J. Neurosci. Methods 122, 43–57 (2002)." href="#ref-CR47" id="ref-link-section-d20974544e2902_1">47</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Harris, K. D., Henze, D. A., Csicsvari, J., Hirase, H. &amp; Buzsaki, G. Accuracy of tetrode spike separation as determined by simultaneous intracellular and extracellular measurements. J. Neurophysiol. 84, 401–414 (2000)." href="/articles/s41593-022-01020-w#ref-CR48" id="ref-link-section-d20974544e2905">48</a></sup>.</p><h3 class="c-article__sub-heading" id="Sec24">Electrode localization</h3><p>Electrode localization was based on postoperative MRI/computed tomography scans. We co-registered postoperative and preoperative MRIs using Freesurfer’s mri_robust_register<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Reuter, M., Rosas, H. D. &amp; Fischl, B. Highly accurate inverse consistent registration: a robust approach. Neuroimage 53, 1181–1196 (2010)." href="/articles/s41593-022-01020-w#ref-CR49" id="ref-link-section-d20974544e2917">49</a></sup>. To summarize electrode positions and to provide across-study comparability, we aligned each participant’s preoperative scan to the CIT168 template brain in MNI152 coordinates<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Pauli, W. M., Nili, A. N. &amp; Tyszka, J. M. A high-resolution probabilistic in vivo atlas of human subcortical brain nuclei. Sci. Data 5, 180063 (2018)." href="/articles/s41593-022-01020-w#ref-CR50" id="ref-link-section-d20974544e2921">50</a></sup> using a concatenation of an affine transformation followed by a symmetric image normalization (SyN) diffeomorphic transform<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Avants, B. et al. Multivariate analysis of structural and diffusion imaging in traumatic brain injury. Acad. Radiol. 15, 1360–1375 (2008)." href="/articles/s41593-022-01020-w#ref-CR51" id="ref-link-section-d20974544e2925">51</a></sup>. The MNI coordinates of the right microwires from the same electrode shank were marked as one location. MNI coordinates of microwires with putative neurons detected across all participants were plotted on a template brain for illustration (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1e</a>).</p><h3 class="c-article__sub-heading" id="Sec25">Data analyses</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec26">Boundary cell</h4><p>For each recorded neuron, we counted spikes within the 0- to 1-s (postboundary) and −1- to 0-s time interval (baseline) relative to boundaries during encoding. A cell was considered a boundary cell if it met the following criteria: (1) its spike counts within postboundary time windows were significantly different from its spike count within baseline time windows for SB and HB but not for NB (<i>P</i> &lt; 0.05, permutation <i>t</i>-test), and (2) its spike counts within postboundary time windows were significantly greater in SB and HB than NB (<i>P</i> &lt; 0.05, permutation <i>t</i>-test).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec27">Event cell</h4><p>A cell was considered an event cell if it met the following criteria: (1) its spike counts within postboundary time windows were significantly different from its spike count within baseline time windows for HB but not for NB and SB (<i>P</i> &lt; 0.05, permutation <i>t</i>-test), and (2) its spike counts within postboundary time windows were significantly greater in HB than NB and SB (<i>P</i> &lt; 0.05, permutation I-test).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec28">Boundary and event cell responses to clip onsets and offsets</h4><p>For each selected boundary cell and event cells, we counted spikes within the 0- to 1-s (post) and −1- to 0-s (pre) time interval relative to clip onsets/offsets during encoding for clips with NB, SB and HB separately. The boundary cell or event cell was considered as not responding to clip onsets/offsets if their spike counts within each boundary condition did not differ between post- and prewindow (<i>P</i> &gt; 0.05, permutation <i>t</i>-test).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec29">Phase-tuning cells</h4><p>We computed the MRL for the theta band phases of all spikes fired within a 0- to 1-s window following a boundary and −1 to 0 s preceding a boundary (baseline) during encoding. We also computed the MRLs in the 0- to 1-s postboundary time window separately for spikes fired in trials that were later remembered (correct) versus forgotten (incorrect) during the scene recognition and time discrimination task. We defined a cell as a ‘phase-tuning neuron’ if it met the following criteria: (1) its MRL within the postboundary time window was significantly different from its MRL within the baseline time window for SB and HB but not for NB trials (<i>P</i> &lt; 0.05, permutation <i>t</i>-test), and (2) its MRL within the postboundary time window was significantly different between correct and incorrect trials in either the scene recognition and/or the time discrimination tasks (<i>P</i> &lt; 0.05, permutation <i>t</i>-test).</p><h3 class="c-article__sub-heading" id="Sec30">Chance level for cell response analyses</h3><p>To estimate the number of neurons that would be considered boundary cells or event cells by chance, we repeated the same procedures for boundary cell and event cell analyses after randomly shuffling the trial labels (NB, SB and HB) 1,000 times. For each iteration, we obtained the proportion of selected boundary cells and event cells relative to the total number of neurons within each region. These 1,000 values formed the empirically estimated null distribution for the proportion of boundary cells and event cells expected by chance. A region was considered to have a significant amount of boundary cells or event cells if its actual fraction of significant cells exceeded 95% of the null distribution (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM1">4</a>; <i>P</i> &lt; 0.05).</p><h3 class="c-article__sub-heading" id="Sec31">Association between spiking activity during encoding and later memory retrieval accuracy</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec32">Firing rate modulation</h4><p>For each boundary cell and event cell, we grouped its spike activity within 0 to 1 s after boundaries during encoding based on participants’ subsequent memory performance either in the scene recognition task (correct versus incorrect recognition) or the time discrimination task (correct versus incorrect discrimination). We then computed the firing rate as a function of time (bin size = 200 ms, step size = 2 ms) for each trial, which was further <i>z</i> score-normalized using the mean and s.d. of the firing rate across the whole trial. For each boundary cell and event cell, we then computed the mean <i>z</i>-scored firing rate within 0- to 1-s time intervals relative to boundaries for each trial and averaged this value across trials within each boundary type. The resulting values across all boundary cells and event cells were used for comparisons across NB, SB and HB conditions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4c,g</a> and Extended Data Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig12">6c</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig13">7c</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec33">Phase modulation</h4><p>For each spike of each boundary cell and event cell, we computed the phase of the spike relative to the theta frequency band-filtered LFP signals recorded from the same microwire. To eliminate potential contamination by the spike waveform, we removed the LFP signal within the 3 ms around each spike and replaced it with a linear interpolation. The cleaned LFP signals were then bandpass filtered between 1 and 300 Hz (a zero-phase delay finite impulse response filter with Hamming window) and downsampled from 32 kHz to 500 Hz. We performed automatic artifact rejection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Banaie Boroujeni, K., Tiesinga, P. &amp; Womelsdorf, T. Adaptive spike-artifact removal from local field potentials uncovers prominent beta and gamma band neuronal synchronization. J. Neurosci. Methods 330, 108485 (2020)." href="/articles/s41593-022-01020-w#ref-CR52" id="ref-link-section-d20974544e3057">52</a></sup> and manual visual inspection (using ft_databrowser.m from Fieldtrip toolbox<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Oostenveld, R., Fries, P., Maris, E. &amp; Schoffelen, J. M. FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data. Comput Intell. Neurosci. 2011, 156869 (2011)." href="/articles/s41593-022-01020-w#ref-CR53" id="ref-link-section-d20974544e3061">53</a></sup> version 20190527) to remove large transient signal changes from the downsampled LFPs. Next, we extracted neural activity within the theta band by bandpass filtering in the 4- to 8-Hz band (eegfilt.m function in EEGLAB toolbox<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Delorme, A. &amp; Makeig, S. EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. J. Neurosci. Methods 134, 9–21 (2004)." href="/articles/s41593-022-01020-w#ref-CR54" id="ref-link-section-d20974544e3065">54</a></sup>, a two-way, zero-phase lag, least-squares finite impulse response filter to prevent phase distortion), followed by the Hilbert transform to obtain theta phase as a function of time. We then extracted the phase for each spike (that is, spike phases) by boundary cells and event cells. The phase-locking strength of each boundary cell or event cell was quantified as the MRL of all spike phases of all spikes that occurred within a 0- to 1-s window after boundaries (0, no phase locking; 1, strongest phase locking). The resulting MRL values were then compared between trials with correct or incorrect subsequent memory performance for NB, SB and HB trials separately (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4d,h</a> and Extended Data Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig12">6d</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig13">7d</a>). The computation of MRL is sensitive to the number of spikes. Therefore, the comparison of MRL between correct and incorrect trials was conducted with balanced spike counts.</p><h3 class="c-article__sub-heading" id="Sec34">State space analyses</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec35">Neural state trajectories</h4><p>For each trial, we binned each neuron’s spike counts during encoding into non-overlapping 10-ms-wide bins, followed by smoothing with a 200-ms s.d. Gaussian kernel and <i>z</i> score normalization (mean and s.d. were calculated across the entire trial). We used these <i>z</i>-scored smoothed spike density estimates from all recorded MTL cells across all participants to form a pseudopopulation. We applied PCA to reduce the dimensionality of the pseudopopulation (MATLAB R2019b function svd.m). We then rank ordered the resulting PCs by their explained variance (function dpca_explainedVariance.m from dpca toolbox<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Kobak, D. et al. Demixed principal component analysis of neural population data. eLife 5, e10989 (2016)" href="/articles/s41593-022-01020-w#ref-CR55" id="ref-link-section-d20974544e3098">55</a></sup>) and plotted the average neural state trajectories for each boundary type in a three-dimensional space constructed by the top three PC components (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5a–c</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec36">MDD</h4><p>MDD was defined as the Euclidean distance between two points in the PC space (with all the first <i>n</i> PCs that accounted for &gt;99% explained variance). Note that while this space captured 99% of explained variance, it was nevertheless substantially lower dimensional than the original space.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec37">AAUC MDD</h4><p>AUC MDD was defined as the cumulative sum of all Euclidean distance values within the 0- to 1-s time window after boundaries (in the PC space).</p><h3 class="c-article__sub-heading" id="Sec38">Reinstatement of neural context</h3><p>This analysis was done separately for each session of simultaneously recorded neurons and did not rely on the pseudopopulations defined in the previous section.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec39">Correlation between encoding and retrieval</h4><p>Neural activity was quantified for each neuron in 1.5-s-wide bins and a step size of 100 ms. We computed the Pearson correlation coefficients (corrcoef.m from MATLAB R2019b) between the neural population activity during scene recognition (1 time bin × number of neurons) and encoding (80 time bins × number of neurons) at each time step.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec40">Significant correlation threshold</h4><p>We computed the same correlation values after randomly shuffling the trial labels (that is, disrupting the correspondence between encoding and scene recognition trials) to obtain the average correlation strength across trials and neurons expected by chance. This procedure was repeated 1,000 times to form a null distribution, in which the 2.5th and 97.5th percentile values were used as the threshold to determine significance of the actual correlation values (dashed horizontal lines in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6</a>).</p><h3 class="c-article__sub-heading" id="Sec41">Statistics and reproducibility</h3><p>No statistical method was used to predetermine sample size, but our sample sizes are similar to those reported in previous publications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Kaminski, J. et al. Persistently active neurons in human medial frontal and medial temporal lobe support working memory. Nat. Neurosci. 20, 590–601 (2017)." href="/articles/s41593-022-01020-w#ref-CR46" id="ref-link-section-d20974544e3161">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Bausch, M. et al. Concept neurons in the human medial temporal lobe flexibly represent abstract relations between concepts. Nat. Commun. 12, 6164 (2021)." href="/articles/s41593-022-01020-w#ref-CR56" id="ref-link-section-d20974544e3164">56</a></sup>. Data collection and analysis were not performed blind to the conditions of the experiments. The experiments were not randomized. No data were excluded from the analyses. For comparisons between two groups, we used the permutation <i>t</i>-test statistic, and for comparisons between more than two groups, we used a parametric one-way ANOVA. For statistical thresholding, permutation tests were conducted to generate a null distribution estimated from 1,000 runs on data with scrambled labels, which avoids the assumption of normality when evaluating significance.</p><h3 class="c-article__sub-heading" id="Sec42">Reporting Summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="/articles/s41593-022-01020-w#MOESM2">Nature Research Reporting Summary</a> linked to this article.</p></div></div></section>
                </div>
            

            <div>
                <section data-title="Data availability"><div class="c-article-section" id="data-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability">Data availability</h2><div class="c-article-section__content" id="data-availability-content">
              
              <p>The data (in NWB format) that supports the key findings of this study are publicly available on the DANDI archive (<a href="https://doi.org/10.48324/dandi.000207/0.220216.0323">https://doi.org/10.48324/dandi.000207/0.220216.0323</a>).</p>
            </div></div></section><section data-title="Code availability"><div class="c-article-section" id="code-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="code-availability">Code availability</h2><div class="c-article-section__content" id="code-availability-content">
              
              <p>Codes that support the key findings of this study are publicly available on GitHub (<a href="https://github.com/rutishauserlab/cogboundary-zheng">https://github.com/rutishauserlab/cogboundary-zheng</a>).</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Ezzyat, Y. &amp; Davachi, L. What constitutes an episode in episodic memory? <i>Psychol. Sci.</i> <b>22</b>, 243–252 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0956797610393742" data-track-action="article reference" href="https://doi.org/10.1177%2F0956797610393742" aria-label="Article reference 1" data-doi="10.1177/0956797610393742">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21178116" aria-label="PubMed reference 1">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20constitutes%20an%20episode%20in%20episodic%20memory%3F&amp;journal=Psychol.%20Sci.&amp;doi=10.1177%2F0956797610393742&amp;volume=22&amp;pages=243-252&amp;publication_year=2011&amp;author=Ezzyat%2CY&amp;author=Davachi%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Tulving, E. Episodic memory: from mind to brain. <i>Annu. Rev. Psychol.</i> <b>53</b>, 1–25 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.psych.53.100901.135114" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.psych.53.100901.135114" aria-label="Article reference 2" data-doi="10.1146/annurev.psych.53.100901.135114">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11752477" aria-label="PubMed reference 2">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Episodic%20memory%3A%20from%20mind%20to%20brain&amp;journal=Annu.%20Rev.%20Psychol.&amp;doi=10.1146%2Fannurev.psych.53.100901.135114&amp;volume=53&amp;pages=1-25&amp;publication_year=2002&amp;author=Tulving%2CE">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Radvansky, G. A. &amp; Zacks, J. M. <i>Event Cognition</i> (Oxford University Press, 2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Desimone, R. &amp; Duncan, J. Neural mechanisms of selective visual attention. <i>Annu. Rev. Neurosci.</i> <b>18</b>, 193–222 (1995).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.ne.18.030195.001205" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.ne.18.030195.001205" aria-label="Article reference 4" data-doi="10.1146/annurev.ne.18.030195.001205">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DyaK2MXktl2ltrk%3D" aria-label="CAS reference 4">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7605061" aria-label="PubMed reference 4">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20mechanisms%20of%20selective%20visual%20attention&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.ne.18.030195.001205&amp;volume=18&amp;pages=193-222&amp;publication_year=1995&amp;author=Desimone%2CR&amp;author=Duncan%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Zacks, J. M. et al. Human brain activity time-locked to perceptual event boundaries. <i>Nat. Neurosci.</i> <b>4</b>, 651–655 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/88486" data-track-action="article reference" href="https://doi.org/10.1038%2F88486" aria-label="Article reference 5" data-doi="10.1038/88486">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD3MXktFOqt74%3D" aria-label="CAS reference 5">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11369948" aria-label="PubMed reference 5">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20brain%20activity%20time-locked%20to%20perceptual%20event%20boundaries&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F88486&amp;volume=4&amp;pages=651-655&amp;publication_year=2001&amp;author=Zacks%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Avrahami, J. &amp; Kareev, Y. The emergence of events. <i>Cognition</i> <b>53</b>, 239–261 (1994).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0010-0277(94)90050-7" data-track-action="article reference" href="https://doi.org/10.1016%2F0010-0277%2894%2990050-7" aria-label="Article reference 6" data-doi="10.1016/0010-0277(94)90050-7">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DyaK2M7ksV2juw%3D%3D" aria-label="CAS reference 6">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7842635" aria-label="PubMed reference 6">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20emergence%20of%20events&amp;journal=Cognition&amp;doi=10.1016%2F0010-0277%2894%2990050-7&amp;volume=53&amp;pages=239-261&amp;publication_year=1994&amp;author=Avrahami%2CJ&amp;author=Kareev%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">DuBrow, S. &amp; Davachi, L. The influence of context boundaries on memory for the sequential order of events. <i>J. Exp. Psychol. Gen.</i> <b>142</b>, 1277–1286 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0034024" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0034024" aria-label="Article reference 7" data-doi="10.1037/a0034024">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23957281" aria-label="PubMed reference 7">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3902141" aria-label="PubMed Central reference 7">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20influence%20of%20context%20boundaries%20on%20memory%20for%20the%20sequential%20order%20of%20events&amp;journal=J.%20Exp.%20Psychol.%20Gen.&amp;doi=10.1037%2Fa0034024&amp;volume=142&amp;pages=1277-1286&amp;publication_year=2013&amp;author=DuBrow%2CS&amp;author=Davachi%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Chen, J. et al. Shared memories reveal shared structure in neural activity across individuals. <i>Nat. Neurosci.</i> <b>20</b>, 115–125 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4450" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4450" aria-label="Article reference 8" data-doi="10.1038/nn.4450">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC28XitVSrurbL" aria-label="CAS reference 8">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27918531" aria-label="PubMed reference 8">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Shared%20memories%20reveal%20shared%20structure%20in%20neural%20activity%20across%20individuals&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4450&amp;volume=20&amp;pages=115-125&amp;publication_year=2017&amp;author=Chen%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Kurby, C. A. &amp; Zacks, J. M. Segmentation in the perception and memory of events. <i>Trends Cogn. Sci.</i> <b>12</b>, 72–79 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2007.11.004" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2007.11.004" aria-label="Article reference 9" data-doi="10.1016/j.tics.2007.11.004">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18178125" aria-label="PubMed reference 9">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2263140" aria-label="PubMed Central reference 9">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Segmentation%20in%20the%20perception%20and%20memory%20of%20events&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2007.11.004&amp;volume=12&amp;pages=72-79&amp;publication_year=2008&amp;author=Kurby%2CCA&amp;author=Zacks%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Zacks, J. M., Speer, N. K., Swallow, K. M., Braver, T. S. &amp; Reynolds, J. R. Event perception: a mind–brain perspective. <i>Psychol. Bull.</i> <b>133</b>, 273–293 (2007).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0033-2909.133.2.273" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-2909.133.2.273" aria-label="Article reference 10" data-doi="10.1037/0033-2909.133.2.273">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17338600" aria-label="PubMed reference 10">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2852534" aria-label="PubMed Central reference 10">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Event%20perception%3A%20a%20mind%E2%80%93brain%20perspective&amp;journal=Psychol.%20Bull.&amp;doi=10.1037%2F0033-2909.133.2.273&amp;volume=133&amp;pages=273-293&amp;publication_year=2007&amp;author=Zacks%2CJM&amp;author=Speer%2CNK&amp;author=Swallow%2CKM&amp;author=Braver%2CTS&amp;author=Reynolds%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Jafarpour, A., Griffin, S., Lin, J. J. &amp; Knight, R. T. Medial orbitofrontal cortex, dorsolateral prefrontal cortex, and hippocampus differentially represent the event saliency. <i>J. Cogn. Neurosci.</i> <b>31</b>, 874–884 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/jocn_a_01392" data-track-action="article reference" href="https://doi.org/10.1162%2Fjocn_a_01392" aria-label="Article reference 11" data-doi="10.1162/jocn_a_01392">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30883290" aria-label="PubMed reference 11">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6941931" aria-label="PubMed Central reference 11">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Medial%20orbitofrontal%20cortex%2C%20dorsolateral%20prefrontal%20cortex%2C%20and%20hippocampus%20differentially%20represent%20the%20event%20saliency&amp;journal=J.%20Cogn.%20Neurosci.&amp;doi=10.1162%2Fjocn_a_01392&amp;volume=31&amp;pages=874-884&amp;publication_year=2019&amp;author=Jafarpour%2CA&amp;author=Griffin%2CS&amp;author=Lin%2CJJ&amp;author=Knight%2CRT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Ben-Yakov, A. &amp; Henson, R. N. The hippocampal film editor: sensitivity and specificity to event boundaries in continuous experience. <i>J. Neurosci.</i> <b>38</b>, 10057–10068 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.0524-18.2018" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.0524-18.2018" aria-label="Article reference 12" data-doi="10.1523/JNEUROSCI.0524-18.2018">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1MXjvFyksrs%3D" aria-label="CAS reference 12">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30301758" aria-label="PubMed reference 12">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6246887" aria-label="PubMed Central reference 12">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20hippocampal%20film%20editor%3A%20sensitivity%20and%20specificity%20to%20event%20boundaries%20in%20continuous%20experience&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.0524-18.2018&amp;volume=38&amp;pages=10057-10068&amp;publication_year=2018&amp;author=Ben-Yakov%2CA&amp;author=Henson%2CRN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Baldassano, C. et al. Discovering event structure in continuous narrative perception and memory. <i>Neuron</i> <b>95</b>, 709–721 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2017.06.041" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2017.06.041" aria-label="Article reference 13" data-doi="10.1016/j.neuron.2017.06.041">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXht1OiurzL" aria-label="CAS reference 13">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28772125" aria-label="PubMed reference 13">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5558154" aria-label="PubMed Central reference 13">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Discovering%20event%20structure%20in%20continuous%20narrative%20perception%20and%20memory&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2017.06.041&amp;volume=95&amp;pages=709-721&amp;publication_year=2017&amp;author=Baldassano%2CC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Spiers, H. J., Hayman, R. M., Jovalekic, A., Marozzi, E. &amp; Jeffery, K. J. Place field repetition and purely local remapping in a multicompartment environment. <i>Cereb. Cortex</i> <b>25</b>, 10–25 (2015).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bht198" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbht198" aria-label="Article reference 14" data-doi="10.1093/cercor/bht198">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23945240" aria-label="PubMed reference 14">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20field%20repetition%20and%20purely%20local%20remapping%20in%20a%20multicompartment%20environment&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbht198&amp;volume=25&amp;pages=10-25&amp;publication_year=2015&amp;author=Spiers%2CHJ&amp;author=Hayman%2CRM&amp;author=Jovalekic%2CA&amp;author=Marozzi%2CE&amp;author=Jeffery%2CKJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Derdikman, D. et al. Fragmentation of grid cell maps in a multicompartment environment. <i>Nat. Neurosci.</i> <b>12</b>, 1325–1332 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.2396" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.2396" aria-label="Article reference 15" data-doi="10.1038/nn.2396">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXhtFaju7zM" aria-label="CAS reference 15">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19749749" aria-label="PubMed reference 15">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Fragmentation%20of%20grid%20cell%20maps%20in%20a%20multicompartment%20environment&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.2396&amp;volume=12&amp;pages=1325-1332&amp;publication_year=2009&amp;author=Derdikman%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Lever, C., Burton, S., Jeewajee, A., O’Keefe, J. &amp; Burgess, N. Boundary vector cells in the subiculum of the hippocampal formation. <i>J. Neurosci.</i> <b>29</b>, 9771–9777 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1319-09.2009" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1319-09.2009" aria-label="Article reference 16" data-doi="10.1523/JNEUROSCI.1319-09.2009">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1MXpvFOmur4%3D" aria-label="CAS reference 16">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19657030" aria-label="PubMed reference 16">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2736390" aria-label="PubMed Central reference 16">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Boundary%20vector%20cells%20in%20the%20subiculum%20of%20the%20hippocampal%20formation&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1319-09.2009&amp;volume=29&amp;pages=9771-9777&amp;publication_year=2009&amp;author=Lever%2CC&amp;author=Burton%2CS&amp;author=Jeewajee%2CA&amp;author=O%E2%80%99Keefe%2CJ&amp;author=Burgess%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">O’Keefe, J. &amp; Burgess, N. Geometric determinants of the place fields of hippocampal neurons. <i>Nature</i> <b>381</b>, 425–428 (1996).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/381425a0" data-track-action="article reference" href="https://doi.org/10.1038%2F381425a0" aria-label="Article reference 17" data-doi="10.1038/381425a0">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8632799" aria-label="PubMed reference 17">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Geometric%20determinants%20of%20the%20place%20fields%20of%20hippocampal%20neurons&amp;journal=Nature&amp;doi=10.1038%2F381425a0&amp;volume=381&amp;pages=425-428&amp;publication_year=1996&amp;author=O%E2%80%99Keefe%2CJ&amp;author=Burgess%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Alme, C. B. et al. Place cells in the hippocampus: eleven maps for eleven rooms. <i>Proc. Natl Acad. Sci. USA</i> <b>111</b>, 18428–18435 (2014).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1421056111" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1421056111" aria-label="Article reference 18" data-doi="10.1073/pnas.1421056111">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2cXitVClu7jK" aria-label="CAS reference 18">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25489089" aria-label="PubMed reference 18">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4284589" aria-label="PubMed Central reference 18">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20cells%20in%20the%20hippocampus%3A%20eleven%20maps%20for%20eleven%20rooms&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1421056111&amp;volume=111&amp;pages=18428-18435&amp;publication_year=2014&amp;author=Alme%2CCB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Colgin, L. L., Moser, E. I. &amp; Moser, M. B. Understanding memory through hippocampal remapping. <i>Trends Neurosci.</i> <b>31</b>, 469–477 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tins.2008.06.008" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tins.2008.06.008" aria-label="Article reference 19" data-doi="10.1016/j.tins.2008.06.008">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXhtVKnurzE" aria-label="CAS reference 19">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18687478" aria-label="PubMed reference 19">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Understanding%20memory%20through%20hippocampal%20remapping&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2008.06.008&amp;volume=31&amp;pages=469-477&amp;publication_year=2008&amp;author=Colgin%2CLL&amp;author=Moser%2CEI&amp;author=Moser%2CMB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Grieves, R. M., Jenkins, B. W., Harland, B. C., Wood, E. R. &amp; Dudchenko, P. A. Place field repetition and spatial learning in a multicompartment environment. <i>Hippocampus</i> <b>26</b>, 118–134 (2016).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/hipo.22496" data-track-action="article reference" href="https://doi.org/10.1002%2Fhipo.22496" aria-label="Article reference 20" data-doi="10.1002/hipo.22496">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26190393" aria-label="PubMed reference 20">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20field%20repetition%20and%20spatial%20learning%20in%20a%20multicompartment%20environment&amp;journal=Hippocampus&amp;doi=10.1002%2Fhipo.22496&amp;volume=26&amp;pages=118-134&amp;publication_year=2016&amp;author=Grieves%2CRM&amp;author=Jenkins%2CBW&amp;author=Harland%2CBC&amp;author=Wood%2CER&amp;author=Dudchenko%2CPA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Sun, C., Yang, W., Martin, J. &amp; Tonegawa, S. Hippocampal neurons represent events as transferable units of experience. <i>Nat. Neurosci.</i> <b>23</b>, 651–663 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-020-0614-x" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-020-0614-x" aria-label="Article reference 21" data-doi="10.1038/s41593-020-0614-x">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3cXmsFShtro%3D" aria-label="CAS reference 21">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32251386" aria-label="PubMed reference 21">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Hippocampal%20neurons%20represent%20events%20as%20transferable%20units%20of%20experience&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-020-0614-x&amp;volume=23&amp;pages=651-663&amp;publication_year=2020&amp;author=Sun%2CC&amp;author=Yang%2CW&amp;author=Martin%2CJ&amp;author=Tonegawa%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Levine, B. et al. Episodic memory and the self in a case of isolated retrograde amnesia. <i>Brain</i> <b>121</b>, 1951–1973 (1998).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/brain/121.10.1951" data-track-action="article reference" href="https://doi.org/10.1093%2Fbrain%2F121.10.1951" aria-label="Article reference 22" data-doi="10.1093/brain/121.10.1951">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9798749" aria-label="PubMed reference 22">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Episodic%20memory%20and%20the%20self%20in%20a%20case%20of%20isolated%20retrograde%20amnesia&amp;journal=Brain&amp;doi=10.1093%2Fbrain%2F121.10.1951&amp;volume=121&amp;pages=1951-1973&amp;publication_year=1998&amp;author=Levine%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Rutishauser, U. Testing models of human declarative memory at the single-neuron level. <i>Trends Cogn. Sci.</i> <b>23</b>, 510–524 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2019.03.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2019.03.006" aria-label="Article reference 23" data-doi="10.1016/j.tics.2019.03.006">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31031021" aria-label="PubMed reference 23">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6637968" aria-label="PubMed Central reference 23">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Testing%20models%20of%20human%20declarative%20memory%20at%20the%20single-neuron%20level&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2019.03.006&amp;volume=23&amp;pages=510-524&amp;publication_year=2019&amp;author=Rutishauser%2CU">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Rutishauser, U., Ross, I. B., Mamelak, A. N. &amp; Schuman, E. M. Human memory strength is predicted by theta-frequency phase-locking of single neurons. <i>Nature</i> <b>464</b>, 903–907 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature08860" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature08860" aria-label="Article reference 24" data-doi="10.1038/nature08860">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3cXjvVShurw%3D" aria-label="CAS reference 24">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20336071" aria-label="PubMed reference 24">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20memory%20strength%20is%20predicted%20by%20theta-frequency%20phase-locking%20of%20single%20neurons&amp;journal=Nature&amp;doi=10.1038%2Fnature08860&amp;volume=464&amp;pages=903-907&amp;publication_year=2010&amp;author=Rutishauser%2CU&amp;author=Ross%2CIB&amp;author=Mamelak%2CAN&amp;author=Schuman%2CEM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Pacheco Estefan, D. et al. Coordinated representational reinstatement in the human hippocampus and lateral temporal cortex during episodic memory retrieval. <i>Nat. Commun.</i> <b>10</b>, 2255 (2019).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-019-09569-0" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-019-09569-0" aria-label="Article reference 25" data-doi="10.1038/s41467-019-09569-0">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BB3M7ot1OmsQ%3D%3D" aria-label="CAS reference 25">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31113952" aria-label="PubMed reference 25">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6529470" aria-label="PubMed Central reference 25">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Coordinated%20representational%20reinstatement%20in%20the%20human%20hippocampus%20and%20lateral%20temporal%20cortex%20during%20episodic%20memory%20retrieval&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-019-09569-0&amp;volume=10&amp;publication_year=2019&amp;author=Pacheco%20Estefan%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Manning, J. R., Polyn, S. M., Baltuch, G. H., Litt, B. &amp; Kahana, M. J. Oscillatory patterns in temporal lobe reveal context reinstatement during memory search. <i>Proc. Natl Acad. Sci. USA</i> <b>108</b>, 12893–12897 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1015174108" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1015174108" aria-label="Article reference 26" data-doi="10.1073/pnas.1015174108">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXhtVemsr7L" aria-label="CAS reference 26">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21737744" aria-label="PubMed reference 26">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3150951" aria-label="PubMed Central reference 26">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Oscillatory%20patterns%20in%20temporal%20lobe%20reveal%20context%20reinstatement%20during%20memory%20search&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1015174108&amp;volume=108&amp;pages=12893-12897&amp;publication_year=2011&amp;author=Manning%2CJR&amp;author=Polyn%2CSM&amp;author=Baltuch%2CGH&amp;author=Litt%2CB&amp;author=Kahana%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Folkerts, S., Rutishauser, U. &amp; Howard, M. W. Human episodic memory retrieval is accompanied by a neural contiguity effect. <i>J. Neurosci.</i> <b>38</b>, 4200–4211 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2312-17.2018" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2312-17.2018" aria-label="Article reference 27" data-doi="10.1523/JNEUROSCI.2312-17.2018">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXit1Gjt77J" aria-label="CAS reference 27">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29615486" aria-label="PubMed reference 27">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5963851" aria-label="PubMed Central reference 27">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20episodic%20memory%20retrieval%20is%20accompanied%20by%20a%20neural%20contiguity%20effect&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2312-17.2018&amp;volume=38&amp;pages=4200-4211&amp;publication_year=2018&amp;author=Folkerts%2CS&amp;author=Rutishauser%2CU&amp;author=Howard%2CMW">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Howard, M. W., Fotedar, M. S., Datey, A. V. &amp; Hasselmo, M. E. The temporal context model in spatial navigation and relational learning: toward a common explanation of medial temporal lobe function across domains. <i>Psychol. Rev.</i> <b>112</b>, 75–116 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0033-295X.112.1.75" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.112.1.75" aria-label="Article reference 28" data-doi="10.1037/0033-295X.112.1.75">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15631589" aria-label="PubMed reference 28">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1421376" aria-label="PubMed Central reference 28">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20temporal%20context%20model%20in%20spatial%20navigation%20and%20relational%20learning%3A%20toward%20a%20common%20explanation%20of%20medial%20temporal%20lobe%20function%20across%20domains&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.112.1.75&amp;volume=112&amp;pages=75-116&amp;publication_year=2005&amp;author=Howard%2CMW&amp;author=Fotedar%2CMS&amp;author=Datey%2CAV&amp;author=Hasselmo%2CME">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Swallow, K. M., Zacks, J. M. &amp; Abrams, R. A. Event boundaries in perception affect memory encoding and updating. <i>J. Exp. Psychol. Gen.</i> <b>138</b>, 236–257 (2009).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0015631" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0015631" aria-label="Article reference 29" data-doi="10.1037/a0015631">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19397382" aria-label="PubMed reference 29">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2819197" aria-label="PubMed Central reference 29">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Event%20boundaries%20in%20perception%20affect%20memory%20encoding%20and%20updating&amp;journal=J.%20Exp.%20Psychol.%20Gen.&amp;doi=10.1037%2Fa0015631&amp;volume=138&amp;pages=236-257&amp;publication_year=2009&amp;author=Swallow%2CKM&amp;author=Zacks%2CJM&amp;author=Abrams%2CRA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Richmond, L. L., Gold, D. A. &amp; Zacks, J. M. Event perception: translations and applications. <i>J. Appl. Res. Mem. Cogn.</i> <b>6</b>, 111–120 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jarmac.2016.11.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jarmac.2016.11.002" aria-label="Article reference 30" data-doi="10.1016/j.jarmac.2016.11.002">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28936393" aria-label="PubMed reference 30">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5602591" aria-label="PubMed Central reference 30">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Event%20perception%3A%20translations%20and%20applications&amp;journal=J.%20Appl.%20Res.%20Mem.%20Cogn.&amp;doi=10.1016%2Fj.jarmac.2016.11.002&amp;volume=6&amp;pages=111-120&amp;publication_year=2017&amp;author=Richmond%2CLL&amp;author=Gold%2CDA&amp;author=Zacks%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Ben-Yakov, A. &amp; Dudai, Y. Constructing realistic engrams: poststimulus activity of hippocampus and dorsal striatum predicts subsequent episodic memory. <i>J. Neurosci.</i> <b>31</b>, 9032–9042 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.0702-11.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.0702-11.2011" aria-label="Article reference 31" data-doi="10.1523/JNEUROSCI.0702-11.2011">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC3MXotVyjsLs%3D" aria-label="CAS reference 31">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21677186" aria-label="PubMed reference 31">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6622928" aria-label="PubMed Central reference 31">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Constructing%20realistic%20engrams%3A%20poststimulus%20activity%20of%20hippocampus%20and%20dorsal%20striatum%20predicts%20subsequent%20episodic%20memory&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.0702-11.2011&amp;volume=31&amp;pages=9032-9042&amp;publication_year=2011&amp;author=Ben-Yakov%2CA&amp;author=Dudai%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Ben-Yakov, A., Eshel, N. &amp; Dudai, Y. Hippocampal immediate poststimulus activity in the encoding of consecutive naturalistic episodes. <i>J. Exp. Psychol. Gen.</i> <b>142</b>, 1255–1263 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0033558" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0033558" aria-label="Article reference 32" data-doi="10.1037/a0033558">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23815458" aria-label="PubMed reference 32">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Hippocampal%20immediate%20poststimulus%20activity%20in%20the%20encoding%20of%20consecutive%20naturalistic%20episodes&amp;journal=J.%20Exp.%20Psychol.%20Gen.&amp;doi=10.1037%2Fa0033558&amp;volume=142&amp;pages=1255-1263&amp;publication_year=2013&amp;author=Ben-Yakov%2CA&amp;author=Eshel%2CN&amp;author=Dudai%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Isik, L., Singer, J., Madsen, J. R., Kanwisher, N. &amp; Kreiman, G. What is changing when: decoding visual information in movies from human intracranial recordings. <i>Neuroimage</i> <b>180</b>, 147–159 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2017.08.027" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2017.08.027" aria-label="Article reference 33" data-doi="10.1016/j.neuroimage.2017.08.027">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28823828" aria-label="PubMed reference 33">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20is%20changing%20when%3A%20decoding%20visual%20information%20in%20movies%20from%20human%20intracranial%20recordings&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2017.08.027&amp;volume=180&amp;pages=147-159&amp;publication_year=2018&amp;author=Isik%2CL&amp;author=Singer%2CJ&amp;author=Madsen%2CJR&amp;author=Kanwisher%2CN&amp;author=Kreiman%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Aminoff, E. M., Kveraga, K. &amp; Bar, M. The role of the parahippocampal cortex in cognition. <i>Trends Cogn. Sci.</i> <b>17</b>, 379–390 (2013).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2013.06.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2013.06.009" aria-label="Article reference 34" data-doi="10.1016/j.tics.2013.06.009">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23850264" aria-label="PubMed reference 34">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3786097" aria-label="PubMed Central reference 34">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20the%20parahippocampal%20cortex%20in%20cognition&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2013.06.009&amp;volume=17&amp;pages=379-390&amp;publication_year=2013&amp;author=Aminoff%2CEM&amp;author=Kveraga%2CK&amp;author=Bar%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Lisman, J. E. &amp; Grace, A. A. The hippocampal-VTA loop: controlling the entry of information into long-term memory. <i>Neuron</i> <b>46</b>, 703–713 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2005.05.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2005.05.002" aria-label="Article reference 35" data-doi="10.1016/j.neuron.2005.05.002">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD2MXlsV2iurs%3D" aria-label="CAS reference 35">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15924857" aria-label="PubMed reference 35">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20hippocampal-VTA%20loop%3A%20controlling%20the%20entry%20of%20information%20into%20long-term%20memory&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2005.05.002&amp;volume=46&amp;pages=703-713&amp;publication_year=2005&amp;author=Lisman%2CJE&amp;author=Grace%2CAA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Vinogradova, O. S. Hippocampus as comparator: role of the two input and two output systems of the hippocampus in selection and registration of information. <i>Hippocampus</i> <b>11</b>, 578–598 (2001).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/hipo.1073" data-track-action="article reference" href="https://doi.org/10.1002%2Fhipo.1073" aria-label="Article reference 36" data-doi="10.1002/hipo.1073">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3Mnos1agsQ%3D%3D" aria-label="CAS reference 36">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11732710" aria-label="PubMed reference 36">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Hippocampus%20as%20comparator%3A%20role%20of%20the%20two%20input%20and%20two%20output%20systems%20of%20the%20hippocampus%20in%20selection%20and%20registration%20of%20information&amp;journal=Hippocampus&amp;doi=10.1002%2Fhipo.1073&amp;volume=11&amp;pages=578-598&amp;publication_year=2001&amp;author=Vinogradova%2COS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Solstad, T., Boccara, C. N., Kropff, E., Moser, M. B. &amp; Moser, E. I. Representation of geometric borders in the entorhinal cortex. <i>Science</i> <b>322</b>, 1865–1868 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1166466" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1166466" aria-label="Article reference 37" data-doi="10.1126/science.1166466">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BD1cXhsFSmtrbJ" aria-label="CAS reference 37">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19095945" aria-label="PubMed reference 37">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Representation%20of%20geometric%20borders%20in%20the%20entorhinal%20cortex&amp;journal=Science&amp;doi=10.1126%2Fscience.1166466&amp;volume=322&amp;pages=1865-1868&amp;publication_year=2008&amp;author=Solstad%2CT&amp;author=Boccara%2CCN&amp;author=Kropff%2CE&amp;author=Moser%2CMB&amp;author=Moser%2CEI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Xiao, X. et al. Transformed neural pattern reinstatement during episodic memory retrieval. <i>J. Neurosci.</i> <b>37</b>, 2986–2998 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.2324-16.2017" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.2324-16.2017" aria-label="Article reference 38" data-doi="10.1523/JNEUROSCI.2324-16.2017">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXhvFCgsL3E" aria-label="CAS reference 38">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28202612" aria-label="PubMed reference 38">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6596730" aria-label="PubMed Central reference 38">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Transformed%20neural%20pattern%20reinstatement%20during%20episodic%20memory%20retrieval&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.2324-16.2017&amp;volume=37&amp;pages=2986-2998&amp;publication_year=2017&amp;author=Xiao%2CX">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Favila, S. E., Samide, R., Sweigart, S. C. &amp; Kuhl, B. A. Parietal representations of stimulus features are amplified during memory retrieval and flexibly aligned with top–down goals. <i>J. Neurosci.</i> <b>38</b>, 7809–7821 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.0564-18.2018" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.0564-18.2018" aria-label="Article reference 39" data-doi="10.1523/JNEUROSCI.0564-18.2018">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC1cXit1Kktb%2FJ" aria-label="CAS reference 39">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30054390" aria-label="PubMed reference 39">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6125807" aria-label="PubMed Central reference 39">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Parietal%20representations%20of%20stimulus%20features%20are%20amplified%20during%20memory%20retrieval%20and%20flexibly%20aligned%20with%20top%E2%80%93down%20goals&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.0564-18.2018&amp;volume=38&amp;pages=7809-7821&amp;publication_year=2018&amp;author=Favila%2CSE&amp;author=Samide%2CR&amp;author=Sweigart%2CSC&amp;author=Kuhl%2CBA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Jang, A. I., Wittig, J. H. Jr., Inati, S. K. &amp; Zaghloul, K. A. Human cortical neurons in the anterior temporal lobe reinstate spiking activity during verbal memory retrieval. <i>Curr. Biol.</i> <b>27</b>, 1700–1705 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cub.2017.05.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cub.2017.05.014" aria-label="Article reference 40" data-doi="10.1016/j.cub.2017.05.014">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXos1Sqtbs%3D" aria-label="CAS reference 40">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28552361" aria-label="PubMed reference 40">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5508588" aria-label="PubMed Central reference 40">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20cortical%20neurons%20in%20the%20anterior%20temporal%20lobe%20reinstate%20spiking%20activity%20during%20verbal%20memory%20retrieval&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2017.05.014&amp;volume=27&amp;pages=1700-1705&amp;publication_year=2017&amp;author=Jang%2CAI&amp;author=Wittig%2CJH&amp;author=Inati%2CSK&amp;author=Zaghloul%2CKA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Howard, M. W. &amp; Natu, V. S. Place from time: reconstructing position from a distributed representation of temporal context. <i>Neural Netw.</i> <b>18</b>, 1150–1162 (2005).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neunet.2005.08.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neunet.2005.08.002" aria-label="Article reference 41" data-doi="10.1016/j.neunet.2005.08.002">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16198538" aria-label="PubMed reference 41">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1444898" aria-label="PubMed Central reference 41">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Place%20from%20time%3A%20reconstructing%20position%20from%20a%20distributed%20representation%20of%20temporal%20context&amp;journal=Neural%20Netw.&amp;doi=10.1016%2Fj.neunet.2005.08.002&amp;volume=18&amp;pages=1150-1162&amp;publication_year=2005&amp;author=Howard%2CMW&amp;author=Natu%2CVS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Polyn, S. M. &amp; Kahana, M. J. Memory search and the neural representation of context. <i>Trends Cogn. Sci.</i> <b>12</b>, 24–30 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2007.10.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2007.10.010" aria-label="Article reference 42" data-doi="10.1016/j.tics.2007.10.010">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18069046" aria-label="PubMed reference 42">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Memory%20search%20and%20the%20neural%20representation%20of%20context&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2007.10.010&amp;volume=12&amp;pages=24-30&amp;publication_year=2008&amp;author=Polyn%2CSM&amp;author=Kahana%2CMJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. in <i>NIPS’12: Proceedings of the 25th International Conference on Neural Information Processing Systems</i>, Vol. 1 (eds Bartlett, P., Pereira, F. C. N., Burges, C. J. C., Bottoue, L., &amp; Weinberger K. Q.) 1097–1105 (Morgan Kaufmann, 2012).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Rutishauser, U., Schuman, E. M. &amp; Mamelak, A. N. Online detection and sorting of extracellularly recorded action potentials in human medial temporal lobe recordings, in vivo. <i>J. Neurosci. Methods</i> <b>154</b>, 204–224 (2006).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jneumeth.2005.12.033" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jneumeth.2005.12.033" aria-label="Article reference 44" data-doi="10.1016/j.jneumeth.2005.12.033">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16488479" aria-label="PubMed reference 44">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Online%20detection%20and%20sorting%20of%20extracellularly%20recorded%20action%20potentials%20in%20human%20medial%20temporal%20lobe%20recordings%2C%20in%20vivo&amp;journal=J.%20Neurosci.%20Methods&amp;doi=10.1016%2Fj.jneumeth.2005.12.033&amp;volume=154&amp;pages=204-224&amp;publication_year=2006&amp;author=Rutishauser%2CU&amp;author=Schuman%2CEM&amp;author=Mamelak%2CAN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">Fried, I., Rutishauser, U., Cerf, M. &amp; Kreiman, G. <i>Single Neuron Studies of the Human Brain: Probing Cognition</i> (The MIT Press, 2014).</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Kaminski, J. et al. Persistently active neurons in human medial frontal and medial temporal lobe support working memory. <i>Nat. Neurosci.</i> <b>20</b>, 590–601 (2017).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4509" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4509" aria-label="Article reference 46" data-doi="10.1038/nn.4509">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BC2sXis1ylsbg%3D" aria-label="CAS reference 46">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28218914" aria-label="PubMed reference 46">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5374017" aria-label="PubMed Central reference 46">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Persistently%20active%20neurons%20in%20human%20medial%20frontal%20and%20medial%20temporal%20lobe%20support%20working%20memory&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4509&amp;volume=20&amp;pages=590-601&amp;publication_year=2017&amp;author=Kaminski%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Pouzat, C., Mazor, O. &amp; Laurent, G. Using noise signature to optimize spike-sorting and to assess neuronal classification quality. <i>J. Neurosci. Methods</i> <b>122</b>, 43–57 (2002).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0165-0270(02)00276-5" data-track-action="article reference" href="https://doi.org/10.1016%2FS0165-0270%2802%2900276-5" aria-label="Article reference 47" data-doi="10.1016/S0165-0270(02)00276-5">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12535763" aria-label="PubMed reference 47">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20noise%20signature%20to%20optimize%20spike-sorting%20and%20to%20assess%20neuronal%20classification%20quality&amp;journal=J.%20Neurosci.%20Methods&amp;doi=10.1016%2FS0165-0270%2802%2900276-5&amp;volume=122&amp;pages=43-57&amp;publication_year=2002&amp;author=Pouzat%2CC&amp;author=Mazor%2CO&amp;author=Laurent%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Harris, K. D., Henze, D. A., Csicsvari, J., Hirase, H. &amp; Buzsaki, G. Accuracy of tetrode spike separation as determined by simultaneous intracellular and extracellular measurements. <i>J. Neurophysiol.</i> <b>84</b>, 401–414 (2000).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.2000.84.1.401" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.2000.84.1.401" aria-label="Article reference 48" data-doi="10.1152/jn.2000.84.1.401">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:STN:280:DC%2BD3cvitFCjsg%3D%3D" aria-label="CAS reference 48">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10899214" aria-label="PubMed reference 48">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Accuracy%20of%20tetrode%20spike%20separation%20as%20determined%20by%20simultaneous%20intracellular%20and%20extracellular%20measurements&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.2000.84.1.401&amp;volume=84&amp;pages=401-414&amp;publication_year=2000&amp;author=Harris%2CKD&amp;author=Henze%2CDA&amp;author=Csicsvari%2CJ&amp;author=Hirase%2CH&amp;author=Buzsaki%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Reuter, M., Rosas, H. D. &amp; Fischl, B. Highly accurate inverse consistent registration: a robust approach. <i>Neuroimage</i> <b>53</b>, 1181–1196 (2010).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.07.020" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.07.020" aria-label="Article reference 49" data-doi="10.1016/j.neuroimage.2010.07.020">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20637289" aria-label="PubMed reference 49">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Highly%20accurate%20inverse%20consistent%20registration%3A%20a%20robust%20approach&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.07.020&amp;volume=53&amp;pages=1181-1196&amp;publication_year=2010&amp;author=Reuter%2CM&amp;author=Rosas%2CHD&amp;author=Fischl%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">Pauli, W. M., Nili, A. N. &amp; Tyszka, J. M. A high-resolution probabilistic in vivo atlas of human subcortical brain nuclei. <i>Sci. Data</i> <b>5</b>, 180063 (2018).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/sdata.2018.63" data-track-action="article reference" href="https://doi.org/10.1038%2Fsdata.2018.63" aria-label="Article reference 50" data-doi="10.1038/sdata.2018.63">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29664465" aria-label="PubMed reference 50">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5903366" aria-label="PubMed Central reference 50">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20high-resolution%20probabilistic%20in%20vivo%20atlas%20of%20human%20subcortical%20brain%20nuclei&amp;journal=Sci.%20Data&amp;doi=10.1038%2Fsdata.2018.63&amp;volume=5&amp;publication_year=2018&amp;author=Pauli%2CWM&amp;author=Nili%2CAN&amp;author=Tyszka%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Avants, B. et al. Multivariate analysis of structural and diffusion imaging in traumatic brain injury. <i>Acad. Radiol.</i> <b>15</b>, 1360–1375 (2008).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.acra.2008.07.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.acra.2008.07.007" aria-label="Article reference 51" data-doi="10.1016/j.acra.2008.07.007">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18995188" aria-label="PubMed reference 51">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6372292" aria-label="PubMed Central reference 51">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Multivariate%20analysis%20of%20structural%20and%20diffusion%20imaging%20in%20traumatic%20brain%20injury&amp;journal=Acad.%20Radiol.&amp;doi=10.1016%2Fj.acra.2008.07.007&amp;volume=15&amp;pages=1360-1375&amp;publication_year=2008&amp;author=Avants%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Banaie Boroujeni, K., Tiesinga, P. &amp; Womelsdorf, T. Adaptive spike-artifact removal from local field potentials uncovers prominent beta and gamma band neuronal synchronization. <i>J. Neurosci. Methods</i> <b>330</b>, 108485 (2020).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jneumeth.2019.108485" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jneumeth.2019.108485" aria-label="Article reference 52" data-doi="10.1016/j.jneumeth.2019.108485">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31705936" aria-label="PubMed reference 52">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Adaptive%20spike-artifact%20removal%20from%20local%20field%20potentials%20uncovers%20prominent%20beta%20and%20gamma%20band%20neuronal%20synchronization&amp;journal=J.%20Neurosci.%20Methods&amp;doi=10.1016%2Fj.jneumeth.2019.108485&amp;volume=330&amp;publication_year=2020&amp;author=Banaie%20Boroujeni%2CK&amp;author=Tiesinga%2CP&amp;author=Womelsdorf%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Oostenveld, R., Fries, P., Maris, E. &amp; Schoffelen, J. M. FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data. <i>Comput Intell. Neurosci.</i> <b>2011</b>, 156869 (2011).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1155/2011/156869" data-track-action="article reference" href="https://doi.org/10.1155%2F2011%2F156869" aria-label="Article reference 53" data-doi="10.1155/2011/156869">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21253357" aria-label="PubMed reference 53">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=FieldTrip%3A%20open%20source%20software%20for%20advanced%20analysis%20of%20MEG%2C%20EEG%2C%20and%20invasive%20electrophysiological%20data&amp;journal=Comput%20Intell.%20Neurosci.&amp;doi=10.1155%2F2011%2F156869&amp;volume=2011&amp;publication_year=2011&amp;author=Oostenveld%2CR&amp;author=Fries%2CP&amp;author=Maris%2CE&amp;author=Schoffelen%2CJM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54."><p class="c-article-references__text" id="ref-CR54">Delorme, A. &amp; Makeig, S. EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. <i>J. Neurosci. Methods</i> <b>134</b>, 9–21 (2004).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jneumeth.2003.10.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jneumeth.2003.10.009" aria-label="Article reference 54" data-doi="10.1016/j.jneumeth.2003.10.009">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15102499" aria-label="PubMed reference 54">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=EEGLAB%3A%20an%20open%20source%20toolbox%20for%20analysis%20of%20single-trial%20EEG%20dynamics%20including%20independent%20component%20analysis&amp;journal=J.%20Neurosci.%20Methods&amp;doi=10.1016%2Fj.jneumeth.2003.10.009&amp;volume=134&amp;pages=9-21&amp;publication_year=2004&amp;author=Delorme%2CA&amp;author=Makeig%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55."><p class="c-article-references__text" id="ref-CR55">Kobak, D. et al. Demixed principal component analysis of neural population data. <i>eLife</i> <b>5</b>, e10989 (2016)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56."><p class="c-article-references__text" id="ref-CR56">Bausch, M. et al. Concept neurons in the human medial temporal lobe flexibly represent abstract relations between concepts. <i>Nat. Commun.</i> <b>12</b>, 6164 (2021).</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-021-26327-3" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-021-26327-3" aria-label="Article reference 56" data-doi="10.1038/s41467-021-26327-3">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="/articles/cas-redirect/1:CAS:528:DC%2BB3MXitlWmsbjE" aria-label="CAS reference 56">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34697305" aria-label="PubMed reference 56">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8545952" aria-label="PubMed Central reference 56">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Concept%20neurons%20in%20the%20human%20medial%20temporal%20lobe%20flexibly%20represent%20abstract%20relations%20between%20concepts&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-021-26327-3&amp;volume=12&amp;publication_year=2021&amp;author=Bausch%2CM">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-022-01020-w?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>We thank C. Katz and K. Patel for helping set up the recording system for single-unit recordings at Toronto Western Hospital, N. Chandravadia and V. Barkely for data transferring and organization, C. Reed, J. Chung and the clinical teams at both Cedars-Sinai Medical Center and Toronto Western Hospital and M. Zhang, J. Kaminski and other members of the Rutishauser and Kreiman labs for discussion. We are especially indebted to the volunteers who participated in this study. This work was supported by NIH U01NS103792 and U01NS117839 (to U.R.), NSF 1231216 (G.K.) and Brain Canada (to T.A.V.). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Department of Ophthalmology, Children’s Hospital, Harvard Medical School, Boston, MA, USA</p><p class="c-article-author-affiliation__authors-list">Jie Zheng &amp; Gabriel Kreiman</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Krembil Brain Institute and Division of Neurosurgery, University Health Network (UHN), University of Toronto, Toronto, Ontario, Canada</p><p class="c-article-author-affiliation__authors-list">Andrea G. P. Schjetnan, Suneil K. Kalia &amp; Taufik A. Valiante</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Department of Neurosurgery, Cedars-Sinai Medical Center, Los Angeles, CA, USA</p><p class="c-article-author-affiliation__authors-list">Mar Yebra, Bernard A. Gomes, Clayton P. Mosher, Adam N. Mamelak &amp; Ueli Rutishauser</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Department of Surgery (Neurosurgery), Institute of Biomedical Engineering, and Electrical and Computer Engineering, University of Toronto, Toronto, Ontario, Canada</p><p class="c-article-author-affiliation__authors-list">Taufik A. Valiante</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">Max Planck-University of Toronto Center for Neural Science and Technology, University of Toronto, Toronto, Ontario, Canada</p><p class="c-article-author-affiliation__authors-list">Taufik A. Valiante</p></li><li id="Aff6"><p class="c-article-author-affiliation__address">Center for Advancing Neurotechnological Innovation to Application, University Health Network, University of Toronto, Toronto, Ontario, Canada</p><p class="c-article-author-affiliation__authors-list">Taufik A. Valiante</p></li><li id="Aff7"><p class="c-article-author-affiliation__address">Center for Brains, Minds and Machines, Cambridge, MA, USA</p><p class="c-article-author-affiliation__authors-list">Gabriel Kreiman</p></li><li id="Aff8"><p class="c-article-author-affiliation__address">Department of Neurology, Cedars-Sinai Medical Center, Los Angeles, CA, USA</p><p class="c-article-author-affiliation__authors-list">Ueli Rutishauser</p></li><li id="Aff9"><p class="c-article-author-affiliation__address">Center for Neural Science and Medicine, Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, CA, USA</p><p class="c-article-author-affiliation__authors-list">Ueli Rutishauser</p></li><li id="Aff10"><p class="c-article-author-affiliation__address">Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, CA, USA</p><p class="c-article-author-affiliation__authors-list">Ueli Rutishauser</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Jie-Zheng-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Jie Zheng</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Jie%20Zheng" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jie%20Zheng" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jie%20Zheng%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Andrea_G__P_-Schjetnan-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Andrea G. P. Schjetnan</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Andrea%20G.%20P.%20Schjetnan" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Andrea%20G.%20P.%20Schjetnan" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Andrea%20G.%20P.%20Schjetnan%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Mar-Yebra-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Mar Yebra</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Mar%20Yebra" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Mar%20Yebra" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Mar%20Yebra%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Bernard_A_-Gomes-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Bernard A. Gomes</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Bernard%20A.%20Gomes" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Bernard%20A.%20Gomes" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Bernard%20A.%20Gomes%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Clayton_P_-Mosher-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Clayton P. Mosher</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Clayton%20P.%20Mosher" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Clayton%20P.%20Mosher" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Clayton%20P.%20Mosher%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Suneil_K_-Kalia-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Suneil K. Kalia</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Suneil%20K.%20Kalia" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Suneil%20K.%20Kalia" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Suneil%20K.%20Kalia%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Taufik_A_-Valiante-Aff2-Aff4-Aff5-Aff6"><span class="c-article-authors-search__title u-h3 js-search-name">Taufik A. Valiante</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Taufik%20A.%20Valiante" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Taufik%20A.%20Valiante" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Taufik%20A.%20Valiante%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Adam_N_-Mamelak-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Adam N. Mamelak</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Adam%20N.%20Mamelak" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Adam%20N.%20Mamelak" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Adam%20N.%20Mamelak%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Gabriel-Kreiman-Aff1-Aff7"><span class="c-article-authors-search__title u-h3 js-search-name">Gabriel Kreiman</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Gabriel%20Kreiman" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Gabriel%20Kreiman" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Gabriel%20Kreiman%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Ueli-Rutishauser-Aff3-Aff8-Aff9-Aff10"><span class="c-article-authors-search__title u-h3 js-search-name">Ueli Rutishauser</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?author=Ueli%20Rutishauser" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ueli%20Rutishauser" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ueli%20Rutishauser%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>J.Z. conceived the project. J.Z., G.K. and U.R. contributed ideas for experiments and analysis. S.K.K., T.A.V. and A.N.M. managed participants and surgeries. J.Z., A.G.P.S., M. Y. and C.P.M. collected data. J.Z. performed the analyses. B.A.G. performed electrode localization. B.A.G., J.Z. and U.R. and produced the Neurodata Without Borders (NWB) formatted dataset for public release. J.Z., G.K. and U.R. wrote the manuscript with input from all authors.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:gabriel.kreiman@childrens.harvard.edu">Gabriel Kreiman</a> or <a id="corresp-c2" href="mailto:ueli.rutishauser@cshs.org">Ueli Rutishauser</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
              
                <h3 class="c-article__sub-heading" id="FPar4">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div class="c-article-section" id="peer-review-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="peer-review">Peer review</h2><div class="c-article-section__content" id="peer-review-content">
              
              
                <h3 class="c-article__sub-heading" id="FPar3">Peer review information</h3>
                <p><i>Nature Neuroscience</i> thanks Christopher Baldassano and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Extended data"><div class="c-article-section" id="Sec44-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec44">Extended data</h2><div class="c-article-section__content" id="Sec44-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig7"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 1 electrode locations in mni co" href="/articles/s41593-022-01020-w/figures/7" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig7_ESM.jpg">Extended Data Fig. 1 Electrode locations in MNI coordinates, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a-c</b>, Each dot is the location of a microwire bundle in either the amygdala (cyan), hippocampus (yellow) or parahippocampus (red) on which at least one event or boundary cell was recorded, also presented in a template brain in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig1">1e</a>. Coordinates are in Montreal Neurological Institute (MNI) 152 space, here plotted on top of the CIT168 brain template for axial (<b>a</b>), coronal (<b>b</b>), and sagittal (<b>c</b>) view (see Methods).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig8"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 2 participants’ performance in " href="/articles/s41593-022-01020-w/figures/8" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig8_ESM.jpg">Extended Data Fig. 2 Participants’ performance in the scene recognition task did not differ significantly across different boundary types, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig2">2</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a-c</b>, Behavior quantified by accuracy (<b>a</b>), reaction time (<b>b</b>), and confidence level (<b>c</b>) across all trials. Results are shown for boundary type NB (green), SB (blue), and HB (red) during the scene recognition task. The horizontal dashed lines in (<b>a</b>) show chance levels (0.5) and in (<b>c</b>) show the maximum possible confidence value (3 = high confidence). Each dot represents one recording session. Black lines in (<b>a</b>-<b>c</b>) denote the mean results averaged across all recording sessions. One-way ANOVA between NB/SB/HB, degrees of freedom = (2, 57).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig9"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 3 boundary cells and event cell" href="/articles/s41593-022-01020-w/figures/9" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig9_ESM.jpg">Extended Data Fig. 3 Boundary cells and event cells do not respond to clip onsets and clip offsets during encoding, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a</b>, Responses during the encoding stage from the same example boundary cells shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3a,b</a> aligned to the clip onsets. <b>b</b>, Firing rates of all 42 boundary cells (solid and dashed arrows denote the examples in <b>a</b>) during the encoding stage aligned to the clip onsets, averaged over trials within each boundary type and normalized to each neuron’s maximum firing rate throughout the entire task (see color scale on bottom). <b>c</b>, Responses during the encoding stage from the same example boundary cells shown in (<b>a</b>) aligned to the clip offsets. <b>d</b>, Firing rates of all 42 boundary cells during the encoding stage aligned to the clip offsets using the same format as (<b>b</b>). <b>e</b>, Responses during the encoding stage from the same example event cells shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3e,f</a> aligned to the clip onsets. <b>f</b>, Firing rates of all 36 event cells (solid and dashed arrows denote the examples in <b>e</b>) during the encoding stage aligned to clip onsets, using the same format as (<b>b</b>). <b>g</b>, Responses during the encoding stage from the same example event cells shown in € aligned to the clip offsets. <b>h</b>, Firing rates of all 36 event cells during the encoding stage aligned to the clip offsets using the same format as (<b>b</b>). For (<b>a</b>), (<b>c</b>), (<b>e</b>), (<b>f</b>), Top: raster plot color coded for different boundary types (green: NB; blue: SB; red: HB). Bottom: Post-stimulus time histogram (bin size = 200 ms, step size = 2 ms, shaded areas represented ± s.e.m. across trials). (<b>b</b> and <b>f</b>) are copied from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3d,h</a> for comparison purposes.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig10"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 4 boundary cells and event cell" href="/articles/s41593-022-01020-w/figures/10" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig10_ESM.jpg">Extended Data Fig. 4 Boundary cells and event cells do not respond to image onsets and offsets during scene recognition and time discrimination, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a-b</b>, Responses during scene recognition from the same example boundary cells shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3a,b</a> aligned to stimulus onset. <b>c</b>, Firing rates of all 42 boundary cells (solid and dashed arrows denote the examples in <b>a</b> and <b>b</b>) during scene recognition aligned to the stimulus onsets, averaged over trials within each boundary type and normalized to each neuron’s maximum firing rate throughout the entire task (see color scale on bottom). <b>d-e</b>, Responses during time discrimination from the same example boundary cells shown in (<b>a</b> and <b>b</b>) aligned to stimulus onset. <b>f</b>, Firing rates of all 42 boundary cells during time discrimination aligned to the stimulus onset using the same format as in <b>c</b>. <b>g-h</b>, Responses during scene recognition from the same example event cells shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3e,f</a> aligned to stimulus onsets. <b>i</b>, Firing rates of all 36 event cells (solid and dashed arrows denote the examples in <b>g</b> and <b>h</b>) during scene recognition aligned to the stimulus onset, using the same format as in <b>a</b> and <b>b</b>. <b>j</b>, Responses during time discrimination from the same example event cells shown in <b>g</b> and <b>h</b> aligned to stimulus onset. <b>k</b>, Firing rates of all 36 event cells during time discrimination aligned to the stimulus onsets using the same format as in <b>f</b>. For (<b>a</b>), (<b>b</b>), (<b>d</b>), (<b>e</b>), (<b>g</b>), (<b>h</b>), (<b>j</b>), (<b>k</b>), Top: raster plot color coded for different boundary types (green: NB; blue: SB; red: HB). Bottom: Post-stimulus time histogram (bin size = 200 ms, step size = 2 ms, shaded areas represented ± s.e.m. across trials).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig11"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 5 neurons that respond to clip " href="/articles/s41593-022-01020-w/figures/11" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig11_ESM.jpg">Extended Data Fig. 5 Neurons that respond to clip onsets and clip offsets do not overlap with boundary and event cells, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig3">3</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a-b</b>, Responses during the encoding stage from an example clip onset-responsive cell located in the amygdala aligned to clip onsets (<b>a</b>), and boundaries (<b>b</b>). Top: raster plots. Bottom: Post-stimulus time histogram (bin size = 200 ms, step size = 2 ms, shaded areas represented ± s.e.m. across trials). A cell was considered as a clip onset cell if its firing rate differed significantly between a 1 s window immediate before and after clip onset (<i>p</i> &lt; 0.05, one-tailed permutation t-test). <b>c-d</b>, Responses during the encoding stage from an example clip offset-responsive cell located in the hippocampus aligned to clip offsets (<b>c</b>), and boundaries (<b>d</b>). A cell was considered as a clip offset cell if its firing rate differed significantly between a 1 s window immediate before and after clip offsets (<i>p</i> &lt; 0.05, one-tailed permutation t-test). Same format as (<b>a</b> and <b>b</b>). <b>e</b>, Seventy six out of 580 cells in the MTL qualified as clip onset-responsive cells and four out of 580 cells in the MTL qualified as clip offset-responsive cells. None of these were also selected as either boundary or event cells.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig12"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 6 responses of boundary cells d" href="/articles/s41593-022-01020-w/figures/12" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig12_ESM.jpg">Extended Data Fig. 6 Responses of boundary cells during encoding grouped by memory outcomes from the time discrimination task, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a</b><sub><b>1</b></sub><b>-a</b><sub><b>2</b></sub>, Response of the same example boundary cell in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4a</a> and Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4b</a>. During encoding, this cell responded to SB and HB transitions regardless of whether the temporal order of the clip was later correctly (<b>a</b><sub><b>1</b></sub>) or incorrectly (<b>a</b><sub><b>2</b></sub>) retrieved in the time discrimination test. Shaded areas represented ± s.e.m. across trials. <b>b</b><sub><b>1</b></sub><b>- b</b><sub><b>2</b></sub>, Left: timing of spikes from the same boundary cell shown in (<b>a</b><sub><b>1</b></sub> and <b>a</b><sub><b>2</b></sub>) relative to theta phase calculated from the local field potentials, for clips whose temporal order were later correctly (<b>b</b><sub><b>1</b></sub>) or incorrectly (<b>b</b><sub><b>2</b></sub>) retrieved. Right: phase distribution of spike times within [0, 1] seconds time windows following the middle of the clip (NB) or boundary (SB, HB) for clips whose temporal order were later correctly (<b>b</b><sub><b>1</b></sub>) or incorrectly (<b>b</b><sub><b>2</b></sub>) retrieved. <b>c-d</b>, Population summary for all 42 boundary cells. <b>c</b>, Z-scored firing rate (0–1 s after boundaries during encoding) for each boundary type did not differ between clips whose temporal orders were later correctly (color filled) vs. incorrectly (empty) retrieved. <b>d</b>, Mean resultant length (MRL) of spike times (relative to theta phases, 0–1 s after boundaries during encoding) across all boundary cells for each boundary type did not differ between clips whose temporal orders were later correctly (color filled) vs. incorrectly (empty) retrieved. Each dot represents one boundary cell. Black lines in <b>c</b> and <b>d</b> denote the mean results averaged across all boundary cells. One-tailed permutation t-test, degrees of freedom = (1, 82).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig13"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 7 responses of event cells duri" href="/articles/s41593-022-01020-w/figures/13" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig13_ESM.jpg">Extended Data Fig. 7 Responses of event cells during encoding grouped by memory outcomes from the scene recognition stage, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a</b><sub><b>1</b></sub>-<b>a</b><sub><b>2</b></sub>, Response of the same example event cell in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig4">4e,f</a>. During encoding, this cell responded to HB transitions regardless of whether frames were later correctly (<b>a</b><sub><b>1</b></sub>) or incorrectly (<b>a</b><sub><b>2</b></sub>) recognized in the scene recognition task. Shaded areas represented ± s.e.m. across trials. <b>b</b><sub><b>1</b></sub><b>-b</b><sub><b>2</b></sub>, Left: timing of spikes from the same event cell shown in <b>a</b><sub><b>1</b></sub><b>-a</b><sub><b>2</b></sub> relative to theta phase calculated from the local field potentials, for frames that were later correctly (<b>b</b><sub><b>1</b></sub>) or incorrectly (<b>b</b><sub><b>2</b></sub>) recognized. Right: phase distribution of spike times within [0, 1] seconds time windows following the middle of the clip (NB) or boundary (SB, HB) for frames that were later correctly (<b>b</b><sub><b>1</b></sub>) or incorrectly (<b>b</b><sub><b>2</b></sub>) recognized. <b>c-d</b>, Population summary for all 36 event cells. <b>c</b>, Z-scored firing rate (0–1 s after boundaries during encoding) for each boundary type did not differ between frames that were later correctly (color filled) vs. incorrectly (empty) recognized. <b>d</b>, Mean resultant length (MRL) of spike times (relative to theta phases, 0–1 s after boundaries during encoding) across all event cells for each boundary type did not differ between frames that were later correctly (color filled) vs. incorrectly (empty) recognized. Each dot represents one event cell. Black lines in <b>c</b> and <b>d</b> denote the mean results averaged across all event cells (<b>c</b>, <b>d</b>). One-tailed permutation t-test, degree of freedom = (1, 70).</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig14"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 8 neural state changes followin" href="/articles/s41593-022-01020-w/figures/14" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig14_ESM.jpg">Extended Data Fig. 8 Neural state changes following soft and hard boundaries shown for individual participants, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Multidimensional distance (MDD, see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig5">5d–g</a> for definition) as a function of time aligned to the middle of the clip (green: NB) and boundaries (blue: SB, red: HB). MDD is shown for all MTL cells within each participant (for example, ‘Sub1 in B1 E2 O32’ denotes MDD computed by 1 boundary cell, 2 event cells and 32 other MTL cells in participant 1). Shaded areas represent ± s.e.m. across trials.</p></div></div><div class="c-article-supplementary__item js-c-reading-companion-figures-item" data-test="supp-item" id="Fig15"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="extended data fig. 9 clip-onsets responsive neuron" href="/articles/s41593-022-01020-w/figures/15" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_Fig15_ESM.jpg">Extended Data Fig. 9 Clip-onsets responsive neurons respond to both correct and incorrect targets during scene recognition, Related to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/articles/s41593-022-01020-w#Fig6">6</a>.</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p><b>a-b</b>, Responses during scene recognition from an example clip onset-responsive cell (see definition in Extended Data Fig. 12) located in the amygdala aligned to image onsets in correctly recognized target (<b>a</b>) and forgotten target (<b>b</b>) trials. Top: raster plots. Bottom: Post-stimulus time histogram (bin size = 200 ms, step size = 2 ms, shaded areas represented ± s.e.m. across trials). <b>c</b>, Comparison (across all 76 identified clip-onsets responsive neurons) between mean firing rates averaged within [0 1.5]s after image onsets for remembered vs forgotten targets. On each box, the central mark indicates the mean results averaged across all clip-onsets responsive neurons, and the bottom and top edges of the box indicate the 25th and 75th percentiles, respectively. The whiskers extend to the most extreme data points not considered outliers, and the outliers are plotted individually using the ‘+‘ marker symbol. One-way ANOVA, degrees of freedom = (1, 150).</p></div></div></div></div></div></section><section data-title="Supplementary information"><div class="c-article-section" id="Sec45-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec45">Supplementary information</h2><div class="c-article-section__content" id="Sec45-content"><div data-test="supplementary-info"><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary information" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_MOESM1_ESM.pdf" data-supp-info-image="">Supplementary Information</a></h3><div class="c-article-supplementary__description" data-component="thumbnail-container"><p>Supplementary Figs. 1–13 and Tables 1–5.</p></div></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM2"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="reporting summary" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-022-01020-w/MediaObjects/41593_2022_1020_MOESM2_ESM.pdf" data-supp-info-image="">Reporting Summary</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Neurons%20detect%20cognitive%20boundaries%20to%20structure%20episodic%20memories%20in%20humans&amp;author=Jie%20Zheng%20et%20al&amp;contentID=10.1038%2Fs41593-022-01020-w&amp;copyright=The%20Author%28s%29%2C%20under%20exclusive%20licence%20to%20Springer%20Nature%20America%2C%20Inc.&amp;publication=1097-6256&amp;publicationDate=2022-03-07&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1038/s41593-022-01020-w" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41593-022-01020-w" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Zheng, J., Schjetnan, A.G.P., Yebra, M. <i>et al.</i> Neurons detect cognitive boundaries to structure episodic memories in humans.
                    <i>Nat Neurosci</i> <b>25</b>, 358–368 (2022). https://doi.org/10.1038/s41593-022-01020-w</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-022-01020-w?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2021-03-01">01 March 2021</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-01-19">19 January 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-03-07">07 March 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-03">March 2022</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1038/s41593-022-01020-w</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><div data-component="article-info-list"></div></div></div></div></div></section>
            </div>

            
        <section>
            <div class="c-article-section js-article-section" id="further-reading-section">
                <h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="further-reading">This article is cited by</h2>
                <div class="c-article-section__content js-collapsible-section" id="further-reading-content">
                    <ul class="c-article-further-reading__list" id="further-reading-list">
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Multimodal single-neuron, intracranial EEG, and fMRI brain responses during movie watching in human patients" href="https://doi.org/10.1038/s41597-024-03029-1">
                                        Multimodal single-neuron, intracranial EEG, and fMRI brain responses during movie watching in human patients
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Umit Keles</li><li>Julien Dubois</li><li>Ueli Rutishauser</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Data</i> (2024)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Hippocampal neurons code individual episodic memories in humans" href="https://doi.org/10.1038/s41562-023-01706-6">
                                        Hippocampal neurons code individual episodic memories in humans
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Luca D. Kolibius</li><li>Frederic Roux</li><li>Simon Hanslmayr</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Human Behaviour</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Aberrant neural processing of event boundaries in persons with Parkinson’s disease" href="https://doi.org/10.1038/s41598-023-36063-x">
                                        Aberrant neural processing of event boundaries in persons with Parkinson’s disease
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Michelle Wyrobnik</li><li>Elke van der Meer</li><li>Fabian Klostermann</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Scientific Reports</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:Semantic novelty modulates neural responses to visual change across the human brain" href="https://doi.org/10.1038/s41467-023-38576-5">
                                        Semantic novelty modulates neural responses to visual change across the human brain
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact c-author-list--truncated u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Maximilian Nentwich</li><li>Marcin Leszczynski</li><li>Lucas C. Parra</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Communications</i> (2023)</p>
                            </li>
                        
                            <li class="c-article-further-reading__item js-ref-item">
                            
                                <h3 class="c-article-further-reading__title">
                                    <a class="print-link" data-track="click" data-track-action="view further reading article"
                                       data-track-label="link:The human brain reactivates context-specific past information at event boundaries of naturalistic experiences" href="https://doi.org/10.1038/s41593-023-01331-6">
                                        The human brain reactivates context-specific past information at event boundaries of naturalistic experiences
                                    </a>
                                </h3>
                            
                                
                                    <ul data-test="author-list" class="c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto">
                                        <li>Avital Hahamy</li><li>Haim Dubossarsky</li><li>Timothy E. J. Behrens</li>
                                    </ul>
                                
                                <p class="c-article-further-reading__journal-title"><i>Nature Neuroscience</i> (2023)</p>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </section>
    

            
        </div>
</article>
</main>

<aside class="c-article-extras u-hide-print" aria-label="Article navigation" data-component-reading-companion data-container-type="reading-companion" data-track-component="reading companion">
    <div class="js-context-bar-sticky-point-desktop">
        

        
            <noscript>
                
<div class="c-nature-box c-nature-box--side " data-component="entitlement-box">
    
        
        <p class="c-nature-box__text js-text">You have full access to this article via your institution.</p>
        
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01020-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </noscript>
            <div class="c-nature-box__wrapper c-nature-box__wrapper--placeholder">
                <div class="c-nature-box c-nature-box--side u-display-none u-hide-print" aria-hidden="true" data-component="entitlement-box"
    id=entitlement-box-right-column
    
    >

    
        <p class="c-nature-box__text js-text u-display-none" aria-hidden="true"></p>
        
        
            
    
        <div class="c-pdf-download u-clear-both js-pdf-download">
            <a href="/articles/s41593-022-01020-w.pdf" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="download-pdf" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="link" data-track-external download>
                <span class="c-pdf-download__text">Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-download"/></svg>
            </a>
        </div>
    

        
    
</div>

            </div>
        
    </div>

    
        
    

    
    

    <div class="c-reading-companion">
        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu>
                    <div class="c-ad c-ad--300x250">
                        <div class="c-ad__inner">
                            <p class="c-ad__label">Advertisement</p>
                            
    <div id="div-gpt-ad-right-2"
         class="div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide"
         data-ad-type="right"
         data-test="right-ad"
         data-pa11y-ignore
         data-gpt
         data-gpt-unitpath="/285/neurosci.nature.com/article"
         data-gpt-sizes="300x250"
         data-gpt-targeting="type=article;pos=right;artid=s41593-022-01020-w;doi=10.1038/s41593-022-01020-w;subjmeta=1595,2167,2649,376,378,443,631;kwrd=Cognitive+neuroscience,Long-term+memory,Neurophysiology">
        <noscript>
            <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=293387958&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-022-01020-w%26doi%3D10.1038/s41593-022-01020-w%26subjmeta%3D1595,2167,2649,376,378,443,631%26kwrd%3DCognitive+neuroscience,Long-term+memory,Neurophysiology">
                <img data-test="gpt-advert-fallback-img"
                     src="//pubads.g.doubleclick.net/gampad/ad?iu=/285/neurosci.nature.com/article&amp;sz=300x250&amp;c=293387958&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41593-022-01020-w%26doi%3D10.1038/s41593-022-01020-w%26subjmeta%3D1595,2167,2649,376,378,443,631%26kwrd%3DCognitive+neuroscience,Long-term+memory,Neurophysiology"
                     alt="Advertisement"
                     width="300"
                     height="250"></a>
        </noscript>
    </div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
        </div>
    </div>
</aside>
</div>


    
        <nav class="c-header__dropdown" aria-labelledby="Explore-content" data-test="Explore-content" id="explore" data-track-component="nature-150-split-header">
            <div class="c-header__container">
                <h2 id="Explore-content" class="c-header__heading c-header__heading--js-hide">Explore content</h2>
                <ul class="c-header__list c-header__list--js-stack">
                    
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-articles"
                                   data-track="click"
                                   data-track-action="research articles"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Research articles
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-and-analysis"
                                   data-track="click"
                                   data-track-action="reviews &amp; analysis"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Reviews &amp; Analysis
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/news-and-comment"
                                   data-track="click"
                                   data-track-action="news &amp; comment"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    News &amp; Comment
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/video"
                                   data-track="click"
                                   data-track-action="videos"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Videos
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/current-issue"
                                   data-track="click"
                                   data-track-action="current issue"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Current issue
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/collections"
                                   data-track="click"
                                   data-track-action="collections"
                                   data-track-label="link"
                                   data-test="explore-nav-item">
                                    Collections
                                </a>
                            </li>
                        
                    
                </ul>
                <ul class="c-header__list c-header__list--js-stack">
                    
                    
                        <li class="c-header__item">
                            <a class="c-header__link"
                               href="https://twitter.com/natureneuro"
                               data-track="click"
                               data-track-action="twitter"
                               data-track-label="link">Follow us on Twitter
                            </a>
                        </li>
                    
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;6"
                               rel="nofollow"
                               data-track="click"
                               data-track-action="Sign up for alerts"
                               data-track-external
                               data-track-label="link (mobile dropdown)">Sign up for alerts<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill="#fff"/></svg>
                            </a>
                        </li>
                    
                    
                        <li class="c-header__item c-header__item--hide-lg">
                            <a class="c-header__link"
                               href="https://www.nature.com/neuro.rss"
                               data-track="click"
                               data-track-action="rss feed"
                               data-track-label="link">
                                <span>RSS feed</span>
                            </a>
                        </li>
                    
                </ul>
            </div>
        </nav>
    
    
        
            <nav class="c-header__dropdown" aria-labelledby="About-the-journal" id="about-the-journal" data-test="about-the-journal" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="About-the-journal" class="c-header__heading c-header__heading--js-hide">About the journal</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/aims"
                                   data-track="click"
                                   data-track-action="aims &amp; scope"
                                   data-track-label="link">
                                    Aims &amp; Scope
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-information"
                                   data-track="click"
                                   data-track-action="journal information"
                                   data-track-label="link">
                                    Journal Information
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/journal-impact"
                                   data-track="click"
                                   data-track-action="journal metrics"
                                   data-track-label="link">
                                    Journal Metrics
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editors"
                                   data-track="click"
                                   data-track-action="about the editors"
                                   data-track-label="link">
                                    About the Editors
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/our-publishing-models"
                                   data-track="click"
                                   data-track-action="our publishing models"
                                   data-track-label="link">
                                    Our publishing models
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-values-statement"
                                   data-track="click"
                                   data-track-action="editorial values statement"
                                   data-track-label="link">
                                    Editorial Values Statement
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/editorial-policies"
                                   data-track="click"
                                   data-track-action="editorial policies"
                                   data-track-label="link">
                                    Editorial Policies
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/content"
                                   data-track="click"
                                   data-track-action="content types"
                                   data-track-label="link">
                                    Content Types
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/web-feeds"
                                   data-track="click"
                                   data-track-action="web feeds"
                                   data-track-label="link">
                                    Web Feeds
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/posters"
                                   data-track="click"
                                   data-track-action="posters"
                                   data-track-label="link">
                                    Posters
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/contact"
                                   data-track="click"
                                   data-track-action="contact"
                                   data-track-label="link">
                                    Contact
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/research-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="research cross-journal editorial team"
                                   data-track-label="link">
                                    Research Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/reviews-cross-journal-editorial-team"
                                   data-track="click"
                                   data-track-action="reviews cross-journal editorial team"
                                   data-track-label="link">
                                    Reviews Cross-Journal Editorial Team
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        

        
            <nav class="c-header__dropdown" aria-labelledby="Publish-with-us-label" id="publish-with-us" data-test="publish-with-us" data-track-component="nature-150-split-header">
                <div class="c-header__container">
                    <h2 id="Publish-with-us-label" class="c-header__heading c-header__heading--js-hide">Publish with us</h2>
                    <ul class="c-header__list c-header__list--js-stack">
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/submission-guidelines"
                                   data-track="click"
                                   data-track-action="submission guidelines"
                                   data-track-label="link">
                                    Submission Guidelines
                                </a>
                            </li>
                        
                            <li class="c-header__item">
                                <a class="c-header__link"
                                   href="/neuro/for-reviewers"
                                   data-track="click"
                                   data-track-action="for reviewers"
                                   data-track-label="link">
                                    For Reviewers
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item">
                                <a class="c-header__link" data-test="nature-author-services"
                                   data-track="click"
                                   data-track-action="manuscript author services"
                                   data-track-label="link manuscript author services"
                                   href="https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022">
                                    Language editing services
                                </a>
                            </li>
                        
                        
                            <li class="c-header__item c-header__item--keyline">
                                <a class="c-header__link"
                                   href="https://mts-nn.nature.com/cgi-bin/main.plex?form_type&#x3D;home&amp;from_idp&#x3D;1"
                                   data-track="click"
                                   data-track-action="submit manuscript"
                                   data-track-label="link (publish with us dropdown menu)"
                                   data-track-external>Submit manuscript<svg role="img" aria-hidden="true" focusable="false" height="18" viewBox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill="#fff"/></svg>
                                </a>
                            </li>
                        
                    </ul>
                </div>
            </nav>
        
    


<div id="search-menu" class="c-header__dropdown c-header__dropdown--full-width" data-track-component="nature-150-split-header">
    <div class="c-header__container">
        <h2 class="c-header__visually-hidden">Search</h2>
        <form class="c-header__search-form" action="/search" method="get" role="search" autocomplete="off" data-test="inline-search">
            <label class="c-header__heading" for="keywords">Search articles by subject, keyword or author</label>
            <div class="c-header__search-layout c-header__search-layout--max-width">
                <div>
                    <input type="text" required="" class="c-header__input" id="keywords" name="q" value="">
                </div>
                <div class="c-header__search-layout">
                    <div>
                        <label for="results-from" class="c-header__visually-hidden">Show results from</label>
                        <select id="results-from" name="journal" class="c-header__select">
                            
                                
                                    <option value="" selected>All journals</option>
                                    <option value="neuro">This journal</option>
                                
                            
                        </select>
                    </div>
                    <div>
                        <button type="submit" class="c-header__search-button">Search</button>
                    </div>
                </div>

            </div>
        </form>

        <div class="c-header__flush">
            <a class="c-header__link" href="/search/advanced"
               data-track="click" data-track-action="advanced search" data-track-label="link">
                Advanced search
            </a>
        </div>

        <h3 class="c-header__heading c-header__heading--keyline">Quick links</h3>
        <ul class="c-header__list">
            <li><a class="c-header__link" href="/subjects" data-track="click" data-track-action="explore articles by subject" data-track-label="link">Explore articles by subject</a></li>
            <li><a class="c-header__link" href="/naturecareers" data-track="click" data-track-action="find a job" data-track-label="link">Find a job</a></li>
            <li><a class="c-header__link" href="/authors/index.html" data-track="click" data-track-action="guide to authors" data-track-label="link">Guide to authors</a></li>
            <li><a class="c-header__link" href="/authors/editorial_policies/" data-track="click" data-track-action="editorial policies" data-track-label="link">Editorial policies</a></li>
        </ul>
    </div>
</div>

<footer class="composite-layer" itemscope itemtype="http://schema.org/Periodical">
        <meta itemprop="publisher" content="Springer Nature">
        

        <div class="u-mt-16 u-mb-16">
    <div class="u-container">
        <div class="u-display-flex u-flex-wrap u-justify-content-space-between">
            

            <p class="c-meta u-ma-0 u-flex-shrink">
                <span class="c-meta__item">
                    Nature Neuroscience (<i>Nat Neurosci</i>)
                </span>
                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="onlineIssn">1546-1726</span> (online)
    </span>
    


                
    
    <span class="c-meta__item">
        <abbr title="International Standard Serial Number">ISSN</abbr> <span itemprop="printIssn">1097-6256</span> (print)
    </span>
    

            </p>
        </div>
    </div>
</div>

    <div class="c-footer">
        <div class="u-hide-print" data-track-component="footer">
    <h2 class="u-visually-hidden">nature.com sitemap</h2>
    <div class="c-footer__container">
        <div class="c-footer__grid c-footer__group--separator">
            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">About Nature Portfolio</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/company_info/index.html"
                                                  data-track="click" data-track-action="about us"
                                                  data-track-label="link">About us</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/npg_/press_room/press_releases.html"
                                                  data-track="click" data-track-action="press releases"
                                                  data-track-label="link">Press releases</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://press.nature.com/"
                                                  data-track="click" data-track-action="press office"
                                                  data-track-label="link">Press office</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://support.nature.com/support/home"
                                                  data-track="click" data-track-action="contact us"
                                                  data-track-label="link">Contact us</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Discover content</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/siteindex"
                                                  data-track="click" data-track-action="journals a-z"
                                                  data-track-label="link">Journals A-Z</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/subjects"
                                                  data-track="click" data-track-action="article by subject"
                                                  data-track-label="link">Articles by subject</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/protocolexchange/"
                                                  data-track="click" data-track-action="protocol exchange"
                                                  data-track-label="link">Protocol Exchange</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureindex.com/"
                                                  data-track="click" data-track-action="nature index"
                                                  data-track-label="link">Nature Index</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Publishing policies</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/authors/editorial_policies"
                                                  data-track="click" data-track-action="Nature portfolio policies"
                                                  data-track-label="link">Nature portfolio policies</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/nature-research/open-access"
                                                  data-track="click" data-track-action="open access"
                                                  data-track-label="link">Open access</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Author &amp; Researcher services</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/reprints"
                                                  data-track="click" data-track-action="reprints and permissions"
                                                  data-track-label="link">Reprints &amp; permissions</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/authors/research-data"
                                                  data-track="click" data-track-action="data research service"
                                                  data-track-label="link">Research data</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/language-editing/"
                                                  data-track="click" data-track-action="language editing"
                                                  data-track-label="link">Language editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://authorservices.springernature.com/scientific-editing/"
                                                  data-track="click" data-track-action="scientific editing"
                                                  data-track-label="link">Scientific editing</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://masterclasses.nature.com/"
                                                  data-track="click" data-track-action="nature masterclasses"
                                                  data-track-label="link">Nature Masterclasses</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://solutions.springernature.com/"
                                                  data-track="click" data-track-action="research solutions"
                                                  data-track-label="link">Research Solutions</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Libraries &amp; institutions</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/tools-services"
                                                  data-track="click" data-track-action="librarian service and tools"
                                                  data-track-label="link">Librarian service &amp; tools</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/manage-your-account/librarianportal"
                                                  data-track="click" data-track-action="librarian portal"
                                                  data-track-label="link">Librarian portal</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.nature.com/openresearch/about-open-access/information-for-institutions"
                                                  data-track="click" data-track-action="open research"
                                                  data-track-label="link">Open research</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://www.springernature.com/gp/librarians/recommend-to-your-library"
                                                  data-track="click" data-track-action="Recommend to library"
                                                  data-track-label="link">Recommend to library</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Advertising &amp; partnerships</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/digital-advertising/"
                                                  data-track="click" data-track-action="advertising"
                                                  data-track-label="link">Advertising</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://partnerships.nature.com/"
                                                  data-track="click" data-track-action="partnerships and services"
                                                  data-track-label="link">Partnerships &amp; Services</a></li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/media-kits/" data-track="click"
                                                  data-track-action="media kits" data-track-label="link">Media kits</a>
                    </li>
                    <li class="c-footer__item"><a class="c-footer__link"
                                                  href="https://partnerships.nature.com/product/branded-content-native-advertising/"
                                                  data-track-action="branded content" data-track-label="link">Branded
                        content</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Professional development</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/naturecareers/"
                                                  data-track="click" data-track-action="nature careers"
                                                  data-track-label="link">Nature Careers</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://conferences.nature.com"
                                                  data-track="click" data-track-action="nature conferences"
                                                  data-track-label="link">Nature<span class="u-visually-hidden"> </span>
                        Conferences</a></li>
                </ul>
            </div>

            <div class="c-footer__group">
                <h3 class="c-footer__heading u-mt-0">Regional websites</h3>
                <ul class="c-footer__list">
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natafrica"
                                                  data-track="click" data-track-action="nature africa"
                                                  data-track-label="link">Nature Africa</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="http://www.naturechina.com"
                                                  data-track="click" data-track-action="nature china"
                                                  data-track-label="link">Nature China</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nindia"
                                                  data-track="click" data-track-action="nature india"
                                                  data-track-label="link">Nature India</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/natitaly"
                                                  data-track="click" data-track-action="nature Italy"
                                                  data-track-label="link">Nature Italy</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ja-jp"
                                                  data-track="click" data-track-action="nature japan"
                                                  data-track-label="link">Nature Japan</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.natureasia.com/ko-kr"
                                                  data-track="click" data-track-action="nature korea"
                                                  data-track-label="link">Nature Korea</a></li>
                    <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/nmiddleeast"
                                                  data-track="click" data-track-action="nature middle east"
                                                  data-track-label="link">Nature Middle East</a></li>
                </ul>
            </div>

        </div>
    </div>
    <div class="c-footer__container">
        <ul class="c-footer__links">
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/privacy"
                                          data-track="click" data-track-action="privacy policy" data-track-label="link">Privacy
                Policy</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/cookies"
                                          data-track="click" data-track-action="use of cookies" data-track-label="link">Use
                of cookies</a></li>
            <li class="c-footer__item">
                <button class="optanon-toggle-display c-footer__link" onclick="javascript:;"
                        data-cc-action="preferences" data-track="click" data-track-action="manage cookies"
                        data-track-label="link">Your privacy choices/Manage cookies
                </button>
            </li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/legal-notice"
                                          data-track="click" data-track-action="legal notice" data-track-label="link">Legal
                notice</a></li>
            <li class="c-footer__item"><a class="c-footer__link"
                                          href="https://www.nature.com/info/accessibility-statement" data-track="click"
                                          data-track-action="accessibility statement" data-track-label="link">Accessibility
                statement</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.nature.com/info/terms-and-conditions"
                                          data-track="click" data-track-action="terms and conditions"
                                          data-track-label="link">Terms &amp; Conditions</a></li>
            <li class="c-footer__item"><a class="c-footer__link" href="https://www.springernature.com/ccpa"
                                          data-track="click" data-track-action="california privacy statement"
                                          data-track-label="link">Your US state privacy rights</a></li>
            
        </ul>
    </div>
</div>


        <div class="c-footer__container">
    <a href="https://www.springernature.com/" class="c-footer__link">
        <img src="/static/images/logos/sn-logo-white-ea63208b81.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
    </a>
    <p class="c-footer__legal" data-test="copyright">&copy; 2024 Springer Nature Limited</p>
</div>

    </div>
    <div class="u-visually-hidden" aria-hidden="true">
    
    <?xml version="1.0" encoding="UTF-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><symbol id="icon-access" viewBox="0 0 18 18"><path d="m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z" fill-rule="evenodd"/></symbol><symbol id="icon-account" viewBox="0 0 18 18"><path d="m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-alert" viewBox="0 0 18 18"><path d="m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-broad" viewBox="0 0 16 16"><path d="m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 14 15)"/></symbol><symbol id="icon-arrow-down" viewBox="0 0 16 16"><path d="m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-left" viewBox="0 0 16 16"><path d="m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-right" viewBox="0 0 16 16"><path d="m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-sub" viewBox="0 0 16 16"><path d="m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z" fill-rule="evenodd"/></symbol><symbol id="icon-arrow-up" viewBox="0 0 16 16"><path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/></symbol><symbol id="icon-article" viewBox="0 0 18 18"><path d="m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z" fill-rule="evenodd"/></symbol><symbol id="icon-audio" viewBox="0 0 18 18"><path d="m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z" fill-rule="evenodd"/></symbol><symbol id="icon-block" viewBox="0 0 24 24"><path d="m0 0h24v24h-24z" fill-rule="evenodd"/></symbol><symbol id="icon-book" viewBox="0 0 18 18"><path d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-broad" viewBox="0 0 24 24"><path d="m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z" fill-rule="evenodd" transform="matrix(-1 0 0 -1 20.182742 24.805206)"/></symbol><symbol id="icon-calendar" viewBox="0 0 18 18"><path d="m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z" fill-rule="evenodd"/></symbol><symbol id="icon-cart" viewBox="0 0 18 18"><path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z"/></symbol><symbol id="icon-chevron-less" viewBox="0 0 10 10"><path d="m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 -1 -1 0 9 9)"/></symbol><symbol id="icon-chevron-more" viewBox="0 0 10 10"><path d="m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-chevron-right" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-circle-fill" viewBox="0 0 16 16"><path d="m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-circle" viewBox="0 0 16 16"><path d="m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z" fill-rule="evenodd"/></symbol><symbol id="icon-citation" viewBox="0 0 18 18"><path d="m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-close" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-collections" viewBox="0 0 18 18"><path d="m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-compare" viewBox="0 0 18 18"><path d="m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z" fill-rule="evenodd"/></symbol><symbol id="icon-download-file" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z" fill-rule="evenodd"/></symbol><symbol id="icon-download" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-editors" viewBox="0 0 18 18"><path d="m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z" fill-rule="evenodd"/></symbol><symbol id="icon-email" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z" fill-rule="evenodd"/></symbol><symbol id="icon-error" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill-rule="evenodd"/></symbol><symbol id="icon-ethics" viewBox="0 0 18 18"><path d="m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z" fill-rule="evenodd"/></symbol><symbol id="icon-expand"><path d="M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z" fill-rule="evenodd"/></symbol><symbol id="icon-explore" viewBox="0 0 18 18"><path d="m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z" fill-rule="evenodd"/></symbol><symbol id="icon-filter" viewBox="0 0 16 16"><path d="m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z"/></symbol><symbol id="icon-home" viewBox="0 0 18 18"><path d="m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z" fill-rule="evenodd"/></symbol><symbol id="icon-image" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z" fill-rule="evenodd"/></symbol><symbol id="icon-info" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-institution" viewBox="0 0 18 18"><path d="m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z" fill-rule="evenodd"/></symbol><symbol id="icon-location" viewBox="0 0 18 18"><path d="m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z" fill-rule="evenodd"/></symbol><symbol id="icon-minus" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-newsletter" viewBox="0 0 18 18"><path d="m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z" fill-rule="evenodd"/></symbol><symbol id="icon-orcid" viewBox="0 0 18 18"><path d="m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z" fill-rule="evenodd"/></symbol><symbol id="icon-plus" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-print" viewBox="0 0 18 18"><path d="m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z" fill-rule="evenodd"/></symbol><symbol id="icon-search" viewBox="0 0 22 22"><path d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z" fill-rule="evenodd"/></symbol><symbol id="icon-social-facebook" viewBox="0 0 24 24"><path d="m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z" fill-rule="evenodd"/></symbol><symbol id="icon-social-twitter" viewBox="0 0 24 24"><path d="m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z" fill-rule="evenodd"/></symbol><symbol id="icon-social-youtube" viewBox="0 0 24 24"><path d="m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z" fill-rule="evenodd"/></symbol><symbol id="icon-subject-medicine" viewBox="0 0 18 18"><path d="m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z" fill-rule="evenodd"/></symbol><symbol id="icon-success" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z" fill-rule="evenodd"/></symbol><symbol id="icon-table" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z" fill-rule="evenodd"/></symbol><symbol id="icon-tick-circle" viewBox="0 0 24 24"><path d="m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z" fill-rule="evenodd"/></symbol><symbol id="icon-tick" viewBox="0 0 16 16"><path d="m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z" fill-rule="evenodd"/></symbol><symbol id="icon-update" viewBox="0 0 18 18"><path d="m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z" fill-rule="evenodd"/></symbol><symbol id="icon-upload" viewBox="0 0 18 18"><path d="m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z" fill-rule="evenodd"/></symbol><symbol id="icon-video" viewBox="0 0 18 18"><path d="m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z" fill-rule="evenodd"/></symbol><symbol id="icon-warning" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-checklist-banner" viewBox="0 0 56.69 56.69"><path style="fill:none" d="M0 0h56.69v56.69H0z"/><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/></symbol><symbol id="icon-chevron-down" viewBox="0 0 16 16"><path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path id="shape" fill-rule="evenodd" clip-rule="evenodd" d="M1 3.78571C1 2.75867 1.85698 2 2.8209 2H6.1791C7.14302 2 8 2.75867 8 3.78571V4H11.1668C11.885 4 12.5585 4.42017 12.8494 5.07033C12.9893 4.98169 13.1425 4.91101 13.3056 4.86206L16.5222 3.89704C17.4454 3.62005 18.4843 4.10046 18.7794 5.08419L22.9256 18.9042C23.2207 19.8878 22.618 20.8608 21.6947 21.1378L18.4781 22.1029C17.5548 22.3799 16.516 21.8993 16.2209 20.9157L13.0001 10.1804V20.2143C13.0001 21.255 12.1231 22 11.1668 22H7.83346C7.54206 22 7.25803 21.9308 7.00392 21.8052C6.75263 21.9305 6.47077 22 6.1791 22H2.8209C1.85693 22 1 21.2412 1 20.2143V3.78571ZM3 4V15H6V4H3ZM3 20V17H6V20H3ZM18.0749 20.1358L17.2129 17.2623L20.0863 16.4002L20.9484 19.2737L18.0749 20.1358ZM19.5116 14.4846L16.6381 15.3466L14.0519 6.72624L16.9254 5.86416L19.5116 14.4846ZM8.00012 20L8.00012 6H11.0001L11.0001 20H8.00012Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 10 10"><path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 16 16"><path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 16 16"><path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 16 16"><path d="m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 18 18"><path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 18 18"><path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/></symbol><symbol id="icon-expand-image" viewBox="0 0 18 18"><path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill-rule="evenodd"/></symbol><symbol id="icon-github" viewBox="0 0 100 100"><path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z"/></symbol><symbol id="icon-springer-arrow-left"><path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/></symbol><symbol id="icon-springer-arrow-right"><path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/></symbol><symbol id="icon-submit-open" viewBox="0 0 16 17"><path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/></symbol></svg>
</div>
</footer>




    

    

<div class="c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif "
data-component-id="nature-briefing-banner"
data-component-expirydays="30"
data-component-trigger-scroll-percentage="15"
data-track="in-view"
data-track-action="in-view"
data-track-category="nature briefing"
data-track-label="Briefing banner visible: Flagship">

    
    <div class="c-site-messages__banner-large">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__form-container">

            <div class="grid grid-12 last">
                <div class="grid grid-4">
                    <img alt="Nature Briefing" src="/static/images/logos/nature-briefing-logo-n150-white-d81c9da3ec.svg" width="250" height="40">
                    <p class="c-site-messages--nature-briefing__strapline extra-tight-line-height">Sign up for the <em>Nature Briefing</em> newsletter — what matters in science, free to your inbox daily.</p>
                </div>
                <div class="grid grid-8 last">
                    <form action="https://www.nature.com/briefing/briefing" method="post" data-location="banner" data-track="submit||nature_briefing_sign_up" data-track-action="transmit-form" data-track-category="nature briefing" data-track-label="Briefing banner submit: Flagship">
                        <input id="briefing-banner-signup-form-input-track-originReferralPoint" type="hidden" name="track_originReferralPoint" value="MainBriefingBanner">
                        <input id="briefing-banner-signup-form-input-track-formType" type="hidden" name="track_formType" value="DirectEmailBanner">

                        <input type="hidden" value="false" name="gdpr_tick" id="gdpr_tick">
                        <input type="hidden" value="false" name="marketing" id="marketing">
                        <input type="hidden" value="false" name="marketing_tick" id="marketing_tick">
                        <input type="hidden" value="MainBriefingBanner" name="brieferEntryPoint" id="brieferEntryPoint">

                        <label class="nature-briefing-banner__email-label" for="emailAddress">Email address</label>

                        <div class="nature-briefing-banner__email-wrapper">
                            <input class="nature-briefing-banner__email-input box-sizing text14" type="email" id="emailAddress" name="emailAddress" value="" placeholder="e.g. jo.smith@university.ac.uk" required data-test-element="briefing-emailbanner-email-input">
                            
                            <input type="hidden" value="true" name="N:nature_briefing_daily" id="defaultNewsletter">
                            <button type="submit" class="nature-briefing-banner__submit-button box-sizing text14" data-test-element="briefing-emailbanner-signup-button">Sign up</button>
                        </div>

                        <div class="nature-briefing-banner__checkbox-wrapper grid grid-12 last">
                            <input class="nature-briefing-banner__checkbox-checkbox" id="gdpr-briefing-banner-checkbox" type="checkbox" name="gdpr" value="true" data-test-element="briefing-emailbanner-gdpr-checkbox" required>
                            <label class="nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height" for="gdpr-briefing-banner-checkbox">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href="https://www.nature.com/info/privacy">Privacy Policy</a>.</label>
                        </div>
                    </form>
                </div>
            </div>

        </div>

    </div>

    
    <div class="c-site-messages__banner-small">

        
<div class="c-site-messages__close-container">
    <button class="c-site-messages__close"
        data-track="click"
        data-track-category="nature briefing"
        data-track-label="Briefing banner dismiss: Flagship">
        <svg width="25px" height="25px" focusable="false" aria-hidden="true" viewBox="0 0 25 25" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <title>Close banner</title>
            <defs></defs>
            <g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <rect opacity="0" x="0" y="0" width="25" height="25"></rect>
                <path d="M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z" fill="#ffffff"></path>
            </g>
        </svg>
        <span class="visually-hidden">Close</span>
    </button>
</div>


        <div class="c-site-messages__content text14">
            <span class="c-site-messages--nature-briefing__strapline strong">Get the most important science stories of the day, free in your inbox.</span>
            <a class="nature-briefing__link text14 sans-serif"
                data-track="click"
                data-track-category="nature briefing"
                data-track-label="Small-screen banner CTA to site"
                data-test-element="briefing-banner-link"
                target="_blank"
                rel="noreferrer noopener"
                href="https://www.nature.com/briefing/signup/?brieferEntryPoint=MainBriefingBanner">Sign up for Nature Briefing
            </a>
        </div>

    </div>

</div>






<noscript>
    <img hidden src="https://verify.nature.com/verify/nature.png" width="0" height="0" style="display: none" alt="">
</noscript>




<script src="//content.readcube.com/ping?doi=10.1038/s41593-022-01020-w&amp;format=js&amp;last_modified=2022-03-07" async></script>
<img src="/c4pwjb2k/article/s41593-022-01020-w" width="1" height="1" alt="" class="u-visually-hidden">
</body>
</html>